{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from keras import regularizers, optimizers, layers, models\n",
    "from IPython.display import display\n",
    "import os\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA PARAMETERS\n",
    "DATASET_NAME = os.path.join(\"..\", \"data\", \"creditcard.csv\")\n",
    "NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET = 400\n",
    "N_SPLITS = 5\n",
    "\n",
    "# NN PARAMETERS\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "NUMBER_OF_NEURONS = 1024\n",
    "REGULARIZATION_LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "dataset = pd.read_csv(DATASET_NAME)\n",
    "dataset = dataset.drop(['Time','Amount'],axis=1)\n",
    "\n",
    "NUMBER_OF_FEATURES = dataset.shape[1] - 1 # Minus 1 because of column: 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEXCAYAAACdwyIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBY+IiFjq/wEs5BITJe0CZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3ab87fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for all data\n",
    "count_classes = pd.value_counts(dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset on train_and_validation dataset and test dataset\n",
    "train_and_validation, test = train_test_split(dataset, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Convert test data to numpyarray and split them.\n",
    "test = test.values\n",
    "x_test = test[:,:-1]\n",
    "y_test = test[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create balanced, under sample train and validation dataset \n",
    "fraud_indices = np.array(train_and_validation[train_and_validation.Class == 1].index)\n",
    "normal_indices = np.array(train_and_validation[train_and_validation.Class == 0].index)\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indices, NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "under_sample_dataset = dataset.iloc[under_sample_indices,:]\n",
    "\n",
    "# Shuffle train and validation dataset\n",
    "under_sample_dataset = under_sample_dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgphYWIiJj6P0+koQ8tk9iMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3e836c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    400\n",
       "1    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for training and validation dataset\n",
    "count_classes = pd.value_counts(under_sample_dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert training and validation dataset to numpy array\n",
    "under_sample_dataset = under_sample_dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pot loss\n",
    "def show_loss(history):   \n",
    "    x_axis = range(0, EPOCHS)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, history.history['loss'], label='train_loss')\n",
    "    ax.plot(x_axis, history.history['val_loss'], label='val_loss')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Log loss')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.title('loss vs epoch number')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ROC(TPR_array, FPR_array):   \n",
    "    plt.title('ROC')\n",
    "    plt.plot(FPR_array, TPR_array, 'b')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 632 samples, validate on 159 samples\n",
      "Epoch 1/1000\n",
      "632/632 [==============================] - 0s - loss: 6.0616 - acc: 0.7801 - precision: 0.7697 - recall: 0.7973 - f1_score: 0.7706 - val_loss: 5.9090 - val_acc: 0.7925 - val_precision: 0.7462 - val_recall: 0.9170 - val_f1_score: 0.8194\n",
      "Epoch 2/1000\n",
      "632/632 [==============================] - 0s - loss: 5.9012 - acc: 0.8196 - precision: 0.7633 - recall: 0.9007 - f1_score: 0.8241 - val_loss: 5.8414 - val_acc: 0.8176 - val_precision: 0.7550 - val_recall: 0.9633 - val_f1_score: 0.8435\n",
      "Epoch 3/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8492 - acc: 0.8275 - precision: 0.7675 - recall: 0.9335 - f1_score: 0.8386 - val_loss: 5.7989 - val_acc: 0.8176 - val_precision: 0.7550 - val_recall: 0.9633 - val_f1_score: 0.8435\n",
      "Epoch 4/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8105 - acc: 0.8275 - precision: 0.7697 - recall: 0.9336 - f1_score: 0.8401 - val_loss: 5.7625 - val_acc: 0.8239 - val_precision: 0.7614 - val_recall: 0.9633 - val_f1_score: 0.8476\n",
      "Epoch 5/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7756 - acc: 0.8339 - precision: 0.7763 - recall: 0.9309 - f1_score: 0.8435 - val_loss: 5.7284 - val_acc: 0.8365 - val_precision: 0.7775 - val_recall: 0.9633 - val_f1_score: 0.8581\n",
      "Epoch 6/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7422 - acc: 0.8544 - precision: 0.7993 - recall: 0.9289 - f1_score: 0.8575 - val_loss: 5.6956 - val_acc: 0.8491 - val_precision: 0.7929 - val_recall: 0.9633 - val_f1_score: 0.8669\n",
      "Epoch 7/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7098 - acc: 0.8671 - precision: 0.8202 - recall: 0.9316 - f1_score: 0.8713 - val_loss: 5.6636 - val_acc: 0.8616 - val_precision: 0.8072 - val_recall: 0.9633 - val_f1_score: 0.8766\n",
      "Epoch 8/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6781 - acc: 0.8782 - precision: 0.8341 - recall: 0.9310 - f1_score: 0.8773 - val_loss: 5.6322 - val_acc: 0.8679 - val_precision: 0.8143 - val_recall: 0.9633 - val_f1_score: 0.8810\n",
      "Epoch 9/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6469 - acc: 0.8877 - precision: 0.8527 - recall: 0.9334 - f1_score: 0.8893 - val_loss: 5.6013 - val_acc: 0.8931 - val_precision: 0.8483 - val_recall: 0.9633 - val_f1_score: 0.9011\n",
      "Epoch 10/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6161 - acc: 0.8908 - precision: 0.8558 - recall: 0.9269 - f1_score: 0.8884 - val_loss: 5.5707 - val_acc: 0.8931 - val_precision: 0.8483 - val_recall: 0.9633 - val_f1_score: 0.9011\n",
      "Epoch 11/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5856 - acc: 0.8956 - precision: 0.8710 - recall: 0.9264 - f1_score: 0.8961 - val_loss: 5.5405 - val_acc: 0.9057 - val_precision: 0.8668 - val_recall: 0.9633 - val_f1_score: 0.9119\n",
      "Epoch 12/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5555 - acc: 0.8987 - precision: 0.8735 - recall: 0.9267 - f1_score: 0.8980 - val_loss: 5.5107 - val_acc: 0.9308 - val_precision: 0.9072 - val_recall: 0.9633 - val_f1_score: 0.9343\n",
      "Epoch 13/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5257 - acc: 0.9019 - precision: 0.8818 - recall: 0.9222 - f1_score: 0.8997 - val_loss: 5.4811 - val_acc: 0.9308 - val_precision: 0.9072 - val_recall: 0.9633 - val_f1_score: 0.9343\n",
      "Epoch 14/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4961 - acc: 0.9146 - precision: 0.9078 - recall: 0.9183 - f1_score: 0.9110 - val_loss: 5.4517 - val_acc: 0.9371 - val_precision: 0.9170 - val_recall: 0.9633 - val_f1_score: 0.9394\n",
      "Epoch 15/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4668 - acc: 0.9256 - precision: 0.9255 - recall: 0.9183 - f1_score: 0.9208 - val_loss: 5.4226 - val_acc: 0.9434 - val_precision: 0.9268 - val_recall: 0.9633 - val_f1_score: 0.9444\n",
      "Epoch 16/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4377 - acc: 0.9241 - precision: 0.9265 - recall: 0.9185 - f1_score: 0.9207 - val_loss: 5.3937 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 17/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4088 - acc: 0.9288 - precision: 0.9365 - recall: 0.9193 - f1_score: 0.9261 - val_loss: 5.3651 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 18/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3802 - acc: 0.9272 - precision: 0.9365 - recall: 0.9133 - f1_score: 0.9243 - val_loss: 5.3367 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 19/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3517 - acc: 0.9304 - precision: 0.9422 - recall: 0.9108 - f1_score: 0.9250 - val_loss: 5.3085 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 20/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3235 - acc: 0.9304 - precision: 0.9444 - recall: 0.9072 - f1_score: 0.9247 - val_loss: 5.2805 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 21/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2955 - acc: 0.9320 - precision: 0.9499 - recall: 0.9056 - f1_score: 0.9261 - val_loss: 5.2526 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 22/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2677 - acc: 0.9304 - precision: 0.9528 - recall: 0.9008 - f1_score: 0.9254 - val_loss: 5.2250 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 23/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2401 - acc: 0.9304 - precision: 0.9524 - recall: 0.9056 - f1_score: 0.9264 - val_loss: 5.1977 - val_acc: 0.9497 - val_precision: 0.9373 - val_recall: 0.9633 - val_f1_score: 0.9497\n",
      "Epoch 24/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2128 - acc: 0.9304 - precision: 0.9526 - recall: 0.9014 - f1_score: 0.9251 - val_loss: 5.1705 - val_acc: 0.9623 - val_precision: 0.9633 - val_recall: 0.9633 - val_f1_score: 0.9633\n",
      "Epoch 25/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1856 - acc: 0.9304 - precision: 0.9523 - recall: 0.9053 - f1_score: 0.9254 - val_loss: 5.1434 - val_acc: 0.9623 - val_precision: 0.9633 - val_recall: 0.9633 - val_f1_score: 0.9633\n",
      "Epoch 26/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1585 - acc: 0.9304 - precision: 0.9494 - recall: 0.9050 - f1_score: 0.9243 - val_loss: 5.1165 - val_acc: 0.9623 - val_precision: 0.9633 - val_recall: 0.9633 - val_f1_score: 0.9633\n",
      "Epoch 27/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1317 - acc: 0.9320 - precision: 0.9556 - recall: 0.9030 - f1_score: 0.9271 - val_loss: 5.0899 - val_acc: 0.9623 - val_precision: 0.9633 - val_recall: 0.9633 - val_f1_score: 0.9633\n",
      "Epoch 28/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1050 - acc: 0.9320 - precision: 0.9572 - recall: 0.9023 - f1_score: 0.9270 - val_loss: 5.0634 - val_acc: 0.9560 - val_precision: 0.9626 - val_recall: 0.9483 - val_f1_score: 0.9553\n",
      "Epoch 29/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0786 - acc: 0.9288 - precision: 0.9574 - recall: 0.8905 - f1_score: 0.9212 - val_loss: 5.0371 - val_acc: 0.9560 - val_precision: 0.9626 - val_recall: 0.9483 - val_f1_score: 0.9553\n",
      "Epoch 30/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0523 - acc: 0.9304 - precision: 0.9597 - recall: 0.8933 - f1_score: 0.9242 - val_loss: 5.0110 - val_acc: 0.9623 - val_precision: 0.9783 - val_recall: 0.9483 - val_f1_score: 0.9626\n",
      "Epoch 31/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0261 - acc: 0.9320 - precision: 0.9608 - recall: 0.8946 - f1_score: 0.9255 - val_loss: 4.9850 - val_acc: 0.9623 - val_precision: 0.9783 - val_recall: 0.9483 - val_f1_score: 0.9626\n",
      "Epoch 32/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0002 - acc: 0.9320 - precision: 0.9643 - recall: 0.8945 - f1_score: 0.9263 - val_loss: 4.9592 - val_acc: 0.9623 - val_precision: 0.9783 - val_recall: 0.9483 - val_f1_score: 0.9626\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.9744 - acc: 0.9320 - precision: 0.9643 - recall: 0.8955 - f1_score: 0.9276 - val_loss: 4.9336 - val_acc: 0.9623 - val_precision: 0.9783 - val_recall: 0.9483 - val_f1_score: 0.9626\n",
      "Epoch 34/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9487 - acc: 0.9320 - precision: 0.9631 - recall: 0.8923 - f1_score: 0.9245 - val_loss: 4.9081 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 35/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9233 - acc: 0.9320 - precision: 0.9618 - recall: 0.8908 - f1_score: 0.9237 - val_loss: 4.8828 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 36/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8980 - acc: 0.9335 - precision: 0.9684 - recall: 0.8932 - f1_score: 0.9283 - val_loss: 4.8576 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 37/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8728 - acc: 0.9351 - precision: 0.9720 - recall: 0.8900 - f1_score: 0.9259 - val_loss: 4.8326 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 38/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8479 - acc: 0.9367 - precision: 0.9763 - recall: 0.8911 - f1_score: 0.9297 - val_loss: 4.8078 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 39/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8231 - acc: 0.9367 - precision: 0.9746 - recall: 0.8939 - f1_score: 0.9301 - val_loss: 4.7831 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 40/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7984 - acc: 0.9351 - precision: 0.9768 - recall: 0.8902 - f1_score: 0.9302 - val_loss: 4.7586 - val_acc: 0.9560 - val_precision: 0.9779 - val_recall: 0.9379 - val_f1_score: 0.9571\n",
      "Epoch 41/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7739 - acc: 0.9351 - precision: 0.9762 - recall: 0.8892 - f1_score: 0.9301 - val_loss: 4.7342 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 42/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7495 - acc: 0.9335 - precision: 0.9764 - recall: 0.8865 - f1_score: 0.9281 - val_loss: 4.7100 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 43/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7253 - acc: 0.9335 - precision: 0.9764 - recall: 0.8878 - f1_score: 0.9292 - val_loss: 4.6859 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 44/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7013 - acc: 0.9335 - precision: 0.9737 - recall: 0.8886 - f1_score: 0.9281 - val_loss: 4.6620 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 45/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6774 - acc: 0.9320 - precision: 0.9765 - recall: 0.8829 - f1_score: 0.9264 - val_loss: 4.6382 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 46/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6536 - acc: 0.9335 - precision: 0.9787 - recall: 0.8827 - f1_score: 0.9266 - val_loss: 4.6145 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 47/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6300 - acc: 0.9335 - precision: 0.9777 - recall: 0.8837 - f1_score: 0.9270 - val_loss: 4.5910 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 48/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6065 - acc: 0.9335 - precision: 0.9780 - recall: 0.8837 - f1_score: 0.9277 - val_loss: 4.5677 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 49/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5832 - acc: 0.9335 - precision: 0.9789 - recall: 0.8794 - f1_score: 0.9246 - val_loss: 4.5445 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 50/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5600 - acc: 0.9335 - precision: 0.9773 - recall: 0.8843 - f1_score: 0.9276 - val_loss: 4.5214 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 51/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5369 - acc: 0.9335 - precision: 0.9787 - recall: 0.8828 - f1_score: 0.9273 - val_loss: 4.4984 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 52/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5140 - acc: 0.9335 - precision: 0.9754 - recall: 0.8812 - f1_score: 0.9248 - val_loss: 4.4756 - val_acc: 0.9497 - val_precision: 0.9775 - val_recall: 0.9274 - val_f1_score: 0.9514\n",
      "Epoch 53/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4912 - acc: 0.9335 - precision: 0.9762 - recall: 0.8822 - f1_score: 0.9261 - val_loss: 4.4529 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 54/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4685 - acc: 0.9335 - precision: 0.9773 - recall: 0.8851 - f1_score: 0.9279 - val_loss: 4.4304 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 55/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4460 - acc: 0.9335 - precision: 0.9782 - recall: 0.8813 - f1_score: 0.9258 - val_loss: 4.4079 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 56/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4236 - acc: 0.9320 - precision: 0.9769 - recall: 0.8771 - f1_score: 0.9233 - val_loss: 4.3857 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 57/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4014 - acc: 0.9320 - precision: 0.9755 - recall: 0.8812 - f1_score: 0.9244 - val_loss: 4.3635 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 58/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3792 - acc: 0.9320 - precision: 0.9781 - recall: 0.8796 - f1_score: 0.9242 - val_loss: 4.3415 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 59/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3572 - acc: 0.9320 - precision: 0.9799 - recall: 0.8810 - f1_score: 0.9269 - val_loss: 4.3196 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 60/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3354 - acc: 0.9304 - precision: 0.9769 - recall: 0.8719 - f1_score: 0.9197 - val_loss: 4.2978 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 61/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3136 - acc: 0.9304 - precision: 0.9767 - recall: 0.8783 - f1_score: 0.9234 - val_loss: 4.2761 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 62/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2920 - acc: 0.9304 - precision: 0.9798 - recall: 0.8793 - f1_score: 0.9247 - val_loss: 4.2546 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 63/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2705 - acc: 0.9304 - precision: 0.9764 - recall: 0.8767 - f1_score: 0.9231 - val_loss: 4.2332 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 64/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2491 - acc: 0.9304 - precision: 0.9785 - recall: 0.8767 - f1_score: 0.9234 - val_loss: 4.2120 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.2279 - acc: 0.9304 - precision: 0.9803 - recall: 0.8785 - f1_score: 0.9253 - val_loss: 4.1908 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 66/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2068 - acc: 0.9304 - precision: 0.9786 - recall: 0.8810 - f1_score: 0.9259 - val_loss: 4.1698 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 67/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1857 - acc: 0.9304 - precision: 0.9780 - recall: 0.8753 - f1_score: 0.9230 - val_loss: 4.1489 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 68/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1649 - acc: 0.9304 - precision: 0.9796 - recall: 0.8752 - f1_score: 0.9236 - val_loss: 4.1281 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 69/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1441 - acc: 0.9304 - precision: 0.9770 - recall: 0.8738 - f1_score: 0.9215 - val_loss: 4.1074 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 70/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1235 - acc: 0.9304 - precision: 0.9794 - recall: 0.8730 - f1_score: 0.9206 - val_loss: 4.0869 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 71/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1029 - acc: 0.9304 - precision: 0.9780 - recall: 0.8734 - f1_score: 0.9214 - val_loss: 4.0664 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 72/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0825 - acc: 0.9304 - precision: 0.9771 - recall: 0.8795 - f1_score: 0.9238 - val_loss: 4.0461 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 73/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0622 - acc: 0.9304 - precision: 0.9777 - recall: 0.8761 - f1_score: 0.9223 - val_loss: 4.0259 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 74/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0420 - acc: 0.9304 - precision: 0.9795 - recall: 0.8771 - f1_score: 0.9234 - val_loss: 4.0058 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 75/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0220 - acc: 0.9304 - precision: 0.9790 - recall: 0.8786 - f1_score: 0.9247 - val_loss: 3.9858 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 76/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0020 - acc: 0.9304 - precision: 0.9782 - recall: 0.8812 - f1_score: 0.9257 - val_loss: 3.9659 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 77/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 3.9930 - acc: 0.8800 - precision: 1.0000 - recall: 0.7931 - f1_score: 0.884 - 0s - loss: 3.9822 - acc: 0.9304 - precision: 0.9774 - recall: 0.8778 - f1_score: 0.9237 - val_loss: 3.9462 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 78/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9624 - acc: 0.9304 - precision: 0.9780 - recall: 0.8754 - f1_score: 0.9227 - val_loss: 3.9265 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 79/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9428 - acc: 0.9304 - precision: 0.9787 - recall: 0.8785 - f1_score: 0.9240 - val_loss: 3.9070 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 80/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9233 - acc: 0.9304 - precision: 0.9763 - recall: 0.8744 - f1_score: 0.9217 - val_loss: 3.8875 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 81/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9039 - acc: 0.9304 - precision: 0.9784 - recall: 0.8792 - f1_score: 0.9250 - val_loss: 3.8682 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 82/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8846 - acc: 0.9304 - precision: 0.9774 - recall: 0.8770 - f1_score: 0.9229 - val_loss: 3.8490 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 83/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8654 - acc: 0.9304 - precision: 0.9783 - recall: 0.8785 - f1_score: 0.9247 - val_loss: 3.8299 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 84/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8463 - acc: 0.9304 - precision: 0.9778 - recall: 0.8753 - f1_score: 0.9220 - val_loss: 3.8109 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 85/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8274 - acc: 0.9304 - precision: 0.9817 - recall: 0.8754 - f1_score: 0.9232 - val_loss: 3.7920 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 86/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8085 - acc: 0.9304 - precision: 0.9781 - recall: 0.8781 - f1_score: 0.9239 - val_loss: 3.7732 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 87/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7897 - acc: 0.9304 - precision: 0.9788 - recall: 0.8773 - f1_score: 0.9233 - val_loss: 3.7545 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 88/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7710 - acc: 0.9304 - precision: 0.9796 - recall: 0.8780 - f1_score: 0.9250 - val_loss: 3.7359 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 89/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7525 - acc: 0.9304 - precision: 0.9792 - recall: 0.8774 - f1_score: 0.9248 - val_loss: 3.7174 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 90/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7340 - acc: 0.9304 - precision: 0.9788 - recall: 0.8731 - f1_score: 0.9217 - val_loss: 3.6991 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 91/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7157 - acc: 0.9304 - precision: 0.9787 - recall: 0.8738 - f1_score: 0.9206 - val_loss: 3.6808 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 92/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6974 - acc: 0.9304 - precision: 0.9801 - recall: 0.8762 - f1_score: 0.9229 - val_loss: 3.6626 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 93/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6793 - acc: 0.9304 - precision: 0.9771 - recall: 0.8780 - f1_score: 0.9240 - val_loss: 3.6445 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 94/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6612 - acc: 0.9304 - precision: 0.9798 - recall: 0.8757 - f1_score: 0.9242 - val_loss: 3.6265 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 95/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6432 - acc: 0.9304 - precision: 0.9785 - recall: 0.8749 - f1_score: 0.9221 - val_loss: 3.6086 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 96/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6254 - acc: 0.9304 - precision: 0.9803 - recall: 0.8798 - f1_score: 0.9259 - val_loss: 3.5908 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.6076 - acc: 0.9304 - precision: 0.9795 - recall: 0.8756 - f1_score: 0.9234 - val_loss: 3.5731 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 98/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5899 - acc: 0.9304 - precision: 0.9785 - recall: 0.8768 - f1_score: 0.9235 - val_loss: 3.5555 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 99/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5724 - acc: 0.9304 - precision: 0.9775 - recall: 0.8738 - f1_score: 0.9218 - val_loss: 3.5380 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 100/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5549 - acc: 0.9304 - precision: 0.9799 - recall: 0.8771 - f1_score: 0.9239 - val_loss: 3.5206 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 101/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5375 - acc: 0.9304 - precision: 0.9789 - recall: 0.8752 - f1_score: 0.9228 - val_loss: 3.5033 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 102/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5202 - acc: 0.9304 - precision: 0.9787 - recall: 0.8774 - f1_score: 0.9236 - val_loss: 3.4861 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 103/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5030 - acc: 0.9304 - precision: 0.9788 - recall: 0.8800 - f1_score: 0.9248 - val_loss: 3.4690 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 104/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4859 - acc: 0.9304 - precision: 0.9764 - recall: 0.8783 - f1_score: 0.9226 - val_loss: 3.4520 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 105/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4689 - acc: 0.9304 - precision: 0.9752 - recall: 0.8767 - f1_score: 0.9220 - val_loss: 3.4350 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 106/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4520 - acc: 0.9304 - precision: 0.9802 - recall: 0.8771 - f1_score: 0.9247 - val_loss: 3.4182 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 107/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4352 - acc: 0.9304 - precision: 0.9796 - recall: 0.8765 - f1_score: 0.9237 - val_loss: 3.4014 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 108/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4185 - acc: 0.9304 - precision: 0.9788 - recall: 0.8784 - f1_score: 0.9250 - val_loss: 3.3848 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 109/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4018 - acc: 0.9320 - precision: 0.9812 - recall: 0.8772 - f1_score: 0.9237 - val_loss: 3.3682 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 110/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3853 - acc: 0.9320 - precision: 0.9825 - recall: 0.8803 - f1_score: 0.9269 - val_loss: 3.3517 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 111/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3688 - acc: 0.9320 - precision: 0.9811 - recall: 0.8793 - f1_score: 0.9258 - val_loss: 3.3353 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 112/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3524 - acc: 0.9320 - precision: 0.9803 - recall: 0.8727 - f1_score: 0.9222 - val_loss: 3.3190 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 113/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3362 - acc: 0.9304 - precision: 0.9826 - recall: 0.8787 - f1_score: 0.9263 - val_loss: 3.3028 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 114/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3200 - acc: 0.9304 - precision: 0.9816 - recall: 0.8748 - f1_score: 0.9237 - val_loss: 3.2867 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 115/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3039 - acc: 0.9304 - precision: 0.9826 - recall: 0.8770 - f1_score: 0.9256 - val_loss: 3.2706 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 116/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2878 - acc: 0.9320 - precision: 0.9855 - recall: 0.8764 - f1_score: 0.9253 - val_loss: 3.2547 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 117/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2719 - acc: 0.9320 - precision: 0.9857 - recall: 0.8741 - f1_score: 0.9254 - val_loss: 3.2388 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 118/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2560 - acc: 0.9320 - precision: 0.9860 - recall: 0.8753 - f1_score: 0.9254 - val_loss: 3.2230 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 119/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2403 - acc: 0.9320 - precision: 0.9853 - recall: 0.8728 - f1_score: 0.9241 - val_loss: 3.2073 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 120/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2246 - acc: 0.9335 - precision: 0.9849 - recall: 0.8739 - f1_score: 0.9246 - val_loss: 3.1917 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 121/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2090 - acc: 0.9335 - precision: 0.9844 - recall: 0.8753 - f1_score: 0.9251 - val_loss: 3.1762 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 122/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1935 - acc: 0.9335 - precision: 0.9864 - recall: 0.8803 - f1_score: 0.9287 - val_loss: 3.1607 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 123/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1781 - acc: 0.9335 - precision: 0.9854 - recall: 0.8721 - f1_score: 0.9238 - val_loss: 3.1453 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 124/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1627 - acc: 0.9335 - precision: 0.9861 - recall: 0.8767 - f1_score: 0.9267 - val_loss: 3.1301 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 125/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1475 - acc: 0.9335 - precision: 0.9833 - recall: 0.8753 - f1_score: 0.9249 - val_loss: 3.1149 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 126/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1323 - acc: 0.9335 - precision: 0.9851 - recall: 0.8796 - f1_score: 0.9281 - val_loss: 3.0997 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 127/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1172 - acc: 0.9335 - precision: 0.9806 - recall: 0.8732 - f1_score: 0.9227 - val_loss: 3.0847 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 128/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1021 - acc: 0.9335 - precision: 0.9855 - recall: 0.8737 - f1_score: 0.9249 - val_loss: 3.0697 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.0872 - acc: 0.9335 - precision: 0.9851 - recall: 0.8733 - f1_score: 0.9232 - val_loss: 3.0549 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 130/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0723 - acc: 0.9335 - precision: 0.9864 - recall: 0.8772 - f1_score: 0.9274 - val_loss: 3.0401 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 131/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0575 - acc: 0.9335 - precision: 0.9863 - recall: 0.8783 - f1_score: 0.9266 - val_loss: 3.0254 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 132/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0428 - acc: 0.9335 - precision: 0.9819 - recall: 0.8718 - f1_score: 0.9227 - val_loss: 3.0107 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 133/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0282 - acc: 0.9320 - precision: 0.9862 - recall: 0.8765 - f1_score: 0.9271 - val_loss: 2.9961 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 134/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0137 - acc: 0.9320 - precision: 0.9854 - recall: 0.8740 - f1_score: 0.9241 - val_loss: 2.9817 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 135/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9992 - acc: 0.9320 - precision: 0.9856 - recall: 0.8703 - f1_score: 0.9235 - val_loss: 2.9672 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 136/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9848 - acc: 0.9335 - precision: 0.9864 - recall: 0.8781 - f1_score: 0.9278 - val_loss: 2.9529 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 137/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9705 - acc: 0.9320 - precision: 0.9826 - recall: 0.8735 - f1_score: 0.9234 - val_loss: 2.9387 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 138/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9562 - acc: 0.9335 - precision: 0.9833 - recall: 0.8722 - f1_score: 0.9228 - val_loss: 2.9245 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 139/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9421 - acc: 0.9335 - precision: 0.9871 - recall: 0.8755 - f1_score: 0.9265 - val_loss: 2.9104 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 140/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9280 - acc: 0.9351 - precision: 0.9901 - recall: 0.8769 - f1_score: 0.9290 - val_loss: 2.8963 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 141/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9140 - acc: 0.9351 - precision: 0.9888 - recall: 0.8787 - f1_score: 0.9277 - val_loss: 2.8824 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 142/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9000 - acc: 0.9351 - precision: 0.9886 - recall: 0.8796 - f1_score: 0.9293 - val_loss: 2.8685 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 143/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8862 - acc: 0.9351 - precision: 0.9889 - recall: 0.8790 - f1_score: 0.9290 - val_loss: 2.8547 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 144/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8724 - acc: 0.9351 - precision: 0.9903 - recall: 0.8753 - f1_score: 0.9269 - val_loss: 2.8410 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 145/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8587 - acc: 0.9351 - precision: 0.9909 - recall: 0.8756 - f1_score: 0.9278 - val_loss: 2.8273 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 146/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8450 - acc: 0.9351 - precision: 0.9885 - recall: 0.8765 - f1_score: 0.9285 - val_loss: 2.8137 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 147/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8314 - acc: 0.9351 - precision: 0.9884 - recall: 0.8850 - f1_score: 0.9319 - val_loss: 2.8002 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 148/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8179 - acc: 0.9351 - precision: 0.9900 - recall: 0.8795 - f1_score: 0.9295 - val_loss: 2.7868 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 149/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8045 - acc: 0.9351 - precision: 0.9888 - recall: 0.8805 - f1_score: 0.9310 - val_loss: 2.7734 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 150/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7911 - acc: 0.9351 - precision: 0.9898 - recall: 0.8775 - f1_score: 0.9288 - val_loss: 2.7601 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 151/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7779 - acc: 0.9351 - precision: 0.9888 - recall: 0.8775 - f1_score: 0.9287 - val_loss: 2.7469 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 152/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7646 - acc: 0.9351 - precision: 0.9894 - recall: 0.8811 - f1_score: 0.9305 - val_loss: 2.7337 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 153/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7515 - acc: 0.9351 - precision: 0.9879 - recall: 0.8746 - f1_score: 0.9272 - val_loss: 2.7206 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 154/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7384 - acc: 0.9351 - precision: 0.9901 - recall: 0.8705 - f1_score: 0.9233 - val_loss: 2.7076 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 155/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7254 - acc: 0.9351 - precision: 0.9897 - recall: 0.8781 - f1_score: 0.9290 - val_loss: 2.6946 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 156/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7124 - acc: 0.9351 - precision: 0.9905 - recall: 0.8805 - f1_score: 0.9314 - val_loss: 2.6817 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 157/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6996 - acc: 0.9351 - precision: 0.9884 - recall: 0.8762 - f1_score: 0.9279 - val_loss: 2.6689 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 158/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6868 - acc: 0.9351 - precision: 0.9875 - recall: 0.8775 - f1_score: 0.9279 - val_loss: 2.6562 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 159/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6740 - acc: 0.9351 - precision: 0.9883 - recall: 0.8756 - f1_score: 0.9278 - val_loss: 2.6435 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 160/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6614 - acc: 0.9351 - precision: 0.9885 - recall: 0.8726 - f1_score: 0.9255 - val_loss: 2.6309 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.6487 - acc: 0.9351 - precision: 0.9883 - recall: 0.8720 - f1_score: 0.9255 - val_loss: 2.6183 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 162/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6362 - acc: 0.9351 - precision: 0.9899 - recall: 0.8733 - f1_score: 0.9258 - val_loss: 2.6058 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 163/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6237 - acc: 0.9351 - precision: 0.9879 - recall: 0.8804 - f1_score: 0.9294 - val_loss: 2.5934 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 164/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6113 - acc: 0.9351 - precision: 0.9883 - recall: 0.8752 - f1_score: 0.9272 - val_loss: 2.5811 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 165/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5990 - acc: 0.9351 - precision: 0.9892 - recall: 0.8771 - f1_score: 0.9289 - val_loss: 2.5688 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 166/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5867 - acc: 0.9351 - precision: 0.9898 - recall: 0.8730 - f1_score: 0.9256 - val_loss: 2.5565 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 167/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5745 - acc: 0.9351 - precision: 0.9895 - recall: 0.8783 - f1_score: 0.9291 - val_loss: 2.5444 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 168/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5624 - acc: 0.9351 - precision: 0.9913 - recall: 0.8784 - f1_score: 0.9294 - val_loss: 2.5323 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 169/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5503 - acc: 0.9351 - precision: 0.9882 - recall: 0.8711 - f1_score: 0.9240 - val_loss: 2.5203 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 170/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5382 - acc: 0.9351 - precision: 0.9892 - recall: 0.8754 - f1_score: 0.9276 - val_loss: 2.5083 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 171/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5263 - acc: 0.9351 - precision: 0.9881 - recall: 0.8751 - f1_score: 0.9272 - val_loss: 2.4964 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 172/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5144 - acc: 0.9351 - precision: 0.9895 - recall: 0.8754 - f1_score: 0.9278 - val_loss: 2.4845 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 173/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5025 - acc: 0.9351 - precision: 0.9906 - recall: 0.8792 - f1_score: 0.9300 - val_loss: 2.4727 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 174/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4908 - acc: 0.9351 - precision: 0.9880 - recall: 0.8771 - f1_score: 0.9274 - val_loss: 2.4610 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 175/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4790 - acc: 0.9351 - precision: 0.9895 - recall: 0.8763 - f1_score: 0.9285 - val_loss: 2.4494 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 176/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4674 - acc: 0.9351 - precision: 0.9881 - recall: 0.8692 - f1_score: 0.9231 - val_loss: 2.4378 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 177/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4558 - acc: 0.9351 - precision: 0.9892 - recall: 0.8756 - f1_score: 0.9279 - val_loss: 2.4262 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 178/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4443 - acc: 0.9351 - precision: 0.9894 - recall: 0.8709 - f1_score: 0.9226 - val_loss: 2.4148 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 179/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4328 - acc: 0.9351 - precision: 0.9882 - recall: 0.8764 - f1_score: 0.9278 - val_loss: 2.4033 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 180/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4214 - acc: 0.9351 - precision: 0.9884 - recall: 0.8779 - f1_score: 0.9284 - val_loss: 2.3920 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 181/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4101 - acc: 0.9351 - precision: 0.9889 - recall: 0.8775 - f1_score: 0.9282 - val_loss: 2.3807 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 182/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3988 - acc: 0.9351 - precision: 0.9895 - recall: 0.8713 - f1_score: 0.9258 - val_loss: 2.3695 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 183/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3876 - acc: 0.9351 - precision: 0.9882 - recall: 0.8824 - f1_score: 0.9311 - val_loss: 2.3583 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 184/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3764 - acc: 0.9351 - precision: 0.9901 - recall: 0.8798 - f1_score: 0.9296 - val_loss: 2.3472 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 185/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3653 - acc: 0.9351 - precision: 0.9878 - recall: 0.8799 - f1_score: 0.9293 - val_loss: 2.3361 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 186/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3542 - acc: 0.9351 - precision: 0.9872 - recall: 0.8746 - f1_score: 0.9259 - val_loss: 2.3251 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 187/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3432 - acc: 0.9351 - precision: 0.9898 - recall: 0.8780 - f1_score: 0.9297 - val_loss: 2.3142 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 188/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3323 - acc: 0.9351 - precision: 0.9888 - recall: 0.8722 - f1_score: 0.9253 - val_loss: 2.3033 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 189/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3214 - acc: 0.9351 - precision: 0.9885 - recall: 0.8788 - f1_score: 0.9296 - val_loss: 2.2925 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 190/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3106 - acc: 0.9351 - precision: 0.9892 - recall: 0.8759 - f1_score: 0.9283 - val_loss: 2.2817 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 191/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2998 - acc: 0.9351 - precision: 0.9890 - recall: 0.8787 - f1_score: 0.9297 - val_loss: 2.2710 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 192/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2891 - acc: 0.9351 - precision: 0.9880 - recall: 0.8804 - f1_score: 0.9290 - val_loss: 2.2603 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.2785 - acc: 0.9351 - precision: 0.9886 - recall: 0.8756 - f1_score: 0.9271 - val_loss: 2.2497 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 194/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2679 - acc: 0.9351 - precision: 0.9898 - recall: 0.8827 - f1_score: 0.9318 - val_loss: 2.2392 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 195/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2573 - acc: 0.9351 - precision: 0.9888 - recall: 0.8778 - f1_score: 0.9282 - val_loss: 2.2287 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 196/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2468 - acc: 0.9351 - precision: 0.9877 - recall: 0.8743 - f1_score: 0.9251 - val_loss: 2.2182 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 197/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2364 - acc: 0.9351 - precision: 0.9889 - recall: 0.8731 - f1_score: 0.9250 - val_loss: 2.2078 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 198/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2260 - acc: 0.9351 - precision: 0.9890 - recall: 0.8783 - f1_score: 0.9295 - val_loss: 2.1975 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 199/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2157 - acc: 0.9351 - precision: 0.9895 - recall: 0.8787 - f1_score: 0.9288 - val_loss: 2.1872 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 200/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2054 - acc: 0.9351 - precision: 0.9889 - recall: 0.8758 - f1_score: 0.9282 - val_loss: 2.1770 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 201/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1952 - acc: 0.9351 - precision: 0.9898 - recall: 0.8739 - f1_score: 0.9266 - val_loss: 2.1668 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 202/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1850 - acc: 0.9351 - precision: 0.9898 - recall: 0.8755 - f1_score: 0.9278 - val_loss: 2.1567 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 203/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1749 - acc: 0.9351 - precision: 0.9909 - recall: 0.8773 - f1_score: 0.9294 - val_loss: 2.1467 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 204/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1649 - acc: 0.9351 - precision: 0.9893 - recall: 0.8771 - f1_score: 0.9287 - val_loss: 2.1367 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 205/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1549 - acc: 0.9351 - precision: 0.9889 - recall: 0.8751 - f1_score: 0.9272 - val_loss: 2.1267 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 206/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1449 - acc: 0.9351 - precision: 0.9885 - recall: 0.8775 - f1_score: 0.9285 - val_loss: 2.1168 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 207/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1350 - acc: 0.9351 - precision: 0.9878 - recall: 0.8786 - f1_score: 0.9288 - val_loss: 2.1069 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 208/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1252 - acc: 0.9351 - precision: 0.9855 - recall: 0.8693 - f1_score: 0.9226 - val_loss: 2.0971 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 209/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1154 - acc: 0.9351 - precision: 0.9896 - recall: 0.8768 - f1_score: 0.9285 - val_loss: 2.0874 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 210/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1056 - acc: 0.9351 - precision: 0.9890 - recall: 0.8776 - f1_score: 0.9287 - val_loss: 2.0777 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 211/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0959 - acc: 0.9351 - precision: 0.9892 - recall: 0.8778 - f1_score: 0.9282 - val_loss: 2.0680 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 212/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0863 - acc: 0.9351 - precision: 0.9902 - recall: 0.8770 - f1_score: 0.9278 - val_loss: 2.0584 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 213/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0767 - acc: 0.9351 - precision: 0.9898 - recall: 0.8753 - f1_score: 0.9267 - val_loss: 2.0489 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 214/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0671 - acc: 0.9351 - precision: 0.9890 - recall: 0.8799 - f1_score: 0.9300 - val_loss: 2.0394 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 215/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0576 - acc: 0.9351 - precision: 0.9893 - recall: 0.8766 - f1_score: 0.9280 - val_loss: 2.0299 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 216/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0482 - acc: 0.9351 - precision: 0.9890 - recall: 0.8739 - f1_score: 0.9267 - val_loss: 2.0205 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 217/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0388 - acc: 0.9351 - precision: 0.9883 - recall: 0.8796 - f1_score: 0.9297 - val_loss: 2.0112 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 218/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0295 - acc: 0.9351 - precision: 0.9906 - recall: 0.8817 - f1_score: 0.9302 - val_loss: 2.0019 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 219/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0202 - acc: 0.9351 - precision: 0.9893 - recall: 0.8762 - f1_score: 0.9283 - val_loss: 1.9926 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 220/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0109 - acc: 0.9351 - precision: 0.9883 - recall: 0.8804 - f1_score: 0.9282 - val_loss: 1.9834 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 221/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0017 - acc: 0.9351 - precision: 0.9884 - recall: 0.8762 - f1_score: 0.9275 - val_loss: 1.9743 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 222/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9925 - acc: 0.9351 - precision: 0.9892 - recall: 0.8756 - f1_score: 0.9274 - val_loss: 1.9652 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 223/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9834 - acc: 0.9351 - precision: 0.9880 - recall: 0.8805 - f1_score: 0.9287 - val_loss: 1.9561 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 224/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9744 - acc: 0.9351 - precision: 0.9876 - recall: 0.8738 - f1_score: 0.9264 - val_loss: 1.9471 - val_acc: 0.9497 - val_precision: 0.9888 - val_recall: 0.9169 - val_f1_score: 0.9506\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.9654 - acc: 0.9351 - precision: 0.9899 - recall: 0.8769 - f1_score: 0.9294 - val_loss: 1.9381 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 226/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9564 - acc: 0.9351 - precision: 0.9889 - recall: 0.8756 - f1_score: 0.9282 - val_loss: 1.9292 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 227/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9475 - acc: 0.9351 - precision: 0.9902 - recall: 0.8766 - f1_score: 0.9279 - val_loss: 1.9203 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 228/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9386 - acc: 0.9351 - precision: 0.9898 - recall: 0.8773 - f1_score: 0.9287 - val_loss: 1.9115 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 229/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9298 - acc: 0.9351 - precision: 0.9892 - recall: 0.8775 - f1_score: 0.9291 - val_loss: 1.9027 - val_acc: 0.9560 - val_precision: 0.9888 - val_recall: 0.9274 - val_f1_score: 0.9565\n",
      "Epoch 230/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9210 - acc: 0.9351 - precision: 0.9888 - recall: 0.8755 - f1_score: 0.9280 - val_loss: 1.8940 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 231/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9123 - acc: 0.9351 - precision: 0.9897 - recall: 0.8736 - f1_score: 0.9274 - val_loss: 1.8853 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 232/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9036 - acc: 0.9351 - precision: 0.9888 - recall: 0.8763 - f1_score: 0.9284 - val_loss: 1.8766 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 233/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8949 - acc: 0.9351 - precision: 0.9843 - recall: 0.8691 - f1_score: 0.9224 - val_loss: 1.8680 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 234/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8863 - acc: 0.9351 - precision: 0.9894 - recall: 0.8705 - f1_score: 0.9232 - val_loss: 1.8595 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 235/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8778 - acc: 0.9351 - precision: 0.9881 - recall: 0.8744 - f1_score: 0.9260 - val_loss: 1.8510 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 236/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8693 - acc: 0.9351 - precision: 0.9870 - recall: 0.8819 - f1_score: 0.9300 - val_loss: 1.8425 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 237/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8608 - acc: 0.9351 - precision: 0.9900 - recall: 0.8766 - f1_score: 0.9292 - val_loss: 1.8341 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 238/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8524 - acc: 0.9351 - precision: 0.9879 - recall: 0.8806 - f1_score: 0.9297 - val_loss: 1.8257 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 239/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8440 - acc: 0.9351 - precision: 0.9896 - recall: 0.8733 - f1_score: 0.9256 - val_loss: 1.8173 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 240/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8356 - acc: 0.9351 - precision: 0.9886 - recall: 0.8754 - f1_score: 0.9274 - val_loss: 1.8091 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 241/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8274 - acc: 0.9351 - precision: 0.9887 - recall: 0.8768 - f1_score: 0.9282 - val_loss: 1.8008 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 242/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8191 - acc: 0.9351 - precision: 0.9896 - recall: 0.8785 - f1_score: 0.9303 - val_loss: 1.7926 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 243/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8109 - acc: 0.9351 - precision: 0.9890 - recall: 0.8799 - f1_score: 0.9303 - val_loss: 1.7844 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 244/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8027 - acc: 0.9351 - precision: 0.9881 - recall: 0.8769 - f1_score: 0.9278 - val_loss: 1.7763 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 245/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7946 - acc: 0.9351 - precision: 0.9887 - recall: 0.8776 - f1_score: 0.9293 - val_loss: 1.7682 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 246/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7865 - acc: 0.9351 - precision: 0.9894 - recall: 0.8770 - f1_score: 0.9293 - val_loss: 1.7602 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 247/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7785 - acc: 0.9351 - precision: 0.9901 - recall: 0.8753 - f1_score: 0.9271 - val_loss: 1.7522 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 248/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7705 - acc: 0.9351 - precision: 0.9898 - recall: 0.8769 - f1_score: 0.9288 - val_loss: 1.7442 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 249/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7626 - acc: 0.9351 - precision: 0.9895 - recall: 0.8776 - f1_score: 0.9278 - val_loss: 1.7363 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 250/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7546 - acc: 0.9351 - precision: 0.9901 - recall: 0.8766 - f1_score: 0.9294 - val_loss: 1.7285 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 251/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7468 - acc: 0.9351 - precision: 0.9889 - recall: 0.8796 - f1_score: 0.9301 - val_loss: 1.7206 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 252/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7389 - acc: 0.9351 - precision: 0.9873 - recall: 0.8717 - f1_score: 0.9241 - val_loss: 1.7128 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 253/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7311 - acc: 0.9351 - precision: 0.9904 - recall: 0.8772 - f1_score: 0.9283 - val_loss: 1.7051 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 254/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7234 - acc: 0.9351 - precision: 0.9905 - recall: 0.8748 - f1_score: 0.9268 - val_loss: 1.6974 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 255/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7156 - acc: 0.9351 - precision: 0.9900 - recall: 0.8740 - f1_score: 0.9260 - val_loss: 1.6897 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 256/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7080 - acc: 0.9351 - precision: 0.9859 - recall: 0.8703 - f1_score: 0.9237 - val_loss: 1.6821 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.7004 - acc: 0.9351 - precision: 0.9884 - recall: 0.8759 - f1_score: 0.9281 - val_loss: 1.6745 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9379 - val_f1_score: 0.9622\n",
      "Epoch 258/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6928 - acc: 0.9351 - precision: 0.9895 - recall: 0.8766 - f1_score: 0.9284 - val_loss: 1.6669 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 259/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6852 - acc: 0.9351 - precision: 0.9892 - recall: 0.8771 - f1_score: 0.9283 - val_loss: 1.6594 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 260/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6777 - acc: 0.9351 - precision: 0.9895 - recall: 0.8755 - f1_score: 0.9283 - val_loss: 1.6520 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 261/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6702 - acc: 0.9351 - precision: 0.9891 - recall: 0.8730 - f1_score: 0.9258 - val_loss: 1.6445 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 262/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6628 - acc: 0.9351 - precision: 0.9904 - recall: 0.8747 - f1_score: 0.9274 - val_loss: 1.6371 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 263/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6554 - acc: 0.9351 - precision: 0.9895 - recall: 0.8770 - f1_score: 0.9290 - val_loss: 1.6298 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 264/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6481 - acc: 0.9351 - precision: 0.9898 - recall: 0.8758 - f1_score: 0.9277 - val_loss: 1.6224 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 265/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6407 - acc: 0.9351 - precision: 0.9881 - recall: 0.8747 - f1_score: 0.9270 - val_loss: 1.6152 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 266/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6334 - acc: 0.9351 - precision: 0.9891 - recall: 0.8720 - f1_score: 0.9233 - val_loss: 1.6079 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 267/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6262 - acc: 0.9351 - precision: 0.9883 - recall: 0.8749 - f1_score: 0.9268 - val_loss: 1.6007 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 268/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6190 - acc: 0.9351 - precision: 0.9895 - recall: 0.8778 - f1_score: 0.9296 - val_loss: 1.5935 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 269/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6118 - acc: 0.9351 - precision: 0.9901 - recall: 0.8731 - f1_score: 0.9263 - val_loss: 1.5864 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 270/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6047 - acc: 0.9351 - precision: 0.9886 - recall: 0.8778 - f1_score: 0.9282 - val_loss: 1.5793 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 271/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5976 - acc: 0.9351 - precision: 0.9882 - recall: 0.8738 - f1_score: 0.9266 - val_loss: 1.5722 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 272/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5905 - acc: 0.9351 - precision: 0.9886 - recall: 0.8787 - f1_score: 0.9290 - val_loss: 1.5652 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 273/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5835 - acc: 0.9367 - precision: 0.9894 - recall: 0.8797 - f1_score: 0.9299 - val_loss: 1.5582 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 274/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5765 - acc: 0.9367 - precision: 0.9895 - recall: 0.8779 - f1_score: 0.9286 - val_loss: 1.5513 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 275/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5696 - acc: 0.9367 - precision: 0.9885 - recall: 0.8776 - f1_score: 0.9288 - val_loss: 1.5444 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 276/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5627 - acc: 0.9367 - precision: 0.9900 - recall: 0.8767 - f1_score: 0.9273 - val_loss: 1.5375 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 277/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5558 - acc: 0.9367 - precision: 0.9897 - recall: 0.8811 - f1_score: 0.9309 - val_loss: 1.5306 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 278/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5489 - acc: 0.9367 - precision: 0.9877 - recall: 0.8818 - f1_score: 0.9299 - val_loss: 1.5238 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 279/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5421 - acc: 0.9367 - precision: 0.9889 - recall: 0.8807 - f1_score: 0.9303 - val_loss: 1.5171 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 280/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5353 - acc: 0.9367 - precision: 0.9902 - recall: 0.8793 - f1_score: 0.9308 - val_loss: 1.5103 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 281/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5286 - acc: 0.9367 - precision: 0.9878 - recall: 0.8773 - f1_score: 0.9279 - val_loss: 1.5036 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 282/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5219 - acc: 0.9367 - precision: 0.9894 - recall: 0.8812 - f1_score: 0.9314 - val_loss: 1.4969 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 283/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5152 - acc: 0.9367 - precision: 0.9886 - recall: 0.8831 - f1_score: 0.9317 - val_loss: 1.4903 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 284/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5086 - acc: 0.9367 - precision: 0.9896 - recall: 0.8812 - f1_score: 0.9308 - val_loss: 1.4837 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 285/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5020 - acc: 0.9367 - precision: 0.9888 - recall: 0.8837 - f1_score: 0.9326 - val_loss: 1.4771 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 286/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4954 - acc: 0.9367 - precision: 0.9889 - recall: 0.8826 - f1_score: 0.9309 - val_loss: 1.4706 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 287/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4889 - acc: 0.9367 - precision: 0.9885 - recall: 0.8793 - f1_score: 0.9297 - val_loss: 1.4641 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 288/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4824 - acc: 0.9367 - precision: 0.9892 - recall: 0.8806 - f1_score: 0.9309 - val_loss: 1.4577 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.4759 - acc: 0.9367 - precision: 0.9896 - recall: 0.8827 - f1_score: 0.9314 - val_loss: 1.4512 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 290/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4695 - acc: 0.9367 - precision: 0.9882 - recall: 0.8788 - f1_score: 0.9288 - val_loss: 1.4448 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 291/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4631 - acc: 0.9367 - precision: 0.9903 - recall: 0.8803 - f1_score: 0.9307 - val_loss: 1.4385 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 292/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4567 - acc: 0.9367 - precision: 0.9919 - recall: 0.8762 - f1_score: 0.9292 - val_loss: 1.4321 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 293/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4504 - acc: 0.9367 - precision: 0.9894 - recall: 0.8808 - f1_score: 0.9314 - val_loss: 1.4258 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 294/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4441 - acc: 0.9367 - precision: 0.9901 - recall: 0.8787 - f1_score: 0.9290 - val_loss: 1.4196 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 295/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4378 - acc: 0.9367 - precision: 0.9884 - recall: 0.8811 - f1_score: 0.9309 - val_loss: 1.4133 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 296/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4316 - acc: 0.9367 - precision: 0.9893 - recall: 0.8808 - f1_score: 0.9302 - val_loss: 1.4071 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 297/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4254 - acc: 0.9367 - precision: 0.9893 - recall: 0.8786 - f1_score: 0.9300 - val_loss: 1.4009 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 298/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4192 - acc: 0.9367 - precision: 0.9890 - recall: 0.8794 - f1_score: 0.9299 - val_loss: 1.3948 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 299/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4131 - acc: 0.9367 - precision: 0.9879 - recall: 0.8780 - f1_score: 0.9280 - val_loss: 1.3887 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 300/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4070 - acc: 0.9367 - precision: 0.9871 - recall: 0.8757 - f1_score: 0.9264 - val_loss: 1.3826 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 301/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4009 - acc: 0.9367 - precision: 0.9894 - recall: 0.8794 - f1_score: 0.9304 - val_loss: 1.3766 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 302/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3948 - acc: 0.9367 - precision: 0.9883 - recall: 0.8833 - f1_score: 0.9303 - val_loss: 1.3705 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 303/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3888 - acc: 0.9367 - precision: 0.9888 - recall: 0.8816 - f1_score: 0.9315 - val_loss: 1.3646 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 304/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3828 - acc: 0.9367 - precision: 0.9890 - recall: 0.8840 - f1_score: 0.9322 - val_loss: 1.3586 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 305/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3769 - acc: 0.9367 - precision: 0.9882 - recall: 0.8812 - f1_score: 0.9301 - val_loss: 1.3527 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 306/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3709 - acc: 0.9367 - precision: 0.9902 - recall: 0.8822 - f1_score: 0.9318 - val_loss: 1.3468 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 307/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3651 - acc: 0.9367 - precision: 0.9889 - recall: 0.8774 - f1_score: 0.9287 - val_loss: 1.3409 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 308/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3592 - acc: 0.9367 - precision: 0.9895 - recall: 0.8771 - f1_score: 0.9280 - val_loss: 1.3351 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 309/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3534 - acc: 0.9367 - precision: 0.9870 - recall: 0.8750 - f1_score: 0.9266 - val_loss: 1.3293 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 310/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3476 - acc: 0.9367 - precision: 0.9896 - recall: 0.8778 - f1_score: 0.9287 - val_loss: 1.3235 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 311/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3418 - acc: 0.9367 - precision: 0.9898 - recall: 0.8798 - f1_score: 0.9308 - val_loss: 1.3178 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 312/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3360 - acc: 0.9367 - precision: 0.9886 - recall: 0.8775 - f1_score: 0.9286 - val_loss: 1.3121 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 313/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3303 - acc: 0.9367 - precision: 0.9899 - recall: 0.8800 - f1_score: 0.9305 - val_loss: 1.3064 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 314/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3246 - acc: 0.9367 - precision: 0.9903 - recall: 0.8825 - f1_score: 0.9329 - val_loss: 1.3007 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 315/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3190 - acc: 0.9367 - precision: 0.9854 - recall: 0.8784 - f1_score: 0.9280 - val_loss: 1.2951 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 316/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3134 - acc: 0.9367 - precision: 0.9898 - recall: 0.8794 - f1_score: 0.9299 - val_loss: 1.2895 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 317/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3078 - acc: 0.9367 - precision: 0.9902 - recall: 0.8795 - f1_score: 0.9296 - val_loss: 1.2840 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 318/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3022 - acc: 0.9367 - precision: 0.9894 - recall: 0.8808 - f1_score: 0.9297 - val_loss: 1.2784 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 319/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2967 - acc: 0.9367 - precision: 0.9904 - recall: 0.8825 - f1_score: 0.9321 - val_loss: 1.2729 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 320/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2911 - acc: 0.9367 - precision: 0.9891 - recall: 0.8810 - f1_score: 0.9309 - val_loss: 1.2674 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.2857 - acc: 0.9367 - precision: 0.9890 - recall: 0.8795 - f1_score: 0.9297 - val_loss: 1.2620 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 322/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2802 - acc: 0.9367 - precision: 0.9866 - recall: 0.8810 - f1_score: 0.9300 - val_loss: 1.2565 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 323/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2748 - acc: 0.9367 - precision: 0.9877 - recall: 0.8786 - f1_score: 0.9284 - val_loss: 1.2511 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 324/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2694 - acc: 0.9367 - precision: 0.9905 - recall: 0.8817 - f1_score: 0.9319 - val_loss: 1.2458 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 325/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2640 - acc: 0.9367 - precision: 0.9891 - recall: 0.8833 - f1_score: 0.9309 - val_loss: 1.2404 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 326/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2587 - acc: 0.9367 - precision: 0.9901 - recall: 0.8782 - f1_score: 0.9293 - val_loss: 1.2351 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 327/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2533 - acc: 0.9367 - precision: 0.9893 - recall: 0.8790 - f1_score: 0.9281 - val_loss: 1.2298 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 328/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2481 - acc: 0.9367 - precision: 0.9907 - recall: 0.8796 - f1_score: 0.9310 - val_loss: 1.2246 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 329/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2428 - acc: 0.9367 - precision: 0.9890 - recall: 0.8838 - f1_score: 0.9323 - val_loss: 1.2193 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 330/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2376 - acc: 0.9367 - precision: 0.9907 - recall: 0.8801 - f1_score: 0.9308 - val_loss: 1.2141 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 331/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2324 - acc: 0.9367 - precision: 0.9881 - recall: 0.8830 - f1_score: 0.9311 - val_loss: 1.2089 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 332/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2272 - acc: 0.9367 - precision: 0.9896 - recall: 0.8830 - f1_score: 0.9318 - val_loss: 1.2038 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 333/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2220 - acc: 0.9367 - precision: 0.9898 - recall: 0.8822 - f1_score: 0.9320 - val_loss: 1.1987 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 334/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2169 - acc: 0.9367 - precision: 0.9895 - recall: 0.8805 - f1_score: 0.9312 - val_loss: 1.1936 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 335/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2118 - acc: 0.9367 - precision: 0.9895 - recall: 0.8845 - f1_score: 0.9324 - val_loss: 1.1885 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 336/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2067 - acc: 0.9367 - precision: 0.9887 - recall: 0.8804 - f1_score: 0.9291 - val_loss: 1.1835 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 337/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2017 - acc: 0.9367 - precision: 0.9892 - recall: 0.8816 - f1_score: 0.9314 - val_loss: 1.1784 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 338/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1966 - acc: 0.9367 - precision: 0.9884 - recall: 0.8829 - f1_score: 0.9312 - val_loss: 1.1734 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 339/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1916 - acc: 0.9367 - precision: 0.9898 - recall: 0.8757 - f1_score: 0.9279 - val_loss: 1.1685 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 340/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1867 - acc: 0.9367 - precision: 0.9904 - recall: 0.8802 - f1_score: 0.9302 - val_loss: 1.1635 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 341/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1817 - acc: 0.9367 - precision: 0.9895 - recall: 0.8790 - f1_score: 0.9288 - val_loss: 1.1586 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 342/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1768 - acc: 0.9367 - precision: 0.9888 - recall: 0.8789 - f1_score: 0.9297 - val_loss: 1.1537 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 343/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1719 - acc: 0.9367 - precision: 0.9900 - recall: 0.8786 - f1_score: 0.9290 - val_loss: 1.1488 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 344/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1670 - acc: 0.9367 - precision: 0.9904 - recall: 0.8829 - f1_score: 0.9323 - val_loss: 1.1440 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 345/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1622 - acc: 0.9367 - precision: 0.9881 - recall: 0.8795 - f1_score: 0.9297 - val_loss: 1.1392 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 346/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1574 - acc: 0.9367 - precision: 0.9898 - recall: 0.8783 - f1_score: 0.9295 - val_loss: 1.1344 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 347/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1526 - acc: 0.9367 - precision: 0.9877 - recall: 0.8790 - f1_score: 0.9297 - val_loss: 1.1296 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 348/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1478 - acc: 0.9367 - precision: 0.9888 - recall: 0.8773 - f1_score: 0.9284 - val_loss: 1.1249 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 349/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1431 - acc: 0.9367 - precision: 0.9901 - recall: 0.8776 - f1_score: 0.9284 - val_loss: 1.1201 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 350/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1383 - acc: 0.9367 - precision: 0.9904 - recall: 0.8779 - f1_score: 0.9291 - val_loss: 1.1154 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 351/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1336 - acc: 0.9367 - precision: 0.9900 - recall: 0.8793 - f1_score: 0.9306 - val_loss: 1.1108 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 352/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1290 - acc: 0.9367 - precision: 0.9893 - recall: 0.8840 - f1_score: 0.9319 - val_loss: 1.1061 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.1243 - acc: 0.9367 - precision: 0.9904 - recall: 0.8802 - f1_score: 0.9314 - val_loss: 1.1015 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 354/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1197 - acc: 0.9367 - precision: 0.9905 - recall: 0.8764 - f1_score: 0.9284 - val_loss: 1.0969 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 355/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1151 - acc: 0.9367 - precision: 0.9899 - recall: 0.8786 - f1_score: 0.9290 - val_loss: 1.0923 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 356/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1105 - acc: 0.9367 - precision: 0.9907 - recall: 0.8813 - f1_score: 0.9316 - val_loss: 1.0878 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 357/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1059 - acc: 0.9367 - precision: 0.9877 - recall: 0.8809 - f1_score: 0.9305 - val_loss: 1.0832 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 358/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1014 - acc: 0.9367 - precision: 0.9908 - recall: 0.8796 - f1_score: 0.9299 - val_loss: 1.0787 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 359/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0969 - acc: 0.9367 - precision: 0.9898 - recall: 0.8796 - f1_score: 0.9300 - val_loss: 1.0742 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 360/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0924 - acc: 0.9367 - precision: 0.9881 - recall: 0.8776 - f1_score: 0.9279 - val_loss: 1.0698 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 361/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0879 - acc: 0.9367 - precision: 0.9871 - recall: 0.8776 - f1_score: 0.9286 - val_loss: 1.0653 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 362/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0835 - acc: 0.9367 - precision: 0.9873 - recall: 0.8793 - f1_score: 0.9294 - val_loss: 1.0609 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 363/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0791 - acc: 0.9367 - precision: 0.9889 - recall: 0.8775 - f1_score: 0.9293 - val_loss: 1.0565 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 364/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0747 - acc: 0.9367 - precision: 0.9910 - recall: 0.8810 - f1_score: 0.9310 - val_loss: 1.0521 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 365/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0703 - acc: 0.9367 - precision: 0.9897 - recall: 0.8884 - f1_score: 0.9341 - val_loss: 1.0478 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 366/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0660 - acc: 0.9367 - precision: 0.9886 - recall: 0.8809 - f1_score: 0.9301 - val_loss: 1.0435 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 367/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0616 - acc: 0.9367 - precision: 0.9887 - recall: 0.8794 - f1_score: 0.9301 - val_loss: 1.0392 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 368/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0573 - acc: 0.9367 - precision: 0.9896 - recall: 0.8799 - f1_score: 0.9307 - val_loss: 1.0349 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 369/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0530 - acc: 0.9367 - precision: 0.9881 - recall: 0.8764 - f1_score: 0.9281 - val_loss: 1.0306 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 370/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0488 - acc: 0.9367 - precision: 0.9882 - recall: 0.8770 - f1_score: 0.9280 - val_loss: 1.0264 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 371/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0445 - acc: 0.9367 - precision: 0.9891 - recall: 0.8827 - f1_score: 0.9318 - val_loss: 1.0222 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 372/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0403 - acc: 0.9367 - precision: 0.9896 - recall: 0.8768 - f1_score: 0.9268 - val_loss: 1.0180 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 373/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0361 - acc: 0.9367 - precision: 0.9890 - recall: 0.8767 - f1_score: 0.9274 - val_loss: 1.0138 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 374/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0319 - acc: 0.9367 - precision: 0.9880 - recall: 0.8783 - f1_score: 0.9289 - val_loss: 1.0097 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 375/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0278 - acc: 0.9367 - precision: 0.9900 - recall: 0.8800 - f1_score: 0.9306 - val_loss: 1.0055 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 376/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0237 - acc: 0.9367 - precision: 0.9893 - recall: 0.8828 - f1_score: 0.9320 - val_loss: 1.0014 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 377/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0195 - acc: 0.9367 - precision: 0.9897 - recall: 0.8836 - f1_score: 0.9319 - val_loss: 0.9973 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 378/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0155 - acc: 0.9367 - precision: 0.9909 - recall: 0.8841 - f1_score: 0.9331 - val_loss: 0.9933 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 379/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0114 - acc: 0.9367 - precision: 0.9900 - recall: 0.8834 - f1_score: 0.9322 - val_loss: 0.9892 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 380/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0073 - acc: 0.9367 - precision: 0.9883 - recall: 0.8818 - f1_score: 0.9313 - val_loss: 0.9852 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 381/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0033 - acc: 0.9367 - precision: 0.9886 - recall: 0.8797 - f1_score: 0.9293 - val_loss: 0.9812 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 382/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9993 - acc: 0.9367 - precision: 0.9879 - recall: 0.8815 - f1_score: 0.9313 - val_loss: 0.9772 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 383/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9953 - acc: 0.9367 - precision: 0.9892 - recall: 0.8842 - f1_score: 0.9324 - val_loss: 0.9732 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 384/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9913 - acc: 0.9367 - precision: 0.9910 - recall: 0.8849 - f1_score: 0.9338 - val_loss: 0.9693 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.9874 - acc: 0.9367 - precision: 0.9887 - recall: 0.8770 - f1_score: 0.9283 - val_loss: 0.9654 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 386/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9835 - acc: 0.9367 - precision: 0.9880 - recall: 0.8802 - f1_score: 0.9302 - val_loss: 0.9615 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 387/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9796 - acc: 0.9367 - precision: 0.9886 - recall: 0.8799 - f1_score: 0.9301 - val_loss: 0.9576 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 388/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9757 - acc: 0.9367 - precision: 0.9886 - recall: 0.8789 - f1_score: 0.9294 - val_loss: 0.9537 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 389/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9718 - acc: 0.9367 - precision: 0.9899 - recall: 0.8832 - f1_score: 0.9317 - val_loss: 0.9499 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 390/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9679 - acc: 0.9367 - precision: 0.9897 - recall: 0.8822 - f1_score: 0.9313 - val_loss: 0.9460 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 391/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9641 - acc: 0.9367 - precision: 0.9882 - recall: 0.8788 - f1_score: 0.9292 - val_loss: 0.9422 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 392/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9603 - acc: 0.9367 - precision: 0.9893 - recall: 0.8800 - f1_score: 0.9309 - val_loss: 0.9384 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 393/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9565 - acc: 0.9367 - precision: 0.9890 - recall: 0.8775 - f1_score: 0.9279 - val_loss: 0.9347 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 394/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9528 - acc: 0.9383 - precision: 0.9893 - recall: 0.8845 - f1_score: 0.9329 - val_loss: 0.9309 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 395/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9490 - acc: 0.9383 - precision: 0.9888 - recall: 0.8792 - f1_score: 0.9295 - val_loss: 0.9272 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 396/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9453 - acc: 0.9383 - precision: 0.9898 - recall: 0.8766 - f1_score: 0.9276 - val_loss: 0.9235 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 397/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9415 - acc: 0.9383 - precision: 0.9889 - recall: 0.8808 - f1_score: 0.9313 - val_loss: 0.9198 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 398/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9379 - acc: 0.9383 - precision: 0.9900 - recall: 0.8843 - f1_score: 0.9322 - val_loss: 0.9161 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 399/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9342 - acc: 0.9383 - precision: 0.9892 - recall: 0.8808 - f1_score: 0.9295 - val_loss: 0.9125 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 400/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9305 - acc: 0.9383 - precision: 0.9858 - recall: 0.8742 - f1_score: 0.9255 - val_loss: 0.9088 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 401/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9269 - acc: 0.9383 - precision: 0.9884 - recall: 0.8808 - f1_score: 0.9303 - val_loss: 0.9052 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 402/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9233 - acc: 0.9383 - precision: 0.9908 - recall: 0.8877 - f1_score: 0.9352 - val_loss: 0.9016 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 403/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9197 - acc: 0.9383 - precision: 0.9875 - recall: 0.8817 - f1_score: 0.9306 - val_loss: 0.8980 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 404/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9161 - acc: 0.9383 - precision: 0.9898 - recall: 0.8879 - f1_score: 0.9320 - val_loss: 0.8945 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 405/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9125 - acc: 0.9383 - precision: 0.9894 - recall: 0.8828 - f1_score: 0.9307 - val_loss: 0.8909 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 406/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9090 - acc: 0.9383 - precision: 0.9883 - recall: 0.8830 - f1_score: 0.9318 - val_loss: 0.8874 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 407/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9054 - acc: 0.9383 - precision: 0.9877 - recall: 0.8776 - f1_score: 0.9274 - val_loss: 0.8839 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 408/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9019 - acc: 0.9383 - precision: 0.9893 - recall: 0.8849 - f1_score: 0.9333 - val_loss: 0.8804 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 409/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8984 - acc: 0.9383 - precision: 0.9875 - recall: 0.8800 - f1_score: 0.9288 - val_loss: 0.8769 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 410/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.9378 - acc: 0.9000 - precision: 1.0000 - recall: 0.8276 - f1_score: 0.905 - 0s - loss: 0.8949 - acc: 0.9383 - precision: 0.9910 - recall: 0.8832 - f1_score: 0.9320 - val_loss: 0.8735 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 411/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8915 - acc: 0.9383 - precision: 0.9887 - recall: 0.8831 - f1_score: 0.9310 - val_loss: 0.8701 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 412/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8880 - acc: 0.9383 - precision: 0.9881 - recall: 0.8805 - f1_score: 0.9299 - val_loss: 0.8666 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 413/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8846 - acc: 0.9383 - precision: 0.9883 - recall: 0.8825 - f1_score: 0.9305 - val_loss: 0.8632 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 414/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8812 - acc: 0.9383 - precision: 0.9891 - recall: 0.8844 - f1_score: 0.9324 - val_loss: 0.8598 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 415/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8778 - acc: 0.9383 - precision: 0.9878 - recall: 0.8840 - f1_score: 0.9316 - val_loss: 0.8565 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 416/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8745 - acc: 0.9383 - precision: 0.9873 - recall: 0.8806 - f1_score: 0.9291 - val_loss: 0.8531 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 417/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.8711 - acc: 0.9383 - precision: 0.9911 - recall: 0.8920 - f1_score: 0.9368 - val_loss: 0.8498 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 418/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8678 - acc: 0.9383 - precision: 0.9892 - recall: 0.8844 - f1_score: 0.9328 - val_loss: 0.8465 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 419/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8644 - acc: 0.9383 - precision: 0.9898 - recall: 0.8795 - f1_score: 0.9303 - val_loss: 0.8432 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 420/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8611 - acc: 0.9383 - precision: 0.9877 - recall: 0.8820 - f1_score: 0.9303 - val_loss: 0.8399 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 421/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8578 - acc: 0.9383 - precision: 0.9881 - recall: 0.8784 - f1_score: 0.9281 - val_loss: 0.8366 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 422/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8546 - acc: 0.9383 - precision: 0.9890 - recall: 0.8832 - f1_score: 0.9312 - val_loss: 0.8334 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 423/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8513 - acc: 0.9383 - precision: 0.9883 - recall: 0.8855 - f1_score: 0.9321 - val_loss: 0.8301 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 424/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8481 - acc: 0.9383 - precision: 0.9892 - recall: 0.8805 - f1_score: 0.9308 - val_loss: 0.8269 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 425/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8449 - acc: 0.9383 - precision: 0.9894 - recall: 0.8837 - f1_score: 0.9331 - val_loss: 0.8237 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 426/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8417 - acc: 0.9383 - precision: 0.9902 - recall: 0.8831 - f1_score: 0.9325 - val_loss: 0.8205 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 427/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8385 - acc: 0.9383 - precision: 0.9892 - recall: 0.8856 - f1_score: 0.9335 - val_loss: 0.8174 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 428/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8353 - acc: 0.9383 - precision: 0.9897 - recall: 0.8858 - f1_score: 0.9334 - val_loss: 0.8142 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 429/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8322 - acc: 0.9383 - precision: 0.9883 - recall: 0.8797 - f1_score: 0.9294 - val_loss: 0.8111 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 430/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8290 - acc: 0.9383 - precision: 0.9883 - recall: 0.8850 - f1_score: 0.9331 - val_loss: 0.8080 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 431/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8259 - acc: 0.9383 - precision: 0.9905 - recall: 0.8824 - f1_score: 0.9313 - val_loss: 0.8049 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 432/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8228 - acc: 0.9383 - precision: 0.9893 - recall: 0.8788 - f1_score: 0.9289 - val_loss: 0.8018 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 433/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8197 - acc: 0.9383 - precision: 0.9890 - recall: 0.8825 - f1_score: 0.9320 - val_loss: 0.7987 - val_acc: 0.9686 - val_precision: 0.9888 - val_recall: 0.9528 - val_f1_score: 0.9703\n",
      "Epoch 434/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8166 - acc: 0.9383 - precision: 0.9883 - recall: 0.8802 - f1_score: 0.9294 - val_loss: 0.7956 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 435/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8135 - acc: 0.9383 - precision: 0.9892 - recall: 0.8867 - f1_score: 0.9333 - val_loss: 0.7926 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 436/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8105 - acc: 0.9383 - precision: 0.9876 - recall: 0.8844 - f1_score: 0.9326 - val_loss: 0.7896 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 437/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8075 - acc: 0.9383 - precision: 0.9881 - recall: 0.8832 - f1_score: 0.9320 - val_loss: 0.7866 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 438/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8045 - acc: 0.9383 - precision: 0.9899 - recall: 0.8796 - f1_score: 0.9300 - val_loss: 0.7836 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 439/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8014 - acc: 0.9383 - precision: 0.9890 - recall: 0.8803 - f1_score: 0.9300 - val_loss: 0.7806 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 440/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7985 - acc: 0.9383 - precision: 0.9893 - recall: 0.8814 - f1_score: 0.9318 - val_loss: 0.7776 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 441/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7955 - acc: 0.9383 - precision: 0.9877 - recall: 0.8789 - f1_score: 0.9296 - val_loss: 0.7747 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 442/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7925 - acc: 0.9383 - precision: 0.9885 - recall: 0.8777 - f1_score: 0.9281 - val_loss: 0.7717 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 443/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7896 - acc: 0.9383 - precision: 0.9885 - recall: 0.8847 - f1_score: 0.9328 - val_loss: 0.7688 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 444/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7867 - acc: 0.9383 - precision: 0.9893 - recall: 0.8851 - f1_score: 0.9329 - val_loss: 0.7659 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 445/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7838 - acc: 0.9383 - precision: 0.9889 - recall: 0.8856 - f1_score: 0.9335 - val_loss: 0.7630 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 446/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7809 - acc: 0.9383 - precision: 0.9905 - recall: 0.8871 - f1_score: 0.9338 - val_loss: 0.7601 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 447/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7780 - acc: 0.9383 - precision: 0.9897 - recall: 0.8820 - f1_score: 0.9316 - val_loss: 0.7573 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 448/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7751 - acc: 0.9383 - precision: 0.9900 - recall: 0.8842 - f1_score: 0.9326 - val_loss: 0.7544 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.7723 - acc: 0.9383 - precision: 0.9892 - recall: 0.8806 - f1_score: 0.9308 - val_loss: 0.7516 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 450/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7694 - acc: 0.9383 - precision: 0.9895 - recall: 0.8814 - f1_score: 0.9319 - val_loss: 0.7488 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 451/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7666 - acc: 0.9383 - precision: 0.9897 - recall: 0.8839 - f1_score: 0.9330 - val_loss: 0.7460 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 452/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7638 - acc: 0.9383 - precision: 0.9904 - recall: 0.8830 - f1_score: 0.9325 - val_loss: 0.7432 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 453/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7610 - acc: 0.9383 - precision: 0.9898 - recall: 0.8850 - f1_score: 0.9338 - val_loss: 0.7404 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 454/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7582 - acc: 0.9383 - precision: 0.9881 - recall: 0.8857 - f1_score: 0.9322 - val_loss: 0.7376 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 455/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7554 - acc: 0.9383 - precision: 0.9898 - recall: 0.8817 - f1_score: 0.9317 - val_loss: 0.7349 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 456/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7527 - acc: 0.9383 - precision: 0.9888 - recall: 0.8859 - f1_score: 0.9336 - val_loss: 0.7321 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 457/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7499 - acc: 0.9383 - precision: 0.9898 - recall: 0.8851 - f1_score: 0.9330 - val_loss: 0.7294 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 458/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7472 - acc: 0.9383 - precision: 0.9863 - recall: 0.8820 - f1_score: 0.9302 - val_loss: 0.7267 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 459/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7445 - acc: 0.9383 - precision: 0.9897 - recall: 0.8848 - f1_score: 0.9330 - val_loss: 0.7240 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 460/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7418 - acc: 0.9383 - precision: 0.9888 - recall: 0.8827 - f1_score: 0.9302 - val_loss: 0.7213 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 461/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7391 - acc: 0.9383 - precision: 0.9906 - recall: 0.8807 - f1_score: 0.9310 - val_loss: 0.7187 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 462/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7364 - acc: 0.9383 - precision: 0.9865 - recall: 0.8835 - f1_score: 0.9313 - val_loss: 0.7160 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 463/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7338 - acc: 0.9383 - precision: 0.9890 - recall: 0.8834 - f1_score: 0.9324 - val_loss: 0.7134 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 464/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7311 - acc: 0.9383 - precision: 0.9886 - recall: 0.8779 - f1_score: 0.9292 - val_loss: 0.7108 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 465/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7285 - acc: 0.9383 - precision: 0.9872 - recall: 0.8832 - f1_score: 0.9305 - val_loss: 0.7081 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 466/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7259 - acc: 0.9383 - precision: 0.9904 - recall: 0.8850 - f1_score: 0.9336 - val_loss: 0.7055 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 467/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7233 - acc: 0.9383 - precision: 0.9894 - recall: 0.8814 - f1_score: 0.9315 - val_loss: 0.7030 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 468/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7207 - acc: 0.9383 - precision: 0.9896 - recall: 0.8849 - f1_score: 0.9335 - val_loss: 0.7004 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 469/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7181 - acc: 0.9383 - precision: 0.9893 - recall: 0.8829 - f1_score: 0.9311 - val_loss: 0.6978 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 470/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7156 - acc: 0.9383 - precision: 0.9872 - recall: 0.8872 - f1_score: 0.9331 - val_loss: 0.6953 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 471/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7130 - acc: 0.9383 - precision: 0.9901 - recall: 0.8840 - f1_score: 0.9317 - val_loss: 0.6927 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 472/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7105 - acc: 0.9383 - precision: 0.9890 - recall: 0.8769 - f1_score: 0.9285 - val_loss: 0.6902 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 473/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7079 - acc: 0.9383 - precision: 0.9880 - recall: 0.8842 - f1_score: 0.9323 - val_loss: 0.6877 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 474/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7054 - acc: 0.9383 - precision: 0.9879 - recall: 0.8847 - f1_score: 0.9327 - val_loss: 0.6852 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 475/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7029 - acc: 0.9383 - precision: 0.9892 - recall: 0.8862 - f1_score: 0.9322 - val_loss: 0.6827 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 476/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7004 - acc: 0.9383 - precision: 0.9896 - recall: 0.8835 - f1_score: 0.9324 - val_loss: 0.6803 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 477/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6979 - acc: 0.9383 - precision: 0.9894 - recall: 0.8848 - f1_score: 0.9334 - val_loss: 0.6778 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 478/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6955 - acc: 0.9383 - precision: 0.9882 - recall: 0.8800 - f1_score: 0.9302 - val_loss: 0.6753 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 479/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6930 - acc: 0.9383 - precision: 0.9880 - recall: 0.8861 - f1_score: 0.9324 - val_loss: 0.6729 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 480/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6906 - acc: 0.9383 - precision: 0.9889 - recall: 0.8843 - f1_score: 0.9327 - val_loss: 0.6705 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6882 - acc: 0.9383 - precision: 0.9893 - recall: 0.8853 - f1_score: 0.9333 - val_loss: 0.6681 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 482/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6857 - acc: 0.9383 - precision: 0.9893 - recall: 0.8791 - f1_score: 0.9295 - val_loss: 0.6657 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 483/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6833 - acc: 0.9383 - precision: 0.9885 - recall: 0.8857 - f1_score: 0.9333 - val_loss: 0.6633 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 484/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6809 - acc: 0.9383 - precision: 0.9901 - recall: 0.8825 - f1_score: 0.9323 - val_loss: 0.6609 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 485/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6786 - acc: 0.9383 - precision: 0.9886 - recall: 0.8825 - f1_score: 0.9311 - val_loss: 0.6586 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 486/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6762 - acc: 0.9383 - precision: 0.9890 - recall: 0.8823 - f1_score: 0.9315 - val_loss: 0.6562 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 487/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6738 - acc: 0.9383 - precision: 0.9887 - recall: 0.8775 - f1_score: 0.9283 - val_loss: 0.6539 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 488/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6715 - acc: 0.9383 - precision: 0.9897 - recall: 0.8840 - f1_score: 0.9326 - val_loss: 0.6515 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 489/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6692 - acc: 0.9383 - precision: 0.9877 - recall: 0.8839 - f1_score: 0.9323 - val_loss: 0.6492 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 490/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6668 - acc: 0.9383 - precision: 0.9896 - recall: 0.8842 - f1_score: 0.9324 - val_loss: 0.6469 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 491/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6645 - acc: 0.9383 - precision: 0.9881 - recall: 0.8818 - f1_score: 0.9314 - val_loss: 0.6446 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 492/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6622 - acc: 0.9383 - precision: 0.9887 - recall: 0.8834 - f1_score: 0.9320 - val_loss: 0.6423 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 493/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6600 - acc: 0.9383 - precision: 0.9884 - recall: 0.8802 - f1_score: 0.9298 - val_loss: 0.6401 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 494/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6577 - acc: 0.9383 - precision: 0.9871 - recall: 0.8816 - f1_score: 0.9310 - val_loss: 0.6378 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 495/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6554 - acc: 0.9383 - precision: 0.9909 - recall: 0.8816 - f1_score: 0.9308 - val_loss: 0.6356 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 496/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6532 - acc: 0.9383 - precision: 0.9893 - recall: 0.8820 - f1_score: 0.9315 - val_loss: 0.6333 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 497/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6509 - acc: 0.9383 - precision: 0.9886 - recall: 0.8840 - f1_score: 0.9313 - val_loss: 0.6311 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 498/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6487 - acc: 0.9383 - precision: 0.9898 - recall: 0.8819 - f1_score: 0.9323 - val_loss: 0.6289 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 499/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6465 - acc: 0.9383 - precision: 0.9898 - recall: 0.8856 - f1_score: 0.9338 - val_loss: 0.6267 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 500/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6443 - acc: 0.9383 - precision: 0.9889 - recall: 0.8805 - f1_score: 0.9306 - val_loss: 0.6245 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 501/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6421 - acc: 0.9383 - precision: 0.9898 - recall: 0.8859 - f1_score: 0.9339 - val_loss: 0.6223 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 502/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6399 - acc: 0.9383 - precision: 0.9900 - recall: 0.8845 - f1_score: 0.9335 - val_loss: 0.6201 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 503/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6377 - acc: 0.9383 - precision: 0.9881 - recall: 0.8873 - f1_score: 0.9328 - val_loss: 0.6180 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 504/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6356 - acc: 0.9383 - precision: 0.9892 - recall: 0.8846 - f1_score: 0.9326 - val_loss: 0.6158 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 505/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6334 - acc: 0.9383 - precision: 0.9885 - recall: 0.8781 - f1_score: 0.9272 - val_loss: 0.6137 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 506/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6313 - acc: 0.9383 - precision: 0.9887 - recall: 0.8867 - f1_score: 0.9338 - val_loss: 0.6116 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 507/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6291 - acc: 0.9383 - precision: 0.9884 - recall: 0.8843 - f1_score: 0.9323 - val_loss: 0.6095 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 508/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6270 - acc: 0.9383 - precision: 0.9901 - recall: 0.8864 - f1_score: 0.9332 - val_loss: 0.6074 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 509/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6249 - acc: 0.9383 - precision: 0.9912 - recall: 0.8850 - f1_score: 0.9346 - val_loss: 0.6053 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 510/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6228 - acc: 0.9383 - precision: 0.9887 - recall: 0.8855 - f1_score: 0.9337 - val_loss: 0.6032 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 511/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6207 - acc: 0.9383 - precision: 0.9890 - recall: 0.8862 - f1_score: 0.9335 - val_loss: 0.6011 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 512/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6186 - acc: 0.9383 - precision: 0.9884 - recall: 0.8896 - f1_score: 0.9352 - val_loss: 0.5990 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6166 - acc: 0.9383 - precision: 0.9896 - recall: 0.8784 - f1_score: 0.9283 - val_loss: 0.5970 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 514/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6145 - acc: 0.9383 - precision: 0.9843 - recall: 0.8778 - f1_score: 0.9266 - val_loss: 0.5949 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 515/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6125 - acc: 0.9383 - precision: 0.9892 - recall: 0.8820 - f1_score: 0.9319 - val_loss: 0.5929 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 516/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6104 - acc: 0.9383 - precision: 0.9893 - recall: 0.8794 - f1_score: 0.9290 - val_loss: 0.5909 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 517/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6084 - acc: 0.9383 - precision: 0.9898 - recall: 0.8847 - f1_score: 0.9334 - val_loss: 0.5889 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 518/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6064 - acc: 0.9383 - precision: 0.9911 - recall: 0.8840 - f1_score: 0.9330 - val_loss: 0.5869 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 519/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6044 - acc: 0.9383 - precision: 0.9900 - recall: 0.8848 - f1_score: 0.9337 - val_loss: 0.5849 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 520/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6024 - acc: 0.9383 - precision: 0.9890 - recall: 0.8852 - f1_score: 0.9333 - val_loss: 0.5829 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 521/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6004 - acc: 0.9383 - precision: 0.9882 - recall: 0.8832 - f1_score: 0.9318 - val_loss: 0.5809 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 522/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5984 - acc: 0.9383 - precision: 0.9875 - recall: 0.8794 - f1_score: 0.9289 - val_loss: 0.5790 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 523/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.6048 - acc: 0.9309 - precision: 0.9858 - recall: 0.8703 - f1_score: 0.924 - 0s - loss: 0.5964 - acc: 0.9383 - precision: 0.9877 - recall: 0.8837 - f1_score: 0.9323 - val_loss: 0.5770 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 524/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5945 - acc: 0.9383 - precision: 0.9901 - recall: 0.8850 - f1_score: 0.9332 - val_loss: 0.5751 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 525/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5925 - acc: 0.9383 - precision: 0.9877 - recall: 0.8794 - f1_score: 0.9291 - val_loss: 0.5731 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 526/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5906 - acc: 0.9383 - precision: 0.9900 - recall: 0.8840 - f1_score: 0.9326 - val_loss: 0.5712 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 527/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5887 - acc: 0.9383 - precision: 0.9892 - recall: 0.8828 - f1_score: 0.9318 - val_loss: 0.5693 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 528/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5867 - acc: 0.9383 - precision: 0.9898 - recall: 0.8831 - f1_score: 0.9330 - val_loss: 0.5674 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 529/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5848 - acc: 0.9383 - precision: 0.9899 - recall: 0.8865 - f1_score: 0.9342 - val_loss: 0.5655 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 530/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5829 - acc: 0.9383 - precision: 0.9898 - recall: 0.8872 - f1_score: 0.9343 - val_loss: 0.5636 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 531/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5810 - acc: 0.9383 - precision: 0.9897 - recall: 0.8846 - f1_score: 0.9328 - val_loss: 0.5617 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 532/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5792 - acc: 0.9383 - precision: 0.9870 - recall: 0.8837 - f1_score: 0.9312 - val_loss: 0.5599 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 533/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5773 - acc: 0.9383 - precision: 0.9895 - recall: 0.8801 - f1_score: 0.9306 - val_loss: 0.5580 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 534/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5754 - acc: 0.9383 - precision: 0.9878 - recall: 0.8838 - f1_score: 0.9322 - val_loss: 0.5561 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 535/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5736 - acc: 0.9383 - precision: 0.9888 - recall: 0.8841 - f1_score: 0.9324 - val_loss: 0.5543 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 536/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5717 - acc: 0.9383 - precision: 0.9911 - recall: 0.8828 - f1_score: 0.9324 - val_loss: 0.5525 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 537/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5699 - acc: 0.9383 - precision: 0.9894 - recall: 0.8843 - f1_score: 0.9328 - val_loss: 0.5507 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 538/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5681 - acc: 0.9383 - precision: 0.9890 - recall: 0.8853 - f1_score: 0.9321 - val_loss: 0.5488 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 539/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5663 - acc: 0.9383 - precision: 0.9900 - recall: 0.8878 - f1_score: 0.9339 - val_loss: 0.5470 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 540/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5644 - acc: 0.9383 - precision: 0.9894 - recall: 0.8842 - f1_score: 0.9335 - val_loss: 0.5452 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 541/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5626 - acc: 0.9383 - precision: 0.9873 - recall: 0.8807 - f1_score: 0.9298 - val_loss: 0.5435 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 542/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5608 - acc: 0.9383 - precision: 0.9893 - recall: 0.8811 - f1_score: 0.9315 - val_loss: 0.5417 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 543/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5591 - acc: 0.9383 - precision: 0.9886 - recall: 0.8826 - f1_score: 0.9305 - val_loss: 0.5399 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 544/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5573 - acc: 0.9383 - precision: 0.9905 - recall: 0.8806 - f1_score: 0.9313 - val_loss: 0.5382 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.5555 - acc: 0.9383 - precision: 0.9882 - recall: 0.8838 - f1_score: 0.9327 - val_loss: 0.5364 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 546/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5538 - acc: 0.9383 - precision: 0.9886 - recall: 0.8803 - f1_score: 0.9300 - val_loss: 0.5347 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 547/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5520 - acc: 0.9383 - precision: 0.9895 - recall: 0.8840 - f1_score: 0.9323 - val_loss: 0.5329 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 548/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5503 - acc: 0.9383 - precision: 0.9895 - recall: 0.8770 - f1_score: 0.9285 - val_loss: 0.5312 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 549/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5486 - acc: 0.9383 - precision: 0.9885 - recall: 0.8832 - f1_score: 0.9320 - val_loss: 0.5295 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 550/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5469 - acc: 0.9383 - precision: 0.9889 - recall: 0.8849 - f1_score: 0.9320 - val_loss: 0.5278 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 551/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5451 - acc: 0.9383 - precision: 0.9891 - recall: 0.8812 - f1_score: 0.9308 - val_loss: 0.5261 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 552/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5434 - acc: 0.9383 - precision: 0.9877 - recall: 0.8778 - f1_score: 0.9283 - val_loss: 0.5244 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 553/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5417 - acc: 0.9383 - precision: 0.9877 - recall: 0.8825 - f1_score: 0.9315 - val_loss: 0.5227 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 554/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5401 - acc: 0.9383 - precision: 0.9889 - recall: 0.8847 - f1_score: 0.9328 - val_loss: 0.5210 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 555/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5384 - acc: 0.9383 - precision: 0.9898 - recall: 0.8867 - f1_score: 0.9346 - val_loss: 0.5194 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 556/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5367 - acc: 0.9383 - precision: 0.9890 - recall: 0.8805 - f1_score: 0.9307 - val_loss: 0.5177 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 557/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5350 - acc: 0.9383 - precision: 0.9878 - recall: 0.8823 - f1_score: 0.9305 - val_loss: 0.5161 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 558/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5334 - acc: 0.9383 - precision: 0.9900 - recall: 0.8830 - f1_score: 0.9327 - val_loss: 0.5144 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 559/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5317 - acc: 0.9383 - precision: 0.9888 - recall: 0.8811 - f1_score: 0.9311 - val_loss: 0.5128 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 560/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5301 - acc: 0.9383 - precision: 0.9902 - recall: 0.8844 - f1_score: 0.9331 - val_loss: 0.5112 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 561/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5285 - acc: 0.9383 - precision: 0.9889 - recall: 0.8821 - f1_score: 0.9308 - val_loss: 0.5096 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 562/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5269 - acc: 0.9383 - precision: 0.9892 - recall: 0.8837 - f1_score: 0.9322 - val_loss: 0.5080 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 563/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5252 - acc: 0.9383 - precision: 0.9878 - recall: 0.8812 - f1_score: 0.9304 - val_loss: 0.5064 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 564/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5236 - acc: 0.9383 - precision: 0.9889 - recall: 0.8840 - f1_score: 0.9329 - val_loss: 0.5048 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 565/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5220 - acc: 0.9383 - precision: 0.9874 - recall: 0.8839 - f1_score: 0.9317 - val_loss: 0.5032 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 566/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5205 - acc: 0.9383 - precision: 0.9909 - recall: 0.8849 - f1_score: 0.9342 - val_loss: 0.5016 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 567/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5189 - acc: 0.9383 - precision: 0.9890 - recall: 0.8868 - f1_score: 0.9341 - val_loss: 0.5000 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 568/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5173 - acc: 0.9383 - precision: 0.9901 - recall: 0.8796 - f1_score: 0.9294 - val_loss: 0.4985 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 569/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5157 - acc: 0.9383 - precision: 0.9901 - recall: 0.8851 - f1_score: 0.9338 - val_loss: 0.4969 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 570/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5142 - acc: 0.9383 - precision: 0.9892 - recall: 0.8875 - f1_score: 0.9347 - val_loss: 0.4954 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 571/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5126 - acc: 0.9383 - precision: 0.9900 - recall: 0.8845 - f1_score: 0.9332 - val_loss: 0.4938 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 572/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5111 - acc: 0.9383 - precision: 0.9884 - recall: 0.8866 - f1_score: 0.9338 - val_loss: 0.4923 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 573/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5095 - acc: 0.9383 - precision: 0.9875 - recall: 0.8837 - f1_score: 0.9315 - val_loss: 0.4908 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 574/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5080 - acc: 0.9383 - precision: 0.9895 - recall: 0.8829 - f1_score: 0.9321 - val_loss: 0.4893 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 575/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5065 - acc: 0.9383 - precision: 0.9885 - recall: 0.8832 - f1_score: 0.9319 - val_loss: 0.4878 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 576/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5050 - acc: 0.9383 - precision: 0.9873 - recall: 0.8783 - f1_score: 0.9281 - val_loss: 0.4863 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.5035 - acc: 0.9383 - precision: 0.9883 - recall: 0.8834 - f1_score: 0.9319 - val_loss: 0.4848 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 578/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5020 - acc: 0.9383 - precision: 0.9893 - recall: 0.8789 - f1_score: 0.9295 - val_loss: 0.4833 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 579/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5005 - acc: 0.9383 - precision: 0.9881 - recall: 0.8824 - f1_score: 0.9311 - val_loss: 0.4818 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 580/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4990 - acc: 0.9383 - precision: 0.9903 - recall: 0.8843 - f1_score: 0.9335 - val_loss: 0.4803 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 581/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4975 - acc: 0.9383 - precision: 0.9893 - recall: 0.8800 - f1_score: 0.9297 - val_loss: 0.4789 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 582/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4961 - acc: 0.9383 - precision: 0.9892 - recall: 0.8806 - f1_score: 0.9297 - val_loss: 0.4774 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 583/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4946 - acc: 0.9383 - precision: 0.9899 - recall: 0.8832 - f1_score: 0.9322 - val_loss: 0.4760 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 584/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4931 - acc: 0.9383 - precision: 0.9902 - recall: 0.8821 - f1_score: 0.9311 - val_loss: 0.4745 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 585/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4917 - acc: 0.9383 - precision: 0.9899 - recall: 0.8820 - f1_score: 0.9309 - val_loss: 0.4731 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 586/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4903 - acc: 0.9383 - precision: 0.9880 - recall: 0.8855 - f1_score: 0.9304 - val_loss: 0.4717 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 587/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4888 - acc: 0.9383 - precision: 0.9904 - recall: 0.8817 - f1_score: 0.9312 - val_loss: 0.4702 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 588/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4874 - acc: 0.9383 - precision: 0.9879 - recall: 0.8905 - f1_score: 0.9339 - val_loss: 0.4688 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 589/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4860 - acc: 0.9383 - precision: 0.9894 - recall: 0.8833 - f1_score: 0.9324 - val_loss: 0.4674 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 590/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4846 - acc: 0.9383 - precision: 0.9895 - recall: 0.8864 - f1_score: 0.9341 - val_loss: 0.4660 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 591/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4832 - acc: 0.9383 - precision: 0.9907 - recall: 0.8833 - f1_score: 0.9333 - val_loss: 0.4646 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 592/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4818 - acc: 0.9383 - precision: 0.9889 - recall: 0.8836 - f1_score: 0.9328 - val_loss: 0.4632 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 593/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4804 - acc: 0.9383 - precision: 0.9876 - recall: 0.8809 - f1_score: 0.9300 - val_loss: 0.4618 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 594/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4790 - acc: 0.9383 - precision: 0.9908 - recall: 0.8832 - f1_score: 0.9330 - val_loss: 0.4605 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 595/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4776 - acc: 0.9383 - precision: 0.9889 - recall: 0.8786 - f1_score: 0.9276 - val_loss: 0.4591 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 596/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4762 - acc: 0.9383 - precision: 0.9900 - recall: 0.8858 - f1_score: 0.9333 - val_loss: 0.4578 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 597/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4749 - acc: 0.9383 - precision: 0.9898 - recall: 0.8820 - f1_score: 0.9310 - val_loss: 0.4564 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 598/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4735 - acc: 0.9383 - precision: 0.9872 - recall: 0.8821 - f1_score: 0.9310 - val_loss: 0.4551 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 599/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4722 - acc: 0.9383 - precision: 0.9899 - recall: 0.8823 - f1_score: 0.9321 - val_loss: 0.4537 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 600/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4708 - acc: 0.9383 - precision: 0.9895 - recall: 0.8832 - f1_score: 0.9322 - val_loss: 0.4524 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 601/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4695 - acc: 0.9383 - precision: 0.9880 - recall: 0.8845 - f1_score: 0.9323 - val_loss: 0.4510 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 602/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4681 - acc: 0.9383 - precision: 0.9899 - recall: 0.8832 - f1_score: 0.9324 - val_loss: 0.4497 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 603/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4668 - acc: 0.9383 - precision: 0.9858 - recall: 0.8852 - f1_score: 0.9309 - val_loss: 0.4484 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 604/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4655 - acc: 0.9383 - precision: 0.9866 - recall: 0.8805 - f1_score: 0.9298 - val_loss: 0.4471 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 605/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4642 - acc: 0.9383 - precision: 0.9889 - recall: 0.8842 - f1_score: 0.9312 - val_loss: 0.4458 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 606/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4629 - acc: 0.9383 - precision: 0.9905 - recall: 0.8864 - f1_score: 0.9343 - val_loss: 0.4445 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 607/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4616 - acc: 0.9383 - precision: 0.9870 - recall: 0.8823 - f1_score: 0.9307 - val_loss: 0.4432 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 608/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4603 - acc: 0.9383 - precision: 0.9876 - recall: 0.8832 - f1_score: 0.9309 - val_loss: 0.4419 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4590 - acc: 0.9383 - precision: 0.9892 - recall: 0.8865 - f1_score: 0.9338 - val_loss: 0.4407 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 610/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4577 - acc: 0.9383 - precision: 0.9894 - recall: 0.8824 - f1_score: 0.9317 - val_loss: 0.4394 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 611/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4564 - acc: 0.9383 - precision: 0.9887 - recall: 0.8777 - f1_score: 0.9278 - val_loss: 0.4381 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 612/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4552 - acc: 0.9383 - precision: 0.9888 - recall: 0.8864 - f1_score: 0.9331 - val_loss: 0.4369 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 613/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4539 - acc: 0.9383 - precision: 0.9879 - recall: 0.8802 - f1_score: 0.9299 - val_loss: 0.4356 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 614/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4527 - acc: 0.9383 - precision: 0.9901 - recall: 0.8740 - f1_score: 0.9245 - val_loss: 0.4344 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 615/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4514 - acc: 0.9383 - precision: 0.9890 - recall: 0.8852 - f1_score: 0.9327 - val_loss: 0.4331 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 616/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4502 - acc: 0.9383 - precision: 0.9888 - recall: 0.8870 - f1_score: 0.9340 - val_loss: 0.4319 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 617/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4489 - acc: 0.9383 - precision: 0.9884 - recall: 0.8820 - f1_score: 0.9309 - val_loss: 0.4307 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 618/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4477 - acc: 0.9383 - precision: 0.9887 - recall: 0.8819 - f1_score: 0.9314 - val_loss: 0.4295 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 619/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4465 - acc: 0.9383 - precision: 0.9892 - recall: 0.8873 - f1_score: 0.9346 - val_loss: 0.4282 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 620/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4452 - acc: 0.9383 - precision: 0.9887 - recall: 0.8865 - f1_score: 0.9336 - val_loss: 0.4270 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 621/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4440 - acc: 0.9383 - precision: 0.9887 - recall: 0.8829 - f1_score: 0.9311 - val_loss: 0.4258 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 622/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4428 - acc: 0.9383 - precision: 0.9885 - recall: 0.8860 - f1_score: 0.9338 - val_loss: 0.4246 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 623/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4416 - acc: 0.9383 - precision: 0.9889 - recall: 0.8858 - f1_score: 0.9329 - val_loss: 0.4235 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 624/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4404 - acc: 0.9383 - precision: 0.9881 - recall: 0.8817 - f1_score: 0.9314 - val_loss: 0.4223 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 625/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4392 - acc: 0.9383 - precision: 0.9896 - recall: 0.8829 - f1_score: 0.9321 - val_loss: 0.4211 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 626/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4381 - acc: 0.9383 - precision: 0.9886 - recall: 0.8861 - f1_score: 0.9339 - val_loss: 0.4199 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 627/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4369 - acc: 0.9383 - precision: 0.9904 - recall: 0.8817 - f1_score: 0.9317 - val_loss: 0.4187 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 628/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4357 - acc: 0.9383 - precision: 0.9890 - recall: 0.8870 - f1_score: 0.9344 - val_loss: 0.4176 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 629/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4345 - acc: 0.9383 - precision: 0.9893 - recall: 0.8862 - f1_score: 0.9335 - val_loss: 0.4164 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 630/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4334 - acc: 0.9383 - precision: 0.9901 - recall: 0.8903 - f1_score: 0.9365 - val_loss: 0.4153 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 631/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4322 - acc: 0.9383 - precision: 0.9885 - recall: 0.8868 - f1_score: 0.9340 - val_loss: 0.4141 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 632/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4311 - acc: 0.9383 - precision: 0.9890 - recall: 0.8832 - f1_score: 0.9323 - val_loss: 0.4130 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 633/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4299 - acc: 0.9383 - precision: 0.9899 - recall: 0.8827 - f1_score: 0.9313 - val_loss: 0.4118 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 634/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4288 - acc: 0.9383 - precision: 0.9886 - recall: 0.8835 - f1_score: 0.9314 - val_loss: 0.4107 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 635/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4277 - acc: 0.9383 - precision: 0.9899 - recall: 0.8815 - f1_score: 0.9315 - val_loss: 0.4096 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 636/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4265 - acc: 0.9383 - precision: 0.9896 - recall: 0.8879 - f1_score: 0.9346 - val_loss: 0.4085 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 637/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4254 - acc: 0.9383 - precision: 0.9902 - recall: 0.8871 - f1_score: 0.9342 - val_loss: 0.4074 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 638/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4243 - acc: 0.9383 - precision: 0.9870 - recall: 0.8838 - f1_score: 0.9312 - val_loss: 0.4063 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 639/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4232 - acc: 0.9383 - precision: 0.9878 - recall: 0.8845 - f1_score: 0.9319 - val_loss: 0.4052 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 640/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4221 - acc: 0.9383 - precision: 0.9891 - recall: 0.8832 - f1_score: 0.9323 - val_loss: 0.4041 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4210 - acc: 0.9383 - precision: 0.9891 - recall: 0.8828 - f1_score: 0.9316 - val_loss: 0.4030 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 642/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4199 - acc: 0.9383 - precision: 0.9905 - recall: 0.8851 - f1_score: 0.9338 - val_loss: 0.4019 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 643/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4188 - acc: 0.9383 - precision: 0.9887 - recall: 0.8788 - f1_score: 0.9289 - val_loss: 0.4008 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 644/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4177 - acc: 0.9383 - precision: 0.9887 - recall: 0.8834 - f1_score: 0.9320 - val_loss: 0.3997 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 645/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4166 - acc: 0.9383 - precision: 0.9911 - recall: 0.8803 - f1_score: 0.9308 - val_loss: 0.3986 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 646/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4155 - acc: 0.9383 - precision: 0.9885 - recall: 0.8838 - f1_score: 0.9321 - val_loss: 0.3976 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 647/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4145 - acc: 0.9383 - precision: 0.9892 - recall: 0.8808 - f1_score: 0.9309 - val_loss: 0.3965 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 648/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4134 - acc: 0.9383 - precision: 0.9885 - recall: 0.8815 - f1_score: 0.9311 - val_loss: 0.3954 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 649/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4123 - acc: 0.9383 - precision: 0.9863 - recall: 0.8808 - f1_score: 0.9293 - val_loss: 0.3944 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 650/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4113 - acc: 0.9383 - precision: 0.9904 - recall: 0.8780 - f1_score: 0.9296 - val_loss: 0.3934 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 651/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4102 - acc: 0.9383 - precision: 0.9890 - recall: 0.8883 - f1_score: 0.9351 - val_loss: 0.3923 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 652/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4092 - acc: 0.9383 - precision: 0.9909 - recall: 0.8825 - f1_score: 0.9321 - val_loss: 0.3913 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 653/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4082 - acc: 0.9383 - precision: 0.9878 - recall: 0.8831 - f1_score: 0.9314 - val_loss: 0.3902 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 654/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4071 - acc: 0.9383 - precision: 0.9898 - recall: 0.8843 - f1_score: 0.9323 - val_loss: 0.3892 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 655/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4061 - acc: 0.9383 - precision: 0.9892 - recall: 0.8885 - f1_score: 0.9345 - val_loss: 0.3882 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 656/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4051 - acc: 0.9383 - precision: 0.9882 - recall: 0.8843 - f1_score: 0.9326 - val_loss: 0.3872 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 657/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4040 - acc: 0.9383 - precision: 0.9885 - recall: 0.8831 - f1_score: 0.9320 - val_loss: 0.3862 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 658/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4030 - acc: 0.9383 - precision: 0.9876 - recall: 0.8808 - f1_score: 0.9299 - val_loss: 0.3852 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 659/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4020 - acc: 0.9383 - precision: 0.9891 - recall: 0.8846 - f1_score: 0.9327 - val_loss: 0.3842 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 660/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4010 - acc: 0.9383 - precision: 0.9871 - recall: 0.8842 - f1_score: 0.9313 - val_loss: 0.3832 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 661/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4000 - acc: 0.9383 - precision: 0.9906 - recall: 0.8827 - f1_score: 0.9323 - val_loss: 0.3822 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 662/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3990 - acc: 0.9383 - precision: 0.9874 - recall: 0.8821 - f1_score: 0.9305 - val_loss: 0.3812 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 663/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3980 - acc: 0.9383 - precision: 0.9884 - recall: 0.8807 - f1_score: 0.9298 - val_loss: 0.3802 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 664/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3971 - acc: 0.9383 - precision: 0.9885 - recall: 0.8882 - f1_score: 0.9337 - val_loss: 0.3792 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 665/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3961 - acc: 0.9383 - precision: 0.9894 - recall: 0.8800 - f1_score: 0.9310 - val_loss: 0.3782 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 666/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3951 - acc: 0.9383 - precision: 0.9885 - recall: 0.8852 - f1_score: 0.9333 - val_loss: 0.3773 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 667/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3941 - acc: 0.9383 - precision: 0.9901 - recall: 0.8857 - f1_score: 0.9337 - val_loss: 0.3763 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 668/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3932 - acc: 0.9383 - precision: 0.9890 - recall: 0.8840 - f1_score: 0.9328 - val_loss: 0.3753 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 669/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3922 - acc: 0.9383 - precision: 0.9883 - recall: 0.8816 - f1_score: 0.9306 - val_loss: 0.3744 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 670/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3912 - acc: 0.9383 - precision: 0.9901 - recall: 0.8844 - f1_score: 0.9332 - val_loss: 0.3734 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 671/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3903 - acc: 0.9383 - precision: 0.9892 - recall: 0.8833 - f1_score: 0.9324 - val_loss: 0.3725 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 672/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3893 - acc: 0.9383 - precision: 0.9902 - recall: 0.8813 - f1_score: 0.9301 - val_loss: 0.3715 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3884 - acc: 0.9383 - precision: 0.9900 - recall: 0.8860 - f1_score: 0.9343 - val_loss: 0.3706 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 674/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3874 - acc: 0.9383 - precision: 0.9884 - recall: 0.8855 - f1_score: 0.9332 - val_loss: 0.3697 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 675/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3865 - acc: 0.9383 - precision: 0.9887 - recall: 0.8757 - f1_score: 0.9266 - val_loss: 0.3687 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 676/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3856 - acc: 0.9383 - precision: 0.9892 - recall: 0.8864 - f1_score: 0.9337 - val_loss: 0.3678 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 677/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3847 - acc: 0.9383 - precision: 0.9911 - recall: 0.8779 - f1_score: 0.9296 - val_loss: 0.3669 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 678/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3837 - acc: 0.9383 - precision: 0.9896 - recall: 0.8801 - f1_score: 0.9302 - val_loss: 0.3660 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 679/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3828 - acc: 0.9383 - precision: 0.9882 - recall: 0.8782 - f1_score: 0.9286 - val_loss: 0.3651 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 680/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3819 - acc: 0.9383 - precision: 0.9877 - recall: 0.8784 - f1_score: 0.9291 - val_loss: 0.3642 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 681/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3810 - acc: 0.9383 - precision: 0.9890 - recall: 0.8859 - f1_score: 0.9339 - val_loss: 0.3633 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 682/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3801 - acc: 0.9383 - precision: 0.9890 - recall: 0.8810 - f1_score: 0.9303 - val_loss: 0.3624 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 683/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3792 - acc: 0.9383 - precision: 0.9892 - recall: 0.8823 - f1_score: 0.9321 - val_loss: 0.3615 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 684/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3783 - acc: 0.9383 - precision: 0.9882 - recall: 0.8834 - f1_score: 0.9324 - val_loss: 0.3606 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 685/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3774 - acc: 0.9383 - precision: 0.9877 - recall: 0.8823 - f1_score: 0.9308 - val_loss: 0.3597 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 686/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3765 - acc: 0.9383 - precision: 0.9891 - recall: 0.8800 - f1_score: 0.9298 - val_loss: 0.3588 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 687/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3756 - acc: 0.9383 - precision: 0.9888 - recall: 0.8822 - f1_score: 0.9307 - val_loss: 0.3579 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 688/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3748 - acc: 0.9383 - precision: 0.9902 - recall: 0.8823 - f1_score: 0.9319 - val_loss: 0.3571 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 689/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3739 - acc: 0.9383 - precision: 0.9902 - recall: 0.8822 - f1_score: 0.9325 - val_loss: 0.3562 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 690/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3730 - acc: 0.9383 - precision: 0.9890 - recall: 0.8868 - f1_score: 0.9330 - val_loss: 0.3553 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 691/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3721 - acc: 0.9383 - precision: 0.9895 - recall: 0.8855 - f1_score: 0.9328 - val_loss: 0.3544 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 692/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3713 - acc: 0.9383 - precision: 0.9886 - recall: 0.8844 - f1_score: 0.9327 - val_loss: 0.3536 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 693/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3704 - acc: 0.9383 - precision: 0.9909 - recall: 0.8791 - f1_score: 0.9291 - val_loss: 0.3527 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 694/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3696 - acc: 0.9383 - precision: 0.9890 - recall: 0.8847 - f1_score: 0.9324 - val_loss: 0.3519 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 695/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3687 - acc: 0.9383 - precision: 0.9890 - recall: 0.8842 - f1_score: 0.9331 - val_loss: 0.3510 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 696/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3679 - acc: 0.9383 - precision: 0.9906 - recall: 0.8873 - f1_score: 0.9354 - val_loss: 0.3502 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 697/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3670 - acc: 0.9383 - precision: 0.9879 - recall: 0.8827 - f1_score: 0.9302 - val_loss: 0.3494 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 698/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3662 - acc: 0.9383 - precision: 0.9878 - recall: 0.8913 - f1_score: 0.9357 - val_loss: 0.3485 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 699/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3654 - acc: 0.9383 - precision: 0.9895 - recall: 0.8824 - f1_score: 0.9320 - val_loss: 0.3477 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 700/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3645 - acc: 0.9383 - precision: 0.9868 - recall: 0.8819 - f1_score: 0.9300 - val_loss: 0.3469 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 701/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3637 - acc: 0.9383 - precision: 0.9891 - recall: 0.8840 - f1_score: 0.9324 - val_loss: 0.3461 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 702/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3629 - acc: 0.9383 - precision: 0.9888 - recall: 0.8865 - f1_score: 0.9337 - val_loss: 0.3453 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 703/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3621 - acc: 0.9383 - precision: 0.9883 - recall: 0.8850 - f1_score: 0.9329 - val_loss: 0.3444 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 704/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3612 - acc: 0.9383 - precision: 0.9901 - recall: 0.8831 - f1_score: 0.9318 - val_loss: 0.3436 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3604 - acc: 0.9383 - precision: 0.9891 - recall: 0.8856 - f1_score: 0.9335 - val_loss: 0.3428 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 706/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3596 - acc: 0.9383 - precision: 0.9892 - recall: 0.8807 - f1_score: 0.9310 - val_loss: 0.3420 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 707/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3588 - acc: 0.9383 - precision: 0.9899 - recall: 0.8834 - f1_score: 0.9328 - val_loss: 0.3412 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 708/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3580 - acc: 0.9383 - precision: 0.9895 - recall: 0.8809 - f1_score: 0.9306 - val_loss: 0.3404 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 709/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3572 - acc: 0.9383 - precision: 0.9896 - recall: 0.8839 - f1_score: 0.9328 - val_loss: 0.3396 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 710/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3564 - acc: 0.9383 - precision: 0.9886 - recall: 0.8830 - f1_score: 0.9314 - val_loss: 0.3389 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 711/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3557 - acc: 0.9383 - precision: 0.9898 - recall: 0.8851 - f1_score: 0.9322 - val_loss: 0.3381 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 712/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3549 - acc: 0.9383 - precision: 0.9887 - recall: 0.8804 - f1_score: 0.9301 - val_loss: 0.3373 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 713/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3541 - acc: 0.9383 - precision: 0.9891 - recall: 0.8862 - f1_score: 0.9337 - val_loss: 0.3365 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 714/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3533 - acc: 0.9383 - precision: 0.9893 - recall: 0.8861 - f1_score: 0.9329 - val_loss: 0.3358 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 715/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3525 - acc: 0.9383 - precision: 0.9892 - recall: 0.8869 - f1_score: 0.9337 - val_loss: 0.3350 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 716/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3518 - acc: 0.9383 - precision: 0.9886 - recall: 0.8855 - f1_score: 0.9330 - val_loss: 0.3342 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 717/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3510 - acc: 0.9383 - precision: 0.9900 - recall: 0.8827 - f1_score: 0.9317 - val_loss: 0.3335 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 718/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3502 - acc: 0.9383 - precision: 0.9886 - recall: 0.8833 - f1_score: 0.9314 - val_loss: 0.3327 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 719/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3495 - acc: 0.9383 - precision: 0.9885 - recall: 0.8812 - f1_score: 0.9307 - val_loss: 0.3320 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 720/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3487 - acc: 0.9383 - precision: 0.9912 - recall: 0.8798 - f1_score: 0.9303 - val_loss: 0.3312 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 721/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3480 - acc: 0.9383 - precision: 0.9912 - recall: 0.8824 - f1_score: 0.9315 - val_loss: 0.3305 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 722/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3472 - acc: 0.9383 - precision: 0.9884 - recall: 0.8853 - f1_score: 0.9332 - val_loss: 0.3297 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 723/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3465 - acc: 0.9383 - precision: 0.9898 - recall: 0.8835 - f1_score: 0.9323 - val_loss: 0.3290 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 724/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3457 - acc: 0.9383 - precision: 0.9885 - recall: 0.8825 - f1_score: 0.9312 - val_loss: 0.3282 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 725/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3450 - acc: 0.9383 - precision: 0.9885 - recall: 0.8853 - f1_score: 0.9330 - val_loss: 0.3275 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 726/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3443 - acc: 0.9383 - precision: 0.9890 - recall: 0.8826 - f1_score: 0.9321 - val_loss: 0.3268 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 727/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3436 - acc: 0.9383 - precision: 0.9909 - recall: 0.8836 - f1_score: 0.9325 - val_loss: 0.3260 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 728/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3428 - acc: 0.9383 - precision: 0.9906 - recall: 0.8832 - f1_score: 0.9318 - val_loss: 0.3253 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 729/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3421 - acc: 0.9383 - precision: 0.9887 - recall: 0.8820 - f1_score: 0.9312 - val_loss: 0.3246 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 730/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3414 - acc: 0.9383 - precision: 0.9904 - recall: 0.8817 - f1_score: 0.9311 - val_loss: 0.3239 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 731/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3407 - acc: 0.9383 - precision: 0.9897 - recall: 0.8825 - f1_score: 0.9325 - val_loss: 0.3232 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 732/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3399 - acc: 0.9383 - precision: 0.9878 - recall: 0.8809 - f1_score: 0.9307 - val_loss: 0.3225 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 733/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3392 - acc: 0.9383 - precision: 0.9883 - recall: 0.8809 - f1_score: 0.9306 - val_loss: 0.3218 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 734/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3385 - acc: 0.9383 - precision: 0.9882 - recall: 0.8776 - f1_score: 0.9283 - val_loss: 0.3211 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 735/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3378 - acc: 0.9383 - precision: 0.9888 - recall: 0.8827 - f1_score: 0.9319 - val_loss: 0.3204 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 736/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3371 - acc: 0.9383 - precision: 0.9889 - recall: 0.8858 - f1_score: 0.9333 - val_loss: 0.3197 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3364 - acc: 0.9383 - precision: 0.9887 - recall: 0.8848 - f1_score: 0.9329 - val_loss: 0.3190 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 738/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3358 - acc: 0.9383 - precision: 0.9899 - recall: 0.8848 - f1_score: 0.9339 - val_loss: 0.3183 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 739/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3351 - acc: 0.9383 - precision: 0.9904 - recall: 0.8874 - f1_score: 0.9345 - val_loss: 0.3176 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 740/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3344 - acc: 0.9383 - precision: 0.9896 - recall: 0.8829 - f1_score: 0.9323 - val_loss: 0.3169 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 741/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3337 - acc: 0.9383 - precision: 0.9883 - recall: 0.8835 - f1_score: 0.9321 - val_loss: 0.3162 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 742/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3330 - acc: 0.9383 - precision: 0.9905 - recall: 0.8839 - f1_score: 0.9330 - val_loss: 0.3156 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 743/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3323 - acc: 0.9383 - precision: 0.9868 - recall: 0.8870 - f1_score: 0.9326 - val_loss: 0.3149 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 744/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3317 - acc: 0.9383 - precision: 0.9872 - recall: 0.8790 - f1_score: 0.9290 - val_loss: 0.3142 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 745/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3310 - acc: 0.9383 - precision: 0.9898 - recall: 0.8841 - f1_score: 0.9313 - val_loss: 0.3135 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 746/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3303 - acc: 0.9383 - precision: 0.9899 - recall: 0.8849 - f1_score: 0.9341 - val_loss: 0.3129 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 747/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3297 - acc: 0.9383 - precision: 0.9913 - recall: 0.8752 - f1_score: 0.9267 - val_loss: 0.3122 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 748/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3290 - acc: 0.9383 - precision: 0.9901 - recall: 0.8877 - f1_score: 0.9340 - val_loss: 0.3116 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 749/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3283 - acc: 0.9383 - precision: 0.9871 - recall: 0.8869 - f1_score: 0.9332 - val_loss: 0.3109 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 750/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3277 - acc: 0.9383 - precision: 0.9900 - recall: 0.8815 - f1_score: 0.9302 - val_loss: 0.3103 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 751/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3270 - acc: 0.9383 - precision: 0.9881 - recall: 0.8791 - f1_score: 0.9291 - val_loss: 0.3096 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 752/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3264 - acc: 0.9383 - precision: 0.9880 - recall: 0.8814 - f1_score: 0.9298 - val_loss: 0.3090 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 753/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3257 - acc: 0.9383 - precision: 0.9898 - recall: 0.8819 - f1_score: 0.9315 - val_loss: 0.3083 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 754/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3251 - acc: 0.9383 - precision: 0.9868 - recall: 0.8797 - f1_score: 0.9293 - val_loss: 0.3077 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 755/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3244 - acc: 0.9383 - precision: 0.9870 - recall: 0.8833 - f1_score: 0.9315 - val_loss: 0.3071 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 756/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3238 - acc: 0.9383 - precision: 0.9885 - recall: 0.8865 - f1_score: 0.9331 - val_loss: 0.3064 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 757/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3232 - acc: 0.9383 - precision: 0.9890 - recall: 0.8821 - f1_score: 0.9319 - val_loss: 0.3058 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 758/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3225 - acc: 0.9383 - precision: 0.9876 - recall: 0.8832 - f1_score: 0.9322 - val_loss: 0.3052 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 759/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3219 - acc: 0.9383 - precision: 0.9897 - recall: 0.8848 - f1_score: 0.9328 - val_loss: 0.3045 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 760/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3213 - acc: 0.9383 - precision: 0.9901 - recall: 0.8858 - f1_score: 0.9339 - val_loss: 0.3039 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 761/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3207 - acc: 0.9383 - precision: 0.9906 - recall: 0.8815 - f1_score: 0.9314 - val_loss: 0.3033 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 762/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3200 - acc: 0.9383 - precision: 0.9903 - recall: 0.8846 - f1_score: 0.9315 - val_loss: 0.3027 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 763/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3194 - acc: 0.9383 - precision: 0.9901 - recall: 0.8810 - f1_score: 0.9305 - val_loss: 0.3021 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 764/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3188 - acc: 0.9383 - precision: 0.9884 - recall: 0.8804 - f1_score: 0.9303 - val_loss: 0.3015 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 765/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3182 - acc: 0.9383 - precision: 0.9900 - recall: 0.8836 - f1_score: 0.9323 - val_loss: 0.3009 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 766/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3176 - acc: 0.9383 - precision: 0.9885 - recall: 0.8761 - f1_score: 0.9260 - val_loss: 0.3003 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 767/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3170 - acc: 0.9383 - precision: 0.9896 - recall: 0.8841 - f1_score: 0.9335 - val_loss: 0.2997 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 768/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3164 - acc: 0.9383 - precision: 0.9899 - recall: 0.8802 - f1_score: 0.9310 - val_loss: 0.2991 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3158 - acc: 0.9383 - precision: 0.9894 - recall: 0.8831 - f1_score: 0.9299 - val_loss: 0.2985 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 770/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3152 - acc: 0.9383 - precision: 0.9900 - recall: 0.8847 - f1_score: 0.9321 - val_loss: 0.2979 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 771/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3146 - acc: 0.9383 - precision: 0.9896 - recall: 0.8825 - f1_score: 0.9312 - val_loss: 0.2973 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 772/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3140 - acc: 0.9383 - precision: 0.9892 - recall: 0.8829 - f1_score: 0.9305 - val_loss: 0.2967 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 773/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3134 - acc: 0.9383 - precision: 0.9893 - recall: 0.8875 - f1_score: 0.9338 - val_loss: 0.2961 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 774/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3128 - acc: 0.9383 - precision: 0.9883 - recall: 0.8875 - f1_score: 0.9330 - val_loss: 0.2955 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 775/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3123 - acc: 0.9383 - precision: 0.9896 - recall: 0.8840 - f1_score: 0.9326 - val_loss: 0.2949 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 776/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3117 - acc: 0.9383 - precision: 0.9886 - recall: 0.8800 - f1_score: 0.9297 - val_loss: 0.2944 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 777/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3111 - acc: 0.9383 - precision: 0.9895 - recall: 0.8839 - f1_score: 0.9334 - val_loss: 0.2938 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 778/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3105 - acc: 0.9383 - precision: 0.9901 - recall: 0.8792 - f1_score: 0.9305 - val_loss: 0.2932 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 779/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3099 - acc: 0.9383 - precision: 0.9889 - recall: 0.8847 - f1_score: 0.9325 - val_loss: 0.2926 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 780/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3094 - acc: 0.9383 - precision: 0.9904 - recall: 0.8809 - f1_score: 0.9309 - val_loss: 0.2921 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 781/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3088 - acc: 0.9383 - precision: 0.9895 - recall: 0.8834 - f1_score: 0.9327 - val_loss: 0.2915 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 782/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3082 - acc: 0.9383 - precision: 0.9888 - recall: 0.8846 - f1_score: 0.9334 - val_loss: 0.2909 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 783/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3077 - acc: 0.9383 - precision: 0.9859 - recall: 0.8792 - f1_score: 0.9281 - val_loss: 0.2904 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 784/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3071 - acc: 0.9383 - precision: 0.9890 - recall: 0.8832 - f1_score: 0.9317 - val_loss: 0.2898 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 785/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3066 - acc: 0.9383 - precision: 0.9877 - recall: 0.8843 - f1_score: 0.9325 - val_loss: 0.2893 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 786/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3060 - acc: 0.9383 - precision: 0.9888 - recall: 0.8826 - f1_score: 0.9313 - val_loss: 0.2887 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 787/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3055 - acc: 0.9383 - precision: 0.9898 - recall: 0.8836 - f1_score: 0.9328 - val_loss: 0.2882 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 788/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3049 - acc: 0.9383 - precision: 0.9895 - recall: 0.8823 - f1_score: 0.9324 - val_loss: 0.2876 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 789/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3044 - acc: 0.9383 - precision: 0.9905 - recall: 0.8830 - f1_score: 0.9310 - val_loss: 0.2871 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 790/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3038 - acc: 0.9383 - precision: 0.9891 - recall: 0.8834 - f1_score: 0.9328 - val_loss: 0.2866 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 791/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3033 - acc: 0.9383 - precision: 0.9883 - recall: 0.8793 - f1_score: 0.9292 - val_loss: 0.2860 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 792/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3027 - acc: 0.9383 - precision: 0.9891 - recall: 0.8841 - f1_score: 0.9325 - val_loss: 0.2855 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 793/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3022 - acc: 0.9383 - precision: 0.9875 - recall: 0.8822 - f1_score: 0.9309 - val_loss: 0.2849 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 794/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3017 - acc: 0.9383 - precision: 0.9904 - recall: 0.8809 - f1_score: 0.9297 - val_loss: 0.2844 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 795/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3011 - acc: 0.9383 - precision: 0.9884 - recall: 0.8888 - f1_score: 0.9344 - val_loss: 0.2839 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 796/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3006 - acc: 0.9383 - precision: 0.9895 - recall: 0.8842 - f1_score: 0.9328 - val_loss: 0.2834 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 797/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3001 - acc: 0.9383 - precision: 0.9887 - recall: 0.8801 - f1_score: 0.9297 - val_loss: 0.2828 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 798/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2996 - acc: 0.9383 - precision: 0.9887 - recall: 0.8826 - f1_score: 0.9316 - val_loss: 0.2823 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 799/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2990 - acc: 0.9383 - precision: 0.9875 - recall: 0.8856 - f1_score: 0.9325 - val_loss: 0.2818 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 800/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2985 - acc: 0.9383 - precision: 0.9889 - recall: 0.8802 - f1_score: 0.9304 - val_loss: 0.2813 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2980 - acc: 0.9383 - precision: 0.9883 - recall: 0.8828 - f1_score: 0.9314 - val_loss: 0.2808 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 802/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2975 - acc: 0.9383 - precision: 0.9888 - recall: 0.8855 - f1_score: 0.9332 - val_loss: 0.2803 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 803/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2970 - acc: 0.9383 - precision: 0.9913 - recall: 0.8821 - f1_score: 0.9322 - val_loss: 0.2797 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 804/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2965 - acc: 0.9383 - precision: 0.9899 - recall: 0.8799 - f1_score: 0.9301 - val_loss: 0.2792 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 805/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2959 - acc: 0.9383 - precision: 0.9886 - recall: 0.8804 - f1_score: 0.9306 - val_loss: 0.2787 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 806/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2954 - acc: 0.9383 - precision: 0.9890 - recall: 0.8862 - f1_score: 0.9331 - val_loss: 0.2782 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 807/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2949 - acc: 0.9383 - precision: 0.9893 - recall: 0.8861 - f1_score: 0.9334 - val_loss: 0.2777 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 808/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2944 - acc: 0.9383 - precision: 0.9896 - recall: 0.8835 - f1_score: 0.9324 - val_loss: 0.2772 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 809/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2939 - acc: 0.9383 - precision: 0.9890 - recall: 0.8848 - f1_score: 0.9330 - val_loss: 0.2767 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 810/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2934 - acc: 0.9383 - precision: 0.9864 - recall: 0.8798 - f1_score: 0.9296 - val_loss: 0.2762 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 811/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2929 - acc: 0.9383 - precision: 0.9888 - recall: 0.8866 - f1_score: 0.9341 - val_loss: 0.2757 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 812/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2925 - acc: 0.9383 - precision: 0.9894 - recall: 0.8810 - f1_score: 0.9310 - val_loss: 0.2752 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 813/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2920 - acc: 0.9383 - precision: 0.9870 - recall: 0.8784 - f1_score: 0.9283 - val_loss: 0.2747 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 814/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2915 - acc: 0.9383 - precision: 0.9890 - recall: 0.8807 - f1_score: 0.9307 - val_loss: 0.2743 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 815/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2910 - acc: 0.9383 - precision: 0.9887 - recall: 0.8878 - f1_score: 0.9339 - val_loss: 0.2738 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 816/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2905 - acc: 0.9383 - precision: 0.9897 - recall: 0.8810 - f1_score: 0.9299 - val_loss: 0.2733 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 817/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2900 - acc: 0.9383 - precision: 0.9890 - recall: 0.8849 - f1_score: 0.9331 - val_loss: 0.2728 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 818/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2896 - acc: 0.9383 - precision: 0.9879 - recall: 0.8790 - f1_score: 0.9297 - val_loss: 0.2724 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 819/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2891 - acc: 0.9383 - precision: 0.9901 - recall: 0.8808 - f1_score: 0.9317 - val_loss: 0.2719 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 820/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2886 - acc: 0.9383 - precision: 0.9890 - recall: 0.8859 - f1_score: 0.9326 - val_loss: 0.2714 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 821/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2881 - acc: 0.9383 - precision: 0.9888 - recall: 0.8840 - f1_score: 0.9322 - val_loss: 0.2709 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 822/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2877 - acc: 0.9399 - precision: 0.9925 - recall: 0.8833 - f1_score: 0.9336 - val_loss: 0.2705 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 823/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2872 - acc: 0.9383 - precision: 0.9906 - recall: 0.8819 - f1_score: 0.9313 - val_loss: 0.2700 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 824/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2867 - acc: 0.9383 - precision: 0.9898 - recall: 0.8849 - f1_score: 0.9329 - val_loss: 0.2695 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 825/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2863 - acc: 0.9399 - precision: 0.9930 - recall: 0.8825 - f1_score: 0.9330 - val_loss: 0.2691 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 826/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2858 - acc: 0.9399 - precision: 0.9927 - recall: 0.8832 - f1_score: 0.9342 - val_loss: 0.2686 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 827/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2853 - acc: 0.9383 - precision: 0.9881 - recall: 0.8834 - f1_score: 0.9320 - val_loss: 0.2681 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 828/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2849 - acc: 0.9383 - precision: 0.9895 - recall: 0.8805 - f1_score: 0.9307 - val_loss: 0.2677 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 829/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2844 - acc: 0.9399 - precision: 0.9926 - recall: 0.8823 - f1_score: 0.9333 - val_loss: 0.2672 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 830/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2840 - acc: 0.9383 - precision: 0.9891 - recall: 0.8786 - f1_score: 0.9295 - val_loss: 0.2668 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 831/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2835 - acc: 0.9383 - precision: 0.9904 - recall: 0.8831 - f1_score: 0.9326 - val_loss: 0.2663 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 832/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2831 - acc: 0.9383 - precision: 0.9865 - recall: 0.8814 - f1_score: 0.9301 - val_loss: 0.2659 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 833/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2826 - acc: 0.9399 - precision: 0.9918 - recall: 0.8827 - f1_score: 0.9330 - val_loss: 0.2655 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 834/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2822 - acc: 0.9383 - precision: 0.9897 - recall: 0.8843 - f1_score: 0.9325 - val_loss: 0.2650 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 835/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2817 - acc: 0.9383 - precision: 0.9899 - recall: 0.8811 - f1_score: 0.9314 - val_loss: 0.2646 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 836/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2813 - acc: 0.9399 - precision: 0.9924 - recall: 0.8840 - f1_score: 0.9347 - val_loss: 0.2641 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 837/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2808 - acc: 0.9383 - precision: 0.9885 - recall: 0.8835 - f1_score: 0.9325 - val_loss: 0.2637 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 838/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2804 - acc: 0.9399 - precision: 0.9931 - recall: 0.8834 - f1_score: 0.9332 - val_loss: 0.2632 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 839/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2800 - acc: 0.9399 - precision: 0.9933 - recall: 0.8847 - f1_score: 0.9352 - val_loss: 0.2628 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 840/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2795 - acc: 0.9383 - precision: 0.9899 - recall: 0.8796 - f1_score: 0.9302 - val_loss: 0.2624 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 841/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2791 - acc: 0.9383 - precision: 0.9892 - recall: 0.8879 - f1_score: 0.9333 - val_loss: 0.2620 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 842/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2787 - acc: 0.9399 - precision: 0.9923 - recall: 0.8782 - f1_score: 0.9304 - val_loss: 0.2615 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 843/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2783 - acc: 0.9383 - precision: 0.9890 - recall: 0.8865 - f1_score: 0.9338 - val_loss: 0.2611 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 844/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2778 - acc: 0.9383 - precision: 0.9883 - recall: 0.8862 - f1_score: 0.9335 - val_loss: 0.2607 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 845/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2774 - acc: 0.9399 - precision: 0.9931 - recall: 0.8868 - f1_score: 0.9353 - val_loss: 0.2602 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 846/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2770 - acc: 0.9383 - precision: 0.9886 - recall: 0.8797 - f1_score: 0.9296 - val_loss: 0.2598 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 847/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2766 - acc: 0.9399 - precision: 0.9913 - recall: 0.8810 - f1_score: 0.9320 - val_loss: 0.2594 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 848/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2761 - acc: 0.9399 - precision: 0.9934 - recall: 0.8824 - f1_score: 0.9332 - val_loss: 0.2590 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 849/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2757 - acc: 0.9399 - precision: 0.9922 - recall: 0.8884 - f1_score: 0.9358 - val_loss: 0.2586 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 850/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2753 - acc: 0.9399 - precision: 0.9932 - recall: 0.8853 - f1_score: 0.9349 - val_loss: 0.2581 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 851/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2749 - acc: 0.9399 - precision: 0.9930 - recall: 0.8790 - f1_score: 0.9308 - val_loss: 0.2577 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 852/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2745 - acc: 0.9383 - precision: 0.9865 - recall: 0.8807 - f1_score: 0.9299 - val_loss: 0.2573 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 853/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2741 - acc: 0.9383 - precision: 0.9892 - recall: 0.8823 - f1_score: 0.9306 - val_loss: 0.2569 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 854/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2737 - acc: 0.9399 - precision: 0.9921 - recall: 0.8860 - f1_score: 0.9344 - val_loss: 0.2565 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 855/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2733 - acc: 0.9399 - precision: 0.9932 - recall: 0.8773 - f1_score: 0.9297 - val_loss: 0.2561 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 856/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2729 - acc: 0.9383 - precision: 0.9896 - recall: 0.8846 - f1_score: 0.9330 - val_loss: 0.2557 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 857/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2725 - acc: 0.9383 - precision: 0.9884 - recall: 0.8854 - f1_score: 0.9324 - val_loss: 0.2553 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 858/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2721 - acc: 0.9383 - precision: 0.9889 - recall: 0.8870 - f1_score: 0.9337 - val_loss: 0.2549 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 859/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2717 - acc: 0.9383 - precision: 0.9884 - recall: 0.8816 - f1_score: 0.9307 - val_loss: 0.2545 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 860/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2713 - acc: 0.9383 - precision: 0.9912 - recall: 0.8831 - f1_score: 0.9334 - val_loss: 0.2541 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 861/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2709 - acc: 0.9383 - precision: 0.9887 - recall: 0.8842 - f1_score: 0.9313 - val_loss: 0.2537 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 862/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2705 - acc: 0.9383 - precision: 0.9859 - recall: 0.8819 - f1_score: 0.9303 - val_loss: 0.2533 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 863/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2701 - acc: 0.9399 - precision: 0.9932 - recall: 0.8840 - f1_score: 0.9349 - val_loss: 0.2529 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 864/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2697 - acc: 0.9383 - precision: 0.9880 - recall: 0.8778 - f1_score: 0.9277 - val_loss: 0.2525 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2693 - acc: 0.9383 - precision: 0.9886 - recall: 0.8857 - f1_score: 0.9335 - val_loss: 0.2521 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 866/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2689 - acc: 0.9399 - precision: 0.9931 - recall: 0.8805 - f1_score: 0.9320 - val_loss: 0.2517 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 867/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2685 - acc: 0.9383 - precision: 0.9887 - recall: 0.8849 - f1_score: 0.9320 - val_loss: 0.2514 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 868/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2682 - acc: 0.9383 - precision: 0.9901 - recall: 0.8852 - f1_score: 0.9339 - val_loss: 0.2510 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 869/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2678 - acc: 0.9383 - precision: 0.9894 - recall: 0.8830 - f1_score: 0.9317 - val_loss: 0.2506 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 870/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2674 - acc: 0.9383 - precision: 0.9897 - recall: 0.8821 - f1_score: 0.9304 - val_loss: 0.2502 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 871/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2670 - acc: 0.9383 - precision: 0.9884 - recall: 0.8874 - f1_score: 0.9340 - val_loss: 0.2498 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 872/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2666 - acc: 0.9383 - precision: 0.9870 - recall: 0.8849 - f1_score: 0.9321 - val_loss: 0.2495 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 873/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2663 - acc: 0.9383 - precision: 0.9889 - recall: 0.8837 - f1_score: 0.9317 - val_loss: 0.2491 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 874/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2659 - acc: 0.9383 - precision: 0.9895 - recall: 0.8790 - f1_score: 0.9300 - val_loss: 0.2487 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 875/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2655 - acc: 0.9383 - precision: 0.9852 - recall: 0.8856 - f1_score: 0.9315 - val_loss: 0.2484 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 876/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2652 - acc: 0.9383 - precision: 0.9911 - recall: 0.8848 - f1_score: 0.9331 - val_loss: 0.2480 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 877/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2648 - acc: 0.9383 - precision: 0.9894 - recall: 0.8825 - f1_score: 0.9312 - val_loss: 0.2476 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 878/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2644 - acc: 0.9383 - precision: 0.9904 - recall: 0.8836 - f1_score: 0.9332 - val_loss: 0.2473 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 879/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2641 - acc: 0.9383 - precision: 0.9891 - recall: 0.8821 - f1_score: 0.9312 - val_loss: 0.2469 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 880/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2637 - acc: 0.9383 - precision: 0.9904 - recall: 0.8853 - f1_score: 0.9338 - val_loss: 0.2466 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 881/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2633 - acc: 0.9383 - precision: 0.9893 - recall: 0.8892 - f1_score: 0.9342 - val_loss: 0.2462 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 882/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2630 - acc: 0.9383 - precision: 0.9889 - recall: 0.8900 - f1_score: 0.9351 - val_loss: 0.2459 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 883/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2626 - acc: 0.9399 - precision: 0.9934 - recall: 0.8778 - f1_score: 0.9283 - val_loss: 0.2455 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 884/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2623 - acc: 0.9383 - precision: 0.9898 - recall: 0.8835 - f1_score: 0.9317 - val_loss: 0.2451 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 885/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2619 - acc: 0.9399 - precision: 0.9929 - recall: 0.8817 - f1_score: 0.9331 - val_loss: 0.2448 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 886/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2616 - acc: 0.9399 - precision: 0.9931 - recall: 0.8855 - f1_score: 0.9351 - val_loss: 0.2444 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 887/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2612 - acc: 0.9383 - precision: 0.9878 - recall: 0.8800 - f1_score: 0.9294 - val_loss: 0.2441 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 888/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2608 - acc: 0.9383 - precision: 0.9896 - recall: 0.8819 - f1_score: 0.9312 - val_loss: 0.2438 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 889/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2605 - acc: 0.9383 - precision: 0.9903 - recall: 0.8870 - f1_score: 0.9345 - val_loss: 0.2434 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 890/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2602 - acc: 0.9383 - precision: 0.9890 - recall: 0.8837 - f1_score: 0.9325 - val_loss: 0.2431 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 891/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2598 - acc: 0.9383 - precision: 0.9902 - recall: 0.8848 - f1_score: 0.9342 - val_loss: 0.2427 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 892/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2595 - acc: 0.9383 - precision: 0.9874 - recall: 0.8832 - f1_score: 0.9316 - val_loss: 0.2424 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 893/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2591 - acc: 0.9383 - precision: 0.9893 - recall: 0.8827 - f1_score: 0.9321 - val_loss: 0.2420 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 894/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2588 - acc: 0.9383 - precision: 0.9891 - recall: 0.8855 - f1_score: 0.9331 - val_loss: 0.2417 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 895/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2584 - acc: 0.9383 - precision: 0.9875 - recall: 0.8829 - f1_score: 0.9313 - val_loss: 0.2413 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 896/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2581 - acc: 0.9383 - precision: 0.9865 - recall: 0.8899 - f1_score: 0.9334 - val_loss: 0.2410 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2578 - acc: 0.9383 - precision: 0.9887 - recall: 0.8842 - f1_score: 0.9325 - val_loss: 0.2407 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 898/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2574 - acc: 0.9383 - precision: 0.9871 - recall: 0.8831 - f1_score: 0.9316 - val_loss: 0.2403 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 899/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2571 - acc: 0.9383 - precision: 0.9882 - recall: 0.8854 - f1_score: 0.9325 - val_loss: 0.2400 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 900/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2568 - acc: 0.9399 - precision: 0.9921 - recall: 0.8854 - f1_score: 0.9349 - val_loss: 0.2397 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 901/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2564 - acc: 0.9383 - precision: 0.9889 - recall: 0.8814 - f1_score: 0.9314 - val_loss: 0.2393 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 902/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2561 - acc: 0.9383 - precision: 0.9883 - recall: 0.8838 - f1_score: 0.9319 - val_loss: 0.2390 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 903/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2558 - acc: 0.9399 - precision: 0.9919 - recall: 0.8837 - f1_score: 0.9339 - val_loss: 0.2387 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 904/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2555 - acc: 0.9383 - precision: 0.9899 - recall: 0.8811 - f1_score: 0.9306 - val_loss: 0.2384 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 905/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2551 - acc: 0.9383 - precision: 0.9890 - recall: 0.8878 - f1_score: 0.9341 - val_loss: 0.2380 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 906/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2548 - acc: 0.9383 - precision: 0.9884 - recall: 0.8841 - f1_score: 0.9322 - val_loss: 0.2377 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 907/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2545 - acc: 0.9383 - precision: 0.9888 - recall: 0.8813 - f1_score: 0.9310 - val_loss: 0.2374 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 908/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2542 - acc: 0.9383 - precision: 0.9890 - recall: 0.8844 - f1_score: 0.9333 - val_loss: 0.2371 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 909/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2538 - acc: 0.9399 - precision: 0.9929 - recall: 0.8846 - f1_score: 0.9347 - val_loss: 0.2368 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 910/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2535 - acc: 0.9383 - precision: 0.9899 - recall: 0.8868 - f1_score: 0.9348 - val_loss: 0.2364 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 911/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2532 - acc: 0.9383 - precision: 0.9904 - recall: 0.8827 - f1_score: 0.9321 - val_loss: 0.2361 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 912/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2529 - acc: 0.9399 - precision: 0.9934 - recall: 0.8826 - f1_score: 0.9338 - val_loss: 0.2358 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 913/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2526 - acc: 0.9383 - precision: 0.9890 - recall: 0.8841 - f1_score: 0.9320 - val_loss: 0.2355 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 914/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2523 - acc: 0.9383 - precision: 0.9901 - recall: 0.8865 - f1_score: 0.9343 - val_loss: 0.2352 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 915/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2520 - acc: 0.9383 - precision: 0.9896 - recall: 0.8860 - f1_score: 0.9336 - val_loss: 0.2349 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 916/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2517 - acc: 0.9383 - precision: 0.9874 - recall: 0.8813 - f1_score: 0.9300 - val_loss: 0.2345 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 917/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2514 - acc: 0.9383 - precision: 0.9899 - recall: 0.8825 - f1_score: 0.9312 - val_loss: 0.2342 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 918/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2510 - acc: 0.9399 - precision: 0.9936 - recall: 0.8801 - f1_score: 0.9317 - val_loss: 0.2339 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 919/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2507 - acc: 0.9383 - precision: 0.9889 - recall: 0.8778 - f1_score: 0.9290 - val_loss: 0.2336 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 920/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2504 - acc: 0.9383 - precision: 0.9887 - recall: 0.8842 - f1_score: 0.9319 - val_loss: 0.2333 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 921/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2501 - acc: 0.9383 - precision: 0.9884 - recall: 0.8813 - f1_score: 0.9302 - val_loss: 0.2330 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 922/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2498 - acc: 0.9383 - precision: 0.9904 - recall: 0.8839 - f1_score: 0.9331 - val_loss: 0.2327 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 923/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2495 - acc: 0.9383 - precision: 0.9899 - recall: 0.8824 - f1_score: 0.9317 - val_loss: 0.2324 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 924/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2492 - acc: 0.9383 - precision: 0.9887 - recall: 0.8859 - f1_score: 0.9332 - val_loss: 0.2321 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 925/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2489 - acc: 0.9383 - precision: 0.9887 - recall: 0.8800 - f1_score: 0.9294 - val_loss: 0.2318 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 926/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2486 - acc: 0.9383 - precision: 0.9883 - recall: 0.8835 - f1_score: 0.9319 - val_loss: 0.2315 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 927/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2483 - acc: 0.9383 - precision: 0.9892 - recall: 0.8838 - f1_score: 0.9324 - val_loss: 0.2312 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 928/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2480 - acc: 0.9383 - precision: 0.9886 - recall: 0.8832 - f1_score: 0.9318 - val_loss: 0.2309 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2478 - acc: 0.9383 - precision: 0.9910 - recall: 0.8765 - f1_score: 0.9274 - val_loss: 0.2306 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 930/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2475 - acc: 0.9383 - precision: 0.9896 - recall: 0.8836 - f1_score: 0.9325 - val_loss: 0.2303 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 931/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3126 - acc: 0.9000 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.857 - 0s - loss: 0.2472 - acc: 0.9383 - precision: 0.9898 - recall: 0.8816 - f1_score: 0.9303 - val_loss: 0.2300 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 932/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.2228 - acc: 0.9600 - precision: 1.0000 - recall: 0.9048 - f1_score: 0.950 - 0s - loss: 0.2469 - acc: 0.9383 - precision: 0.9903 - recall: 0.8816 - f1_score: 0.9312 - val_loss: 0.2297 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 933/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2466 - acc: 0.9383 - precision: 0.9891 - recall: 0.8836 - f1_score: 0.9323 - val_loss: 0.2295 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 934/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2463 - acc: 0.9383 - precision: 0.9888 - recall: 0.8817 - f1_score: 0.9305 - val_loss: 0.2292 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 935/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2460 - acc: 0.9383 - precision: 0.9895 - recall: 0.8855 - f1_score: 0.9340 - val_loss: 0.2289 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 936/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2457 - acc: 0.9383 - precision: 0.9898 - recall: 0.8860 - f1_score: 0.9332 - val_loss: 0.2286 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 937/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2455 - acc: 0.9383 - precision: 0.9886 - recall: 0.8851 - f1_score: 0.9333 - val_loss: 0.2283 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 938/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2452 - acc: 0.9383 - precision: 0.9875 - recall: 0.8803 - f1_score: 0.9290 - val_loss: 0.2280 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 939/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2449 - acc: 0.9383 - precision: 0.9887 - recall: 0.8850 - f1_score: 0.9329 - val_loss: 0.2278 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 940/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2446 - acc: 0.9383 - precision: 0.9889 - recall: 0.8858 - f1_score: 0.9333 - val_loss: 0.2275 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 941/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2443 - acc: 0.9383 - precision: 0.9887 - recall: 0.8822 - f1_score: 0.9301 - val_loss: 0.2272 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 942/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2441 - acc: 0.9383 - precision: 0.9888 - recall: 0.8826 - f1_score: 0.9319 - val_loss: 0.2269 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 943/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.1818 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.000 - 0s - loss: 0.2438 - acc: 0.9383 - precision: 0.9890 - recall: 0.8859 - f1_score: 0.9334 - val_loss: 0.2266 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 944/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2435 - acc: 0.9383 - precision: 0.9896 - recall: 0.8793 - f1_score: 0.9295 - val_loss: 0.2264 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 945/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2433 - acc: 0.9399 - precision: 0.9898 - recall: 0.8839 - f1_score: 0.9318 - val_loss: 0.2261 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 946/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2430 - acc: 0.9383 - precision: 0.9896 - recall: 0.8822 - f1_score: 0.9314 - val_loss: 0.2258 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 947/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2427 - acc: 0.9383 - precision: 0.9893 - recall: 0.8829 - f1_score: 0.9320 - val_loss: 0.2256 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 948/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2424 - acc: 0.9383 - precision: 0.9899 - recall: 0.8861 - f1_score: 0.9340 - val_loss: 0.2253 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 949/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2422 - acc: 0.9383 - precision: 0.9904 - recall: 0.8822 - f1_score: 0.9314 - val_loss: 0.2250 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 950/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2419 - acc: 0.9383 - precision: 0.9890 - recall: 0.8800 - f1_score: 0.9302 - val_loss: 0.2248 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 951/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2416 - acc: 0.9383 - precision: 0.9896 - recall: 0.8771 - f1_score: 0.9284 - val_loss: 0.2245 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 952/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2414 - acc: 0.9383 - precision: 0.9890 - recall: 0.8856 - f1_score: 0.9335 - val_loss: 0.2242 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 953/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2411 - acc: 0.9383 - precision: 0.9902 - recall: 0.8810 - f1_score: 0.9307 - val_loss: 0.2240 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 954/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2409 - acc: 0.9383 - precision: 0.9874 - recall: 0.8856 - f1_score: 0.9323 - val_loss: 0.2237 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 955/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2406 - acc: 0.9383 - precision: 0.9892 - recall: 0.8822 - f1_score: 0.9321 - val_loss: 0.2235 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 956/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2403 - acc: 0.9383 - precision: 0.9879 - recall: 0.8838 - f1_score: 0.9318 - val_loss: 0.2232 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 957/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2401 - acc: 0.9399 - precision: 0.9892 - recall: 0.8875 - f1_score: 0.9340 - val_loss: 0.2229 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 958/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2398 - acc: 0.9399 - precision: 0.9905 - recall: 0.8843 - f1_score: 0.9316 - val_loss: 0.2227 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 959/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2396 - acc: 0.9383 - precision: 0.9888 - recall: 0.8792 - f1_score: 0.9301 - val_loss: 0.2225 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 960/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2393 - acc: 0.9399 - precision: 0.9883 - recall: 0.8882 - f1_score: 0.9349 - val_loss: 0.2222 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 961/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2391 - acc: 0.9399 - precision: 0.9901 - recall: 0.8879 - f1_score: 0.9349 - val_loss: 0.2220 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 962/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2388 - acc: 0.9399 - precision: 0.9896 - recall: 0.8895 - f1_score: 0.9354 - val_loss: 0.2217 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 963/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2386 - acc: 0.9383 - precision: 0.9895 - recall: 0.8827 - f1_score: 0.9319 - val_loss: 0.2215 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 964/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2383 - acc: 0.9399 - precision: 0.9884 - recall: 0.8858 - f1_score: 0.9335 - val_loss: 0.2212 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 965/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2381 - acc: 0.9383 - precision: 0.9873 - recall: 0.8863 - f1_score: 0.9326 - val_loss: 0.2209 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 966/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2378 - acc: 0.9383 - precision: 0.9894 - recall: 0.8861 - f1_score: 0.9329 - val_loss: 0.2207 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 967/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2376 - acc: 0.9383 - precision: 0.9890 - recall: 0.8846 - f1_score: 0.9327 - val_loss: 0.2205 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 968/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2373 - acc: 0.9383 - precision: 0.9883 - recall: 0.8865 - f1_score: 0.9335 - val_loss: 0.2202 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 969/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2371 - acc: 0.9383 - precision: 0.9888 - recall: 0.8874 - f1_score: 0.9340 - val_loss: 0.2200 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 970/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2368 - acc: 0.9399 - precision: 0.9895 - recall: 0.8939 - f1_score: 0.9377 - val_loss: 0.2197 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 971/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2366 - acc: 0.9399 - precision: 0.9891 - recall: 0.8855 - f1_score: 0.9327 - val_loss: 0.2195 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 972/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2363 - acc: 0.9399 - precision: 0.9889 - recall: 0.8851 - f1_score: 0.9329 - val_loss: 0.2193 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 973/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2361 - acc: 0.9399 - precision: 0.9898 - recall: 0.8860 - f1_score: 0.9336 - val_loss: 0.2190 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 974/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2359 - acc: 0.9383 - precision: 0.9893 - recall: 0.8875 - f1_score: 0.9347 - val_loss: 0.2188 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 975/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2356 - acc: 0.9383 - precision: 0.9892 - recall: 0.8829 - f1_score: 0.9322 - val_loss: 0.2185 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 976/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2354 - acc: 0.9399 - precision: 0.9895 - recall: 0.8881 - f1_score: 0.9352 - val_loss: 0.2183 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 977/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2352 - acc: 0.9399 - precision: 0.9883 - recall: 0.8892 - f1_score: 0.9349 - val_loss: 0.2180 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 978/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2349 - acc: 0.9399 - precision: 0.9901 - recall: 0.8854 - f1_score: 0.9338 - val_loss: 0.2178 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 979/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2347 - acc: 0.9399 - precision: 0.9894 - recall: 0.8855 - f1_score: 0.9340 - val_loss: 0.2176 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 980/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2344 - acc: 0.9399 - precision: 0.9900 - recall: 0.8853 - f1_score: 0.9335 - val_loss: 0.2174 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 981/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2342 - acc: 0.9399 - precision: 0.9879 - recall: 0.8880 - f1_score: 0.9348 - val_loss: 0.2171 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 982/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2340 - acc: 0.9399 - precision: 0.9899 - recall: 0.8845 - f1_score: 0.9331 - val_loss: 0.2169 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 983/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2337 - acc: 0.9399 - precision: 0.9900 - recall: 0.8913 - f1_score: 0.9372 - val_loss: 0.2167 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 984/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2335 - acc: 0.9399 - precision: 0.9864 - recall: 0.8855 - f1_score: 0.9319 - val_loss: 0.2164 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 985/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2333 - acc: 0.9399 - precision: 0.9893 - recall: 0.8859 - f1_score: 0.9338 - val_loss: 0.2162 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 986/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2331 - acc: 0.9399 - precision: 0.9894 - recall: 0.8841 - f1_score: 0.9331 - val_loss: 0.2160 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 987/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2328 - acc: 0.9399 - precision: 0.9885 - recall: 0.8863 - f1_score: 0.9336 - val_loss: 0.2157 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 988/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2326 - acc: 0.9399 - precision: 0.9868 - recall: 0.8880 - f1_score: 0.9335 - val_loss: 0.2155 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 989/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2324 - acc: 0.9399 - precision: 0.9888 - recall: 0.8925 - f1_score: 0.9365 - val_loss: 0.2153 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 990/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2322 - acc: 0.9399 - precision: 0.9906 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 0.2151 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 991/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2319 - acc: 0.9399 - precision: 0.9888 - recall: 0.8871 - f1_score: 0.9341 - val_loss: 0.2148 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2317 - acc: 0.9399 - precision: 0.9889 - recall: 0.8876 - f1_score: 0.9337 - val_loss: 0.2146 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 993/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2315 - acc: 0.9399 - precision: 0.9906 - recall: 0.8847 - f1_score: 0.9316 - val_loss: 0.2144 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 994/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2313 - acc: 0.9399 - precision: 0.9884 - recall: 0.8838 - f1_score: 0.9306 - val_loss: 0.2142 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 995/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2311 - acc: 0.9399 - precision: 0.9884 - recall: 0.8817 - f1_score: 0.9311 - val_loss: 0.2140 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 996/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2308 - acc: 0.9399 - precision: 0.9874 - recall: 0.8885 - f1_score: 0.9332 - val_loss: 0.2137 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 997/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2306 - acc: 0.9399 - precision: 0.9864 - recall: 0.8872 - f1_score: 0.9333 - val_loss: 0.2135 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 998/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2304 - acc: 0.9399 - precision: 0.9881 - recall: 0.8798 - f1_score: 0.9295 - val_loss: 0.2133 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 999/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2302 - acc: 0.9399 - precision: 0.9905 - recall: 0.8847 - f1_score: 0.9328 - val_loss: 0.2131 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      "Epoch 1000/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2300 - acc: 0.9399 - precision: 0.9873 - recall: 0.8817 - f1_score: 0.9294 - val_loss: 0.2128 - val_acc: 0.9623 - val_precision: 0.9888 - val_recall: 0.9423 - val_f1_score: 0.9645\n",
      " 50/159 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.0281 - acc: 0.6177 - precision: 0.5809 - recall: 0.9831 - f1_score: 0.7258 - val_loss: 6.0339 - val_acc: 0.5316 - val_precision: 0.4507 - val_recall: 0.9849 - val_f1_score: 0.6158\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9448 - acc: 0.6193 - precision: 0.5785 - recall: 0.9938 - f1_score: 0.7280 - val_loss: 5.9865 - val_acc: 0.5380 - val_precision: 0.4539 - val_recall: 0.9849 - val_f1_score: 0.6191\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8968 - acc: 0.6288 - precision: 0.5851 - recall: 0.9939 - f1_score: 0.7351 - val_loss: 5.9468 - val_acc: 0.5443 - val_precision: 0.4571 - val_recall: 0.9849 - val_f1_score: 0.6220\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8562 - acc: 0.6351 - precision: 0.5905 - recall: 0.9940 - f1_score: 0.7392 - val_loss: 5.9102 - val_acc: 0.5443 - val_precision: 0.4571 - val_recall: 0.9849 - val_f1_score: 0.6220\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8190 - acc: 0.6493 - precision: 0.5988 - recall: 0.9936 - f1_score: 0.7444 - val_loss: 5.8750 - val_acc: 0.5696 - val_precision: 0.4710 - val_recall: 0.9849 - val_f1_score: 0.6354\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7836 - acc: 0.6572 - precision: 0.6044 - recall: 0.9936 - f1_score: 0.7484 - val_loss: 5.8408 - val_acc: 0.5823 - val_precision: 0.4788 - val_recall: 0.9849 - val_f1_score: 0.6430\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7493 - acc: 0.6667 - precision: 0.6122 - recall: 0.9938 - f1_score: 0.7554 - val_loss: 5.8071 - val_acc: 0.5949 - val_precision: 0.4869 - val_recall: 0.9849 - val_f1_score: 0.6504\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7159 - acc: 0.6825 - precision: 0.6223 - recall: 0.9939 - f1_score: 0.7645 - val_loss: 5.7739 - val_acc: 0.6266 - val_precision: 0.5069 - val_recall: 0.9849 - val_f1_score: 0.6682\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6831 - acc: 0.7014 - precision: 0.6375 - recall: 0.9945 - f1_score: 0.7742 - val_loss: 5.7412 - val_acc: 0.6456 - val_precision: 0.5193 - val_recall: 0.9849 - val_f1_score: 0.6787\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6508 - acc: 0.7141 - precision: 0.6474 - recall: 0.9946 - f1_score: 0.7802 - val_loss: 5.7089 - val_acc: 0.6519 - val_precision: 0.5245 - val_recall: 0.9699 - val_f1_score: 0.6797\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6190 - acc: 0.7346 - precision: 0.6617 - recall: 0.9938 - f1_score: 0.7922 - val_loss: 5.6769 - val_acc: 0.6772 - val_precision: 0.5439 - val_recall: 0.9699 - val_f1_score: 0.6958\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5876 - acc: 0.7504 - precision: 0.6789 - recall: 0.9939 - f1_score: 0.8052 - val_loss: 5.6452 - val_acc: 0.6899 - val_precision: 0.5546 - val_recall: 0.9699 - val_f1_score: 0.7047\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5565 - acc: 0.7709 - precision: 0.6969 - recall: 0.9934 - f1_score: 0.8178 - val_loss: 5.6138 - val_acc: 0.7025 - val_precision: 0.5663 - val_recall: 0.9699 - val_f1_score: 0.7134\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5258 - acc: 0.7836 - precision: 0.7108 - recall: 0.9917 - f1_score: 0.8240 - val_loss: 5.5827 - val_acc: 0.7089 - val_precision: 0.5727 - val_recall: 0.9699 - val_f1_score: 0.7179\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4954 - acc: 0.7930 - precision: 0.7199 - recall: 0.9887 - f1_score: 0.8320 - val_loss: 5.5518 - val_acc: 0.7342 - val_precision: 0.6004 - val_recall: 0.9699 - val_f1_score: 0.7379\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4653 - acc: 0.8120 - precision: 0.7442 - recall: 0.9845 - f1_score: 0.8449 - val_loss: 5.5213 - val_acc: 0.7658 - val_precision: 0.6285 - val_recall: 0.9699 - val_f1_score: 0.7605\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4354 - acc: 0.8294 - precision: 0.7628 - recall: 0.9751 - f1_score: 0.8547 - val_loss: 5.4910 - val_acc: 0.7848 - val_precision: 0.6494 - val_recall: 0.9699 - val_f1_score: 0.7767\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4059 - acc: 0.8389 - precision: 0.7753 - recall: 0.9711 - f1_score: 0.8607 - val_loss: 5.4609 - val_acc: 0.7785 - val_precision: 0.6455 - val_recall: 0.9548 - val_f1_score: 0.7692\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3765 - acc: 0.8452 - precision: 0.7853 - recall: 0.9689 - f1_score: 0.8659 - val_loss: 5.4312 - val_acc: 0.7911 - val_precision: 0.6601 - val_recall: 0.9548 - val_f1_score: 0.7799\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3475 - acc: 0.8515 - precision: 0.7930 - recall: 0.9703 - f1_score: 0.8705 - val_loss: 5.4017 - val_acc: 0.8038 - val_precision: 0.6734 - val_recall: 0.9548 - val_f1_score: 0.7890\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3187 - acc: 0.8657 - precision: 0.8118 - recall: 0.9665 - f1_score: 0.8803 - val_loss: 5.3724 - val_acc: 0.8228 - val_precision: 0.7079 - val_recall: 0.9397 - val_f1_score: 0.8073\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2901 - acc: 0.8768 - precision: 0.8265 - recall: 0.9684 - f1_score: 0.8904 - val_loss: 5.3433 - val_acc: 0.8354 - val_precision: 0.7232 - val_recall: 0.9397 - val_f1_score: 0.8173\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2618 - acc: 0.8831 - precision: 0.8343 - recall: 0.9679 - f1_score: 0.8942 - val_loss: 5.3145 - val_acc: 0.8481 - val_precision: 0.7404 - val_recall: 0.9397 - val_f1_score: 0.8280\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.2336 - acc: 0.8894 - precision: 0.8461 - recall: 0.9685 - f1_score: 0.9013 - val_loss: 5.2859 - val_acc: 0.8608 - val_precision: 0.7589 - val_recall: 0.9397 - val_f1_score: 0.8391\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2058 - acc: 0.8973 - precision: 0.8538 - recall: 0.9667 - f1_score: 0.9056 - val_loss: 5.2576 - val_acc: 0.8734 - val_precision: 0.7852 - val_recall: 0.9397 - val_f1_score: 0.8555\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1781 - acc: 0.9021 - precision: 0.8628 - recall: 0.9685 - f1_score: 0.9096 - val_loss: 5.2295 - val_acc: 0.8924 - val_precision: 0.8208 - val_recall: 0.9397 - val_f1_score: 0.8761\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1506 - acc: 0.9100 - precision: 0.8771 - recall: 0.9676 - f1_score: 0.9191 - val_loss: 5.2016 - val_acc: 0.9051 - val_precision: 0.8491 - val_recall: 0.9397 - val_f1_score: 0.8918\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1233 - acc: 0.9147 - precision: 0.8831 - recall: 0.9630 - f1_score: 0.9206 - val_loss: 5.1739 - val_acc: 0.9051 - val_precision: 0.8581 - val_recall: 0.9247 - val_f1_score: 0.8898\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0962 - acc: 0.9194 - precision: 0.8914 - recall: 0.9654 - f1_score: 0.9251 - val_loss: 5.1464 - val_acc: 0.9177 - val_precision: 0.8824 - val_recall: 0.9247 - val_f1_score: 0.9025\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0694 - acc: 0.9210 - precision: 0.8942 - recall: 0.9639 - f1_score: 0.9254 - val_loss: 5.1191 - val_acc: 0.9241 - val_precision: 0.8947 - val_recall: 0.9247 - val_f1_score: 0.9088\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0427 - acc: 0.9242 - precision: 0.9054 - recall: 0.9557 - f1_score: 0.9285 - val_loss: 5.0920 - val_acc: 0.9241 - val_precision: 0.8947 - val_recall: 0.9247 - val_f1_score: 0.9088\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0162 - acc: 0.9226 - precision: 0.9052 - recall: 0.9481 - f1_score: 0.9251 - val_loss: 5.0651 - val_acc: 0.9241 - val_precision: 0.8947 - val_recall: 0.9247 - val_f1_score: 0.9088\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9899 - acc: 0.9242 - precision: 0.9127 - recall: 0.9452 - f1_score: 0.9274 - val_loss: 5.0384 - val_acc: 0.9241 - val_precision: 0.8947 - val_recall: 0.9247 - val_f1_score: 0.9088\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9638 - acc: 0.9273 - precision: 0.9153 - recall: 0.9434 - f1_score: 0.9282 - val_loss: 5.0119 - val_acc: 0.9367 - val_precision: 0.9281 - val_recall: 0.9247 - val_f1_score: 0.9256\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9379 - acc: 0.9289 - precision: 0.9244 - recall: 0.9428 - f1_score: 0.9318 - val_loss: 4.9856 - val_acc: 0.9367 - val_precision: 0.9281 - val_recall: 0.9247 - val_f1_score: 0.9256\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9121 - acc: 0.9321 - precision: 0.9291 - recall: 0.9410 - f1_score: 0.9347 - val_loss: 4.9596 - val_acc: 0.9430 - val_precision: 0.9424 - val_recall: 0.9247 - val_f1_score: 0.9326\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8866 - acc: 0.9352 - precision: 0.9351 - recall: 0.9366 - f1_score: 0.9354 - val_loss: 4.9337 - val_acc: 0.9367 - val_precision: 0.9424 - val_recall: 0.9036 - val_f1_score: 0.9217\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8612 - acc: 0.9431 - precision: 0.9546 - recall: 0.9418 - f1_score: 0.9471 - val_loss: 4.9080 - val_acc: 0.9430 - val_precision: 0.9525 - val_recall: 0.9036 - val_f1_score: 0.9273\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8360 - acc: 0.9463 - precision: 0.9579 - recall: 0.9407 - f1_score: 0.9486 - val_loss: 4.8824 - val_acc: 0.9430 - val_precision: 0.9525 - val_recall: 0.9036 - val_f1_score: 0.9273\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8109 - acc: 0.9463 - precision: 0.9579 - recall: 0.9377 - f1_score: 0.9469 - val_loss: 4.8570 - val_acc: 0.9430 - val_precision: 0.9525 - val_recall: 0.9036 - val_f1_score: 0.9273\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7860 - acc: 0.9463 - precision: 0.9576 - recall: 0.9389 - f1_score: 0.9473 - val_loss: 4.8317 - val_acc: 0.9494 - val_precision: 0.9684 - val_recall: 0.9036 - val_f1_score: 0.9347\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7612 - acc: 0.9431 - precision: 0.9607 - recall: 0.9325 - f1_score: 0.9452 - val_loss: 4.8066 - val_acc: 0.9494 - val_precision: 0.9684 - val_recall: 0.9036 - val_f1_score: 0.9347\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7366 - acc: 0.9447 - precision: 0.9645 - recall: 0.9320 - f1_score: 0.9468 - val_loss: 4.7817 - val_acc: 0.9494 - val_precision: 0.9684 - val_recall: 0.9036 - val_f1_score: 0.9347\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7122 - acc: 0.9447 - precision: 0.9641 - recall: 0.9284 - f1_score: 0.9450 - val_loss: 4.7570 - val_acc: 0.9494 - val_precision: 0.9684 - val_recall: 0.9036 - val_f1_score: 0.9347\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6879 - acc: 0.9463 - precision: 0.9670 - recall: 0.9323 - f1_score: 0.9483 - val_loss: 4.7324 - val_acc: 0.9494 - val_precision: 0.9684 - val_recall: 0.9036 - val_f1_score: 0.9347\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6638 - acc: 0.9463 - precision: 0.9647 - recall: 0.9309 - f1_score: 0.9464 - val_loss: 4.7081 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 4.6380 - acc: 0.9520 - precision: 0.9612 - recall: 0.9456 - f1_score: 0.952 - 0s - loss: 4.6399 - acc: 0.9463 - precision: 0.9664 - recall: 0.9289 - f1_score: 0.9463 - val_loss: 4.6839 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6161 - acc: 0.9463 - precision: 0.9657 - recall: 0.9315 - f1_score: 0.9476 - val_loss: 4.6598 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5925 - acc: 0.9494 - precision: 0.9741 - recall: 0.9277 - f1_score: 0.9486 - val_loss: 4.6359 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5690 - acc: 0.9510 - precision: 0.9760 - recall: 0.9313 - f1_score: 0.9523 - val_loss: 4.6121 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5456 - acc: 0.9526 - precision: 0.9782 - recall: 0.9312 - f1_score: 0.9539 - val_loss: 4.5885 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5224 - acc: 0.9510 - precision: 0.9780 - recall: 0.9300 - f1_score: 0.9518 - val_loss: 4.5651 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4993 - acc: 0.9510 - precision: 0.9813 - recall: 0.9255 - f1_score: 0.9521 - val_loss: 4.5418 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4764 - acc: 0.9510 - precision: 0.9823 - recall: 0.9255 - f1_score: 0.9520 - val_loss: 4.5186 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4536 - acc: 0.9510 - precision: 0.9793 - recall: 0.9223 - f1_score: 0.9491 - val_loss: 4.4957 - val_acc: 0.9430 - val_precision: 0.9667 - val_recall: 0.8885 - val_f1_score: 0.9258\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.4310 - acc: 0.9494 - precision: 0.9789 - recall: 0.9172 - f1_score: 0.9465 - val_loss: 4.4728 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4085 - acc: 0.9463 - precision: 0.9800 - recall: 0.9142 - f1_score: 0.9453 - val_loss: 4.4501 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3861 - acc: 0.9463 - precision: 0.9810 - recall: 0.9139 - f1_score: 0.9456 - val_loss: 4.4275 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3639 - acc: 0.9463 - precision: 0.9777 - recall: 0.9145 - f1_score: 0.9441 - val_loss: 4.4051 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3418 - acc: 0.9463 - precision: 0.9813 - recall: 0.9149 - f1_score: 0.9452 - val_loss: 4.3828 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3199 - acc: 0.9447 - precision: 0.9805 - recall: 0.9135 - f1_score: 0.9451 - val_loss: 4.3607 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2980 - acc: 0.9447 - precision: 0.9771 - recall: 0.9091 - f1_score: 0.9410 - val_loss: 4.3386 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2763 - acc: 0.9447 - precision: 0.9812 - recall: 0.9111 - f1_score: 0.9435 - val_loss: 4.3167 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2547 - acc: 0.9447 - precision: 0.9818 - recall: 0.9127 - f1_score: 0.9451 - val_loss: 4.2949 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2333 - acc: 0.9447 - precision: 0.9799 - recall: 0.9141 - f1_score: 0.9453 - val_loss: 4.2734 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2120 - acc: 0.9447 - precision: 0.9825 - recall: 0.9075 - f1_score: 0.9422 - val_loss: 4.2519 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1908 - acc: 0.9431 - precision: 0.9803 - recall: 0.9088 - f1_score: 0.9425 - val_loss: 4.2305 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1697 - acc: 0.9431 - precision: 0.9816 - recall: 0.9107 - f1_score: 0.9440 - val_loss: 4.2093 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1488 - acc: 0.9431 - precision: 0.9793 - recall: 0.9100 - f1_score: 0.9424 - val_loss: 4.1882 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1279 - acc: 0.9431 - precision: 0.9805 - recall: 0.9058 - f1_score: 0.9409 - val_loss: 4.1672 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1072 - acc: 0.9431 - precision: 0.9802 - recall: 0.9083 - f1_score: 0.9417 - val_loss: 4.1464 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0867 - acc: 0.9431 - precision: 0.9817 - recall: 0.9097 - f1_score: 0.9436 - val_loss: 4.1257 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0662 - acc: 0.9431 - precision: 0.9808 - recall: 0.9074 - f1_score: 0.9412 - val_loss: 4.1051 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0459 - acc: 0.9431 - precision: 0.9799 - recall: 0.9109 - f1_score: 0.9434 - val_loss: 4.0846 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0256 - acc: 0.9431 - precision: 0.9817 - recall: 0.9090 - f1_score: 0.9430 - val_loss: 4.0643 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0055 - acc: 0.9431 - precision: 0.9806 - recall: 0.9100 - f1_score: 0.9435 - val_loss: 4.0441 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9855 - acc: 0.9431 - precision: 0.9800 - recall: 0.9078 - f1_score: 0.9417 - val_loss: 4.0239 - val_acc: 0.9494 - val_precision: 0.9824 - val_recall: 0.8885 - val_f1_score: 0.9327\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9656 - acc: 0.9431 - precision: 0.9796 - recall: 0.9086 - f1_score: 0.9414 - val_loss: 4.0039 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9459 - acc: 0.9431 - precision: 0.9811 - recall: 0.9103 - f1_score: 0.9435 - val_loss: 3.9840 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9262 - acc: 0.9431 - precision: 0.9796 - recall: 0.9111 - f1_score: 0.9432 - val_loss: 3.9643 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9066 - acc: 0.9431 - precision: 0.9808 - recall: 0.9083 - f1_score: 0.9420 - val_loss: 3.9446 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8872 - acc: 0.9431 - precision: 0.9808 - recall: 0.9113 - f1_score: 0.9437 - val_loss: 3.9251 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8679 - acc: 0.9415 - precision: 0.9810 - recall: 0.9074 - f1_score: 0.9419 - val_loss: 3.9056 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8487 - acc: 0.9415 - precision: 0.9793 - recall: 0.9037 - f1_score: 0.9392 - val_loss: 3.8863 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8296 - acc: 0.9431 - precision: 0.9821 - recall: 0.9097 - f1_score: 0.9429 - val_loss: 3.8671 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8105 - acc: 0.9415 - precision: 0.9792 - recall: 0.9071 - f1_score: 0.9411 - val_loss: 3.8480 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7917 - acc: 0.9415 - precision: 0.9808 - recall: 0.9064 - f1_score: 0.9413 - val_loss: 3.8291 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.7729 - acc: 0.9400 - precision: 0.9806 - recall: 0.9024 - f1_score: 0.9382 - val_loss: 3.8102 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7542 - acc: 0.9400 - precision: 0.9797 - recall: 0.9038 - f1_score: 0.9393 - val_loss: 3.7914 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7356 - acc: 0.9400 - precision: 0.9803 - recall: 0.9046 - f1_score: 0.9399 - val_loss: 3.7728 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7171 - acc: 0.9400 - precision: 0.9788 - recall: 0.9057 - f1_score: 0.9399 - val_loss: 3.7542 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6987 - acc: 0.9400 - precision: 0.9822 - recall: 0.9037 - f1_score: 0.9396 - val_loss: 3.7357 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6805 - acc: 0.9400 - precision: 0.9794 - recall: 0.9051 - f1_score: 0.9383 - val_loss: 3.7174 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6623 - acc: 0.9400 - precision: 0.9804 - recall: 0.9047 - f1_score: 0.9398 - val_loss: 3.6992 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6442 - acc: 0.9368 - precision: 0.9775 - recall: 0.8942 - f1_score: 0.9326 - val_loss: 3.6810 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6263 - acc: 0.9368 - precision: 0.9788 - recall: 0.8963 - f1_score: 0.9351 - val_loss: 3.6630 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6084 - acc: 0.9368 - precision: 0.9815 - recall: 0.8965 - f1_score: 0.9362 - val_loss: 3.6451 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5906 - acc: 0.9368 - precision: 0.9799 - recall: 0.8971 - f1_score: 0.9354 - val_loss: 3.6272 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5730 - acc: 0.9368 - precision: 0.9810 - recall: 0.8974 - f1_score: 0.9363 - val_loss: 3.6095 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 3.5510 - acc: 0.9400 - precision: 1.0000 - recall: 0.8966 - f1_score: 0.945 - 0s - loss: 3.5554 - acc: 0.9368 - precision: 0.9802 - recall: 0.8974 - f1_score: 0.9366 - val_loss: 3.5919 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5379 - acc: 0.9368 - precision: 0.9792 - recall: 0.8976 - f1_score: 0.9358 - val_loss: 3.5744 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5206 - acc: 0.9368 - precision: 0.9795 - recall: 0.8957 - f1_score: 0.9347 - val_loss: 3.5570 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5033 - acc: 0.9368 - precision: 0.9809 - recall: 0.8982 - f1_score: 0.9368 - val_loss: 3.5396 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4861 - acc: 0.9368 - precision: 0.9815 - recall: 0.9004 - f1_score: 0.9373 - val_loss: 3.5224 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4690 - acc: 0.9368 - precision: 0.9816 - recall: 0.8957 - f1_score: 0.9359 - val_loss: 3.5052 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4520 - acc: 0.9368 - precision: 0.9817 - recall: 0.8965 - f1_score: 0.9355 - val_loss: 3.4882 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4351 - acc: 0.9368 - precision: 0.9787 - recall: 0.8996 - f1_score: 0.9366 - val_loss: 3.4712 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4183 - acc: 0.9368 - precision: 0.9813 - recall: 0.8949 - f1_score: 0.9343 - val_loss: 3.4544 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4015 - acc: 0.9368 - precision: 0.9805 - recall: 0.8951 - f1_score: 0.9349 - val_loss: 3.4376 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3849 - acc: 0.9368 - precision: 0.9785 - recall: 0.8970 - f1_score: 0.9354 - val_loss: 3.4210 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3684 - acc: 0.9368 - precision: 0.9803 - recall: 0.8994 - f1_score: 0.9369 - val_loss: 3.4044 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3519 - acc: 0.9368 - precision: 0.9804 - recall: 0.8978 - f1_score: 0.9361 - val_loss: 3.3879 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3355 - acc: 0.9368 - precision: 0.9814 - recall: 0.8977 - f1_score: 0.9362 - val_loss: 3.3715 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3193 - acc: 0.9368 - precision: 0.9805 - recall: 0.8977 - f1_score: 0.9365 - val_loss: 3.3551 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3031 - acc: 0.9368 - precision: 0.9816 - recall: 0.8967 - f1_score: 0.9353 - val_loss: 3.3389 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2870 - acc: 0.9368 - precision: 0.9805 - recall: 0.8969 - f1_score: 0.9356 - val_loss: 3.3228 - val_acc: 0.9430 - val_precision: 0.9814 - val_recall: 0.8734 - val_f1_score: 0.9233\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2710 - acc: 0.9368 - precision: 0.9810 - recall: 0.9008 - f1_score: 0.9378 - val_loss: 3.3068 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2551 - acc: 0.9368 - precision: 0.9817 - recall: 0.9008 - f1_score: 0.9389 - val_loss: 3.2908 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2392 - acc: 0.9368 - precision: 0.9818 - recall: 0.8967 - f1_score: 0.9362 - val_loss: 3.2750 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 120/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.2235 - acc: 0.9368 - precision: 0.9788 - recall: 0.8941 - f1_score: 0.9326 - val_loss: 3.2592 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2078 - acc: 0.9368 - precision: 0.9797 - recall: 0.8987 - f1_score: 0.9359 - val_loss: 3.2434 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1922 - acc: 0.9368 - precision: 0.9785 - recall: 0.8918 - f1_score: 0.9322 - val_loss: 3.2278 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1767 - acc: 0.9368 - precision: 0.9809 - recall: 0.8960 - f1_score: 0.9357 - val_loss: 3.2123 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1613 - acc: 0.9368 - precision: 0.9804 - recall: 0.8986 - f1_score: 0.9370 - val_loss: 3.1968 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1459 - acc: 0.9368 - precision: 0.9816 - recall: 0.8999 - f1_score: 0.9376 - val_loss: 3.1815 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1307 - acc: 0.9368 - precision: 0.9811 - recall: 0.9000 - f1_score: 0.9373 - val_loss: 3.1662 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1155 - acc: 0.9368 - precision: 0.9798 - recall: 0.8972 - f1_score: 0.9359 - val_loss: 3.1510 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1005 - acc: 0.9368 - precision: 0.9814 - recall: 0.8985 - f1_score: 0.9367 - val_loss: 3.1359 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0854 - acc: 0.9368 - precision: 0.9812 - recall: 0.8936 - f1_score: 0.9336 - val_loss: 3.1209 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0705 - acc: 0.9368 - precision: 0.9829 - recall: 0.8965 - f1_score: 0.9363 - val_loss: 3.1059 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0557 - acc: 0.9368 - precision: 0.9790 - recall: 0.8950 - f1_score: 0.9340 - val_loss: 3.0911 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0409 - acc: 0.9368 - precision: 0.9790 - recall: 0.8970 - f1_score: 0.9347 - val_loss: 3.0763 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0262 - acc: 0.9368 - precision: 0.9811 - recall: 0.9029 - f1_score: 0.9395 - val_loss: 3.0616 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0116 - acc: 0.9368 - precision: 0.9807 - recall: 0.8994 - f1_score: 0.9376 - val_loss: 3.0469 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9971 - acc: 0.9368 - precision: 0.9798 - recall: 0.8962 - f1_score: 0.9353 - val_loss: 3.0324 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9826 - acc: 0.9368 - precision: 0.9799 - recall: 0.8969 - f1_score: 0.9353 - val_loss: 3.0179 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9682 - acc: 0.9368 - precision: 0.9790 - recall: 0.8955 - f1_score: 0.9342 - val_loss: 3.0035 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9539 - acc: 0.9368 - precision: 0.9802 - recall: 0.8961 - f1_score: 0.9354 - val_loss: 2.9892 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9397 - acc: 0.9368 - precision: 0.9771 - recall: 0.8977 - f1_score: 0.9344 - val_loss: 2.9750 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9256 - acc: 0.9368 - precision: 0.9806 - recall: 0.8970 - f1_score: 0.9358 - val_loss: 2.9608 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9115 - acc: 0.9384 - precision: 0.9815 - recall: 0.8994 - f1_score: 0.9369 - val_loss: 2.9467 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8975 - acc: 0.9368 - precision: 0.9793 - recall: 0.8912 - f1_score: 0.9318 - val_loss: 2.9327 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8836 - acc: 0.9384 - precision: 0.9805 - recall: 0.9003 - f1_score: 0.9365 - val_loss: 2.9188 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8697 - acc: 0.9384 - precision: 0.9797 - recall: 0.9000 - f1_score: 0.9366 - val_loss: 2.9049 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8560 - acc: 0.9384 - precision: 0.9795 - recall: 0.9000 - f1_score: 0.9372 - val_loss: 2.8912 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8423 - acc: 0.9384 - precision: 0.9804 - recall: 0.9032 - f1_score: 0.9393 - val_loss: 2.8775 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8286 - acc: 0.9384 - precision: 0.9815 - recall: 0.8993 - f1_score: 0.9365 - val_loss: 2.8638 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8151 - acc: 0.9384 - precision: 0.9809 - recall: 0.9005 - f1_score: 0.9380 - val_loss: 2.8502 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8016 - acc: 0.9384 - precision: 0.9820 - recall: 0.9027 - f1_score: 0.9404 - val_loss: 2.8368 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7882 - acc: 0.9384 - precision: 0.9809 - recall: 0.9012 - f1_score: 0.9388 - val_loss: 2.8233 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7748 - acc: 0.9384 - precision: 0.9816 - recall: 0.8998 - f1_score: 0.9376 - val_loss: 2.8100 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.7616 - acc: 0.9384 - precision: 0.9818 - recall: 0.8993 - f1_score: 0.9373 - val_loss: 2.7967 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7484 - acc: 0.9384 - precision: 0.9812 - recall: 0.8998 - f1_score: 0.9385 - val_loss: 2.7835 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7352 - acc: 0.9384 - precision: 0.9798 - recall: 0.8988 - f1_score: 0.9366 - val_loss: 2.7704 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7222 - acc: 0.9384 - precision: 0.9784 - recall: 0.8962 - f1_score: 0.9346 - val_loss: 2.7573 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7092 - acc: 0.9384 - precision: 0.9805 - recall: 0.9014 - f1_score: 0.9378 - val_loss: 2.7443 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6962 - acc: 0.9384 - precision: 0.9815 - recall: 0.8991 - f1_score: 0.9380 - val_loss: 2.7314 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6834 - acc: 0.9384 - precision: 0.9795 - recall: 0.9017 - f1_score: 0.9385 - val_loss: 2.7185 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6706 - acc: 0.9384 - precision: 0.9814 - recall: 0.9016 - f1_score: 0.9392 - val_loss: 2.7057 - val_acc: 0.9367 - val_precision: 0.9802 - val_recall: 0.8583 - val_f1_score: 0.9134\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6579 - acc: 0.9384 - precision: 0.9810 - recall: 0.8975 - f1_score: 0.9361 - val_loss: 2.6930 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6452 - acc: 0.9384 - precision: 0.9808 - recall: 0.8996 - f1_score: 0.9376 - val_loss: 2.6804 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6327 - acc: 0.9384 - precision: 0.9798 - recall: 0.9005 - f1_score: 0.9375 - val_loss: 2.6678 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6201 - acc: 0.9384 - precision: 0.9808 - recall: 0.9008 - f1_score: 0.9383 - val_loss: 2.6553 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6077 - acc: 0.9384 - precision: 0.9793 - recall: 0.8990 - f1_score: 0.9366 - val_loss: 2.6428 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5953 - acc: 0.9384 - precision: 0.9794 - recall: 0.9004 - f1_score: 0.9366 - val_loss: 2.6304 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5830 - acc: 0.9384 - precision: 0.9806 - recall: 0.9004 - f1_score: 0.9385 - val_loss: 2.6181 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5707 - acc: 0.9384 - precision: 0.9819 - recall: 0.8989 - f1_score: 0.9353 - val_loss: 2.6058 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5585 - acc: 0.9384 - precision: 0.9805 - recall: 0.9013 - f1_score: 0.9382 - val_loss: 2.5936 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5464 - acc: 0.9384 - precision: 0.9812 - recall: 0.8988 - f1_score: 0.9372 - val_loss: 2.5815 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5343 - acc: 0.9384 - precision: 0.9780 - recall: 0.9023 - f1_score: 0.9366 - val_loss: 2.5695 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5223 - acc: 0.9384 - precision: 0.9793 - recall: 0.8991 - f1_score: 0.9367 - val_loss: 2.5575 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5104 - acc: 0.9384 - precision: 0.9792 - recall: 0.9011 - f1_score: 0.9382 - val_loss: 2.5456 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4985 - acc: 0.9384 - precision: 0.9813 - recall: 0.9036 - f1_score: 0.9397 - val_loss: 2.5337 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.5529 - acc: 0.8600 - precision: 0.9524 - recall: 0.7692 - f1_score: 0.851 - 0s - loss: 2.4867 - acc: 0.9400 - precision: 0.9776 - recall: 0.9012 - f1_score: 0.9367 - val_loss: 2.5219 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4750 - acc: 0.9384 - precision: 0.9810 - recall: 0.8984 - f1_score: 0.9360 - val_loss: 2.5101 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4633 - acc: 0.9384 - precision: 0.9814 - recall: 0.8990 - f1_score: 0.9373 - val_loss: 2.4985 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4517 - acc: 0.9384 - precision: 0.9809 - recall: 0.8968 - f1_score: 0.9360 - val_loss: 2.4868 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4401 - acc: 0.9400 - precision: 0.9798 - recall: 0.9028 - f1_score: 0.9384 - val_loss: 2.4753 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4286 - acc: 0.9400 - precision: 0.9812 - recall: 0.9034 - f1_score: 0.9397 - val_loss: 2.4638 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4172 - acc: 0.9400 - precision: 0.9795 - recall: 0.9033 - f1_score: 0.9383 - val_loss: 2.4523 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4058 - acc: 0.9400 - precision: 0.9795 - recall: 0.9031 - f1_score: 0.9389 - val_loss: 2.4410 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3945 - acc: 0.9400 - precision: 0.9807 - recall: 0.9031 - f1_score: 0.9398 - val_loss: 2.4297 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3832 - acc: 0.9400 - precision: 0.9823 - recall: 0.9039 - f1_score: 0.9403 - val_loss: 2.4184 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.3720 - acc: 0.9400 - precision: 0.9814 - recall: 0.9082 - f1_score: 0.9428 - val_loss: 2.4072 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3609 - acc: 0.9400 - precision: 0.9781 - recall: 0.9015 - f1_score: 0.9377 - val_loss: 2.3961 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3498 - acc: 0.9400 - precision: 0.9810 - recall: 0.9023 - f1_score: 0.9390 - val_loss: 2.3850 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3387 - acc: 0.9400 - precision: 0.9823 - recall: 0.9018 - f1_score: 0.9391 - val_loss: 2.3740 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3278 - acc: 0.9400 - precision: 0.9813 - recall: 0.9062 - f1_score: 0.9407 - val_loss: 2.3630 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3169 - acc: 0.9400 - precision: 0.9823 - recall: 0.9016 - f1_score: 0.9387 - val_loss: 2.3521 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3060 - acc: 0.9400 - precision: 0.9778 - recall: 0.9054 - f1_score: 0.9393 - val_loss: 2.3413 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2952 - acc: 0.9400 - precision: 0.9808 - recall: 0.9015 - f1_score: 0.9389 - val_loss: 2.3305 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2845 - acc: 0.9400 - precision: 0.9802 - recall: 0.9018 - f1_score: 0.9382 - val_loss: 2.3197 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2738 - acc: 0.9400 - precision: 0.9805 - recall: 0.9060 - f1_score: 0.9406 - val_loss: 2.3090 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2631 - acc: 0.9400 - precision: 0.9770 - recall: 0.9049 - f1_score: 0.9378 - val_loss: 2.2984 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2526 - acc: 0.9400 - precision: 0.9807 - recall: 0.9034 - f1_score: 0.9394 - val_loss: 2.2878 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2420 - acc: 0.9400 - precision: 0.9804 - recall: 0.9055 - f1_score: 0.9399 - val_loss: 2.2773 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2316 - acc: 0.9400 - precision: 0.9791 - recall: 0.8957 - f1_score: 0.9340 - val_loss: 2.2669 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2212 - acc: 0.9400 - precision: 0.9799 - recall: 0.9022 - f1_score: 0.9380 - val_loss: 2.2565 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2108 - acc: 0.9400 - precision: 0.9793 - recall: 0.8983 - f1_score: 0.9362 - val_loss: 2.2461 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2005 - acc: 0.9400 - precision: 0.9796 - recall: 0.9040 - f1_score: 0.9391 - val_loss: 2.2358 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1903 - acc: 0.9400 - precision: 0.9806 - recall: 0.9012 - f1_score: 0.9380 - val_loss: 2.2256 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1801 - acc: 0.9400 - precision: 0.9811 - recall: 0.9055 - f1_score: 0.9410 - val_loss: 2.2154 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1699 - acc: 0.9400 - precision: 0.9792 - recall: 0.8954 - f1_score: 0.9341 - val_loss: 2.2053 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1599 - acc: 0.9400 - precision: 0.9805 - recall: 0.9012 - f1_score: 0.9383 - val_loss: 2.1952 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1498 - acc: 0.9400 - precision: 0.9805 - recall: 0.9029 - f1_score: 0.9391 - val_loss: 2.1852 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1398 - acc: 0.9400 - precision: 0.9788 - recall: 0.9044 - f1_score: 0.9395 - val_loss: 2.1752 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1299 - acc: 0.9400 - precision: 0.9812 - recall: 0.9026 - f1_score: 0.9394 - val_loss: 2.1653 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1200 - acc: 0.9400 - precision: 0.9813 - recall: 0.9050 - f1_score: 0.9406 - val_loss: 2.1554 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1102 - acc: 0.9400 - precision: 0.9796 - recall: 0.9019 - f1_score: 0.9381 - val_loss: 2.1456 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1004 - acc: 0.9400 - precision: 0.9799 - recall: 0.9045 - f1_score: 0.9392 - val_loss: 2.1358 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0907 - acc: 0.9415 - precision: 0.9838 - recall: 0.9020 - f1_score: 0.9408 - val_loss: 2.1261 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0810 - acc: 0.9400 - precision: 0.9781 - recall: 0.9033 - f1_score: 0.9385 - val_loss: 2.1164 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0714 - acc: 0.9415 - precision: 0.9828 - recall: 0.8988 - f1_score: 0.9379 - val_loss: 2.1068 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0618 - acc: 0.9415 - precision: 0.9841 - recall: 0.9047 - f1_score: 0.9419 - val_loss: 2.0972 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0523 - acc: 0.9415 - precision: 0.9836 - recall: 0.9034 - f1_score: 0.9409 - val_loss: 2.0877 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.0428 - acc: 0.9415 - precision: 0.9820 - recall: 0.9053 - f1_score: 0.9406 - val_loss: 2.0783 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0334 - acc: 0.9415 - precision: 0.9861 - recall: 0.9048 - f1_score: 0.9430 - val_loss: 2.0689 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0240 - acc: 0.9415 - precision: 0.9834 - recall: 0.9037 - f1_score: 0.9414 - val_loss: 2.0595 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0147 - acc: 0.9415 - precision: 0.9832 - recall: 0.9015 - f1_score: 0.9394 - val_loss: 2.0502 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0054 - acc: 0.9415 - precision: 0.9835 - recall: 0.9043 - f1_score: 0.9407 - val_loss: 2.0409 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9962 - acc: 0.9415 - precision: 0.9828 - recall: 0.9038 - f1_score: 0.9407 - val_loss: 2.0317 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9870 - acc: 0.9415 - precision: 0.9848 - recall: 0.9029 - f1_score: 0.9408 - val_loss: 2.0225 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9779 - acc: 0.9415 - precision: 0.9850 - recall: 0.8989 - f1_score: 0.9388 - val_loss: 2.0134 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9688 - acc: 0.9415 - precision: 0.9831 - recall: 0.9052 - f1_score: 0.9411 - val_loss: 2.0043 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9598 - acc: 0.9415 - precision: 0.9843 - recall: 0.9020 - f1_score: 0.9404 - val_loss: 1.9953 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9508 - acc: 0.9415 - precision: 0.9832 - recall: 0.9004 - f1_score: 0.9379 - val_loss: 1.9863 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9418 - acc: 0.9415 - precision: 0.9815 - recall: 0.9037 - f1_score: 0.9402 - val_loss: 1.9774 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9329 - acc: 0.9415 - precision: 0.9821 - recall: 0.9043 - f1_score: 0.9405 - val_loss: 1.9685 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9241 - acc: 0.9415 - precision: 0.9827 - recall: 0.9038 - f1_score: 0.9404 - val_loss: 1.9596 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9153 - acc: 0.9415 - precision: 0.9836 - recall: 0.9046 - f1_score: 0.9408 - val_loss: 1.9508 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9065 - acc: 0.9415 - precision: 0.9831 - recall: 0.9020 - f1_score: 0.9402 - val_loss: 1.9421 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8978 - acc: 0.9415 - precision: 0.9834 - recall: 0.9023 - f1_score: 0.9397 - val_loss: 1.9334 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8891 - acc: 0.9415 - precision: 0.9839 - recall: 0.9009 - f1_score: 0.9389 - val_loss: 1.9247 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8805 - acc: 0.9415 - precision: 0.9830 - recall: 0.9022 - f1_score: 0.9397 - val_loss: 1.9161 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8719 - acc: 0.9415 - precision: 0.9842 - recall: 0.9059 - f1_score: 0.9420 - val_loss: 1.9076 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8634 - acc: 0.9415 - precision: 0.9837 - recall: 0.9026 - f1_score: 0.9402 - val_loss: 1.8990 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8549 - acc: 0.9415 - precision: 0.9834 - recall: 0.9020 - f1_score: 0.9400 - val_loss: 1.8905 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8465 - acc: 0.9415 - precision: 0.9854 - recall: 0.9052 - f1_score: 0.9429 - val_loss: 1.8821 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8381 - acc: 0.9415 - precision: 0.9856 - recall: 0.9020 - f1_score: 0.9408 - val_loss: 1.8737 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8297 - acc: 0.9415 - precision: 0.9836 - recall: 0.9030 - f1_score: 0.9408 - val_loss: 1.8654 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8214 - acc: 0.9415 - precision: 0.9825 - recall: 0.9036 - f1_score: 0.9407 - val_loss: 1.8571 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8131 - acc: 0.9415 - precision: 0.9835 - recall: 0.9018 - f1_score: 0.9402 - val_loss: 1.8488 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8049 - acc: 0.9415 - precision: 0.9850 - recall: 0.9017 - f1_score: 0.9408 - val_loss: 1.8406 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7967 - acc: 0.9415 - precision: 0.9845 - recall: 0.9012 - f1_score: 0.9401 - val_loss: 1.8324 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7886 - acc: 0.9415 - precision: 0.9842 - recall: 0.9023 - f1_score: 0.9405 - val_loss: 1.8243 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7805 - acc: 0.9415 - precision: 0.9831 - recall: 0.9040 - f1_score: 0.9407 - val_loss: 1.8162 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7724 - acc: 0.9415 - precision: 0.9848 - recall: 0.9042 - f1_score: 0.9417 - val_loss: 1.8081 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 248/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.7644 - acc: 0.9415 - precision: 0.9835 - recall: 0.9054 - f1_score: 0.9422 - val_loss: 1.8001 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7564 - acc: 0.9415 - precision: 0.9832 - recall: 0.9035 - f1_score: 0.9405 - val_loss: 1.7922 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7485 - acc: 0.9415 - precision: 0.9836 - recall: 0.9016 - f1_score: 0.9401 - val_loss: 1.7842 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7406 - acc: 0.9415 - precision: 0.9828 - recall: 0.9025 - f1_score: 0.9403 - val_loss: 1.7764 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7327 - acc: 0.9415 - precision: 0.9838 - recall: 0.9048 - f1_score: 0.9422 - val_loss: 1.7685 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.7566 - acc: 0.9000 - precision: 0.9655 - recall: 0.8750 - f1_score: 0.918 - 0s - loss: 1.7249 - acc: 0.9415 - precision: 0.9836 - recall: 0.9054 - f1_score: 0.9425 - val_loss: 1.7607 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7171 - acc: 0.9415 - precision: 0.9836 - recall: 0.9063 - f1_score: 0.9422 - val_loss: 1.7529 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7094 - acc: 0.9415 - precision: 0.9835 - recall: 0.8988 - f1_score: 0.9381 - val_loss: 1.7452 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7017 - acc: 0.9415 - precision: 0.9834 - recall: 0.9055 - f1_score: 0.9419 - val_loss: 1.7375 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6941 - acc: 0.9415 - precision: 0.9841 - recall: 0.9037 - f1_score: 0.9416 - val_loss: 1.7299 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6865 - acc: 0.9415 - precision: 0.9828 - recall: 0.9002 - f1_score: 0.9392 - val_loss: 1.7223 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6789 - acc: 0.9415 - precision: 0.9840 - recall: 0.9008 - f1_score: 0.9395 - val_loss: 1.7147 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6713 - acc: 0.9415 - precision: 0.9832 - recall: 0.9021 - f1_score: 0.9404 - val_loss: 1.7072 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6638 - acc: 0.9415 - precision: 0.9824 - recall: 0.9050 - f1_score: 0.9411 - val_loss: 1.6997 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6564 - acc: 0.9415 - precision: 0.9854 - recall: 0.9026 - f1_score: 0.9400 - val_loss: 1.6923 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6490 - acc: 0.9415 - precision: 0.9851 - recall: 0.9022 - f1_score: 0.9408 - val_loss: 1.6849 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6416 - acc: 0.9415 - precision: 0.9829 - recall: 0.9033 - f1_score: 0.9407 - val_loss: 1.6775 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6343 - acc: 0.9415 - precision: 0.9841 - recall: 0.9045 - f1_score: 0.9417 - val_loss: 1.6702 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.6894 - acc: 0.9200 - precision: 1.0000 - recall: 0.7647 - f1_score: 0.866 - 0s - loss: 1.6270 - acc: 0.9415 - precision: 0.9835 - recall: 0.9001 - f1_score: 0.9380 - val_loss: 1.6629 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6197 - acc: 0.9415 - precision: 0.9840 - recall: 0.8996 - f1_score: 0.9388 - val_loss: 1.6556 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6125 - acc: 0.9415 - precision: 0.9839 - recall: 0.9030 - f1_score: 0.9408 - val_loss: 1.6484 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6053 - acc: 0.9415 - precision: 0.9835 - recall: 0.9045 - f1_score: 0.9419 - val_loss: 1.6412 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5981 - acc: 0.9415 - precision: 0.9837 - recall: 0.9008 - f1_score: 0.9389 - val_loss: 1.6341 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5910 - acc: 0.9415 - precision: 0.9819 - recall: 0.9015 - f1_score: 0.9393 - val_loss: 1.6270 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5839 - acc: 0.9415 - precision: 0.9841 - recall: 0.9010 - f1_score: 0.9405 - val_loss: 1.6199 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5769 - acc: 0.9415 - precision: 0.9813 - recall: 0.9032 - f1_score: 0.9390 - val_loss: 1.6129 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5699 - acc: 0.9415 - precision: 0.9837 - recall: 0.9038 - f1_score: 0.9403 - val_loss: 1.6059 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5629 - acc: 0.9415 - precision: 0.9830 - recall: 0.9042 - f1_score: 0.9409 - val_loss: 1.5989 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5560 - acc: 0.9415 - precision: 0.9824 - recall: 0.9010 - f1_score: 0.9392 - val_loss: 1.5920 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5491 - acc: 0.9415 - precision: 0.9821 - recall: 0.9043 - f1_score: 0.9407 - val_loss: 1.5851 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5422 - acc: 0.9415 - precision: 0.9835 - recall: 0.9047 - f1_score: 0.9415 - val_loss: 1.5783 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.5354 - acc: 0.9415 - precision: 0.9833 - recall: 0.9032 - f1_score: 0.9400 - val_loss: 1.5715 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5286 - acc: 0.9415 - precision: 0.9831 - recall: 0.9074 - f1_score: 0.9420 - val_loss: 1.5647 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5218 - acc: 0.9415 - precision: 0.9839 - recall: 0.9021 - f1_score: 0.9399 - val_loss: 1.5579 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5151 - acc: 0.9415 - precision: 0.9812 - recall: 0.8985 - f1_score: 0.9372 - val_loss: 1.5512 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5084 - acc: 0.9415 - precision: 0.9840 - recall: 0.9043 - f1_score: 0.9416 - val_loss: 1.5445 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5018 - acc: 0.9415 - precision: 0.9839 - recall: 0.9008 - f1_score: 0.9393 - val_loss: 1.5379 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4951 - acc: 0.9415 - precision: 0.9829 - recall: 0.9042 - f1_score: 0.9411 - val_loss: 1.5313 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4886 - acc: 0.9415 - precision: 0.9826 - recall: 0.9016 - f1_score: 0.9397 - val_loss: 1.5247 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4820 - acc: 0.9415 - precision: 0.9831 - recall: 0.9034 - f1_score: 0.9401 - val_loss: 1.5182 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4755 - acc: 0.9415 - precision: 0.9840 - recall: 0.9026 - f1_score: 0.9409 - val_loss: 1.5116 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4690 - acc: 0.9415 - precision: 0.9843 - recall: 0.9045 - f1_score: 0.9420 - val_loss: 1.5052 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4626 - acc: 0.9415 - precision: 0.9864 - recall: 0.9044 - f1_score: 0.9426 - val_loss: 1.4987 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4562 - acc: 0.9415 - precision: 0.9846 - recall: 0.9017 - f1_score: 0.9398 - val_loss: 1.4923 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4498 - acc: 0.9415 - precision: 0.9830 - recall: 0.9041 - f1_score: 0.9408 - val_loss: 1.4860 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4434 - acc: 0.9415 - precision: 0.9851 - recall: 0.9043 - f1_score: 0.9414 - val_loss: 1.4796 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4371 - acc: 0.9415 - precision: 0.9810 - recall: 0.9031 - f1_score: 0.9398 - val_loss: 1.4733 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4308 - acc: 0.9415 - precision: 0.9840 - recall: 0.9040 - f1_score: 0.9406 - val_loss: 1.4670 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4246 - acc: 0.9415 - precision: 0.9826 - recall: 0.9014 - f1_score: 0.9390 - val_loss: 1.4608 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4183 - acc: 0.9415 - precision: 0.9819 - recall: 0.9044 - f1_score: 0.9408 - val_loss: 1.4546 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4122 - acc: 0.9415 - precision: 0.9817 - recall: 0.9016 - f1_score: 0.9396 - val_loss: 1.4484 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4060 - acc: 0.9415 - precision: 0.9835 - recall: 0.9031 - f1_score: 0.9404 - val_loss: 1.4422 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3999 - acc: 0.9415 - precision: 0.9827 - recall: 0.9011 - f1_score: 0.9392 - val_loss: 1.4361 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3938 - acc: 0.9415 - precision: 0.9829 - recall: 0.9043 - f1_score: 0.9398 - val_loss: 1.4301 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3877 - acc: 0.9415 - precision: 0.9831 - recall: 0.9033 - f1_score: 0.9406 - val_loss: 1.4240 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3817 - acc: 0.9415 - precision: 0.9843 - recall: 0.9055 - f1_score: 0.9423 - val_loss: 1.4180 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3757 - acc: 0.9415 - precision: 0.9820 - recall: 0.8990 - f1_score: 0.9375 - val_loss: 1.4120 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3697 - acc: 0.9415 - precision: 0.9831 - recall: 0.9024 - f1_score: 0.9403 - val_loss: 1.4060 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3638 - acc: 0.9415 - precision: 0.9833 - recall: 0.9031 - f1_score: 0.9405 - val_loss: 1.4001 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3579 - acc: 0.9415 - precision: 0.9843 - recall: 0.9050 - f1_score: 0.9419 - val_loss: 1.3942 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3520 - acc: 0.9415 - precision: 0.9828 - recall: 0.9033 - f1_score: 0.9403 - val_loss: 1.3883 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3462 - acc: 0.9415 - precision: 0.9831 - recall: 0.9028 - f1_score: 0.9406 - val_loss: 1.3825 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3403 - acc: 0.9415 - precision: 0.9837 - recall: 0.9051 - f1_score: 0.9415 - val_loss: 1.3767 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3346 - acc: 0.9415 - precision: 0.9830 - recall: 0.9045 - f1_score: 0.9403 - val_loss: 1.3709 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3288 - acc: 0.9447 - precision: 0.9841 - recall: 0.9099 - f1_score: 0.9447 - val_loss: 1.3652 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3231 - acc: 0.9431 - precision: 0.9851 - recall: 0.9067 - f1_score: 0.9432 - val_loss: 1.3594 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3174 - acc: 0.9447 - precision: 0.9826 - recall: 0.9074 - f1_score: 0.9424 - val_loss: 1.3537 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3117 - acc: 0.9447 - precision: 0.9839 - recall: 0.9097 - f1_score: 0.9445 - val_loss: 1.3481 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3061 - acc: 0.9447 - precision: 0.9832 - recall: 0.9143 - f1_score: 0.9466 - val_loss: 1.3425 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3004 - acc: 0.9447 - precision: 0.9825 - recall: 0.9072 - f1_score: 0.9427 - val_loss: 1.3368 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2949 - acc: 0.9447 - precision: 0.9842 - recall: 0.9096 - f1_score: 0.9447 - val_loss: 1.3313 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2893 - acc: 0.9447 - precision: 0.9843 - recall: 0.9077 - f1_score: 0.9440 - val_loss: 1.3257 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2838 - acc: 0.9447 - precision: 0.9833 - recall: 0.9048 - f1_score: 0.9417 - val_loss: 1.3202 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2783 - acc: 0.9447 - precision: 0.9825 - recall: 0.9077 - f1_score: 0.9424 - val_loss: 1.3147 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2728 - acc: 0.9447 - precision: 0.9831 - recall: 0.9096 - f1_score: 0.9439 - val_loss: 1.3093 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2674 - acc: 0.9447 - precision: 0.9843 - recall: 0.9120 - f1_score: 0.9458 - val_loss: 1.3039 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2620 - acc: 0.9447 - precision: 0.9849 - recall: 0.9099 - f1_score: 0.9454 - val_loss: 1.2985 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2566 - acc: 0.9447 - precision: 0.9858 - recall: 0.9083 - f1_score: 0.9440 - val_loss: 1.2931 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2512 - acc: 0.9447 - precision: 0.9850 - recall: 0.9129 - f1_score: 0.9462 - val_loss: 1.2877 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2459 - acc: 0.9447 - precision: 0.9849 - recall: 0.9076 - f1_score: 0.9437 - val_loss: 1.2824 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2406 - acc: 0.9447 - precision: 0.9831 - recall: 0.9087 - f1_score: 0.9437 - val_loss: 1.2771 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2353 - acc: 0.9447 - precision: 0.9847 - recall: 0.9120 - f1_score: 0.9462 - val_loss: 1.2718 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2301 - acc: 0.9447 - precision: 0.9840 - recall: 0.9094 - f1_score: 0.9446 - val_loss: 1.2666 - val_acc: 0.9304 - val_precision: 0.9628 - val_recall: 0.8583 - val_f1_score: 0.9066\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2249 - acc: 0.9447 - precision: 0.9822 - recall: 0.9091 - f1_score: 0.9436 - val_loss: 1.2614 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2197 - acc: 0.9447 - precision: 0.9833 - recall: 0.9093 - f1_score: 0.9442 - val_loss: 1.2562 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2145 - acc: 0.9447 - precision: 0.9833 - recall: 0.9091 - f1_score: 0.9436 - val_loss: 1.2511 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2094 - acc: 0.9447 - precision: 0.9815 - recall: 0.9062 - f1_score: 0.9420 - val_loss: 1.2459 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2042 - acc: 0.9447 - precision: 0.9850 - recall: 0.9056 - f1_score: 0.9425 - val_loss: 1.2408 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1992 - acc: 0.9463 - precision: 0.9861 - recall: 0.9111 - f1_score: 0.9466 - val_loss: 1.2357 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1941 - acc: 0.9463 - precision: 0.9872 - recall: 0.9101 - f1_score: 0.9464 - val_loss: 1.2307 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1891 - acc: 0.9447 - precision: 0.9821 - recall: 0.9072 - f1_score: 0.9423 - val_loss: 1.2256 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1840 - acc: 0.9463 - precision: 0.9882 - recall: 0.9080 - f1_score: 0.9446 - val_loss: 1.2206 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1791 - acc: 0.9463 - precision: 0.9866 - recall: 0.9065 - f1_score: 0.9442 - val_loss: 1.2157 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1741 - acc: 0.9463 - precision: 0.9874 - recall: 0.9134 - f1_score: 0.9478 - val_loss: 1.2107 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1692 - acc: 0.9463 - precision: 0.9862 - recall: 0.9068 - f1_score: 0.9442 - val_loss: 1.2058 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1643 - acc: 0.9463 - precision: 0.9880 - recall: 0.9117 - f1_score: 0.9478 - val_loss: 1.2009 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1594 - acc: 0.9463 - precision: 0.9870 - recall: 0.9139 - f1_score: 0.9477 - val_loss: 1.1960 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1545 - acc: 0.9463 - precision: 0.9872 - recall: 0.9096 - f1_score: 0.9457 - val_loss: 1.1912 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1497 - acc: 0.9463 - precision: 0.9878 - recall: 0.9109 - f1_score: 0.9469 - val_loss: 1.1864 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1449 - acc: 0.9463 - precision: 0.9869 - recall: 0.9125 - f1_score: 0.9473 - val_loss: 1.1816 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1401 - acc: 0.9463 - precision: 0.9875 - recall: 0.9099 - f1_score: 0.9468 - val_loss: 1.1768 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1353 - acc: 0.9463 - precision: 0.9857 - recall: 0.9071 - f1_score: 0.9438 - val_loss: 1.1720 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1306 - acc: 0.9463 - precision: 0.9870 - recall: 0.9108 - f1_score: 0.9466 - val_loss: 1.1673 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1259 - acc: 0.9463 - precision: 0.9869 - recall: 0.9099 - f1_score: 0.9461 - val_loss: 1.1626 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1212 - acc: 0.9463 - precision: 0.9878 - recall: 0.9113 - f1_score: 0.9467 - val_loss: 1.1579 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1166 - acc: 0.9463 - precision: 0.9863 - recall: 0.9098 - f1_score: 0.9448 - val_loss: 1.1533 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1119 - acc: 0.9463 - precision: 0.9879 - recall: 0.9027 - f1_score: 0.9422 - val_loss: 1.1486 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1073 - acc: 0.9463 - precision: 0.9864 - recall: 0.9086 - f1_score: 0.9453 - val_loss: 1.1440 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1027 - acc: 0.9463 - precision: 0.9875 - recall: 0.9100 - f1_score: 0.9463 - val_loss: 1.1394 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0981 - acc: 0.9447 - precision: 0.9885 - recall: 0.9041 - f1_score: 0.9432 - val_loss: 1.1349 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0936 - acc: 0.9447 - precision: 0.9870 - recall: 0.9083 - f1_score: 0.9455 - val_loss: 1.1303 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0891 - acc: 0.9447 - precision: 0.9861 - recall: 0.9063 - f1_score: 0.9439 - val_loss: 1.1258 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0846 - acc: 0.9447 - precision: 0.9874 - recall: 0.9035 - f1_score: 0.9414 - val_loss: 1.1213 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0801 - acc: 0.9447 - precision: 0.9876 - recall: 0.9088 - f1_score: 0.9450 - val_loss: 1.1169 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0756 - acc: 0.9447 - precision: 0.9866 - recall: 0.9080 - f1_score: 0.9444 - val_loss: 1.1124 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0712 - acc: 0.9447 - precision: 0.9878 - recall: 0.9061 - f1_score: 0.9434 - val_loss: 1.1080 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0668 - acc: 0.9447 - precision: 0.9876 - recall: 0.9075 - f1_score: 0.9447 - val_loss: 1.1036 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0624 - acc: 0.9447 - precision: 0.9850 - recall: 0.9048 - f1_score: 0.9419 - val_loss: 1.0992 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0581 - acc: 0.9447 - precision: 0.9866 - recall: 0.9097 - f1_score: 0.9449 - val_loss: 1.0949 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0537 - acc: 0.9447 - precision: 0.9860 - recall: 0.9027 - f1_score: 0.9416 - val_loss: 1.0905 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0494 - acc: 0.9447 - precision: 0.9871 - recall: 0.9087 - f1_score: 0.9453 - val_loss: 1.0862 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0451 - acc: 0.9447 - precision: 0.9860 - recall: 0.9111 - f1_score: 0.9461 - val_loss: 1.0820 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0408 - acc: 0.9447 - precision: 0.9880 - recall: 0.9063 - f1_score: 0.9441 - val_loss: 1.0777 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0366 - acc: 0.9447 - precision: 0.9861 - recall: 0.9054 - f1_score: 0.9435 - val_loss: 1.0734 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0324 - acc: 0.9447 - precision: 0.9855 - recall: 0.9064 - f1_score: 0.9434 - val_loss: 1.0692 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0281 - acc: 0.9447 - precision: 0.9880 - recall: 0.9054 - f1_score: 0.9435 - val_loss: 1.0650 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0240 - acc: 0.9447 - precision: 0.9855 - recall: 0.9071 - f1_score: 0.9435 - val_loss: 1.0608 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0198 - acc: 0.9447 - precision: 0.9866 - recall: 0.9042 - f1_score: 0.9423 - val_loss: 1.0567 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0157 - acc: 0.9447 - precision: 0.9870 - recall: 0.9025 - f1_score: 0.9414 - val_loss: 1.0525 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0115 - acc: 0.9447 - precision: 0.9867 - recall: 0.9079 - f1_score: 0.9447 - val_loss: 1.0484 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0074 - acc: 0.9447 - precision: 0.9880 - recall: 0.9035 - f1_score: 0.9431 - val_loss: 1.0443 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0033 - acc: 0.9447 - precision: 0.9870 - recall: 0.9087 - f1_score: 0.9448 - val_loss: 1.0403 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.9514 - acc: 0.9800 - precision: 0.9706 - recall: 1.0000 - f1_score: 0.985 - 0s - loss: 0.9993 - acc: 0.9447 - precision: 0.9879 - recall: 0.9005 - f1_score: 0.9411 - val_loss: 1.0362 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9952 - acc: 0.9447 - precision: 0.9866 - recall: 0.9039 - f1_score: 0.9411 - val_loss: 1.0322 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9912 - acc: 0.9447 - precision: 0.9868 - recall: 0.9059 - f1_score: 0.9436 - val_loss: 1.0281 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9872 - acc: 0.9447 - precision: 0.9851 - recall: 0.9076 - f1_score: 0.9439 - val_loss: 1.0242 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9832 - acc: 0.9447 - precision: 0.9882 - recall: 0.9081 - f1_score: 0.9454 - val_loss: 1.0202 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9793 - acc: 0.9447 - precision: 0.9869 - recall: 0.9101 - f1_score: 0.9455 - val_loss: 1.0162 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9754 - acc: 0.9447 - precision: 0.9860 - recall: 0.9034 - f1_score: 0.9420 - val_loss: 1.0123 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9714 - acc: 0.9447 - precision: 0.9860 - recall: 0.9050 - f1_score: 0.9429 - val_loss: 1.0084 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9675 - acc: 0.9447 - precision: 0.9885 - recall: 0.9077 - f1_score: 0.9455 - val_loss: 1.0045 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9637 - acc: 0.9447 - precision: 0.9882 - recall: 0.8985 - f1_score: 0.9379 - val_loss: 1.0006 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9598 - acc: 0.9447 - precision: 0.9869 - recall: 0.9064 - f1_score: 0.9434 - val_loss: 0.9968 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9560 - acc: 0.9447 - precision: 0.9859 - recall: 0.9045 - f1_score: 0.9427 - val_loss: 0.9929 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9521 - acc: 0.9447 - precision: 0.9856 - recall: 0.9030 - f1_score: 0.9413 - val_loss: 0.9891 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9483 - acc: 0.9447 - precision: 0.9883 - recall: 0.9062 - f1_score: 0.9442 - val_loss: 0.9853 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9446 - acc: 0.9447 - precision: 0.9874 - recall: 0.9099 - f1_score: 0.9461 - val_loss: 0.9816 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9408 - acc: 0.9447 - precision: 0.9883 - recall: 0.9079 - f1_score: 0.9452 - val_loss: 0.9778 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9371 - acc: 0.9447 - precision: 0.9860 - recall: 0.9062 - f1_score: 0.9435 - val_loss: 0.9741 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9333 - acc: 0.9447 - precision: 0.9864 - recall: 0.9057 - f1_score: 0.9437 - val_loss: 0.9703 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9296 - acc: 0.9447 - precision: 0.9876 - recall: 0.9084 - f1_score: 0.9447 - val_loss: 0.9666 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9259 - acc: 0.9447 - precision: 0.9878 - recall: 0.9092 - f1_score: 0.9461 - val_loss: 0.9630 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9223 - acc: 0.9447 - precision: 0.9869 - recall: 0.9059 - f1_score: 0.9437 - val_loss: 0.9593 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9186 - acc: 0.9447 - precision: 0.9872 - recall: 0.9075 - f1_score: 0.9450 - val_loss: 0.9557 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9150 - acc: 0.9447 - precision: 0.9874 - recall: 0.9031 - f1_score: 0.9414 - val_loss: 0.9520 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9114 - acc: 0.9447 - precision: 0.9858 - recall: 0.9058 - f1_score: 0.9435 - val_loss: 0.9484 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9078 - acc: 0.9447 - precision: 0.9876 - recall: 0.9047 - f1_score: 0.9435 - val_loss: 0.9448 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9042 - acc: 0.9447 - precision: 0.9871 - recall: 0.9041 - f1_score: 0.9425 - val_loss: 0.9413 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9007 - acc: 0.9447 - precision: 0.9879 - recall: 0.9053 - f1_score: 0.9440 - val_loss: 0.9377 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8971 - acc: 0.9447 - precision: 0.9865 - recall: 0.9046 - f1_score: 0.9433 - val_loss: 0.9342 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8936 - acc: 0.9447 - precision: 0.9867 - recall: 0.9049 - f1_score: 0.9431 - val_loss: 0.9307 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8901 - acc: 0.9463 - precision: 0.9878 - recall: 0.9111 - f1_score: 0.9468 - val_loss: 0.9272 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8866 - acc: 0.9447 - precision: 0.9860 - recall: 0.9059 - f1_score: 0.9431 - val_loss: 0.9237 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8831 - acc: 0.9463 - precision: 0.9872 - recall: 0.9097 - f1_score: 0.9461 - val_loss: 0.9202 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8797 - acc: 0.9463 - precision: 0.9870 - recall: 0.9143 - f1_score: 0.9485 - val_loss: 0.9168 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8763 - acc: 0.9463 - precision: 0.9878 - recall: 0.9039 - f1_score: 0.9425 - val_loss: 0.9133 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8729 - acc: 0.9463 - precision: 0.9865 - recall: 0.9063 - f1_score: 0.9440 - val_loss: 0.9099 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8695 - acc: 0.9463 - precision: 0.9876 - recall: 0.9116 - f1_score: 0.9467 - val_loss: 0.9065 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8661 - acc: 0.9463 - precision: 0.9879 - recall: 0.9097 - f1_score: 0.9464 - val_loss: 0.9032 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8627 - acc: 0.9463 - precision: 0.9859 - recall: 0.9103 - f1_score: 0.9459 - val_loss: 0.8998 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8594 - acc: 0.9463 - precision: 0.9883 - recall: 0.9036 - f1_score: 0.9423 - val_loss: 0.8965 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8560 - acc: 0.9463 - precision: 0.9861 - recall: 0.9082 - f1_score: 0.9449 - val_loss: 0.8931 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8527 - acc: 0.9463 - precision: 0.9872 - recall: 0.9110 - f1_score: 0.9471 - val_loss: 0.8898 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8494 - acc: 0.9463 - precision: 0.9866 - recall: 0.9090 - f1_score: 0.9452 - val_loss: 0.8866 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8462 - acc: 0.9463 - precision: 0.9879 - recall: 0.9069 - f1_score: 0.9447 - val_loss: 0.8833 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8429 - acc: 0.9463 - precision: 0.9887 - recall: 0.9098 - f1_score: 0.9469 - val_loss: 0.8800 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8396 - acc: 0.9463 - precision: 0.9870 - recall: 0.9123 - f1_score: 0.9472 - val_loss: 0.8768 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8364 - acc: 0.9463 - precision: 0.9879 - recall: 0.9073 - f1_score: 0.9442 - val_loss: 0.8736 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8332 - acc: 0.9463 - precision: 0.9878 - recall: 0.9089 - f1_score: 0.9463 - val_loss: 0.8703 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8300 - acc: 0.9463 - precision: 0.9872 - recall: 0.9118 - f1_score: 0.9471 - val_loss: 0.8672 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8268 - acc: 0.9463 - precision: 0.9879 - recall: 0.9091 - f1_score: 0.9459 - val_loss: 0.8640 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8237 - acc: 0.9463 - precision: 0.9877 - recall: 0.9108 - f1_score: 0.9471 - val_loss: 0.8608 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8205 - acc: 0.9463 - precision: 0.9869 - recall: 0.9096 - f1_score: 0.9457 - val_loss: 0.8577 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8174 - acc: 0.9463 - precision: 0.9870 - recall: 0.9073 - f1_score: 0.9446 - val_loss: 0.8545 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8143 - acc: 0.9463 - precision: 0.9859 - recall: 0.9079 - f1_score: 0.9445 - val_loss: 0.8514 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8112 - acc: 0.9463 - precision: 0.9879 - recall: 0.9070 - f1_score: 0.9446 - val_loss: 0.8483 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8081 - acc: 0.9463 - precision: 0.9875 - recall: 0.9109 - f1_score: 0.9468 - val_loss: 0.8453 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8050 - acc: 0.9463 - precision: 0.9882 - recall: 0.9097 - f1_score: 0.9464 - val_loss: 0.8422 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8020 - acc: 0.9463 - precision: 0.9851 - recall: 0.9116 - f1_score: 0.9463 - val_loss: 0.8391 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7989 - acc: 0.9463 - precision: 0.9866 - recall: 0.9064 - f1_score: 0.9441 - val_loss: 0.8361 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7959 - acc: 0.9463 - precision: 0.9872 - recall: 0.9093 - f1_score: 0.9454 - val_loss: 0.8331 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7929 - acc: 0.9463 - precision: 0.9874 - recall: 0.9061 - f1_score: 0.9442 - val_loss: 0.8301 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7899 - acc: 0.9463 - precision: 0.9867 - recall: 0.9101 - f1_score: 0.9457 - val_loss: 0.8271 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7869 - acc: 0.9463 - precision: 0.9880 - recall: 0.9088 - f1_score: 0.9455 - val_loss: 0.8241 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7840 - acc: 0.9463 - precision: 0.9858 - recall: 0.9125 - f1_score: 0.9459 - val_loss: 0.8212 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7810 - acc: 0.9463 - precision: 0.9869 - recall: 0.9103 - f1_score: 0.9453 - val_loss: 0.8182 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7781 - acc: 0.9463 - precision: 0.9859 - recall: 0.9118 - f1_score: 0.9462 - val_loss: 0.8153 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7752 - acc: 0.9463 - precision: 0.9877 - recall: 0.9106 - f1_score: 0.9465 - val_loss: 0.8124 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7723 - acc: 0.9463 - precision: 0.9875 - recall: 0.9097 - f1_score: 0.9454 - val_loss: 0.8095 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7694 - acc: 0.9463 - precision: 0.9864 - recall: 0.9111 - f1_score: 0.9463 - val_loss: 0.8066 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7665 - acc: 0.9463 - precision: 0.9866 - recall: 0.9096 - f1_score: 0.9451 - val_loss: 0.8037 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7636 - acc: 0.9463 - precision: 0.9875 - recall: 0.9080 - f1_score: 0.9451 - val_loss: 0.8009 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7608 - acc: 0.9463 - precision: 0.9864 - recall: 0.9103 - f1_score: 0.9458 - val_loss: 0.7980 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7580 - acc: 0.9463 - precision: 0.9874 - recall: 0.9069 - f1_score: 0.9448 - val_loss: 0.7952 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7552 - acc: 0.9463 - precision: 0.9873 - recall: 0.9035 - f1_score: 0.9425 - val_loss: 0.7924 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7524 - acc: 0.9463 - precision: 0.9872 - recall: 0.9087 - f1_score: 0.9458 - val_loss: 0.7896 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7496 - acc: 0.9463 - precision: 0.9879 - recall: 0.9094 - f1_score: 0.9455 - val_loss: 0.7868 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7468 - acc: 0.9463 - precision: 0.9876 - recall: 0.9081 - f1_score: 0.9456 - val_loss: 0.7840 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7440 - acc: 0.9463 - precision: 0.9875 - recall: 0.9088 - f1_score: 0.9456 - val_loss: 0.7813 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7413 - acc: 0.9463 - precision: 0.9875 - recall: 0.9085 - f1_score: 0.9454 - val_loss: 0.7785 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7386 - acc: 0.9463 - precision: 0.9862 - recall: 0.9065 - f1_score: 0.9433 - val_loss: 0.7758 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7358 - acc: 0.9463 - precision: 0.9857 - recall: 0.9080 - f1_score: 0.9448 - val_loss: 0.7731 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7331 - acc: 0.9463 - precision: 0.9867 - recall: 0.9112 - f1_score: 0.9467 - val_loss: 0.7704 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7304 - acc: 0.9463 - precision: 0.9870 - recall: 0.9052 - f1_score: 0.9423 - val_loss: 0.7677 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7278 - acc: 0.9463 - precision: 0.9880 - recall: 0.9079 - f1_score: 0.9448 - val_loss: 0.7650 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7251 - acc: 0.9463 - precision: 0.9865 - recall: 0.9058 - f1_score: 0.9430 - val_loss: 0.7624 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7225 - acc: 0.9463 - precision: 0.9883 - recall: 0.9103 - f1_score: 0.9466 - val_loss: 0.7597 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7198 - acc: 0.9463 - precision: 0.9874 - recall: 0.9087 - f1_score: 0.9457 - val_loss: 0.7571 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7172 - acc: 0.9463 - precision: 0.9847 - recall: 0.9052 - f1_score: 0.9423 - val_loss: 0.7544 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7146 - acc: 0.9463 - precision: 0.9870 - recall: 0.9101 - f1_score: 0.9462 - val_loss: 0.7518 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7120 - acc: 0.9463 - precision: 0.9869 - recall: 0.9095 - f1_score: 0.9461 - val_loss: 0.7492 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7094 - acc: 0.9463 - precision: 0.9872 - recall: 0.9095 - f1_score: 0.9460 - val_loss: 0.7466 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7068 - acc: 0.9463 - precision: 0.9865 - recall: 0.9086 - f1_score: 0.9446 - val_loss: 0.7441 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7043 - acc: 0.9463 - precision: 0.9864 - recall: 0.9103 - f1_score: 0.9462 - val_loss: 0.7415 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7017 - acc: 0.9463 - precision: 0.9884 - recall: 0.9091 - f1_score: 0.9461 - val_loss: 0.7390 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6992 - acc: 0.9463 - precision: 0.9873 - recall: 0.9094 - f1_score: 0.9462 - val_loss: 0.7364 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6967 - acc: 0.9463 - precision: 0.9869 - recall: 0.9127 - f1_score: 0.9471 - val_loss: 0.7339 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6942 - acc: 0.9463 - precision: 0.9870 - recall: 0.9109 - f1_score: 0.9467 - val_loss: 0.7314 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6917 - acc: 0.9463 - precision: 0.9865 - recall: 0.9092 - f1_score: 0.9454 - val_loss: 0.7289 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6892 - acc: 0.9463 - precision: 0.9861 - recall: 0.9096 - f1_score: 0.9452 - val_loss: 0.7264 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6867 - acc: 0.9463 - precision: 0.9882 - recall: 0.9065 - f1_score: 0.9451 - val_loss: 0.7240 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6843 - acc: 0.9463 - precision: 0.9874 - recall: 0.9116 - f1_score: 0.9474 - val_loss: 0.7215 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6818 - acc: 0.9463 - precision: 0.9881 - recall: 0.9111 - f1_score: 0.9473 - val_loss: 0.7191 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6794 - acc: 0.9463 - precision: 0.9883 - recall: 0.9089 - f1_score: 0.9448 - val_loss: 0.7166 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6770 - acc: 0.9463 - precision: 0.9878 - recall: 0.9093 - f1_score: 0.9462 - val_loss: 0.7142 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6745 - acc: 0.9463 - precision: 0.9869 - recall: 0.9089 - f1_score: 0.9456 - val_loss: 0.7118 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6722 - acc: 0.9463 - precision: 0.9862 - recall: 0.9106 - f1_score: 0.9464 - val_loss: 0.7094 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6698 - acc: 0.9463 - precision: 0.9867 - recall: 0.9096 - f1_score: 0.9459 - val_loss: 0.7070 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6674 - acc: 0.9463 - precision: 0.9862 - recall: 0.9105 - f1_score: 0.9463 - val_loss: 0.7046 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6650 - acc: 0.9463 - precision: 0.9868 - recall: 0.9132 - f1_score: 0.9470 - val_loss: 0.7023 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6627 - acc: 0.9463 - precision: 0.9864 - recall: 0.9077 - f1_score: 0.9449 - val_loss: 0.6999 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6604 - acc: 0.9463 - precision: 0.9863 - recall: 0.9092 - f1_score: 0.9446 - val_loss: 0.6976 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6580 - acc: 0.9463 - precision: 0.9866 - recall: 0.9060 - f1_score: 0.9439 - val_loss: 0.6953 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6557 - acc: 0.9463 - precision: 0.9859 - recall: 0.9058 - f1_score: 0.9431 - val_loss: 0.6930 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6534 - acc: 0.9463 - precision: 0.9863 - recall: 0.9089 - f1_score: 0.9452 - val_loss: 0.6907 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6511 - acc: 0.9463 - precision: 0.9875 - recall: 0.9104 - f1_score: 0.9463 - val_loss: 0.6884 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6488 - acc: 0.9463 - precision: 0.9872 - recall: 0.9110 - f1_score: 0.9466 - val_loss: 0.6861 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6466 - acc: 0.9463 - precision: 0.9883 - recall: 0.9097 - f1_score: 0.9462 - val_loss: 0.6838 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6443 - acc: 0.9463 - precision: 0.9877 - recall: 0.9103 - f1_score: 0.9464 - val_loss: 0.6816 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6421 - acc: 0.9463 - precision: 0.9862 - recall: 0.9079 - f1_score: 0.9445 - val_loss: 0.6793 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6398 - acc: 0.9479 - precision: 0.9890 - recall: 0.9098 - f1_score: 0.9469 - val_loss: 0.6771 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6376 - acc: 0.9479 - precision: 0.9893 - recall: 0.9075 - f1_score: 0.9456 - val_loss: 0.6749 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6354 - acc: 0.9479 - precision: 0.9910 - recall: 0.9064 - f1_score: 0.9452 - val_loss: 0.6727 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6332 - acc: 0.9479 - precision: 0.9894 - recall: 0.9070 - f1_score: 0.9459 - val_loss: 0.6705 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6310 - acc: 0.9479 - precision: 0.9915 - recall: 0.9075 - f1_score: 0.9467 - val_loss: 0.6683 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - ETA: 0s - loss: 0.6616 - acc: 0.9400 - precision: 1.0000 - recall: 0.8571 - f1_score: 0.923 - 0s - loss: 0.6288 - acc: 0.9479 - precision: 0.9908 - recall: 0.9084 - f1_score: 0.9467 - val_loss: 0.6661 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6267 - acc: 0.9479 - precision: 0.9891 - recall: 0.9105 - f1_score: 0.9472 - val_loss: 0.6639 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6245 - acc: 0.9479 - precision: 0.9893 - recall: 0.9069 - f1_score: 0.9454 - val_loss: 0.6618 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6224 - acc: 0.9479 - precision: 0.9900 - recall: 0.9127 - f1_score: 0.9489 - val_loss: 0.6596 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6202 - acc: 0.9479 - precision: 0.9890 - recall: 0.9069 - f1_score: 0.9457 - val_loss: 0.6575 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6181 - acc: 0.9479 - precision: 0.9917 - recall: 0.9101 - f1_score: 0.9475 - val_loss: 0.6554 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6160 - acc: 0.9479 - precision: 0.9899 - recall: 0.9078 - f1_score: 0.9466 - val_loss: 0.6532 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6139 - acc: 0.9479 - precision: 0.9915 - recall: 0.9065 - f1_score: 0.9458 - val_loss: 0.6511 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6118 - acc: 0.9479 - precision: 0.9887 - recall: 0.9072 - f1_score: 0.9457 - val_loss: 0.6490 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6097 - acc: 0.9479 - precision: 0.9908 - recall: 0.9066 - f1_score: 0.9457 - val_loss: 0.6470 - val_acc: 0.9241 - val_precision: 0.9628 - val_recall: 0.8433 - val_f1_score: 0.8981\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6076 - acc: 0.9479 - precision: 0.9891 - recall: 0.9109 - f1_score: 0.9475 - val_loss: 0.6449 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6056 - acc: 0.9479 - precision: 0.9906 - recall: 0.9080 - f1_score: 0.9468 - val_loss: 0.6428 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6035 - acc: 0.9479 - precision: 0.9900 - recall: 0.9117 - f1_score: 0.9485 - val_loss: 0.6408 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6015 - acc: 0.9479 - precision: 0.9904 - recall: 0.9089 - f1_score: 0.9459 - val_loss: 0.6387 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5995 - acc: 0.9479 - precision: 0.9887 - recall: 0.9039 - f1_score: 0.9437 - val_loss: 0.6367 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5974 - acc: 0.9479 - precision: 0.9898 - recall: 0.9092 - f1_score: 0.9464 - val_loss: 0.6347 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5954 - acc: 0.9479 - precision: 0.9903 - recall: 0.9077 - f1_score: 0.9460 - val_loss: 0.6327 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5934 - acc: 0.9479 - precision: 0.9910 - recall: 0.9085 - f1_score: 0.9474 - val_loss: 0.6307 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5914 - acc: 0.9479 - precision: 0.9909 - recall: 0.9061 - f1_score: 0.9457 - val_loss: 0.6287 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5895 - acc: 0.9479 - precision: 0.9895 - recall: 0.9084 - f1_score: 0.9460 - val_loss: 0.6267 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5875 - acc: 0.9479 - precision: 0.9899 - recall: 0.9093 - f1_score: 0.9467 - val_loss: 0.6247 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5855 - acc: 0.9479 - precision: 0.9901 - recall: 0.9069 - f1_score: 0.9461 - val_loss: 0.6228 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5836 - acc: 0.9479 - precision: 0.9901 - recall: 0.9083 - f1_score: 0.9467 - val_loss: 0.6208 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5816 - acc: 0.9479 - precision: 0.9903 - recall: 0.9057 - f1_score: 0.9454 - val_loss: 0.6189 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5797 - acc: 0.9479 - precision: 0.9886 - recall: 0.9126 - f1_score: 0.9482 - val_loss: 0.6169 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5778 - acc: 0.9479 - precision: 0.9897 - recall: 0.9078 - f1_score: 0.9460 - val_loss: 0.6150 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5759 - acc: 0.9479 - precision: 0.9898 - recall: 0.9111 - f1_score: 0.9479 - val_loss: 0.6131 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5740 - acc: 0.9479 - precision: 0.9901 - recall: 0.9096 - f1_score: 0.9475 - val_loss: 0.6112 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5721 - acc: 0.9479 - precision: 0.9909 - recall: 0.9101 - f1_score: 0.9481 - val_loss: 0.6093 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5702 - acc: 0.9479 - precision: 0.9904 - recall: 0.9112 - f1_score: 0.9478 - val_loss: 0.6074 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5683 - acc: 0.9479 - precision: 0.9908 - recall: 0.9104 - f1_score: 0.9484 - val_loss: 0.6055 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5664 - acc: 0.9479 - precision: 0.9902 - recall: 0.9064 - f1_score: 0.9452 - val_loss: 0.6037 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5646 - acc: 0.9479 - precision: 0.9902 - recall: 0.9115 - f1_score: 0.9486 - val_loss: 0.6018 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5627 - acc: 0.9479 - precision: 0.9894 - recall: 0.9105 - f1_score: 0.9476 - val_loss: 0.5999 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5609 - acc: 0.9479 - precision: 0.9900 - recall: 0.9098 - f1_score: 0.9475 - val_loss: 0.5981 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.5895 - acc: 0.9400 - precision: 0.9524 - recall: 0.9091 - f1_score: 0.930 - 0s - loss: 0.5591 - acc: 0.9479 - precision: 0.9892 - recall: 0.9094 - f1_score: 0.9468 - val_loss: 0.5963 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5572 - acc: 0.9479 - precision: 0.9901 - recall: 0.9094 - f1_score: 0.9475 - val_loss: 0.5944 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5554 - acc: 0.9479 - precision: 0.9908 - recall: 0.9119 - f1_score: 0.9469 - val_loss: 0.5926 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5536 - acc: 0.9479 - precision: 0.9894 - recall: 0.9107 - f1_score: 0.9471 - val_loss: 0.5908 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5519 - acc: 0.9479 - precision: 0.9906 - recall: 0.9091 - f1_score: 0.9472 - val_loss: 0.5890 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5501 - acc: 0.9479 - precision: 0.9900 - recall: 0.9098 - f1_score: 0.9476 - val_loss: 0.5872 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5483 - acc: 0.9479 - precision: 0.9898 - recall: 0.9113 - f1_score: 0.9483 - val_loss: 0.5855 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5465 - acc: 0.9479 - precision: 0.9902 - recall: 0.9093 - f1_score: 0.9477 - val_loss: 0.5837 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5448 - acc: 0.9479 - precision: 0.9878 - recall: 0.9071 - f1_score: 0.9452 - val_loss: 0.5819 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5430 - acc: 0.9479 - precision: 0.9889 - recall: 0.9080 - f1_score: 0.9455 - val_loss: 0.5802 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5413 - acc: 0.9479 - precision: 0.9909 - recall: 0.9102 - f1_score: 0.9484 - val_loss: 0.5784 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5395 - acc: 0.9479 - precision: 0.9890 - recall: 0.9083 - f1_score: 0.9462 - val_loss: 0.5767 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5378 - acc: 0.9479 - precision: 0.9897 - recall: 0.9144 - f1_score: 0.9496 - val_loss: 0.5750 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5361 - acc: 0.9479 - precision: 0.9901 - recall: 0.9103 - f1_score: 0.9477 - val_loss: 0.5733 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5344 - acc: 0.9479 - precision: 0.9894 - recall: 0.9069 - f1_score: 0.9460 - val_loss: 0.5716 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5327 - acc: 0.9479 - precision: 0.9890 - recall: 0.9112 - f1_score: 0.9478 - val_loss: 0.5699 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5310 - acc: 0.9479 - precision: 0.9905 - recall: 0.9103 - f1_score: 0.9475 - val_loss: 0.5682 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5293 - acc: 0.9479 - precision: 0.9901 - recall: 0.9107 - f1_score: 0.9480 - val_loss: 0.5665 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5277 - acc: 0.9479 - precision: 0.9899 - recall: 0.9083 - f1_score: 0.9462 - val_loss: 0.5648 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5260 - acc: 0.9479 - precision: 0.9904 - recall: 0.9096 - f1_score: 0.9471 - val_loss: 0.5631 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5243 - acc: 0.9479 - precision: 0.9906 - recall: 0.9070 - f1_score: 0.9457 - val_loss: 0.5615 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5227 - acc: 0.9479 - precision: 0.9902 - recall: 0.9099 - f1_score: 0.9470 - val_loss: 0.5598 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5211 - acc: 0.9479 - precision: 0.9915 - recall: 0.9100 - f1_score: 0.9479 - val_loss: 0.5582 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5194 - acc: 0.9479 - precision: 0.9898 - recall: 0.9083 - f1_score: 0.9459 - val_loss: 0.5566 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5178 - acc: 0.9479 - precision: 0.9895 - recall: 0.9057 - f1_score: 0.9452 - val_loss: 0.5549 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5162 - acc: 0.9479 - precision: 0.9906 - recall: 0.9113 - f1_score: 0.9485 - val_loss: 0.5533 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5146 - acc: 0.9479 - precision: 0.9893 - recall: 0.9115 - f1_score: 0.9480 - val_loss: 0.5517 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5130 - acc: 0.9479 - precision: 0.9894 - recall: 0.9115 - f1_score: 0.9478 - val_loss: 0.5501 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5114 - acc: 0.9479 - precision: 0.9869 - recall: 0.9027 - f1_score: 0.9420 - val_loss: 0.5485 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 567/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5098 - acc: 0.9479 - precision: 0.9896 - recall: 0.9073 - f1_score: 0.9453 - val_loss: 0.5469 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5082 - acc: 0.9479 - precision: 0.9903 - recall: 0.9037 - f1_score: 0.9431 - val_loss: 0.5453 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5067 - acc: 0.9479 - precision: 0.9901 - recall: 0.9106 - f1_score: 0.9477 - val_loss: 0.5438 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5051 - acc: 0.9479 - precision: 0.9905 - recall: 0.9089 - f1_score: 0.9472 - val_loss: 0.5422 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5035 - acc: 0.9479 - precision: 0.9894 - recall: 0.9097 - f1_score: 0.9473 - val_loss: 0.5406 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5020 - acc: 0.9479 - precision: 0.9904 - recall: 0.9099 - f1_score: 0.9481 - val_loss: 0.5391 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5005 - acc: 0.9479 - precision: 0.9902 - recall: 0.9130 - f1_score: 0.9490 - val_loss: 0.5376 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4989 - acc: 0.9479 - precision: 0.9914 - recall: 0.9117 - f1_score: 0.9487 - val_loss: 0.5360 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4974 - acc: 0.9479 - precision: 0.9897 - recall: 0.9131 - f1_score: 0.9490 - val_loss: 0.5345 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4959 - acc: 0.9479 - precision: 0.9911 - recall: 0.9097 - f1_score: 0.9477 - val_loss: 0.5330 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4944 - acc: 0.9479 - precision: 0.9904 - recall: 0.9121 - f1_score: 0.9481 - val_loss: 0.5315 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4929 - acc: 0.9479 - precision: 0.9882 - recall: 0.9090 - f1_score: 0.9463 - val_loss: 0.5300 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4914 - acc: 0.9479 - precision: 0.9919 - recall: 0.9098 - f1_score: 0.9478 - val_loss: 0.5285 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4899 - acc: 0.9479 - precision: 0.9899 - recall: 0.9120 - f1_score: 0.9485 - val_loss: 0.5270 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4884 - acc: 0.9479 - precision: 0.9906 - recall: 0.9083 - f1_score: 0.9473 - val_loss: 0.5255 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4870 - acc: 0.9479 - precision: 0.9903 - recall: 0.9091 - f1_score: 0.9466 - val_loss: 0.5240 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4855 - acc: 0.9479 - precision: 0.9903 - recall: 0.9109 - f1_score: 0.9482 - val_loss: 0.5226 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4840 - acc: 0.9479 - precision: 0.9879 - recall: 0.9134 - f1_score: 0.9468 - val_loss: 0.5211 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4826 - acc: 0.9479 - precision: 0.9894 - recall: 0.9099 - f1_score: 0.9477 - val_loss: 0.5196 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4812 - acc: 0.9479 - precision: 0.9886 - recall: 0.9094 - f1_score: 0.9465 - val_loss: 0.5182 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4797 - acc: 0.9479 - precision: 0.9907 - recall: 0.9132 - f1_score: 0.9495 - val_loss: 0.5168 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4783 - acc: 0.9479 - precision: 0.9902 - recall: 0.9074 - f1_score: 0.9458 - val_loss: 0.5153 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4769 - acc: 0.9479 - precision: 0.9898 - recall: 0.9105 - f1_score: 0.9481 - val_loss: 0.5139 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4755 - acc: 0.9479 - precision: 0.9913 - recall: 0.9117 - f1_score: 0.9494 - val_loss: 0.5125 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4741 - acc: 0.9479 - precision: 0.9877 - recall: 0.9067 - f1_score: 0.9448 - val_loss: 0.5111 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4726 - acc: 0.9479 - precision: 0.9900 - recall: 0.9109 - f1_score: 0.9479 - val_loss: 0.5097 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4713 - acc: 0.9479 - precision: 0.9905 - recall: 0.9076 - f1_score: 0.9463 - val_loss: 0.5083 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4699 - acc: 0.9479 - precision: 0.9886 - recall: 0.9085 - f1_score: 0.9463 - val_loss: 0.5069 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4685 - acc: 0.9479 - precision: 0.9903 - recall: 0.9044 - f1_score: 0.9441 - val_loss: 0.5055 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4671 - acc: 0.9479 - precision: 0.9901 - recall: 0.9096 - f1_score: 0.9469 - val_loss: 0.5041 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4657 - acc: 0.9479 - precision: 0.9906 - recall: 0.9092 - f1_score: 0.9473 - val_loss: 0.5027 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4644 - acc: 0.9479 - precision: 0.9900 - recall: 0.9126 - f1_score: 0.9479 - val_loss: 0.5014 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4630 - acc: 0.9479 - precision: 0.9899 - recall: 0.9060 - f1_score: 0.9455 - val_loss: 0.5000 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4617 - acc: 0.9479 - precision: 0.9895 - recall: 0.9120 - f1_score: 0.9480 - val_loss: 0.4987 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4603 - acc: 0.9479 - precision: 0.9897 - recall: 0.9107 - f1_score: 0.9482 - val_loss: 0.4973 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4590 - acc: 0.9479 - precision: 0.9903 - recall: 0.9101 - f1_score: 0.9473 - val_loss: 0.4960 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4577 - acc: 0.9479 - precision: 0.9895 - recall: 0.9103 - f1_score: 0.9476 - val_loss: 0.4947 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4564 - acc: 0.9479 - precision: 0.9904 - recall: 0.9052 - f1_score: 0.9441 - val_loss: 0.4933 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4551 - acc: 0.9479 - precision: 0.9902 - recall: 0.9124 - f1_score: 0.9489 - val_loss: 0.4920 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4537 - acc: 0.9479 - precision: 0.9894 - recall: 0.9114 - f1_score: 0.9474 - val_loss: 0.4907 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4524 - acc: 0.9479 - precision: 0.9911 - recall: 0.9082 - f1_score: 0.9472 - val_loss: 0.4894 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4511 - acc: 0.9479 - precision: 0.9904 - recall: 0.9120 - f1_score: 0.9491 - val_loss: 0.4881 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4499 - acc: 0.9479 - precision: 0.9883 - recall: 0.9096 - f1_score: 0.9467 - val_loss: 0.4868 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4486 - acc: 0.9479 - precision: 0.9902 - recall: 0.9109 - f1_score: 0.9477 - val_loss: 0.4855 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4473 - acc: 0.9479 - precision: 0.9912 - recall: 0.9116 - f1_score: 0.9490 - val_loss: 0.4842 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4460 - acc: 0.9479 - precision: 0.9903 - recall: 0.9068 - f1_score: 0.9463 - val_loss: 0.4830 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4448 - acc: 0.9479 - precision: 0.9896 - recall: 0.9092 - f1_score: 0.9462 - val_loss: 0.4817 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4435 - acc: 0.9479 - precision: 0.9910 - recall: 0.9083 - f1_score: 0.9468 - val_loss: 0.4804 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4423 - acc: 0.9479 - precision: 0.9912 - recall: 0.9062 - f1_score: 0.9455 - val_loss: 0.4792 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4410 - acc: 0.9479 - precision: 0.9902 - recall: 0.9106 - f1_score: 0.9468 - val_loss: 0.4779 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4398 - acc: 0.9479 - precision: 0.9894 - recall: 0.9119 - f1_score: 0.9480 - val_loss: 0.4767 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4385 - acc: 0.9479 - precision: 0.9904 - recall: 0.9104 - f1_score: 0.9482 - val_loss: 0.4755 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4373 - acc: 0.9479 - precision: 0.9891 - recall: 0.9112 - f1_score: 0.9478 - val_loss: 0.4742 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4361 - acc: 0.9479 - precision: 0.9908 - recall: 0.9084 - f1_score: 0.9475 - val_loss: 0.4730 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4349 - acc: 0.9479 - precision: 0.9887 - recall: 0.9063 - f1_score: 0.9449 - val_loss: 0.4718 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4337 - acc: 0.9479 - precision: 0.9879 - recall: 0.9090 - f1_score: 0.9460 - val_loss: 0.4706 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4325 - acc: 0.9479 - precision: 0.9898 - recall: 0.9080 - f1_score: 0.9464 - val_loss: 0.4694 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4313 - acc: 0.9479 - precision: 0.9914 - recall: 0.9088 - f1_score: 0.9474 - val_loss: 0.4681 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4301 - acc: 0.9479 - precision: 0.9895 - recall: 0.9099 - f1_score: 0.9470 - val_loss: 0.4670 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4289 - acc: 0.9479 - precision: 0.9899 - recall: 0.9095 - f1_score: 0.9475 - val_loss: 0.4658 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4277 - acc: 0.9479 - precision: 0.9896 - recall: 0.9092 - f1_score: 0.9469 - val_loss: 0.4646 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4265 - acc: 0.9479 - precision: 0.9900 - recall: 0.9078 - f1_score: 0.9455 - val_loss: 0.4634 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4254 - acc: 0.9479 - precision: 0.9904 - recall: 0.9073 - f1_score: 0.9462 - val_loss: 0.4622 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4242 - acc: 0.9479 - precision: 0.9898 - recall: 0.9069 - f1_score: 0.9454 - val_loss: 0.4610 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4230 - acc: 0.9479 - precision: 0.9907 - recall: 0.9091 - f1_score: 0.9476 - val_loss: 0.4599 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4219 - acc: 0.9479 - precision: 0.9903 - recall: 0.9103 - f1_score: 0.9479 - val_loss: 0.4587 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3917 - acc: 0.9800 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.977 - 0s - loss: 0.4207 - acc: 0.9479 - precision: 0.9902 - recall: 0.9080 - f1_score: 0.9467 - val_loss: 0.4576 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4196 - acc: 0.9479 - precision: 0.9892 - recall: 0.9081 - f1_score: 0.9451 - val_loss: 0.4564 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4185 - acc: 0.9479 - precision: 0.9913 - recall: 0.9056 - f1_score: 0.9451 - val_loss: 0.4553 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4173 - acc: 0.9479 - precision: 0.9898 - recall: 0.9106 - f1_score: 0.9480 - val_loss: 0.4541 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4162 - acc: 0.9479 - precision: 0.9911 - recall: 0.9064 - f1_score: 0.9458 - val_loss: 0.4530 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4151 - acc: 0.9479 - precision: 0.9885 - recall: 0.9091 - f1_score: 0.9458 - val_loss: 0.4519 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4140 - acc: 0.9479 - precision: 0.9895 - recall: 0.9158 - f1_score: 0.9493 - val_loss: 0.4508 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4129 - acc: 0.9479 - precision: 0.9885 - recall: 0.9105 - f1_score: 0.9470 - val_loss: 0.4497 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4118 - acc: 0.9479 - precision: 0.9898 - recall: 0.9074 - f1_score: 0.9455 - val_loss: 0.4486 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4107 - acc: 0.9479 - precision: 0.9907 - recall: 0.9078 - f1_score: 0.9466 - val_loss: 0.4475 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4096 - acc: 0.9479 - precision: 0.9900 - recall: 0.9090 - f1_score: 0.9470 - val_loss: 0.4464 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4085 - acc: 0.9479 - precision: 0.9918 - recall: 0.9106 - f1_score: 0.9487 - val_loss: 0.4453 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4074 - acc: 0.9479 - precision: 0.9882 - recall: 0.9080 - f1_score: 0.9460 - val_loss: 0.4442 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4063 - acc: 0.9479 - precision: 0.9894 - recall: 0.9105 - f1_score: 0.9478 - val_loss: 0.4431 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4053 - acc: 0.9479 - precision: 0.9899 - recall: 0.9078 - f1_score: 0.9465 - val_loss: 0.4420 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4042 - acc: 0.9479 - precision: 0.9895 - recall: 0.9104 - f1_score: 0.9475 - val_loss: 0.4409 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4031 - acc: 0.9479 - precision: 0.9902 - recall: 0.9089 - f1_score: 0.9470 - val_loss: 0.4399 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4021 - acc: 0.9479 - precision: 0.9900 - recall: 0.9119 - f1_score: 0.9473 - val_loss: 0.4388 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4010 - acc: 0.9479 - precision: 0.9893 - recall: 0.9093 - f1_score: 0.9470 - val_loss: 0.4378 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4000 - acc: 0.9479 - precision: 0.9919 - recall: 0.9094 - f1_score: 0.9475 - val_loss: 0.4367 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3990 - acc: 0.9479 - precision: 0.9899 - recall: 0.9128 - f1_score: 0.9484 - val_loss: 0.4357 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3979 - acc: 0.9479 - precision: 0.9896 - recall: 0.9149 - f1_score: 0.9494 - val_loss: 0.4346 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3969 - acc: 0.9479 - precision: 0.9911 - recall: 0.9095 - f1_score: 0.9478 - val_loss: 0.4336 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3959 - acc: 0.9479 - precision: 0.9884 - recall: 0.9073 - f1_score: 0.9459 - val_loss: 0.4326 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3948 - acc: 0.9479 - precision: 0.9908 - recall: 0.9110 - f1_score: 0.9483 - val_loss: 0.4315 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3938 - acc: 0.9479 - precision: 0.9895 - recall: 0.9124 - f1_score: 0.9484 - val_loss: 0.4305 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3928 - acc: 0.9479 - precision: 0.9896 - recall: 0.9087 - f1_score: 0.9467 - val_loss: 0.4295 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3918 - acc: 0.9479 - precision: 0.9886 - recall: 0.9053 - f1_score: 0.9442 - val_loss: 0.4285 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3908 - acc: 0.9479 - precision: 0.9891 - recall: 0.9102 - f1_score: 0.9471 - val_loss: 0.4275 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3898 - acc: 0.9479 - precision: 0.9893 - recall: 0.9109 - f1_score: 0.9474 - val_loss: 0.4265 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3888 - acc: 0.9479 - precision: 0.9903 - recall: 0.9114 - f1_score: 0.9481 - val_loss: 0.4255 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3878 - acc: 0.9479 - precision: 0.9902 - recall: 0.9130 - f1_score: 0.9486 - val_loss: 0.4245 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3869 - acc: 0.9479 - precision: 0.9908 - recall: 0.9105 - f1_score: 0.9478 - val_loss: 0.4235 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3859 - acc: 0.9479 - precision: 0.9909 - recall: 0.9099 - f1_score: 0.9477 - val_loss: 0.4225 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3849 - acc: 0.9479 - precision: 0.9923 - recall: 0.9031 - f1_score: 0.9441 - val_loss: 0.4215 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3839 - acc: 0.9479 - precision: 0.9899 - recall: 0.9072 - f1_score: 0.9459 - val_loss: 0.4206 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3830 - acc: 0.9479 - precision: 0.9904 - recall: 0.9071 - f1_score: 0.9457 - val_loss: 0.4196 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3820 - acc: 0.9479 - precision: 0.9898 - recall: 0.9040 - f1_score: 0.9437 - val_loss: 0.4186 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3811 - acc: 0.9479 - precision: 0.9903 - recall: 0.9072 - f1_score: 0.9466 - val_loss: 0.4177 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3801 - acc: 0.9479 - precision: 0.9894 - recall: 0.9075 - f1_score: 0.9457 - val_loss: 0.4167 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3792 - acc: 0.9479 - precision: 0.9898 - recall: 0.9076 - f1_score: 0.9450 - val_loss: 0.4158 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3782 - acc: 0.9479 - precision: 0.9896 - recall: 0.9067 - f1_score: 0.9460 - val_loss: 0.4148 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3773 - acc: 0.9479 - precision: 0.9904 - recall: 0.9087 - f1_score: 0.9468 - val_loss: 0.4139 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3764 - acc: 0.9479 - precision: 0.9910 - recall: 0.9113 - f1_score: 0.9480 - val_loss: 0.4129 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3754 - acc: 0.9479 - precision: 0.9913 - recall: 0.9075 - f1_score: 0.9452 - val_loss: 0.4120 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3745 - acc: 0.9479 - precision: 0.9908 - recall: 0.9097 - f1_score: 0.9476 - val_loss: 0.4111 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3736 - acc: 0.9479 - precision: 0.9910 - recall: 0.9101 - f1_score: 0.9479 - val_loss: 0.4102 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3727 - acc: 0.9479 - precision: 0.9921 - recall: 0.9053 - f1_score: 0.9456 - val_loss: 0.4092 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3718 - acc: 0.9479 - precision: 0.9901 - recall: 0.9104 - f1_score: 0.9480 - val_loss: 0.4083 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3709 - acc: 0.9479 - precision: 0.9894 - recall: 0.9045 - f1_score: 0.9441 - val_loss: 0.4074 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3700 - acc: 0.9479 - precision: 0.9891 - recall: 0.9100 - f1_score: 0.9471 - val_loss: 0.4065 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3691 - acc: 0.9479 - precision: 0.9897 - recall: 0.9088 - f1_score: 0.9470 - val_loss: 0.4056 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3682 - acc: 0.9479 - precision: 0.9898 - recall: 0.9088 - f1_score: 0.9472 - val_loss: 0.4047 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3673 - acc: 0.9479 - precision: 0.9897 - recall: 0.9097 - f1_score: 0.9464 - val_loss: 0.4038 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3664 - acc: 0.9479 - precision: 0.9905 - recall: 0.9093 - f1_score: 0.9466 - val_loss: 0.4029 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3655 - acc: 0.9479 - precision: 0.9901 - recall: 0.9090 - f1_score: 0.9472 - val_loss: 0.4020 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3647 - acc: 0.9479 - precision: 0.9913 - recall: 0.9061 - f1_score: 0.9458 - val_loss: 0.4012 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3638 - acc: 0.9479 - precision: 0.9902 - recall: 0.9106 - f1_score: 0.9474 - val_loss: 0.4003 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3629 - acc: 0.9479 - precision: 0.9910 - recall: 0.9102 - f1_score: 0.9477 - val_loss: 0.3994 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3621 - acc: 0.9479 - precision: 0.9904 - recall: 0.9090 - f1_score: 0.9474 - val_loss: 0.3986 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3612 - acc: 0.9479 - precision: 0.9899 - recall: 0.9119 - f1_score: 0.9479 - val_loss: 0.3977 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3604 - acc: 0.9479 - precision: 0.9890 - recall: 0.9086 - f1_score: 0.9465 - val_loss: 0.3968 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3595 - acc: 0.9479 - precision: 0.9889 - recall: 0.9079 - f1_score: 0.9458 - val_loss: 0.3960 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3587 - acc: 0.9479 - precision: 0.9904 - recall: 0.9094 - f1_score: 0.9470 - val_loss: 0.3951 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3578 - acc: 0.9479 - precision: 0.9912 - recall: 0.9055 - f1_score: 0.9459 - val_loss: 0.3943 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3570 - acc: 0.9479 - precision: 0.9903 - recall: 0.9121 - f1_score: 0.9473 - val_loss: 0.3934 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3562 - acc: 0.9479 - precision: 0.9889 - recall: 0.9072 - f1_score: 0.9454 - val_loss: 0.3926 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3553 - acc: 0.9479 - precision: 0.9894 - recall: 0.9093 - f1_score: 0.9471 - val_loss: 0.3918 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3545 - acc: 0.9479 - precision: 0.9900 - recall: 0.9075 - f1_score: 0.9464 - val_loss: 0.3909 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3537 - acc: 0.9479 - precision: 0.9904 - recall: 0.9065 - f1_score: 0.9451 - val_loss: 0.3901 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3529 - acc: 0.9479 - precision: 0.9903 - recall: 0.9131 - f1_score: 0.9489 - val_loss: 0.3893 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3520 - acc: 0.9479 - precision: 0.9900 - recall: 0.9057 - f1_score: 0.9449 - val_loss: 0.3885 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3512 - acc: 0.9479 - precision: 0.9904 - recall: 0.9080 - f1_score: 0.9461 - val_loss: 0.3877 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3504 - acc: 0.9479 - precision: 0.9898 - recall: 0.9087 - f1_score: 0.9464 - val_loss: 0.3868 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3496 - acc: 0.9479 - precision: 0.9907 - recall: 0.9059 - f1_score: 0.9446 - val_loss: 0.3860 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3488 - acc: 0.9479 - precision: 0.9893 - recall: 0.9101 - f1_score: 0.9475 - val_loss: 0.3852 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3480 - acc: 0.9479 - precision: 0.9909 - recall: 0.9115 - f1_score: 0.9490 - val_loss: 0.3844 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3472 - acc: 0.9479 - precision: 0.9890 - recall: 0.9053 - f1_score: 0.9444 - val_loss: 0.3836 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3464 - acc: 0.9479 - precision: 0.9921 - recall: 0.9084 - f1_score: 0.9476 - val_loss: 0.3828 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3457 - acc: 0.9479 - precision: 0.9903 - recall: 0.9090 - f1_score: 0.9468 - val_loss: 0.3820 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3449 - acc: 0.9479 - precision: 0.9920 - recall: 0.9060 - f1_score: 0.9456 - val_loss: 0.3812 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3441 - acc: 0.9479 - precision: 0.9895 - recall: 0.9116 - f1_score: 0.9472 - val_loss: 0.3805 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3433 - acc: 0.9479 - precision: 0.9900 - recall: 0.9108 - f1_score: 0.9481 - val_loss: 0.3797 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3426 - acc: 0.9479 - precision: 0.9895 - recall: 0.9092 - f1_score: 0.9471 - val_loss: 0.3789 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3418 - acc: 0.9479 - precision: 0.9887 - recall: 0.9069 - f1_score: 0.9456 - val_loss: 0.3781 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3410 - acc: 0.9479 - precision: 0.9910 - recall: 0.9081 - f1_score: 0.9466 - val_loss: 0.3774 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3403 - acc: 0.9479 - precision: 0.9910 - recall: 0.9095 - f1_score: 0.9482 - val_loss: 0.3766 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3395 - acc: 0.9479 - precision: 0.9913 - recall: 0.9142 - f1_score: 0.9499 - val_loss: 0.3758 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3388 - acc: 0.9479 - precision: 0.9909 - recall: 0.9080 - f1_score: 0.9466 - val_loss: 0.3751 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3380 - acc: 0.9479 - precision: 0.9898 - recall: 0.9095 - f1_score: 0.9474 - val_loss: 0.3743 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3373 - acc: 0.9479 - precision: 0.9911 - recall: 0.9113 - f1_score: 0.9485 - val_loss: 0.3736 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3365 - acc: 0.9479 - precision: 0.9915 - recall: 0.9105 - f1_score: 0.9487 - val_loss: 0.3728 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3358 - acc: 0.9479 - precision: 0.9903 - recall: 0.9093 - f1_score: 0.9474 - val_loss: 0.3721 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3351 - acc: 0.9479 - precision: 0.9900 - recall: 0.9130 - f1_score: 0.9495 - val_loss: 0.3713 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 727/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3343 - acc: 0.9479 - precision: 0.9905 - recall: 0.9097 - f1_score: 0.9477 - val_loss: 0.3706 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3336 - acc: 0.9479 - precision: 0.9898 - recall: 0.9089 - f1_score: 0.9472 - val_loss: 0.3699 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3329 - acc: 0.9479 - precision: 0.9890 - recall: 0.9102 - f1_score: 0.9470 - val_loss: 0.3691 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3322 - acc: 0.9479 - precision: 0.9889 - recall: 0.9090 - f1_score: 0.9466 - val_loss: 0.3684 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9479 - precision: 0.9906 - recall: 0.9089 - f1_score: 0.9473 - val_loss: 0.3677 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3307 - acc: 0.9479 - precision: 0.9896 - recall: 0.9085 - f1_score: 0.9468 - val_loss: 0.3670 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3300 - acc: 0.9479 - precision: 0.9912 - recall: 0.9097 - f1_score: 0.9481 - val_loss: 0.3663 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3293 - acc: 0.9479 - precision: 0.9908 - recall: 0.9101 - f1_score: 0.9483 - val_loss: 0.3656 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3286 - acc: 0.9479 - precision: 0.9911 - recall: 0.9107 - f1_score: 0.9481 - val_loss: 0.3648 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3279 - acc: 0.9479 - precision: 0.9897 - recall: 0.9093 - f1_score: 0.9466 - val_loss: 0.3641 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3272 - acc: 0.9479 - precision: 0.9910 - recall: 0.9086 - f1_score: 0.9472 - val_loss: 0.3634 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3265 - acc: 0.9479 - precision: 0.9896 - recall: 0.9097 - f1_score: 0.9475 - val_loss: 0.3627 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3258 - acc: 0.9479 - precision: 0.9911 - recall: 0.9124 - f1_score: 0.9496 - val_loss: 0.3621 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3252 - acc: 0.9479 - precision: 0.9913 - recall: 0.9081 - f1_score: 0.9471 - val_loss: 0.3614 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3245 - acc: 0.9479 - precision: 0.9903 - recall: 0.9090 - f1_score: 0.9473 - val_loss: 0.3607 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3238 - acc: 0.9479 - precision: 0.9909 - recall: 0.9070 - f1_score: 0.9464 - val_loss: 0.3600 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3231 - acc: 0.9479 - precision: 0.9886 - recall: 0.9082 - f1_score: 0.9456 - val_loss: 0.3593 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3224 - acc: 0.9479 - precision: 0.9898 - recall: 0.9084 - f1_score: 0.9469 - val_loss: 0.3586 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3218 - acc: 0.9479 - precision: 0.9895 - recall: 0.9107 - f1_score: 0.9468 - val_loss: 0.3579 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3211 - acc: 0.9479 - precision: 0.9912 - recall: 0.9096 - f1_score: 0.9477 - val_loss: 0.3573 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3204 - acc: 0.9479 - precision: 0.9906 - recall: 0.9083 - f1_score: 0.9466 - val_loss: 0.3566 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3198 - acc: 0.9479 - precision: 0.9892 - recall: 0.9086 - f1_score: 0.9455 - val_loss: 0.3559 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3191 - acc: 0.9479 - precision: 0.9904 - recall: 0.9114 - f1_score: 0.9482 - val_loss: 0.3553 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3185 - acc: 0.9479 - precision: 0.9893 - recall: 0.9115 - f1_score: 0.9478 - val_loss: 0.3546 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3178 - acc: 0.9479 - precision: 0.9904 - recall: 0.9138 - f1_score: 0.9491 - val_loss: 0.3540 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9479 - precision: 0.9906 - recall: 0.9090 - f1_score: 0.9471 - val_loss: 0.3533 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3165 - acc: 0.9479 - precision: 0.9912 - recall: 0.9094 - f1_score: 0.9479 - val_loss: 0.3526 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3159 - acc: 0.9479 - precision: 0.9889 - recall: 0.9085 - f1_score: 0.9458 - val_loss: 0.3520 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3152 - acc: 0.9479 - precision: 0.9898 - recall: 0.9115 - f1_score: 0.9474 - val_loss: 0.3514 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3146 - acc: 0.9479 - precision: 0.9887 - recall: 0.9042 - f1_score: 0.9438 - val_loss: 0.3507 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3140 - acc: 0.9479 - precision: 0.9903 - recall: 0.9099 - f1_score: 0.9466 - val_loss: 0.3501 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3133 - acc: 0.9479 - precision: 0.9878 - recall: 0.9113 - f1_score: 0.9471 - val_loss: 0.3494 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3127 - acc: 0.9479 - precision: 0.9889 - recall: 0.9124 - f1_score: 0.9482 - val_loss: 0.3488 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3121 - acc: 0.9479 - precision: 0.9900 - recall: 0.9090 - f1_score: 0.9470 - val_loss: 0.3482 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3114 - acc: 0.9479 - precision: 0.9910 - recall: 0.9079 - f1_score: 0.9467 - val_loss: 0.3475 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3108 - acc: 0.9479 - precision: 0.9897 - recall: 0.9056 - f1_score: 0.9448 - val_loss: 0.3469 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3102 - acc: 0.9479 - precision: 0.9899 - recall: 0.9104 - f1_score: 0.9479 - val_loss: 0.3463 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3096 - acc: 0.9479 - precision: 0.9896 - recall: 0.9090 - f1_score: 0.9466 - val_loss: 0.3457 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3090 - acc: 0.9479 - precision: 0.9906 - recall: 0.9107 - f1_score: 0.9478 - val_loss: 0.3451 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3084 - acc: 0.9479 - precision: 0.9902 - recall: 0.9094 - f1_score: 0.9475 - val_loss: 0.3444 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3078 - acc: 0.9479 - precision: 0.9900 - recall: 0.9092 - f1_score: 0.9467 - val_loss: 0.3438 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3072 - acc: 0.9479 - precision: 0.9898 - recall: 0.9088 - f1_score: 0.9461 - val_loss: 0.3432 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3066 - acc: 0.9479 - precision: 0.9891 - recall: 0.9023 - f1_score: 0.9428 - val_loss: 0.3426 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3060 - acc: 0.9479 - precision: 0.9892 - recall: 0.9103 - f1_score: 0.9471 - val_loss: 0.3420 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3054 - acc: 0.9479 - precision: 0.9899 - recall: 0.9075 - f1_score: 0.9463 - val_loss: 0.3414 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3048 - acc: 0.9479 - precision: 0.9905 - recall: 0.9095 - f1_score: 0.9477 - val_loss: 0.3408 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3042 - acc: 0.9479 - precision: 0.9912 - recall: 0.9085 - f1_score: 0.9474 - val_loss: 0.3402 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3036 - acc: 0.9479 - precision: 0.9911 - recall: 0.9089 - f1_score: 0.9472 - val_loss: 0.3396 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3030 - acc: 0.9479 - precision: 0.9891 - recall: 0.9097 - f1_score: 0.9471 - val_loss: 0.3390 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3025 - acc: 0.9479 - precision: 0.9892 - recall: 0.9084 - f1_score: 0.9465 - val_loss: 0.3384 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3019 - acc: 0.9479 - precision: 0.9893 - recall: 0.9090 - f1_score: 0.9471 - val_loss: 0.3379 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3013 - acc: 0.9479 - precision: 0.9904 - recall: 0.9101 - f1_score: 0.9475 - val_loss: 0.3373 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3007 - acc: 0.9479 - precision: 0.9882 - recall: 0.9082 - f1_score: 0.9460 - val_loss: 0.3367 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3002 - acc: 0.9479 - precision: 0.9907 - recall: 0.9110 - f1_score: 0.9489 - val_loss: 0.3361 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2996 - acc: 0.9479 - precision: 0.9902 - recall: 0.9094 - f1_score: 0.9473 - val_loss: 0.3356 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2990 - acc: 0.9479 - precision: 0.9895 - recall: 0.9079 - f1_score: 0.9459 - val_loss: 0.3350 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2985 - acc: 0.9479 - precision: 0.9912 - recall: 0.9116 - f1_score: 0.9488 - val_loss: 0.3344 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2979 - acc: 0.9479 - precision: 0.9900 - recall: 0.9073 - f1_score: 0.9458 - val_loss: 0.3339 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2974 - acc: 0.9479 - precision: 0.9903 - recall: 0.9097 - f1_score: 0.9474 - val_loss: 0.3333 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2968 - acc: 0.9479 - precision: 0.9903 - recall: 0.9124 - f1_score: 0.9490 - val_loss: 0.3327 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2963 - acc: 0.9479 - precision: 0.9912 - recall: 0.9069 - f1_score: 0.9460 - val_loss: 0.3322 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2957 - acc: 0.9479 - precision: 0.9905 - recall: 0.9128 - f1_score: 0.9489 - val_loss: 0.3316 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2952 - acc: 0.9479 - precision: 0.9911 - recall: 0.9151 - f1_score: 0.9510 - val_loss: 0.3311 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2946 - acc: 0.9479 - precision: 0.9911 - recall: 0.9103 - f1_score: 0.9482 - val_loss: 0.3305 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 791/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2941 - acc: 0.9479 - precision: 0.9905 - recall: 0.9099 - f1_score: 0.9481 - val_loss: 0.3300 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2935 - acc: 0.9479 - precision: 0.9898 - recall: 0.9095 - f1_score: 0.9476 - val_loss: 0.3294 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2930 - acc: 0.9479 - precision: 0.9909 - recall: 0.9070 - f1_score: 0.9465 - val_loss: 0.3289 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2925 - acc: 0.9479 - precision: 0.9908 - recall: 0.9064 - f1_score: 0.9453 - val_loss: 0.3283 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2919 - acc: 0.9479 - precision: 0.9908 - recall: 0.9115 - f1_score: 0.9489 - val_loss: 0.3278 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2914 - acc: 0.9479 - precision: 0.9908 - recall: 0.9090 - f1_score: 0.9475 - val_loss: 0.3273 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2909 - acc: 0.9479 - precision: 0.9901 - recall: 0.9075 - f1_score: 0.9461 - val_loss: 0.3267 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2904 - acc: 0.9479 - precision: 0.9901 - recall: 0.9090 - f1_score: 0.9468 - val_loss: 0.3262 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2898 - acc: 0.9479 - precision: 0.9904 - recall: 0.9141 - f1_score: 0.9498 - val_loss: 0.3257 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2893 - acc: 0.9479 - precision: 0.9886 - recall: 0.9108 - f1_score: 0.9473 - val_loss: 0.3252 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2888 - acc: 0.9479 - precision: 0.9897 - recall: 0.9079 - f1_score: 0.9454 - val_loss: 0.3246 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2883 - acc: 0.9479 - precision: 0.9905 - recall: 0.9110 - f1_score: 0.9480 - val_loss: 0.3241 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2878 - acc: 0.9479 - precision: 0.9889 - recall: 0.9083 - f1_score: 0.9464 - val_loss: 0.3236 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2873 - acc: 0.9479 - precision: 0.9906 - recall: 0.9140 - f1_score: 0.9496 - val_loss: 0.3231 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2868 - acc: 0.9479 - precision: 0.9908 - recall: 0.9099 - f1_score: 0.9479 - val_loss: 0.3226 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2863 - acc: 0.9479 - precision: 0.9895 - recall: 0.9129 - f1_score: 0.9484 - val_loss: 0.3221 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2858 - acc: 0.9479 - precision: 0.9890 - recall: 0.9078 - f1_score: 0.9461 - val_loss: 0.3216 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2853 - acc: 0.9479 - precision: 0.9899 - recall: 0.9043 - f1_score: 0.9434 - val_loss: 0.3210 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9479 - precision: 0.9913 - recall: 0.9124 - f1_score: 0.9492 - val_loss: 0.3205 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9479 - precision: 0.9883 - recall: 0.9088 - f1_score: 0.9457 - val_loss: 0.3200 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2838 - acc: 0.9479 - precision: 0.9909 - recall: 0.9110 - f1_score: 0.9479 - val_loss: 0.3195 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2833 - acc: 0.9479 - precision: 0.9897 - recall: 0.9107 - f1_score: 0.9475 - val_loss: 0.3190 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2828 - acc: 0.9479 - precision: 0.9916 - recall: 0.9080 - f1_score: 0.9463 - val_loss: 0.3185 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2823 - acc: 0.9479 - precision: 0.9883 - recall: 0.9095 - f1_score: 0.9468 - val_loss: 0.3180 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2818 - acc: 0.9479 - precision: 0.9904 - recall: 0.9094 - f1_score: 0.9476 - val_loss: 0.3176 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2813 - acc: 0.9479 - precision: 0.9911 - recall: 0.9087 - f1_score: 0.9477 - val_loss: 0.3171 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2808 - acc: 0.9479 - precision: 0.9909 - recall: 0.9105 - f1_score: 0.9485 - val_loss: 0.3166 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2804 - acc: 0.9479 - precision: 0.9898 - recall: 0.9130 - f1_score: 0.9487 - val_loss: 0.3161 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2799 - acc: 0.9479 - precision: 0.9901 - recall: 0.9109 - f1_score: 0.9481 - val_loss: 0.3156 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2794 - acc: 0.9479 - precision: 0.9901 - recall: 0.9108 - f1_score: 0.9483 - val_loss: 0.3151 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2789 - acc: 0.9479 - precision: 0.9897 - recall: 0.9085 - f1_score: 0.9460 - val_loss: 0.3147 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9479 - precision: 0.9909 - recall: 0.9100 - f1_score: 0.9483 - val_loss: 0.3142 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2780 - acc: 0.9479 - precision: 0.9895 - recall: 0.9123 - f1_score: 0.9482 - val_loss: 0.3137 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2775 - acc: 0.9479 - precision: 0.9900 - recall: 0.9096 - f1_score: 0.9473 - val_loss: 0.3132 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2771 - acc: 0.9479 - precision: 0.9895 - recall: 0.9100 - f1_score: 0.9477 - val_loss: 0.3128 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2766 - acc: 0.9479 - precision: 0.9891 - recall: 0.9086 - f1_score: 0.9460 - val_loss: 0.3123 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2762 - acc: 0.9479 - precision: 0.9913 - recall: 0.9063 - f1_score: 0.9454 - val_loss: 0.3118 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2757 - acc: 0.9479 - precision: 0.9896 - recall: 0.9087 - f1_score: 0.9465 - val_loss: 0.3114 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2753 - acc: 0.9479 - precision: 0.9922 - recall: 0.9100 - f1_score: 0.9485 - val_loss: 0.3109 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2748 - acc: 0.9479 - precision: 0.9896 - recall: 0.9122 - f1_score: 0.9488 - val_loss: 0.3104 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9479 - precision: 0.9911 - recall: 0.9112 - f1_score: 0.9489 - val_loss: 0.3100 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2739 - acc: 0.9479 - precision: 0.9902 - recall: 0.9090 - f1_score: 0.9474 - val_loss: 0.3095 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2735 - acc: 0.9479 - precision: 0.9897 - recall: 0.9101 - f1_score: 0.9465 - val_loss: 0.3091 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2730 - acc: 0.9479 - precision: 0.9905 - recall: 0.9125 - f1_score: 0.9488 - val_loss: 0.3086 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2726 - acc: 0.9479 - precision: 0.9891 - recall: 0.9112 - f1_score: 0.9477 - val_loss: 0.3082 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9479 - precision: 0.9913 - recall: 0.9111 - f1_score: 0.9487 - val_loss: 0.3077 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2717 - acc: 0.9479 - precision: 0.9900 - recall: 0.9103 - f1_score: 0.9476 - val_loss: 0.3073 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2713 - acc: 0.9479 - precision: 0.9900 - recall: 0.9093 - f1_score: 0.9470 - val_loss: 0.3068 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2708 - acc: 0.9479 - precision: 0.9904 - recall: 0.9086 - f1_score: 0.9467 - val_loss: 0.3064 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2704 - acc: 0.9479 - precision: 0.9904 - recall: 0.9095 - f1_score: 0.9470 - val_loss: 0.3060 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2700 - acc: 0.9479 - precision: 0.9901 - recall: 0.9089 - f1_score: 0.9471 - val_loss: 0.3055 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2695 - acc: 0.9479 - precision: 0.9904 - recall: 0.9098 - f1_score: 0.9475 - val_loss: 0.3051 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2691 - acc: 0.9479 - precision: 0.9901 - recall: 0.9082 - f1_score: 0.9465 - val_loss: 0.3047 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2687 - acc: 0.9479 - precision: 0.9898 - recall: 0.9093 - f1_score: 0.9464 - val_loss: 0.3042 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2683 - acc: 0.9479 - precision: 0.9906 - recall: 0.9067 - f1_score: 0.9451 - val_loss: 0.3038 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2678 - acc: 0.9479 - precision: 0.9914 - recall: 0.9047 - f1_score: 0.9435 - val_loss: 0.3034 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2674 - acc: 0.9479 - precision: 0.9898 - recall: 0.9123 - f1_score: 0.9487 - val_loss: 0.3030 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2670 - acc: 0.9479 - precision: 0.9908 - recall: 0.9124 - f1_score: 0.9490 - val_loss: 0.3025 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2666 - acc: 0.9479 - precision: 0.9907 - recall: 0.9079 - f1_score: 0.9463 - val_loss: 0.3021 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2662 - acc: 0.9479 - precision: 0.9895 - recall: 0.9144 - f1_score: 0.9497 - val_loss: 0.3017 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2658 - acc: 0.9479 - precision: 0.9906 - recall: 0.9106 - f1_score: 0.9476 - val_loss: 0.3013 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2654 - acc: 0.9479 - precision: 0.9903 - recall: 0.9042 - f1_score: 0.9435 - val_loss: 0.3009 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2650 - acc: 0.9479 - precision: 0.9904 - recall: 0.9102 - f1_score: 0.9480 - val_loss: 0.3004 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2645 - acc: 0.9479 - precision: 0.9904 - recall: 0.9100 - f1_score: 0.9462 - val_loss: 0.3000 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 855/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2641 - acc: 0.9479 - precision: 0.9905 - recall: 0.9116 - f1_score: 0.9490 - val_loss: 0.2996 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2637 - acc: 0.9479 - precision: 0.9889 - recall: 0.9109 - f1_score: 0.9477 - val_loss: 0.2992 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2633 - acc: 0.9479 - precision: 0.9907 - recall: 0.9097 - f1_score: 0.9481 - val_loss: 0.2988 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2629 - acc: 0.9479 - precision: 0.9871 - recall: 0.9115 - f1_score: 0.9472 - val_loss: 0.2984 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2625 - acc: 0.9479 - precision: 0.9900 - recall: 0.9093 - f1_score: 0.9469 - val_loss: 0.2980 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2621 - acc: 0.9479 - precision: 0.9903 - recall: 0.9104 - f1_score: 0.9480 - val_loss: 0.2976 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2687 - acc: 0.9460 - precision: 0.9955 - recall: 0.9017 - f1_score: 0.944 - 0s - loss: 0.2618 - acc: 0.9479 - precision: 0.9915 - recall: 0.9118 - f1_score: 0.9486 - val_loss: 0.2972 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2614 - acc: 0.9479 - precision: 0.9906 - recall: 0.9066 - f1_score: 0.9456 - val_loss: 0.2968 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2610 - acc: 0.9479 - precision: 0.9908 - recall: 0.9116 - f1_score: 0.9484 - val_loss: 0.2964 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2606 - acc: 0.9479 - precision: 0.9903 - recall: 0.9109 - f1_score: 0.9483 - val_loss: 0.2960 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9479 - precision: 0.9908 - recall: 0.9109 - f1_score: 0.9485 - val_loss: 0.2956 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9479 - precision: 0.9900 - recall: 0.9104 - f1_score: 0.9479 - val_loss: 0.2952 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2594 - acc: 0.9479 - precision: 0.9885 - recall: 0.9115 - f1_score: 0.9480 - val_loss: 0.2948 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2590 - acc: 0.9479 - precision: 0.9890 - recall: 0.9113 - f1_score: 0.9480 - val_loss: 0.2945 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2587 - acc: 0.9479 - precision: 0.9908 - recall: 0.9106 - f1_score: 0.9485 - val_loss: 0.2941 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2583 - acc: 0.9479 - precision: 0.9893 - recall: 0.9105 - f1_score: 0.9471 - val_loss: 0.2937 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2579 - acc: 0.9479 - precision: 0.9904 - recall: 0.9096 - f1_score: 0.9476 - val_loss: 0.2933 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9479 - precision: 0.9893 - recall: 0.9077 - f1_score: 0.9462 - val_loss: 0.2929 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9479 - precision: 0.9910 - recall: 0.9172 - f1_score: 0.9516 - val_loss: 0.2925 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2568 - acc: 0.9479 - precision: 0.9906 - recall: 0.9071 - f1_score: 0.9464 - val_loss: 0.2922 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2564 - acc: 0.9479 - precision: 0.9915 - recall: 0.9051 - f1_score: 0.9451 - val_loss: 0.2918 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2561 - acc: 0.9479 - precision: 0.9901 - recall: 0.9130 - f1_score: 0.9488 - val_loss: 0.2914 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2557 - acc: 0.9479 - precision: 0.9899 - recall: 0.9070 - f1_score: 0.9458 - val_loss: 0.2910 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2553 - acc: 0.9479 - precision: 0.9900 - recall: 0.9056 - f1_score: 0.9453 - val_loss: 0.2907 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2550 - acc: 0.9479 - precision: 0.9904 - recall: 0.9093 - f1_score: 0.9474 - val_loss: 0.2903 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2546 - acc: 0.9479 - precision: 0.9904 - recall: 0.9097 - f1_score: 0.9479 - val_loss: 0.2899 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2542 - acc: 0.9479 - precision: 0.9908 - recall: 0.9102 - f1_score: 0.9480 - val_loss: 0.2895 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2539 - acc: 0.9479 - precision: 0.9890 - recall: 0.9076 - f1_score: 0.9450 - val_loss: 0.2892 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2535 - acc: 0.9479 - precision: 0.9899 - recall: 0.9117 - f1_score: 0.9480 - val_loss: 0.2888 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2532 - acc: 0.9479 - precision: 0.9892 - recall: 0.9128 - f1_score: 0.9478 - val_loss: 0.2884 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2528 - acc: 0.9479 - precision: 0.9891 - recall: 0.9095 - f1_score: 0.9469 - val_loss: 0.2881 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2525 - acc: 0.9479 - precision: 0.9900 - recall: 0.9048 - f1_score: 0.9437 - val_loss: 0.2877 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2521 - acc: 0.9479 - precision: 0.9906 - recall: 0.9086 - f1_score: 0.9461 - val_loss: 0.2874 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2518 - acc: 0.9479 - precision: 0.9912 - recall: 0.9095 - f1_score: 0.9458 - val_loss: 0.2870 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2514 - acc: 0.9479 - precision: 0.9908 - recall: 0.9063 - f1_score: 0.9455 - val_loss: 0.2867 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2511 - acc: 0.9479 - precision: 0.9895 - recall: 0.9134 - f1_score: 0.9489 - val_loss: 0.2863 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2507 - acc: 0.9479 - precision: 0.9892 - recall: 0.9066 - f1_score: 0.9453 - val_loss: 0.2860 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2504 - acc: 0.9479 - precision: 0.9892 - recall: 0.9081 - f1_score: 0.9462 - val_loss: 0.2856 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2500 - acc: 0.9479 - precision: 0.9896 - recall: 0.9068 - f1_score: 0.9456 - val_loss: 0.2853 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2497 - acc: 0.9479 - precision: 0.9902 - recall: 0.9045 - f1_score: 0.9433 - val_loss: 0.2849 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2494 - acc: 0.9479 - precision: 0.9883 - recall: 0.9094 - f1_score: 0.9468 - val_loss: 0.2846 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2490 - acc: 0.9479 - precision: 0.9900 - recall: 0.9096 - f1_score: 0.9477 - val_loss: 0.2842 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2487 - acc: 0.9479 - precision: 0.9908 - recall: 0.9102 - f1_score: 0.9481 - val_loss: 0.2839 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9479 - precision: 0.9902 - recall: 0.9072 - f1_score: 0.9462 - val_loss: 0.2835 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2480 - acc: 0.9479 - precision: 0.9901 - recall: 0.9109 - f1_score: 0.9480 - val_loss: 0.2832 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2477 - acc: 0.9479 - precision: 0.9902 - recall: 0.9084 - f1_score: 0.9463 - val_loss: 0.2829 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2474 - acc: 0.9479 - precision: 0.9897 - recall: 0.9062 - f1_score: 0.9450 - val_loss: 0.2825 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9479 - precision: 0.9885 - recall: 0.9093 - f1_score: 0.9460 - val_loss: 0.2822 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9479 - precision: 0.9898 - recall: 0.9106 - f1_score: 0.9480 - val_loss: 0.2818 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9479 - precision: 0.9897 - recall: 0.9092 - f1_score: 0.9469 - val_loss: 0.2815 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2461 - acc: 0.9479 - precision: 0.9900 - recall: 0.9042 - f1_score: 0.9438 - val_loss: 0.2812 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2457 - acc: 0.9479 - precision: 0.9899 - recall: 0.9091 - f1_score: 0.9468 - val_loss: 0.2808 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2454 - acc: 0.9479 - precision: 0.9898 - recall: 0.9098 - f1_score: 0.9478 - val_loss: 0.2805 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2451 - acc: 0.9479 - precision: 0.9904 - recall: 0.9104 - f1_score: 0.9478 - val_loss: 0.2802 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9479 - precision: 0.9915 - recall: 0.9099 - f1_score: 0.9483 - val_loss: 0.2799 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2445 - acc: 0.9479 - precision: 0.9908 - recall: 0.9091 - f1_score: 0.9469 - val_loss: 0.2795 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2441 - acc: 0.9479 - precision: 0.9895 - recall: 0.9092 - f1_score: 0.9462 - val_loss: 0.2792 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2438 - acc: 0.9479 - precision: 0.9891 - recall: 0.9101 - f1_score: 0.9472 - val_loss: 0.2789 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2435 - acc: 0.9479 - precision: 0.9916 - recall: 0.9081 - f1_score: 0.9469 - val_loss: 0.2786 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2432 - acc: 0.9479 - precision: 0.9897 - recall: 0.9097 - f1_score: 0.9472 - val_loss: 0.2783 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9479 - precision: 0.9908 - recall: 0.9095 - f1_score: 0.9471 - val_loss: 0.2779 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9479 - precision: 0.9909 - recall: 0.9098 - f1_score: 0.9471 - val_loss: 0.2776 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9479 - precision: 0.9891 - recall: 0.9091 - f1_score: 0.9469 - val_loss: 0.2773 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2420 - acc: 0.9479 - precision: 0.9891 - recall: 0.9062 - f1_score: 0.9451 - val_loss: 0.2770 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2417 - acc: 0.9479 - precision: 0.9899 - recall: 0.9099 - f1_score: 0.9473 - val_loss: 0.2767 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2414 - acc: 0.9479 - precision: 0.9896 - recall: 0.9076 - f1_score: 0.9462 - val_loss: 0.2764 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2411 - acc: 0.9479 - precision: 0.9903 - recall: 0.9090 - f1_score: 0.9474 - val_loss: 0.2761 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2408 - acc: 0.9479 - precision: 0.9878 - recall: 0.9051 - f1_score: 0.9435 - val_loss: 0.2758 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2405 - acc: 0.9479 - precision: 0.9911 - recall: 0.9065 - f1_score: 0.9453 - val_loss: 0.2755 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9479 - precision: 0.9899 - recall: 0.9088 - f1_score: 0.9467 - val_loss: 0.2751 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9479 - precision: 0.9912 - recall: 0.9094 - f1_score: 0.9473 - val_loss: 0.2748 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2396 - acc: 0.9479 - precision: 0.9888 - recall: 0.9088 - f1_score: 0.9453 - val_loss: 0.2745 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2393 - acc: 0.9479 - precision: 0.9908 - recall: 0.9110 - f1_score: 0.9479 - val_loss: 0.2742 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2390 - acc: 0.9479 - precision: 0.9902 - recall: 0.9079 - f1_score: 0.9463 - val_loss: 0.2739 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2387 - acc: 0.9479 - precision: 0.9895 - recall: 0.9081 - f1_score: 0.9463 - val_loss: 0.2737 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9479 - precision: 0.9912 - recall: 0.9056 - f1_score: 0.9453 - val_loss: 0.2734 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2381 - acc: 0.9479 - precision: 0.9883 - recall: 0.9132 - f1_score: 0.9485 - val_loss: 0.2731 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2378 - acc: 0.9479 - precision: 0.9900 - recall: 0.9127 - f1_score: 0.9488 - val_loss: 0.2728 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2375 - acc: 0.9479 - precision: 0.9896 - recall: 0.9105 - f1_score: 0.9475 - val_loss: 0.2725 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9479 - precision: 0.9906 - recall: 0.9092 - f1_score: 0.9470 - val_loss: 0.2722 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9479 - precision: 0.9905 - recall: 0.9085 - f1_score: 0.9471 - val_loss: 0.2719 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2367 - acc: 0.9479 - precision: 0.9904 - recall: 0.9115 - f1_score: 0.9484 - val_loss: 0.2716 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2364 - acc: 0.9479 - precision: 0.9909 - recall: 0.9093 - f1_score: 0.9476 - val_loss: 0.2713 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9479 - precision: 0.9910 - recall: 0.9095 - f1_score: 0.9471 - val_loss: 0.2710 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9479 - precision: 0.9906 - recall: 0.9113 - f1_score: 0.9482 - val_loss: 0.2707 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2356 - acc: 0.9479 - precision: 0.9896 - recall: 0.9073 - f1_score: 0.9456 - val_loss: 0.2705 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9479 - precision: 0.9903 - recall: 0.9118 - f1_score: 0.9483 - val_loss: 0.2702 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9479 - precision: 0.9901 - recall: 0.9090 - f1_score: 0.9469 - val_loss: 0.2699 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2347 - acc: 0.9479 - precision: 0.9904 - recall: 0.9109 - f1_score: 0.9483 - val_loss: 0.2696 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2345 - acc: 0.9479 - precision: 0.9895 - recall: 0.9083 - f1_score: 0.9462 - val_loss: 0.2693 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2342 - acc: 0.9479 - precision: 0.9906 - recall: 0.9094 - f1_score: 0.9465 - val_loss: 0.2691 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9479 - precision: 0.9903 - recall: 0.9076 - f1_score: 0.9464 - val_loss: 0.2688 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9479 - precision: 0.9908 - recall: 0.9121 - f1_score: 0.9478 - val_loss: 0.2685 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9479 - precision: 0.9906 - recall: 0.9114 - f1_score: 0.9481 - val_loss: 0.2682 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2331 - acc: 0.9479 - precision: 0.9896 - recall: 0.9087 - f1_score: 0.9463 - val_loss: 0.2680 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2328 - acc: 0.9479 - precision: 0.9885 - recall: 0.9074 - f1_score: 0.9454 - val_loss: 0.2677 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2326 - acc: 0.9479 - precision: 0.9900 - recall: 0.9035 - f1_score: 0.9434 - val_loss: 0.2674 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2323 - acc: 0.9479 - precision: 0.9900 - recall: 0.9079 - f1_score: 0.9465 - val_loss: 0.2671 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2321 - acc: 0.9479 - precision: 0.9874 - recall: 0.9075 - f1_score: 0.9449 - val_loss: 0.2669 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2318 - acc: 0.9479 - precision: 0.9893 - recall: 0.9058 - f1_score: 0.9452 - val_loss: 0.2666 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2315 - acc: 0.9479 - precision: 0.9908 - recall: 0.9071 - f1_score: 0.9460 - val_loss: 0.2663 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2313 - acc: 0.9479 - precision: 0.9877 - recall: 0.9067 - f1_score: 0.9448 - val_loss: 0.2661 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9479 - precision: 0.9897 - recall: 0.9117 - f1_score: 0.9485 - val_loss: 0.2658 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2308 - acc: 0.9479 - precision: 0.9897 - recall: 0.9094 - f1_score: 0.9465 - val_loss: 0.2655 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2305 - acc: 0.9479 - precision: 0.9910 - recall: 0.9086 - f1_score: 0.9470 - val_loss: 0.2653 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2303 - acc: 0.9479 - precision: 0.9899 - recall: 0.9140 - f1_score: 0.9485 - val_loss: 0.2650 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2300 - acc: 0.9479 - precision: 0.9896 - recall: 0.9115 - f1_score: 0.9477 - val_loss: 0.2648 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2298 - acc: 0.9479 - precision: 0.9901 - recall: 0.9091 - f1_score: 0.9477 - val_loss: 0.2645 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2295 - acc: 0.9479 - precision: 0.9914 - recall: 0.9106 - f1_score: 0.9480 - val_loss: 0.2642 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2292 - acc: 0.9479 - precision: 0.9902 - recall: 0.9080 - f1_score: 0.9464 - val_loss: 0.2640 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2290 - acc: 0.9479 - precision: 0.9900 - recall: 0.9089 - f1_score: 0.9465 - val_loss: 0.2637 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2287 - acc: 0.9479 - precision: 0.9909 - recall: 0.9105 - f1_score: 0.9485 - val_loss: 0.2635 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2285 - acc: 0.9479 - precision: 0.9908 - recall: 0.9081 - f1_score: 0.9468 - val_loss: 0.2632 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2283 - acc: 0.9479 - precision: 0.9901 - recall: 0.9137 - f1_score: 0.9492 - val_loss: 0.2630 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2280 - acc: 0.9479 - precision: 0.9914 - recall: 0.9111 - f1_score: 0.9489 - val_loss: 0.2627 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2278 - acc: 0.9479 - precision: 0.9905 - recall: 0.9105 - f1_score: 0.9481 - val_loss: 0.2625 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2275 - acc: 0.9479 - precision: 0.9892 - recall: 0.9070 - f1_score: 0.9458 - val_loss: 0.2622 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2273 - acc: 0.9479 - precision: 0.9915 - recall: 0.9066 - f1_score: 0.9455 - val_loss: 0.2620 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2270 - acc: 0.9479 - precision: 0.9908 - recall: 0.9098 - f1_score: 0.9481 - val_loss: 0.2617 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2268 - acc: 0.9479 - precision: 0.9902 - recall: 0.9109 - f1_score: 0.9481 - val_loss: 0.2615 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2266 - acc: 0.9479 - precision: 0.9886 - recall: 0.9080 - f1_score: 0.9461 - val_loss: 0.2612 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2263 - acc: 0.9479 - precision: 0.9891 - recall: 0.9096 - f1_score: 0.9465 - val_loss: 0.2610 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2261 - acc: 0.9479 - precision: 0.9904 - recall: 0.9149 - f1_score: 0.9499 - val_loss: 0.2607 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2259 - acc: 0.9479 - precision: 0.9906 - recall: 0.9026 - f1_score: 0.9435 - val_loss: 0.2605 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2256 - acc: 0.9479 - precision: 0.9907 - recall: 0.9118 - f1_score: 0.9491 - val_loss: 0.2602 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2254 - acc: 0.9479 - precision: 0.9908 - recall: 0.9088 - f1_score: 0.9476 - val_loss: 0.2600 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2251 - acc: 0.9479 - precision: 0.9907 - recall: 0.9135 - f1_score: 0.9497 - val_loss: 0.2598 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2249 - acc: 0.9479 - precision: 0.9884 - recall: 0.9057 - f1_score: 0.9443 - val_loss: 0.2595 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 983/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2247 - acc: 0.9479 - precision: 0.9912 - recall: 0.9071 - f1_score: 0.9465 - val_loss: 0.2593 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2245 - acc: 0.9479 - precision: 0.9911 - recall: 0.9049 - f1_score: 0.9448 - val_loss: 0.2590 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2242 - acc: 0.9479 - precision: 0.9907 - recall: 0.9131 - f1_score: 0.9493 - val_loss: 0.2588 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2240 - acc: 0.9479 - precision: 0.9912 - recall: 0.9103 - f1_score: 0.9480 - val_loss: 0.2586 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2238 - acc: 0.9479 - precision: 0.9905 - recall: 0.9091 - f1_score: 0.9469 - val_loss: 0.2583 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2236 - acc: 0.9479 - precision: 0.9902 - recall: 0.9109 - f1_score: 0.9482 - val_loss: 0.2581 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2233 - acc: 0.9479 - precision: 0.9899 - recall: 0.9080 - f1_score: 0.9462 - val_loss: 0.2579 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2231 - acc: 0.9479 - precision: 0.9889 - recall: 0.9129 - f1_score: 0.9483 - val_loss: 0.2576 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2229 - acc: 0.9479 - precision: 0.9903 - recall: 0.9104 - f1_score: 0.9478 - val_loss: 0.2574 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2226 - acc: 0.9479 - precision: 0.9894 - recall: 0.9090 - f1_score: 0.9466 - val_loss: 0.2572 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2224 - acc: 0.9479 - precision: 0.9904 - recall: 0.9094 - f1_score: 0.9475 - val_loss: 0.2569 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2222 - acc: 0.9479 - precision: 0.9896 - recall: 0.9088 - f1_score: 0.9464 - val_loss: 0.2567 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2220 - acc: 0.9479 - precision: 0.9890 - recall: 0.9078 - f1_score: 0.9458 - val_loss: 0.2565 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2218 - acc: 0.9479 - precision: 0.9911 - recall: 0.9102 - f1_score: 0.9486 - val_loss: 0.2563 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2216 - acc: 0.9479 - precision: 0.9899 - recall: 0.9084 - f1_score: 0.9467 - val_loss: 0.2561 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2213 - acc: 0.9479 - precision: 0.9910 - recall: 0.9102 - f1_score: 0.9478 - val_loss: 0.2558 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2211 - acc: 0.9479 - precision: 0.9899 - recall: 0.9057 - f1_score: 0.9453 - val_loss: 0.2556 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2209 - acc: 0.9479 - precision: 0.9906 - recall: 0.9076 - f1_score: 0.9462 - val_loss: 0.2554 - val_acc: 0.9304 - val_precision: 0.9802 - val_recall: 0.8433 - val_f1_score: 0.9049\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.1330 - acc: 0.7346 - precision: 0.7423 - recall: 0.5941 - f1_score: 0.6268 - val_loss: 5.9515 - val_acc: 0.8671 - val_precision: 0.8538 - val_recall: 0.9216 - val_f1_score: 0.8857\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9591 - acc: 0.8468 - precision: 0.8045 - recall: 0.8972 - f1_score: 0.8466 - val_loss: 5.8761 - val_acc: 0.8608 - val_precision: 0.8368 - val_recall: 0.9329 - val_f1_score: 0.8813\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9035 - acc: 0.8468 - precision: 0.7979 - recall: 0.9067 - f1_score: 0.8459 - val_loss: 5.8286 - val_acc: 0.8671 - val_precision: 0.8372 - val_recall: 0.9442 - val_f1_score: 0.8869\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8612 - acc: 0.8531 - precision: 0.8064 - recall: 0.9117 - f1_score: 0.8542 - val_loss: 5.7889 - val_acc: 0.8734 - val_precision: 0.8462 - val_recall: 0.9442 - val_f1_score: 0.8922\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8236 - acc: 0.8610 - precision: 0.8231 - recall: 0.9071 - f1_score: 0.8598 - val_loss: 5.7526 - val_acc: 0.8734 - val_precision: 0.8462 - val_recall: 0.9442 - val_f1_score: 0.8922\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7884 - acc: 0.8657 - precision: 0.8235 - recall: 0.9049 - f1_score: 0.8598 - val_loss: 5.7181 - val_acc: 0.8797 - val_precision: 0.8550 - val_recall: 0.9442 - val_f1_score: 0.8970\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7545 - acc: 0.8689 - precision: 0.8341 - recall: 0.9096 - f1_score: 0.8680 - val_loss: 5.6849 - val_acc: 0.8861 - val_precision: 0.8651 - val_recall: 0.9442 - val_f1_score: 0.9015\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7216 - acc: 0.8847 - precision: 0.8637 - recall: 0.9088 - f1_score: 0.8811 - val_loss: 5.6525 - val_acc: 0.8861 - val_precision: 0.8651 - val_recall: 0.9442 - val_f1_score: 0.9015\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6895 - acc: 0.8910 - precision: 0.8741 - recall: 0.9071 - f1_score: 0.8876 - val_loss: 5.6208 - val_acc: 0.8861 - val_precision: 0.8651 - val_recall: 0.9442 - val_f1_score: 0.9015\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6578 - acc: 0.9021 - precision: 0.8932 - recall: 0.9064 - f1_score: 0.8980 - val_loss: 5.5897 - val_acc: 0.8924 - val_precision: 0.8734 - val_recall: 0.9442 - val_f1_score: 0.9059\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6267 - acc: 0.9068 - precision: 0.8934 - recall: 0.9029 - f1_score: 0.8965 - val_loss: 5.5589 - val_acc: 0.9051 - val_precision: 0.8916 - val_recall: 0.9442 - val_f1_score: 0.9155\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5959 - acc: 0.9115 - precision: 0.9043 - recall: 0.9064 - f1_score: 0.9033 - val_loss: 5.5285 - val_acc: 0.9241 - val_precision: 0.9217 - val_recall: 0.9442 - val_f1_score: 0.9318\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5654 - acc: 0.9179 - precision: 0.9236 - recall: 0.9082 - f1_score: 0.9127 - val_loss: 5.4985 - val_acc: 0.9241 - val_precision: 0.9217 - val_recall: 0.9442 - val_f1_score: 0.9318\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5353 - acc: 0.9194 - precision: 0.9220 - recall: 0.8980 - f1_score: 0.9083 - val_loss: 5.4688 - val_acc: 0.9241 - val_precision: 0.9217 - val_recall: 0.9442 - val_f1_score: 0.9318\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.5055 - acc: 0.9194 - precision: 0.9257 - recall: 0.9078 - f1_score: 0.9135 - val_loss: 5.4394 - val_acc: 0.9241 - val_precision: 0.9217 - val_recall: 0.9442 - val_f1_score: 0.9318\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4760 - acc: 0.9226 - precision: 0.9304 - recall: 0.8987 - f1_score: 0.9127 - val_loss: 5.4103 - val_acc: 0.9241 - val_precision: 0.9217 - val_recall: 0.9442 - val_f1_score: 0.9318\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4467 - acc: 0.9242 - precision: 0.9368 - recall: 0.9017 - f1_score: 0.9167 - val_loss: 5.3814 - val_acc: 0.9367 - val_precision: 0.9422 - val_recall: 0.9442 - val_f1_score: 0.9425\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4177 - acc: 0.9258 - precision: 0.9355 - recall: 0.9072 - f1_score: 0.9181 - val_loss: 5.3528 - val_acc: 0.9430 - val_precision: 0.9521 - val_recall: 0.9442 - val_f1_score: 0.9474\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3889 - acc: 0.9273 - precision: 0.9406 - recall: 0.9055 - f1_score: 0.9214 - val_loss: 5.3244 - val_acc: 0.9430 - val_precision: 0.9521 - val_recall: 0.9442 - val_f1_score: 0.9474\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3603 - acc: 0.9273 - precision: 0.9426 - recall: 0.9008 - f1_score: 0.9196 - val_loss: 5.2963 - val_acc: 0.9430 - val_precision: 0.9521 - val_recall: 0.9442 - val_f1_score: 0.9474\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3320 - acc: 0.9273 - precision: 0.9408 - recall: 0.9028 - f1_score: 0.9207 - val_loss: 5.2684 - val_acc: 0.9367 - val_precision: 0.9512 - val_recall: 0.9329 - val_f1_score: 0.9412\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3038 - acc: 0.9273 - precision: 0.9411 - recall: 0.9053 - f1_score: 0.9203 - val_loss: 5.2407 - val_acc: 0.9430 - val_precision: 0.9625 - val_recall: 0.9329 - val_f1_score: 0.9465\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2759 - acc: 0.9289 - precision: 0.9445 - recall: 0.9026 - f1_score: 0.9206 - val_loss: 5.2131 - val_acc: 0.9494 - val_precision: 0.9746 - val_recall: 0.9329 - val_f1_score: 0.9527\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2482 - acc: 0.9289 - precision: 0.9451 - recall: 0.9026 - f1_score: 0.9230 - val_loss: 5.1858 - val_acc: 0.9494 - val_precision: 0.9746 - val_recall: 0.9329 - val_f1_score: 0.9527\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2206 - acc: 0.9289 - precision: 0.9431 - recall: 0.9016 - f1_score: 0.9211 - val_loss: 5.1587 - val_acc: 0.9494 - val_precision: 0.9746 - val_recall: 0.9329 - val_f1_score: 0.9527\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1933 - acc: 0.9289 - precision: 0.9439 - recall: 0.9041 - f1_score: 0.9223 - val_loss: 5.1318 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1662 - acc: 0.9305 - precision: 0.9457 - recall: 0.9106 - f1_score: 0.9254 - val_loss: 5.1051 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1393 - acc: 0.9321 - precision: 0.9521 - recall: 0.9045 - f1_score: 0.9259 - val_loss: 5.0786 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1125 - acc: 0.9352 - precision: 0.9548 - recall: 0.8966 - f1_score: 0.9232 - val_loss: 5.0523 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0859 - acc: 0.9352 - precision: 0.9579 - recall: 0.9054 - f1_score: 0.9297 - val_loss: 5.0261 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0595 - acc: 0.9368 - precision: 0.9609 - recall: 0.9034 - f1_score: 0.9295 - val_loss: 5.0001 - val_acc: 0.9557 - val_precision: 0.9868 - val_recall: 0.9329 - val_f1_score: 0.9583\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0333 - acc: 0.9368 - precision: 0.9606 - recall: 0.9053 - f1_score: 0.9301 - val_loss: 4.9743 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0072 - acc: 0.9336 - precision: 0.9624 - recall: 0.8984 - f1_score: 0.9278 - val_loss: 4.9487 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9813 - acc: 0.9336 - precision: 0.9625 - recall: 0.9020 - f1_score: 0.9294 - val_loss: 4.9232 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9556 - acc: 0.9336 - precision: 0.9609 - recall: 0.8927 - f1_score: 0.9242 - val_loss: 4.8979 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9301 - acc: 0.9336 - precision: 0.9599 - recall: 0.8961 - f1_score: 0.9254 - val_loss: 4.8728 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9047 - acc: 0.9321 - precision: 0.9612 - recall: 0.8955 - f1_score: 0.9248 - val_loss: 4.8478 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8795 - acc: 0.9321 - precision: 0.9609 - recall: 0.8919 - f1_score: 0.9237 - val_loss: 4.8230 - val_acc: 0.9494 - val_precision: 0.9868 - val_recall: 0.9216 - val_f1_score: 0.9518\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8545 - acc: 0.9273 - precision: 0.9600 - recall: 0.8852 - f1_score: 0.9204 - val_loss: 4.7983 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8296 - acc: 0.9273 - precision: 0.9600 - recall: 0.8835 - f1_score: 0.9192 - val_loss: 4.7738 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8048 - acc: 0.9258 - precision: 0.9615 - recall: 0.8841 - f1_score: 0.9191 - val_loss: 4.7495 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7803 - acc: 0.9258 - precision: 0.9621 - recall: 0.8784 - f1_score: 0.9167 - val_loss: 4.7253 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7558 - acc: 0.9273 - precision: 0.9618 - recall: 0.8822 - f1_score: 0.9193 - val_loss: 4.7013 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7315 - acc: 0.9273 - precision: 0.9649 - recall: 0.8828 - f1_score: 0.9210 - val_loss: 4.6774 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7074 - acc: 0.9273 - precision: 0.9633 - recall: 0.8804 - f1_score: 0.9190 - val_loss: 4.6536 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6834 - acc: 0.9289 - precision: 0.9701 - recall: 0.8823 - f1_score: 0.9225 - val_loss: 4.6300 - val_acc: 0.9430 - val_precision: 0.9868 - val_recall: 0.9117 - val_f1_score: 0.9466\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.6596 - acc: 0.9289 - precision: 0.9659 - recall: 0.8776 - f1_score: 0.9189 - val_loss: 4.6066 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6359 - acc: 0.9289 - precision: 0.9670 - recall: 0.8828 - f1_score: 0.9208 - val_loss: 4.5833 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6123 - acc: 0.9289 - precision: 0.9679 - recall: 0.8831 - f1_score: 0.9223 - val_loss: 4.5601 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5890 - acc: 0.9289 - precision: 0.9681 - recall: 0.8823 - f1_score: 0.9223 - val_loss: 4.5370 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5657 - acc: 0.9305 - precision: 0.9731 - recall: 0.8837 - f1_score: 0.9238 - val_loss: 4.5141 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5426 - acc: 0.9305 - precision: 0.9717 - recall: 0.8814 - f1_score: 0.9235 - val_loss: 4.4914 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5196 - acc: 0.9305 - precision: 0.9711 - recall: 0.8785 - f1_score: 0.9209 - val_loss: 4.4687 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4968 - acc: 0.9305 - precision: 0.9723 - recall: 0.8824 - f1_score: 0.9239 - val_loss: 4.4463 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4741 - acc: 0.9305 - precision: 0.9716 - recall: 0.8788 - f1_score: 0.9218 - val_loss: 4.4239 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4515 - acc: 0.9305 - precision: 0.9716 - recall: 0.8860 - f1_score: 0.9251 - val_loss: 4.4017 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4290 - acc: 0.9321 - precision: 0.9746 - recall: 0.8819 - f1_score: 0.9245 - val_loss: 4.3796 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4067 - acc: 0.9321 - precision: 0.9752 - recall: 0.8794 - f1_score: 0.9237 - val_loss: 4.3576 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3846 - acc: 0.9321 - precision: 0.9713 - recall: 0.8812 - f1_score: 0.9221 - val_loss: 4.3358 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3625 - acc: 0.9321 - precision: 0.9747 - recall: 0.8840 - f1_score: 0.9248 - val_loss: 4.3141 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3406 - acc: 0.9321 - precision: 0.9758 - recall: 0.8820 - f1_score: 0.9247 - val_loss: 4.2925 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3188 - acc: 0.9321 - precision: 0.9738 - recall: 0.8807 - f1_score: 0.9232 - val_loss: 4.2710 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2972 - acc: 0.9321 - precision: 0.9742 - recall: 0.8832 - f1_score: 0.9248 - val_loss: 4.2497 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2756 - acc: 0.9321 - precision: 0.9752 - recall: 0.8797 - f1_score: 0.9241 - val_loss: 4.2284 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2542 - acc: 0.9321 - precision: 0.9714 - recall: 0.8838 - f1_score: 0.9238 - val_loss: 4.2074 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2329 - acc: 0.9321 - precision: 0.9753 - recall: 0.8845 - f1_score: 0.9264 - val_loss: 4.1864 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2118 - acc: 0.9321 - precision: 0.9731 - recall: 0.8899 - f1_score: 0.9272 - val_loss: 4.1655 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1907 - acc: 0.9321 - precision: 0.9754 - recall: 0.8813 - f1_score: 0.9246 - val_loss: 4.1448 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1698 - acc: 0.9321 - precision: 0.9732 - recall: 0.8789 - f1_score: 0.9225 - val_loss: 4.1242 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1490 - acc: 0.9321 - precision: 0.9728 - recall: 0.8782 - f1_score: 0.9219 - val_loss: 4.1037 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1283 - acc: 0.9321 - precision: 0.9729 - recall: 0.8801 - f1_score: 0.9216 - val_loss: 4.0833 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1078 - acc: 0.9321 - precision: 0.9757 - recall: 0.8813 - f1_score: 0.9252 - val_loss: 4.0630 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0873 - acc: 0.9321 - precision: 0.9723 - recall: 0.8787 - f1_score: 0.9213 - val_loss: 4.0428 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0670 - acc: 0.9321 - precision: 0.9766 - recall: 0.8775 - f1_score: 0.9232 - val_loss: 4.0228 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0468 - acc: 0.9321 - precision: 0.9726 - recall: 0.8749 - f1_score: 0.9205 - val_loss: 4.0029 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0267 - acc: 0.9321 - precision: 0.9737 - recall: 0.8766 - f1_score: 0.9209 - val_loss: 3.9830 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0067 - acc: 0.9321 - precision: 0.9723 - recall: 0.8840 - f1_score: 0.9245 - val_loss: 3.9633 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9868 - acc: 0.9321 - precision: 0.9739 - recall: 0.8812 - f1_score: 0.9227 - val_loss: 3.9437 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.9670 - acc: 0.9321 - precision: 0.9748 - recall: 0.8829 - f1_score: 0.9249 - val_loss: 3.9242 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9474 - acc: 0.9336 - precision: 0.9776 - recall: 0.8838 - f1_score: 0.9270 - val_loss: 3.9048 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9278 - acc: 0.9336 - precision: 0.9809 - recall: 0.8848 - f1_score: 0.9286 - val_loss: 3.8856 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9084 - acc: 0.9336 - precision: 0.9780 - recall: 0.8799 - f1_score: 0.9248 - val_loss: 3.8664 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8890 - acc: 0.9336 - precision: 0.9770 - recall: 0.8816 - f1_score: 0.9256 - val_loss: 3.8473 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8698 - acc: 0.9336 - precision: 0.9793 - recall: 0.8817 - f1_score: 0.9272 - val_loss: 3.8283 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8507 - acc: 0.9336 - precision: 0.9766 - recall: 0.8740 - f1_score: 0.9215 - val_loss: 3.8095 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8317 - acc: 0.9336 - precision: 0.9795 - recall: 0.8822 - f1_score: 0.9268 - val_loss: 3.7907 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8128 - acc: 0.9336 - precision: 0.9768 - recall: 0.8796 - f1_score: 0.9243 - val_loss: 3.7721 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7940 - acc: 0.9336 - precision: 0.9784 - recall: 0.8804 - f1_score: 0.9249 - val_loss: 3.7536 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7753 - acc: 0.9336 - precision: 0.9803 - recall: 0.8843 - f1_score: 0.9284 - val_loss: 3.7351 - val_acc: 0.9367 - val_precision: 0.9868 - val_recall: 0.9018 - val_f1_score: 0.9413\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7567 - acc: 0.9336 - precision: 0.9788 - recall: 0.8804 - f1_score: 0.9247 - val_loss: 3.7168 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7382 - acc: 0.9336 - precision: 0.9780 - recall: 0.8810 - f1_score: 0.9254 - val_loss: 3.6985 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7199 - acc: 0.9336 - precision: 0.9756 - recall: 0.8821 - f1_score: 0.9257 - val_loss: 3.6804 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7016 - acc: 0.9336 - precision: 0.9758 - recall: 0.8782 - f1_score: 0.9230 - val_loss: 3.6623 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6834 - acc: 0.9336 - precision: 0.9769 - recall: 0.8841 - f1_score: 0.9268 - val_loss: 3.6444 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6653 - acc: 0.9336 - precision: 0.9779 - recall: 0.8810 - f1_score: 0.9262 - val_loss: 3.6265 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6473 - acc: 0.9336 - precision: 0.9797 - recall: 0.8802 - f1_score: 0.9254 - val_loss: 3.6088 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6294 - acc: 0.9336 - precision: 0.9784 - recall: 0.8854 - f1_score: 0.9275 - val_loss: 3.5911 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6116 - acc: 0.9336 - precision: 0.9772 - recall: 0.8829 - f1_score: 0.9266 - val_loss: 3.5735 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5940 - acc: 0.9336 - precision: 0.9785 - recall: 0.8796 - f1_score: 0.9261 - val_loss: 3.5561 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5764 - acc: 0.9336 - precision: 0.9794 - recall: 0.8803 - f1_score: 0.9259 - val_loss: 3.5387 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5589 - acc: 0.9336 - precision: 0.9771 - recall: 0.8785 - f1_score: 0.9227 - val_loss: 3.5214 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5415 - acc: 0.9336 - precision: 0.9806 - recall: 0.8814 - f1_score: 0.9270 - val_loss: 3.5042 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 3.5218 - acc: 0.9367 - precision: 0.9793 - recall: 0.8900 - f1_score: 0.931 - 0s - loss: 3.5242 - acc: 0.9336 - precision: 0.9764 - recall: 0.8853 - f1_score: 0.9273 - val_loss: 3.4871 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5069 - acc: 0.9336 - precision: 0.9776 - recall: 0.8850 - f1_score: 0.9278 - val_loss: 3.4701 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4898 - acc: 0.9336 - precision: 0.9763 - recall: 0.8805 - f1_score: 0.9240 - val_loss: 3.4532 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4728 - acc: 0.9336 - precision: 0.9807 - recall: 0.8820 - f1_score: 0.9276 - val_loss: 3.4364 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4559 - acc: 0.9336 - precision: 0.9789 - recall: 0.8784 - f1_score: 0.9243 - val_loss: 3.4197 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4390 - acc: 0.9336 - precision: 0.9789 - recall: 0.8776 - f1_score: 0.9245 - val_loss: 3.4030 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4223 - acc: 0.9336 - precision: 0.9776 - recall: 0.8786 - f1_score: 0.9239 - val_loss: 3.3865 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4056 - acc: 0.9336 - precision: 0.9788 - recall: 0.8864 - f1_score: 0.9293 - val_loss: 3.3700 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.3891 - acc: 0.9336 - precision: 0.9802 - recall: 0.8827 - f1_score: 0.9270 - val_loss: 3.3537 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3726 - acc: 0.9336 - precision: 0.9798 - recall: 0.8813 - f1_score: 0.9268 - val_loss: 3.3374 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3562 - acc: 0.9336 - precision: 0.9803 - recall: 0.8819 - f1_score: 0.9274 - val_loss: 3.3212 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3399 - acc: 0.9336 - precision: 0.9785 - recall: 0.8784 - f1_score: 0.9250 - val_loss: 3.3051 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3237 - acc: 0.9336 - precision: 0.9771 - recall: 0.8823 - f1_score: 0.9264 - val_loss: 3.2890 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3076 - acc: 0.9305 - precision: 0.9782 - recall: 0.8787 - f1_score: 0.9247 - val_loss: 3.2731 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2915 - acc: 0.9305 - precision: 0.9753 - recall: 0.8781 - f1_score: 0.9222 - val_loss: 3.2573 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2756 - acc: 0.9305 - precision: 0.9781 - recall: 0.8805 - f1_score: 0.9257 - val_loss: 3.2415 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2597 - acc: 0.9305 - precision: 0.9765 - recall: 0.8746 - f1_score: 0.9217 - val_loss: 3.2258 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2439 - acc: 0.9305 - precision: 0.9797 - recall: 0.8748 - f1_score: 0.9226 - val_loss: 3.2102 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2282 - acc: 0.9305 - precision: 0.9765 - recall: 0.8764 - f1_score: 0.9223 - val_loss: 3.1947 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2126 - acc: 0.9305 - precision: 0.9777 - recall: 0.8720 - f1_score: 0.9202 - val_loss: 3.1793 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1971 - acc: 0.9305 - precision: 0.9783 - recall: 0.8753 - f1_score: 0.9232 - val_loss: 3.1639 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1816 - acc: 0.9305 - precision: 0.9777 - recall: 0.8720 - f1_score: 0.9202 - val_loss: 3.1486 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1663 - acc: 0.9305 - precision: 0.9774 - recall: 0.8747 - f1_score: 0.9208 - val_loss: 3.1334 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1510 - acc: 0.9305 - precision: 0.9796 - recall: 0.8762 - f1_score: 0.9219 - val_loss: 3.1183 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1358 - acc: 0.9305 - precision: 0.9767 - recall: 0.8776 - f1_score: 0.9227 - val_loss: 3.1033 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1207 - acc: 0.9305 - precision: 0.9774 - recall: 0.8730 - f1_score: 0.9202 - val_loss: 3.0884 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1056 - acc: 0.9305 - precision: 0.9764 - recall: 0.8740 - f1_score: 0.9213 - val_loss: 3.0735 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0907 - acc: 0.9305 - precision: 0.9809 - recall: 0.8753 - f1_score: 0.9235 - val_loss: 3.0587 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0758 - acc: 0.9305 - precision: 0.9769 - recall: 0.8723 - f1_score: 0.9203 - val_loss: 3.0440 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0610 - acc: 0.9305 - precision: 0.9775 - recall: 0.8743 - f1_score: 0.9214 - val_loss: 3.0293 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0463 - acc: 0.9305 - precision: 0.9798 - recall: 0.8753 - f1_score: 0.9235 - val_loss: 3.0148 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0316 - acc: 0.9305 - precision: 0.9786 - recall: 0.8744 - f1_score: 0.9221 - val_loss: 3.0003 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0171 - acc: 0.9305 - precision: 0.9802 - recall: 0.8778 - f1_score: 0.9244 - val_loss: 2.9859 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0026 - acc: 0.9305 - precision: 0.9769 - recall: 0.8745 - f1_score: 0.9202 - val_loss: 2.9716 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9882 - acc: 0.9305 - precision: 0.9769 - recall: 0.8709 - f1_score: 0.9199 - val_loss: 2.9573 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9738 - acc: 0.9305 - precision: 0.9774 - recall: 0.8762 - f1_score: 0.9223 - val_loss: 2.9431 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9596 - acc: 0.9305 - precision: 0.9774 - recall: 0.8711 - f1_score: 0.9200 - val_loss: 2.9290 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9454 - acc: 0.9305 - precision: 0.9782 - recall: 0.8738 - f1_score: 0.9223 - val_loss: 2.9150 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9313 - acc: 0.9305 - precision: 0.9774 - recall: 0.8751 - f1_score: 0.9225 - val_loss: 2.9011 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9173 - acc: 0.9305 - precision: 0.9766 - recall: 0.8765 - f1_score: 0.9216 - val_loss: 2.8872 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.9033 - acc: 0.9305 - precision: 0.9791 - recall: 0.8752 - f1_score: 0.9237 - val_loss: 2.8734 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8894 - acc: 0.9305 - precision: 0.9791 - recall: 0.8721 - f1_score: 0.9214 - val_loss: 2.8596 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8756 - acc: 0.9305 - precision: 0.9763 - recall: 0.8776 - f1_score: 0.9228 - val_loss: 2.8460 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8619 - acc: 0.9305 - precision: 0.9762 - recall: 0.8742 - f1_score: 0.9214 - val_loss: 2.8324 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8482 - acc: 0.9305 - precision: 0.9808 - recall: 0.8737 - f1_score: 0.9233 - val_loss: 2.8189 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8346 - acc: 0.9305 - precision: 0.9796 - recall: 0.8720 - f1_score: 0.9211 - val_loss: 2.8054 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8211 - acc: 0.9305 - precision: 0.9759 - recall: 0.8722 - f1_score: 0.9192 - val_loss: 2.7921 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8077 - acc: 0.9305 - precision: 0.9763 - recall: 0.8732 - f1_score: 0.9191 - val_loss: 2.7788 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7943 - acc: 0.9305 - precision: 0.9784 - recall: 0.8728 - f1_score: 0.9212 - val_loss: 2.7655 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7810 - acc: 0.9305 - precision: 0.9798 - recall: 0.8713 - f1_score: 0.9205 - val_loss: 2.7524 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7678 - acc: 0.9321 - precision: 0.9839 - recall: 0.8735 - f1_score: 0.9240 - val_loss: 2.7393 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7546 - acc: 0.9321 - precision: 0.9790 - recall: 0.8741 - f1_score: 0.9217 - val_loss: 2.7262 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7415 - acc: 0.9321 - precision: 0.9813 - recall: 0.8745 - f1_score: 0.9229 - val_loss: 2.7133 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7285 - acc: 0.9321 - precision: 0.9817 - recall: 0.8753 - f1_score: 0.9232 - val_loss: 2.7004 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7155 - acc: 0.9321 - precision: 0.9828 - recall: 0.8712 - f1_score: 0.9207 - val_loss: 2.6876 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7026 - acc: 0.9321 - precision: 0.9817 - recall: 0.8772 - f1_score: 0.9250 - val_loss: 2.6748 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6898 - acc: 0.9321 - precision: 0.9798 - recall: 0.8770 - f1_score: 0.9248 - val_loss: 2.6621 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6771 - acc: 0.9321 - precision: 0.9817 - recall: 0.8744 - f1_score: 0.9237 - val_loss: 2.6495 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6644 - acc: 0.9321 - precision: 0.9803 - recall: 0.8749 - f1_score: 0.9225 - val_loss: 2.6370 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6518 - acc: 0.9321 - precision: 0.9815 - recall: 0.8679 - f1_score: 0.9181 - val_loss: 2.6245 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6392 - acc: 0.9321 - precision: 0.9816 - recall: 0.8780 - f1_score: 0.9251 - val_loss: 2.6121 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6267 - acc: 0.9321 - precision: 0.9809 - recall: 0.8769 - f1_score: 0.9238 - val_loss: 2.5997 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6143 - acc: 0.9321 - precision: 0.9806 - recall: 0.8763 - f1_score: 0.9241 - val_loss: 2.5874 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6019 - acc: 0.9336 - precision: 0.9844 - recall: 0.8715 - f1_score: 0.9231 - val_loss: 2.5752 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5897 - acc: 0.9336 - precision: 0.9835 - recall: 0.8757 - f1_score: 0.9239 - val_loss: 2.5630 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5774 - acc: 0.9336 - precision: 0.9862 - recall: 0.8723 - f1_score: 0.9229 - val_loss: 2.5509 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5653 - acc: 0.9336 - precision: 0.9859 - recall: 0.8750 - f1_score: 0.9259 - val_loss: 2.5389 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5532 - acc: 0.9336 - precision: 0.9839 - recall: 0.8760 - f1_score: 0.9252 - val_loss: 2.5269 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5411 - acc: 0.9336 - precision: 0.9841 - recall: 0.8726 - f1_score: 0.9241 - val_loss: 2.5150 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5292 - acc: 0.9336 - precision: 0.9845 - recall: 0.8727 - f1_score: 0.9249 - val_loss: 2.5031 - val_acc: 0.9430 - val_precision: 1.0000 - val_recall: 0.9018 - val_f1_score: 0.9477\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5173 - acc: 0.9336 - precision: 0.9845 - recall: 0.8764 - f1_score: 0.9255 - val_loss: 2.4913 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5054 - acc: 0.9336 - precision: 0.9852 - recall: 0.8736 - f1_score: 0.9240 - val_loss: 2.4796 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.4936 - acc: 0.9336 - precision: 0.9845 - recall: 0.8784 - f1_score: 0.9265 - val_loss: 2.4680 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4819 - acc: 0.9336 - precision: 0.9847 - recall: 0.8754 - f1_score: 0.9257 - val_loss: 2.4564 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4702 - acc: 0.9336 - precision: 0.9848 - recall: 0.8740 - f1_score: 0.9248 - val_loss: 2.4448 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4587 - acc: 0.9336 - precision: 0.9856 - recall: 0.8742 - f1_score: 0.9255 - val_loss: 2.4333 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4471 - acc: 0.9336 - precision: 0.9852 - recall: 0.8751 - f1_score: 0.9252 - val_loss: 2.4219 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4356 - acc: 0.9336 - precision: 0.9866 - recall: 0.8689 - f1_score: 0.9225 - val_loss: 2.4106 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4242 - acc: 0.9321 - precision: 0.9849 - recall: 0.8715 - f1_score: 0.9232 - val_loss: 2.3992 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4129 - acc: 0.9321 - precision: 0.9866 - recall: 0.8707 - f1_score: 0.9241 - val_loss: 2.3880 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4016 - acc: 0.9321 - precision: 0.9850 - recall: 0.8739 - f1_score: 0.9249 - val_loss: 2.3768 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3903 - acc: 0.9321 - precision: 0.9858 - recall: 0.8680 - f1_score: 0.9204 - val_loss: 2.3657 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3792 - acc: 0.9321 - precision: 0.9813 - recall: 0.8648 - f1_score: 0.9174 - val_loss: 2.3546 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3680 - acc: 0.9321 - precision: 0.9865 - recall: 0.8686 - f1_score: 0.9226 - val_loss: 2.3436 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3570 - acc: 0.9321 - precision: 0.9839 - recall: 0.8695 - f1_score: 0.9210 - val_loss: 2.3327 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3460 - acc: 0.9321 - precision: 0.9847 - recall: 0.8741 - f1_score: 0.9246 - val_loss: 2.3218 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3350 - acc: 0.9321 - precision: 0.9839 - recall: 0.8684 - f1_score: 0.9205 - val_loss: 2.3110 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3241 - acc: 0.9321 - precision: 0.9860 - recall: 0.8651 - f1_score: 0.9200 - val_loss: 2.3002 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3133 - acc: 0.9321 - precision: 0.9855 - recall: 0.8704 - f1_score: 0.9224 - val_loss: 2.2894 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3025 - acc: 0.9321 - precision: 0.9857 - recall: 0.8739 - f1_score: 0.9250 - val_loss: 2.2788 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2918 - acc: 0.9321 - precision: 0.9830 - recall: 0.8700 - f1_score: 0.9215 - val_loss: 2.2681 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2811 - acc: 0.9321 - precision: 0.9859 - recall: 0.8676 - f1_score: 0.9211 - val_loss: 2.2576 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2705 - acc: 0.9336 - precision: 0.9842 - recall: 0.8710 - f1_score: 0.9218 - val_loss: 2.2471 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2600 - acc: 0.9336 - precision: 0.9863 - recall: 0.8744 - f1_score: 0.9261 - val_loss: 2.2366 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2495 - acc: 0.9336 - precision: 0.9851 - recall: 0.8773 - f1_score: 0.9265 - val_loss: 2.2263 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2390 - acc: 0.9336 - precision: 0.9852 - recall: 0.8732 - f1_score: 0.9244 - val_loss: 2.2159 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2287 - acc: 0.9336 - precision: 0.9846 - recall: 0.8720 - f1_score: 0.9236 - val_loss: 2.2056 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2183 - acc: 0.9336 - precision: 0.9853 - recall: 0.8814 - f1_score: 0.9287 - val_loss: 2.1954 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2080 - acc: 0.9336 - precision: 0.9844 - recall: 0.8696 - f1_score: 0.9208 - val_loss: 2.1852 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1978 - acc: 0.9336 - precision: 0.9838 - recall: 0.8707 - f1_score: 0.9217 - val_loss: 2.1751 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1876 - acc: 0.9336 - precision: 0.9858 - recall: 0.8727 - f1_score: 0.9240 - val_loss: 2.1650 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1775 - acc: 0.9336 - precision: 0.9853 - recall: 0.8719 - f1_score: 0.9235 - val_loss: 2.1550 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1675 - acc: 0.9336 - precision: 0.9866 - recall: 0.8722 - f1_score: 0.9235 - val_loss: 2.1450 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1574 - acc: 0.9352 - precision: 0.9853 - recall: 0.8759 - f1_score: 0.9253 - val_loss: 2.1351 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 207/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.1475 - acc: 0.9352 - precision: 0.9849 - recall: 0.8788 - f1_score: 0.9284 - val_loss: 2.1253 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1376 - acc: 0.9352 - precision: 0.9866 - recall: 0.8767 - f1_score: 0.9258 - val_loss: 2.1155 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1277 - acc: 0.9352 - precision: 0.9854 - recall: 0.8738 - f1_score: 0.9253 - val_loss: 2.1057 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1179 - acc: 0.9352 - precision: 0.9847 - recall: 0.8803 - f1_score: 0.9279 - val_loss: 2.0960 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1081 - acc: 0.9352 - precision: 0.9853 - recall: 0.8754 - f1_score: 0.9254 - val_loss: 2.0863 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0984 - acc: 0.9352 - precision: 0.9837 - recall: 0.8727 - f1_score: 0.9220 - val_loss: 2.0767 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0888 - acc: 0.9352 - precision: 0.9867 - recall: 0.8794 - f1_score: 0.9289 - val_loss: 2.0672 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0792 - acc: 0.9352 - precision: 0.9868 - recall: 0.8781 - f1_score: 0.9257 - val_loss: 2.0577 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0696 - acc: 0.9352 - precision: 0.9857 - recall: 0.8803 - f1_score: 0.9294 - val_loss: 2.0482 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0601 - acc: 0.9352 - precision: 0.9845 - recall: 0.8753 - f1_score: 0.9256 - val_loss: 2.0388 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0507 - acc: 0.9352 - precision: 0.9856 - recall: 0.8811 - f1_score: 0.9288 - val_loss: 2.0294 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0413 - acc: 0.9352 - precision: 0.9859 - recall: 0.8783 - f1_score: 0.9276 - val_loss: 2.0201 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0319 - acc: 0.9352 - precision: 0.9869 - recall: 0.8799 - f1_score: 0.9287 - val_loss: 2.0108 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0226 - acc: 0.9352 - precision: 0.9843 - recall: 0.8770 - f1_score: 0.9263 - val_loss: 2.0016 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0133 - acc: 0.9352 - precision: 0.9859 - recall: 0.8776 - f1_score: 0.9280 - val_loss: 1.9924 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0041 - acc: 0.9352 - precision: 0.9843 - recall: 0.8758 - f1_score: 0.9263 - val_loss: 1.9833 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9950 - acc: 0.9352 - precision: 0.9851 - recall: 0.8720 - f1_score: 0.9234 - val_loss: 1.9742 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9858 - acc: 0.9352 - precision: 0.9858 - recall: 0.8764 - f1_score: 0.9259 - val_loss: 1.9652 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9768 - acc: 0.9352 - precision: 0.9868 - recall: 0.8780 - f1_score: 0.9286 - val_loss: 1.9562 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9678 - acc: 0.9352 - precision: 0.9842 - recall: 0.8809 - f1_score: 0.9282 - val_loss: 1.9473 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9588 - acc: 0.9352 - precision: 0.9854 - recall: 0.8762 - f1_score: 0.9264 - val_loss: 1.9384 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9498 - acc: 0.9352 - precision: 0.9857 - recall: 0.8775 - f1_score: 0.9277 - val_loss: 1.9296 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9410 - acc: 0.9352 - precision: 0.9857 - recall: 0.8812 - f1_score: 0.9286 - val_loss: 1.9208 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9321 - acc: 0.9352 - precision: 0.9890 - recall: 0.8808 - f1_score: 0.9293 - val_loss: 1.9120 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9233 - acc: 0.9352 - precision: 0.9865 - recall: 0.8751 - f1_score: 0.9262 - val_loss: 1.9033 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9146 - acc: 0.9352 - precision: 0.9856 - recall: 0.8748 - f1_score: 0.9258 - val_loss: 1.8947 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9059 - acc: 0.9352 - precision: 0.9847 - recall: 0.8756 - f1_score: 0.9256 - val_loss: 1.8861 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8972 - acc: 0.9352 - precision: 0.9863 - recall: 0.8807 - f1_score: 0.9292 - val_loss: 1.8775 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8886 - acc: 0.9352 - precision: 0.9838 - recall: 0.8745 - f1_score: 0.9254 - val_loss: 1.8690 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8801 - acc: 0.9352 - precision: 0.9856 - recall: 0.8806 - f1_score: 0.9287 - val_loss: 1.8605 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8715 - acc: 0.9352 - precision: 0.9848 - recall: 0.8745 - f1_score: 0.9248 - val_loss: 1.8521 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8631 - acc: 0.9352 - precision: 0.9860 - recall: 0.8790 - f1_score: 0.9283 - val_loss: 1.8437 - val_acc: 0.9367 - val_precision: 0.9873 - val_recall: 0.9018 - val_f1_score: 0.9422\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.8546 - acc: 0.9352 - precision: 0.9851 - recall: 0.8763 - f1_score: 0.9261 - val_loss: 1.8353 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8462 - acc: 0.9352 - precision: 0.9857 - recall: 0.8759 - f1_score: 0.9265 - val_loss: 1.8270 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8379 - acc: 0.9352 - precision: 0.9851 - recall: 0.8750 - f1_score: 0.9259 - val_loss: 1.8188 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8296 - acc: 0.9352 - precision: 0.9856 - recall: 0.8783 - f1_score: 0.9273 - val_loss: 1.8105 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8213 - acc: 0.9352 - precision: 0.9852 - recall: 0.8786 - f1_score: 0.9276 - val_loss: 1.8024 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8131 - acc: 0.9352 - precision: 0.9842 - recall: 0.8799 - f1_score: 0.9285 - val_loss: 1.7942 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8049 - acc: 0.9352 - precision: 0.9846 - recall: 0.8790 - f1_score: 0.9283 - val_loss: 1.7861 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7968 - acc: 0.9352 - precision: 0.9854 - recall: 0.8709 - f1_score: 0.9220 - val_loss: 1.7781 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7887 - acc: 0.9352 - precision: 0.9852 - recall: 0.8794 - f1_score: 0.9274 - val_loss: 1.7701 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7807 - acc: 0.9352 - precision: 0.9816 - recall: 0.8745 - f1_score: 0.9235 - val_loss: 1.7621 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7727 - acc: 0.9352 - precision: 0.9856 - recall: 0.8787 - f1_score: 0.9270 - val_loss: 1.7542 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7647 - acc: 0.9352 - precision: 0.9848 - recall: 0.8815 - f1_score: 0.9296 - val_loss: 1.7463 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7568 - acc: 0.9352 - precision: 0.9875 - recall: 0.8795 - f1_score: 0.9287 - val_loss: 1.7385 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7489 - acc: 0.9352 - precision: 0.9846 - recall: 0.8792 - f1_score: 0.9282 - val_loss: 1.7307 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7411 - acc: 0.9352 - precision: 0.9807 - recall: 0.8735 - f1_score: 0.9231 - val_loss: 1.7229 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7333 - acc: 0.9352 - precision: 0.9849 - recall: 0.8802 - f1_score: 0.9280 - val_loss: 1.7152 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7255 - acc: 0.9352 - precision: 0.9840 - recall: 0.8781 - f1_score: 0.9265 - val_loss: 1.7075 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7178 - acc: 0.9352 - precision: 0.9858 - recall: 0.8846 - f1_score: 0.9309 - val_loss: 1.6999 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7101 - acc: 0.9368 - precision: 0.9870 - recall: 0.8801 - f1_score: 0.9279 - val_loss: 1.6923 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7025 - acc: 0.9368 - precision: 0.9837 - recall: 0.8854 - f1_score: 0.9305 - val_loss: 1.6847 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6948 - acc: 0.9368 - precision: 0.9858 - recall: 0.8833 - f1_score: 0.9302 - val_loss: 1.6772 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6873 - acc: 0.9368 - precision: 0.9847 - recall: 0.8797 - f1_score: 0.9283 - val_loss: 1.6697 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6798 - acc: 0.9368 - precision: 0.9840 - recall: 0.8795 - f1_score: 0.9280 - val_loss: 1.6622 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6723 - acc: 0.9368 - precision: 0.9845 - recall: 0.8802 - f1_score: 0.9283 - val_loss: 1.6548 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6648 - acc: 0.9368 - precision: 0.9868 - recall: 0.8778 - f1_score: 0.9263 - val_loss: 1.6475 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6574 - acc: 0.9368 - precision: 0.9849 - recall: 0.8823 - f1_score: 0.9301 - val_loss: 1.6401 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6501 - acc: 0.9368 - precision: 0.9852 - recall: 0.8802 - f1_score: 0.9289 - val_loss: 1.6329 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6427 - acc: 0.9368 - precision: 0.9833 - recall: 0.8776 - f1_score: 0.9265 - val_loss: 1.6256 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6354 - acc: 0.9368 - precision: 0.9829 - recall: 0.8802 - f1_score: 0.9277 - val_loss: 1.6184 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6282 - acc: 0.9368 - precision: 0.9857 - recall: 0.8835 - f1_score: 0.9298 - val_loss: 1.6112 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6210 - acc: 0.9368 - precision: 0.9852 - recall: 0.8866 - f1_score: 0.9314 - val_loss: 1.6041 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6138 - acc: 0.9368 - precision: 0.9834 - recall: 0.8866 - f1_score: 0.9298 - val_loss: 1.5970 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.6066 - acc: 0.9368 - precision: 0.9849 - recall: 0.8810 - f1_score: 0.9297 - val_loss: 1.5899 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5995 - acc: 0.9368 - precision: 0.9835 - recall: 0.8836 - f1_score: 0.9298 - val_loss: 1.5829 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5925 - acc: 0.9368 - precision: 0.9854 - recall: 0.8783 - f1_score: 0.9281 - val_loss: 1.5759 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5854 - acc: 0.9368 - precision: 0.9869 - recall: 0.8802 - f1_score: 0.9294 - val_loss: 1.5689 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5784 - acc: 0.9368 - precision: 0.9864 - recall: 0.8807 - f1_score: 0.9288 - val_loss: 1.5620 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5715 - acc: 0.9368 - precision: 0.9849 - recall: 0.8814 - f1_score: 0.9291 - val_loss: 1.5551 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5645 - acc: 0.9384 - precision: 0.9834 - recall: 0.8861 - f1_score: 0.9314 - val_loss: 1.5482 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5577 - acc: 0.9384 - precision: 0.9850 - recall: 0.8848 - f1_score: 0.9313 - val_loss: 1.5414 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5508 - acc: 0.9384 - precision: 0.9860 - recall: 0.8864 - f1_score: 0.9324 - val_loss: 1.5347 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5440 - acc: 0.9384 - precision: 0.9866 - recall: 0.8829 - f1_score: 0.9307 - val_loss: 1.5279 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5372 - acc: 0.9384 - precision: 0.9849 - recall: 0.8853 - f1_score: 0.9319 - val_loss: 1.5212 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5304 - acc: 0.9384 - precision: 0.9865 - recall: 0.8835 - f1_score: 0.9311 - val_loss: 1.5145 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5237 - acc: 0.9400 - precision: 0.9838 - recall: 0.8891 - f1_score: 0.9327 - val_loss: 1.5079 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5171 - acc: 0.9400 - precision: 0.9864 - recall: 0.8904 - f1_score: 0.9350 - val_loss: 1.5013 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5104 - acc: 0.9400 - precision: 0.9840 - recall: 0.8868 - f1_score: 0.9324 - val_loss: 1.4947 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5038 - acc: 0.9400 - precision: 0.9864 - recall: 0.8880 - f1_score: 0.9330 - val_loss: 1.4882 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4972 - acc: 0.9400 - precision: 0.9854 - recall: 0.8842 - f1_score: 0.9309 - val_loss: 1.4816 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4907 - acc: 0.9400 - precision: 0.9851 - recall: 0.8887 - f1_score: 0.9336 - val_loss: 1.4752 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4842 - acc: 0.9400 - precision: 0.9848 - recall: 0.8836 - f1_score: 0.9299 - val_loss: 1.4687 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4777 - acc: 0.9400 - precision: 0.9838 - recall: 0.8885 - f1_score: 0.9324 - val_loss: 1.4623 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4713 - acc: 0.9400 - precision: 0.9846 - recall: 0.8920 - f1_score: 0.9342 - val_loss: 1.4560 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4649 - acc: 0.9400 - precision: 0.9846 - recall: 0.8917 - f1_score: 0.9343 - val_loss: 1.4496 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4585 - acc: 0.9400 - precision: 0.9869 - recall: 0.8883 - f1_score: 0.9340 - val_loss: 1.4433 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4521 - acc: 0.9400 - precision: 0.9846 - recall: 0.8912 - f1_score: 0.9344 - val_loss: 1.4371 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4458 - acc: 0.9400 - precision: 0.9870 - recall: 0.8880 - f1_score: 0.9332 - val_loss: 1.4308 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4395 - acc: 0.9400 - precision: 0.9849 - recall: 0.8879 - f1_score: 0.9334 - val_loss: 1.4246 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4333 - acc: 0.9400 - precision: 0.9865 - recall: 0.8899 - f1_score: 0.9348 - val_loss: 1.4184 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4271 - acc: 0.9400 - precision: 0.9849 - recall: 0.8906 - f1_score: 0.9336 - val_loss: 1.4123 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4209 - acc: 0.9400 - precision: 0.9847 - recall: 0.8889 - f1_score: 0.9330 - val_loss: 1.4062 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4147 - acc: 0.9400 - precision: 0.9869 - recall: 0.8865 - f1_score: 0.9328 - val_loss: 1.4001 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4086 - acc: 0.9400 - precision: 0.9861 - recall: 0.8873 - f1_score: 0.9329 - val_loss: 1.3940 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4025 - acc: 0.9400 - precision: 0.9856 - recall: 0.8873 - f1_score: 0.9326 - val_loss: 1.3880 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3965 - acc: 0.9400 - precision: 0.9847 - recall: 0.8868 - f1_score: 0.9325 - val_loss: 1.3820 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3905 - acc: 0.9400 - precision: 0.9856 - recall: 0.8841 - f1_score: 0.9305 - val_loss: 1.3761 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3845 - acc: 0.9400 - precision: 0.9862 - recall: 0.8857 - f1_score: 0.9322 - val_loss: 1.3701 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3785 - acc: 0.9400 - precision: 0.9872 - recall: 0.8878 - f1_score: 0.9330 - val_loss: 1.3642 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3726 - acc: 0.9400 - precision: 0.9857 - recall: 0.8906 - f1_score: 0.9338 - val_loss: 1.3584 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3667 - acc: 0.9400 - precision: 0.9860 - recall: 0.8928 - f1_score: 0.9362 - val_loss: 1.3525 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3608 - acc: 0.9400 - precision: 0.9847 - recall: 0.8853 - f1_score: 0.9310 - val_loss: 1.3467 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3550 - acc: 0.9400 - precision: 0.9857 - recall: 0.8891 - f1_score: 0.9341 - val_loss: 1.3410 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3491 - acc: 0.9400 - precision: 0.9852 - recall: 0.8888 - f1_score: 0.9339 - val_loss: 1.3352 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3434 - acc: 0.9400 - precision: 0.9834 - recall: 0.8858 - f1_score: 0.9305 - val_loss: 1.3295 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3376 - acc: 0.9400 - precision: 0.9862 - recall: 0.8842 - f1_score: 0.9306 - val_loss: 1.3238 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3319 - acc: 0.9400 - precision: 0.9870 - recall: 0.8881 - f1_score: 0.9334 - val_loss: 1.3182 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3262 - acc: 0.9400 - precision: 0.9858 - recall: 0.8859 - f1_score: 0.9314 - val_loss: 1.3125 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.3451 - acc: 0.9200 - precision: 1.0000 - recall: 0.8571 - f1_score: 0.923 - 0s - loss: 1.3205 - acc: 0.9400 - precision: 0.9842 - recall: 0.8865 - f1_score: 0.9312 - val_loss: 1.3069 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3149 - acc: 0.9400 - precision: 0.9846 - recall: 0.8891 - f1_score: 0.9327 - val_loss: 1.3014 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3093 - acc: 0.9400 - precision: 0.9852 - recall: 0.8878 - f1_score: 0.9321 - val_loss: 1.2958 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3037 - acc: 0.9400 - precision: 0.9845 - recall: 0.8842 - f1_score: 0.9296 - val_loss: 1.2903 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2982 - acc: 0.9400 - precision: 0.9829 - recall: 0.8901 - f1_score: 0.9326 - val_loss: 1.2848 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2926 - acc: 0.9400 - precision: 0.9848 - recall: 0.8887 - f1_score: 0.9336 - val_loss: 1.2794 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2871 - acc: 0.9400 - precision: 0.9845 - recall: 0.8923 - f1_score: 0.9352 - val_loss: 1.2739 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2817 - acc: 0.9400 - precision: 0.9854 - recall: 0.8865 - f1_score: 0.9323 - val_loss: 1.2685 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2762 - acc: 0.9400 - precision: 0.9867 - recall: 0.8879 - f1_score: 0.9335 - val_loss: 1.2632 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2708 - acc: 0.9400 - precision: 0.9853 - recall: 0.8908 - f1_score: 0.9341 - val_loss: 1.2578 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2655 - acc: 0.9400 - precision: 0.9867 - recall: 0.8914 - f1_score: 0.9355 - val_loss: 1.2525 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2601 - acc: 0.9400 - precision: 0.9863 - recall: 0.8882 - f1_score: 0.9333 - val_loss: 1.2472 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2548 - acc: 0.9400 - precision: 0.9854 - recall: 0.8887 - f1_score: 0.9327 - val_loss: 1.2420 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2495 - acc: 0.9400 - precision: 0.9861 - recall: 0.8902 - f1_score: 0.9351 - val_loss: 1.2367 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2442 - acc: 0.9400 - precision: 0.9846 - recall: 0.8838 - f1_score: 0.9298 - val_loss: 1.2315 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2390 - acc: 0.9400 - precision: 0.9839 - recall: 0.8873 - f1_score: 0.9319 - val_loss: 1.2263 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2337 - acc: 0.9400 - precision: 0.9875 - recall: 0.8854 - f1_score: 0.9319 - val_loss: 1.2212 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2286 - acc: 0.9400 - precision: 0.9832 - recall: 0.8907 - f1_score: 0.9334 - val_loss: 1.2160 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2234 - acc: 0.9400 - precision: 0.9856 - recall: 0.8939 - f1_score: 0.9347 - val_loss: 1.2109 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2183 - acc: 0.9400 - precision: 0.9852 - recall: 0.8882 - f1_score: 0.9336 - val_loss: 1.2059 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2131 - acc: 0.9400 - precision: 0.9855 - recall: 0.8849 - f1_score: 0.9303 - val_loss: 1.2008 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2081 - acc: 0.9400 - precision: 0.9850 - recall: 0.8863 - f1_score: 0.9322 - val_loss: 1.1958 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2030 - acc: 0.9400 - precision: 0.9848 - recall: 0.8902 - f1_score: 0.9338 - val_loss: 1.1908 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1980 - acc: 0.9400 - precision: 0.9852 - recall: 0.8889 - f1_score: 0.9333 - val_loss: 1.1858 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1930 - acc: 0.9400 - precision: 0.9839 - recall: 0.8859 - f1_score: 0.9309 - val_loss: 1.1809 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1880 - acc: 0.9400 - precision: 0.9850 - recall: 0.8823 - f1_score: 0.9283 - val_loss: 1.1759 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1830 - acc: 0.9400 - precision: 0.9855 - recall: 0.8860 - f1_score: 0.9321 - val_loss: 1.1711 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1781 - acc: 0.9400 - precision: 0.9860 - recall: 0.8878 - f1_score: 0.9331 - val_loss: 1.1662 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1732 - acc: 0.9400 - precision: 0.9838 - recall: 0.8900 - f1_score: 0.9328 - val_loss: 1.1613 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1683 - acc: 0.9400 - precision: 0.9849 - recall: 0.8893 - f1_score: 0.9337 - val_loss: 1.1565 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1634 - acc: 0.9400 - precision: 0.9854 - recall: 0.8870 - f1_score: 0.9324 - val_loss: 1.1517 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1586 - acc: 0.9400 - precision: 0.9859 - recall: 0.8909 - f1_score: 0.9345 - val_loss: 1.1470 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1538 - acc: 0.9400 - precision: 0.9846 - recall: 0.8840 - f1_score: 0.9303 - val_loss: 1.1422 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1490 - acc: 0.9400 - precision: 0.9833 - recall: 0.8865 - f1_score: 0.9311 - val_loss: 1.1375 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1443 - acc: 0.9400 - precision: 0.9846 - recall: 0.8899 - f1_score: 0.9336 - val_loss: 1.1328 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1395 - acc: 0.9400 - precision: 0.9851 - recall: 0.8900 - f1_score: 0.9328 - val_loss: 1.1281 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1348 - acc: 0.9400 - precision: 0.9872 - recall: 0.8856 - f1_score: 0.9327 - val_loss: 1.1235 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1301 - acc: 0.9400 - precision: 0.9820 - recall: 0.8852 - f1_score: 0.9300 - val_loss: 1.1188 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1255 - acc: 0.9400 - precision: 0.9864 - recall: 0.8838 - f1_score: 0.9300 - val_loss: 1.1142 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1208 - acc: 0.9400 - precision: 0.9842 - recall: 0.8891 - f1_score: 0.9336 - val_loss: 1.1096 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1162 - acc: 0.9400 - precision: 0.9844 - recall: 0.8856 - f1_score: 0.9312 - val_loss: 1.1051 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1116 - acc: 0.9400 - precision: 0.9839 - recall: 0.8918 - f1_score: 0.9343 - val_loss: 1.1006 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1071 - acc: 0.9400 - precision: 0.9864 - recall: 0.8873 - f1_score: 0.9328 - val_loss: 1.0960 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1025 - acc: 0.9400 - precision: 0.9859 - recall: 0.8876 - f1_score: 0.9333 - val_loss: 1.0916 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0980 - acc: 0.9400 - precision: 0.9857 - recall: 0.8841 - f1_score: 0.9314 - val_loss: 1.0871 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0935 - acc: 0.9400 - precision: 0.9830 - recall: 0.8819 - f1_score: 0.9290 - val_loss: 1.0827 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0890 - acc: 0.9400 - precision: 0.9851 - recall: 0.8896 - f1_score: 0.9340 - val_loss: 1.0782 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0846 - acc: 0.9400 - precision: 0.9851 - recall: 0.8895 - f1_score: 0.9338 - val_loss: 1.0739 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0802 - acc: 0.9400 - precision: 0.9847 - recall: 0.8867 - f1_score: 0.9316 - val_loss: 1.0695 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0758 - acc: 0.9400 - precision: 0.9840 - recall: 0.8826 - f1_score: 0.9291 - val_loss: 1.0651 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0714 - acc: 0.9400 - precision: 0.9864 - recall: 0.8855 - f1_score: 0.9310 - val_loss: 1.0608 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0670 - acc: 0.9400 - precision: 0.9850 - recall: 0.8909 - f1_score: 0.9347 - val_loss: 1.0565 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0627 - acc: 0.9400 - precision: 0.9848 - recall: 0.8848 - f1_score: 0.9303 - val_loss: 1.0522 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0584 - acc: 0.9400 - precision: 0.9844 - recall: 0.8932 - f1_score: 0.9349 - val_loss: 1.0480 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0541 - acc: 0.9400 - precision: 0.9863 - recall: 0.8899 - f1_score: 0.9345 - val_loss: 1.0437 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0498 - acc: 0.9400 - precision: 0.9862 - recall: 0.8869 - f1_score: 0.9318 - val_loss: 1.0395 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0455 - acc: 0.9400 - precision: 0.9849 - recall: 0.8903 - f1_score: 0.9342 - val_loss: 1.0353 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0413 - acc: 0.9400 - precision: 0.9873 - recall: 0.8864 - f1_score: 0.9327 - val_loss: 1.0311 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0371 - acc: 0.9400 - precision: 0.9872 - recall: 0.8851 - f1_score: 0.9321 - val_loss: 1.0270 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0329 - acc: 0.9400 - precision: 0.9833 - recall: 0.8900 - f1_score: 0.9335 - val_loss: 1.0229 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0287 - acc: 0.9400 - precision: 0.9844 - recall: 0.8871 - f1_score: 0.9323 - val_loss: 1.0188 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0246 - acc: 0.9400 - precision: 0.9862 - recall: 0.8929 - f1_score: 0.9354 - val_loss: 1.0147 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0205 - acc: 0.9400 - precision: 0.9861 - recall: 0.8873 - f1_score: 0.9325 - val_loss: 1.0106 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0164 - acc: 0.9400 - precision: 0.9869 - recall: 0.8828 - f1_score: 0.9304 - val_loss: 1.0065 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0123 - acc: 0.9400 - precision: 0.9846 - recall: 0.8884 - f1_score: 0.9337 - val_loss: 1.0025 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0082 - acc: 0.9400 - precision: 0.9860 - recall: 0.8835 - f1_score: 0.9309 - val_loss: 0.9985 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0042 - acc: 0.9400 - precision: 0.9853 - recall: 0.8876 - f1_score: 0.9333 - val_loss: 0.9945 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0002 - acc: 0.9400 - precision: 0.9862 - recall: 0.8905 - f1_score: 0.9351 - val_loss: 0.9906 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9962 - acc: 0.9400 - precision: 0.9856 - recall: 0.8832 - f1_score: 0.9295 - val_loss: 0.9866 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9922 - acc: 0.9400 - precision: 0.9844 - recall: 0.8874 - f1_score: 0.9318 - val_loss: 0.9827 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9882 - acc: 0.9400 - precision: 0.9834 - recall: 0.8872 - f1_score: 0.9316 - val_loss: 0.9788 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9843 - acc: 0.9400 - precision: 0.9856 - recall: 0.8905 - f1_score: 0.9344 - val_loss: 0.9749 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9804 - acc: 0.9400 - precision: 0.9834 - recall: 0.8873 - f1_score: 0.9318 - val_loss: 0.9710 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9765 - acc: 0.9400 - precision: 0.9851 - recall: 0.8880 - f1_score: 0.9313 - val_loss: 0.9672 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9726 - acc: 0.9400 - precision: 0.9852 - recall: 0.8902 - f1_score: 0.9340 - val_loss: 0.9634 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9688 - acc: 0.9400 - precision: 0.9848 - recall: 0.8905 - f1_score: 0.9334 - val_loss: 0.9596 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9649 - acc: 0.9400 - precision: 0.9873 - recall: 0.8905 - f1_score: 0.9352 - val_loss: 0.9558 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9611 - acc: 0.9400 - precision: 0.9873 - recall: 0.8863 - f1_score: 0.9328 - val_loss: 0.9520 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9573 - acc: 0.9400 - precision: 0.9833 - recall: 0.8884 - f1_score: 0.9320 - val_loss: 0.9483 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9535 - acc: 0.9400 - precision: 0.9848 - recall: 0.8841 - f1_score: 0.9298 - val_loss: 0.9445 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9497 - acc: 0.9400 - precision: 0.9852 - recall: 0.8885 - f1_score: 0.9320 - val_loss: 0.9408 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9460 - acc: 0.9400 - precision: 0.9828 - recall: 0.8865 - f1_score: 0.9299 - val_loss: 0.9371 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9423 - acc: 0.9400 - precision: 0.9827 - recall: 0.8838 - f1_score: 0.9296 - val_loss: 0.9335 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 399/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9386 - acc: 0.9400 - precision: 0.9838 - recall: 0.8833 - f1_score: 0.9296 - val_loss: 0.9298 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9349 - acc: 0.9400 - precision: 0.9848 - recall: 0.8884 - f1_score: 0.9336 - val_loss: 0.9262 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9312 - acc: 0.9400 - precision: 0.9837 - recall: 0.8892 - f1_score: 0.9333 - val_loss: 0.9226 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9276 - acc: 0.9400 - precision: 0.9858 - recall: 0.8858 - f1_score: 0.9320 - val_loss: 0.9190 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9240 - acc: 0.9400 - precision: 0.9851 - recall: 0.8886 - f1_score: 0.9337 - val_loss: 0.9154 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9203 - acc: 0.9400 - precision: 0.9853 - recall: 0.8876 - f1_score: 0.9327 - val_loss: 0.9118 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9167 - acc: 0.9400 - precision: 0.9850 - recall: 0.8880 - f1_score: 0.9316 - val_loss: 0.9083 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9132 - acc: 0.9400 - precision: 0.9864 - recall: 0.8951 - f1_score: 0.9357 - val_loss: 0.9048 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9096 - acc: 0.9400 - precision: 0.9861 - recall: 0.8907 - f1_score: 0.9339 - val_loss: 0.9013 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9061 - acc: 0.9400 - precision: 0.9859 - recall: 0.8893 - f1_score: 0.9338 - val_loss: 0.8978 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9026 - acc: 0.9400 - precision: 0.9848 - recall: 0.8895 - f1_score: 0.9336 - val_loss: 0.8943 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8991 - acc: 0.9400 - precision: 0.9861 - recall: 0.8886 - f1_score: 0.9341 - val_loss: 0.8909 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8956 - acc: 0.9400 - precision: 0.9837 - recall: 0.8919 - f1_score: 0.9333 - val_loss: 0.8874 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8921 - acc: 0.9400 - precision: 0.9849 - recall: 0.8853 - f1_score: 0.9310 - val_loss: 0.8840 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8886 - acc: 0.9400 - precision: 0.9848 - recall: 0.8862 - f1_score: 0.9317 - val_loss: 0.8806 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8852 - acc: 0.9400 - precision: 0.9852 - recall: 0.8856 - f1_score: 0.9308 - val_loss: 0.8773 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8818 - acc: 0.9400 - precision: 0.9874 - recall: 0.8817 - f1_score: 0.9295 - val_loss: 0.8739 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8784 - acc: 0.9400 - precision: 0.9859 - recall: 0.8863 - f1_score: 0.9321 - val_loss: 0.8705 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8750 - acc: 0.9400 - precision: 0.9858 - recall: 0.8889 - f1_score: 0.9345 - val_loss: 0.8672 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8717 - acc: 0.9400 - precision: 0.9842 - recall: 0.8867 - f1_score: 0.9321 - val_loss: 0.8639 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8683 - acc: 0.9400 - precision: 0.9836 - recall: 0.8913 - f1_score: 0.9339 - val_loss: 0.8606 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8650 - acc: 0.9400 - precision: 0.9844 - recall: 0.8851 - f1_score: 0.9308 - val_loss: 0.8573 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8617 - acc: 0.9400 - precision: 0.9849 - recall: 0.8850 - f1_score: 0.9312 - val_loss: 0.8541 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8584 - acc: 0.9400 - precision: 0.9850 - recall: 0.8893 - f1_score: 0.9334 - val_loss: 0.8508 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8551 - acc: 0.9400 - precision: 0.9825 - recall: 0.8890 - f1_score: 0.9324 - val_loss: 0.8476 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8518 - acc: 0.9400 - precision: 0.9865 - recall: 0.8865 - f1_score: 0.9322 - val_loss: 0.8444 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8486 - acc: 0.9415 - precision: 0.9879 - recall: 0.8827 - f1_score: 0.9306 - val_loss: 0.8412 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8454 - acc: 0.9415 - precision: 0.9900 - recall: 0.8840 - f1_score: 0.9311 - val_loss: 0.8380 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8421 - acc: 0.9400 - precision: 0.9865 - recall: 0.8864 - f1_score: 0.9319 - val_loss: 0.8348 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8389 - acc: 0.9400 - precision: 0.9858 - recall: 0.8869 - f1_score: 0.9322 - val_loss: 0.8317 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8358 - acc: 0.9415 - precision: 0.9879 - recall: 0.8864 - f1_score: 0.9334 - val_loss: 0.8286 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8326 - acc: 0.9415 - precision: 0.9893 - recall: 0.8876 - f1_score: 0.9349 - val_loss: 0.8254 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 431/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8294 - acc: 0.9415 - precision: 0.9892 - recall: 0.8859 - f1_score: 0.9340 - val_loss: 0.8223 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8263 - acc: 0.9415 - precision: 0.9897 - recall: 0.8861 - f1_score: 0.9332 - val_loss: 0.8193 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8232 - acc: 0.9415 - precision: 0.9889 - recall: 0.8837 - f1_score: 0.9316 - val_loss: 0.8162 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8201 - acc: 0.9415 - precision: 0.9883 - recall: 0.8889 - f1_score: 0.9351 - val_loss: 0.8131 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8170 - acc: 0.9415 - precision: 0.9902 - recall: 0.8932 - f1_score: 0.9375 - val_loss: 0.8101 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8139 - acc: 0.9415 - precision: 0.9894 - recall: 0.8878 - f1_score: 0.9346 - val_loss: 0.8071 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8109 - acc: 0.9415 - precision: 0.9890 - recall: 0.8835 - f1_score: 0.9319 - val_loss: 0.8041 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8078 - acc: 0.9415 - precision: 0.9886 - recall: 0.8843 - f1_score: 0.9326 - val_loss: 0.8011 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8048 - acc: 0.9415 - precision: 0.9859 - recall: 0.8863 - f1_score: 0.9322 - val_loss: 0.7981 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8018 - acc: 0.9415 - precision: 0.9883 - recall: 0.8880 - f1_score: 0.9340 - val_loss: 0.7952 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7988 - acc: 0.9415 - precision: 0.9886 - recall: 0.8863 - f1_score: 0.9341 - val_loss: 0.7922 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7958 - acc: 0.9415 - precision: 0.9887 - recall: 0.8858 - f1_score: 0.9336 - val_loss: 0.7893 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7929 - acc: 0.9415 - precision: 0.9872 - recall: 0.8892 - f1_score: 0.9338 - val_loss: 0.7864 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7899 - acc: 0.9415 - precision: 0.9892 - recall: 0.8879 - f1_score: 0.9352 - val_loss: 0.7835 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7870 - acc: 0.9415 - precision: 0.9882 - recall: 0.8899 - f1_score: 0.9354 - val_loss: 0.7806 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7841 - acc: 0.9415 - precision: 0.9908 - recall: 0.8890 - f1_score: 0.9365 - val_loss: 0.7777 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7811 - acc: 0.9415 - precision: 0.9893 - recall: 0.8893 - f1_score: 0.9357 - val_loss: 0.7749 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7783 - acc: 0.9415 - precision: 0.9899 - recall: 0.8874 - f1_score: 0.9347 - val_loss: 0.7720 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7754 - acc: 0.9415 - precision: 0.9896 - recall: 0.8890 - f1_score: 0.9356 - val_loss: 0.7692 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7725 - acc: 0.9415 - precision: 0.9903 - recall: 0.8867 - f1_score: 0.9347 - val_loss: 0.7664 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7697 - acc: 0.9415 - precision: 0.9885 - recall: 0.8870 - f1_score: 0.9342 - val_loss: 0.7636 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7668 - acc: 0.9415 - precision: 0.9887 - recall: 0.8860 - f1_score: 0.9337 - val_loss: 0.7608 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7640 - acc: 0.9415 - precision: 0.9908 - recall: 0.8891 - f1_score: 0.9364 - val_loss: 0.7581 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7612 - acc: 0.9415 - precision: 0.9882 - recall: 0.8928 - f1_score: 0.9361 - val_loss: 0.7553 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7584 - acc: 0.9415 - precision: 0.9886 - recall: 0.8884 - f1_score: 0.9344 - val_loss: 0.7526 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7556 - acc: 0.9415 - precision: 0.9886 - recall: 0.8874 - f1_score: 0.9343 - val_loss: 0.7498 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7529 - acc: 0.9415 - precision: 0.9900 - recall: 0.8886 - f1_score: 0.9356 - val_loss: 0.7471 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7501 - acc: 0.9415 - precision: 0.9879 - recall: 0.8863 - f1_score: 0.9330 - val_loss: 0.7444 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7474 - acc: 0.9415 - precision: 0.9889 - recall: 0.8856 - f1_score: 0.9337 - val_loss: 0.7417 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7447 - acc: 0.9415 - precision: 0.9875 - recall: 0.8874 - f1_score: 0.9339 - val_loss: 0.7391 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7420 - acc: 0.9415 - precision: 0.9876 - recall: 0.8862 - f1_score: 0.9318 - val_loss: 0.7364 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7393 - acc: 0.9415 - precision: 0.9897 - recall: 0.8836 - f1_score: 0.9316 - val_loss: 0.7338 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 463/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7366 - acc: 0.9415 - precision: 0.9875 - recall: 0.8885 - f1_score: 0.9342 - val_loss: 0.7311 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7339 - acc: 0.9415 - precision: 0.9910 - recall: 0.8832 - f1_score: 0.9332 - val_loss: 0.7285 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7313 - acc: 0.9415 - precision: 0.9889 - recall: 0.8893 - f1_score: 0.9352 - val_loss: 0.7259 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7286 - acc: 0.9415 - precision: 0.9872 - recall: 0.8870 - f1_score: 0.9333 - val_loss: 0.7233 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7260 - acc: 0.9415 - precision: 0.9881 - recall: 0.8870 - f1_score: 0.9333 - val_loss: 0.7207 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7234 - acc: 0.9415 - precision: 0.9898 - recall: 0.8841 - f1_score: 0.9330 - val_loss: 0.7182 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7208 - acc: 0.9415 - precision: 0.9888 - recall: 0.8890 - f1_score: 0.9340 - val_loss: 0.7156 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7182 - acc: 0.9415 - precision: 0.9890 - recall: 0.8854 - f1_score: 0.9324 - val_loss: 0.7131 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7156 - acc: 0.9415 - precision: 0.9884 - recall: 0.8888 - f1_score: 0.9350 - val_loss: 0.7106 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7131 - acc: 0.9415 - precision: 0.9903 - recall: 0.8880 - f1_score: 0.9354 - val_loss: 0.7080 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7105 - acc: 0.9415 - precision: 0.9890 - recall: 0.8887 - f1_score: 0.9358 - val_loss: 0.7055 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7080 - acc: 0.9415 - precision: 0.9895 - recall: 0.8896 - f1_score: 0.9362 - val_loss: 0.7031 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7055 - acc: 0.9415 - precision: 0.9897 - recall: 0.8853 - f1_score: 0.9333 - val_loss: 0.7006 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7030 - acc: 0.9415 - precision: 0.9887 - recall: 0.8919 - f1_score: 0.9364 - val_loss: 0.6981 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7005 - acc: 0.9415 - precision: 0.9892 - recall: 0.8891 - f1_score: 0.9356 - val_loss: 0.6957 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6980 - acc: 0.9415 - precision: 0.9870 - recall: 0.8863 - f1_score: 0.9317 - val_loss: 0.6932 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6955 - acc: 0.9415 - precision: 0.9889 - recall: 0.8879 - f1_score: 0.9346 - val_loss: 0.6908 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6930 - acc: 0.9415 - precision: 0.9886 - recall: 0.8879 - f1_score: 0.9346 - val_loss: 0.6884 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6906 - acc: 0.9415 - precision: 0.9877 - recall: 0.8861 - f1_score: 0.9336 - val_loss: 0.6860 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6882 - acc: 0.9415 - precision: 0.9874 - recall: 0.8841 - f1_score: 0.9325 - val_loss: 0.6836 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6857 - acc: 0.9415 - precision: 0.9879 - recall: 0.8884 - f1_score: 0.9349 - val_loss: 0.6812 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6833 - acc: 0.9431 - precision: 0.9890 - recall: 0.8894 - f1_score: 0.9353 - val_loss: 0.6789 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6809 - acc: 0.9431 - precision: 0.9894 - recall: 0.8928 - f1_score: 0.9371 - val_loss: 0.6765 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6785 - acc: 0.9431 - precision: 0.9895 - recall: 0.8946 - f1_score: 0.9385 - val_loss: 0.6742 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6762 - acc: 0.9431 - precision: 0.9888 - recall: 0.8947 - f1_score: 0.9381 - val_loss: 0.6718 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6738 - acc: 0.9431 - precision: 0.9899 - recall: 0.8892 - f1_score: 0.9354 - val_loss: 0.6695 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6714 - acc: 0.9431 - precision: 0.9909 - recall: 0.8921 - f1_score: 0.9376 - val_loss: 0.6672 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6691 - acc: 0.9431 - precision: 0.9890 - recall: 0.8889 - f1_score: 0.9346 - val_loss: 0.6649 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6668 - acc: 0.9431 - precision: 0.9900 - recall: 0.8858 - f1_score: 0.9323 - val_loss: 0.6627 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6644 - acc: 0.9431 - precision: 0.9860 - recall: 0.8862 - f1_score: 0.9324 - val_loss: 0.6604 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6621 - acc: 0.9431 - precision: 0.9908 - recall: 0.8895 - f1_score: 0.9357 - val_loss: 0.6581 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6598 - acc: 0.9431 - precision: 0.9895 - recall: 0.8937 - f1_score: 0.9379 - val_loss: 0.6559 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 495/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6576 - acc: 0.9431 - precision: 0.9885 - recall: 0.8926 - f1_score: 0.9371 - val_loss: 0.6537 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6553 - acc: 0.9431 - precision: 0.9898 - recall: 0.8921 - f1_score: 0.9369 - val_loss: 0.6514 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6530 - acc: 0.9431 - precision: 0.9872 - recall: 0.8909 - f1_score: 0.9348 - val_loss: 0.6492 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6508 - acc: 0.9431 - precision: 0.9884 - recall: 0.8901 - f1_score: 0.9359 - val_loss: 0.6470 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6485 - acc: 0.9431 - precision: 0.9902 - recall: 0.8868 - f1_score: 0.9336 - val_loss: 0.6448 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6463 - acc: 0.9431 - precision: 0.9900 - recall: 0.8948 - f1_score: 0.9385 - val_loss: 0.6426 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6441 - acc: 0.9431 - precision: 0.9900 - recall: 0.8922 - f1_score: 0.9373 - val_loss: 0.6405 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6419 - acc: 0.9431 - precision: 0.9898 - recall: 0.8973 - f1_score: 0.9398 - val_loss: 0.6383 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6397 - acc: 0.9431 - precision: 0.9895 - recall: 0.8828 - f1_score: 0.9302 - val_loss: 0.6362 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6375 - acc: 0.9431 - precision: 0.9885 - recall: 0.8945 - f1_score: 0.9382 - val_loss: 0.6341 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6354 - acc: 0.9431 - precision: 0.9889 - recall: 0.8947 - f1_score: 0.9382 - val_loss: 0.6319 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6332 - acc: 0.9431 - precision: 0.9896 - recall: 0.8915 - f1_score: 0.9370 - val_loss: 0.6298 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6310 - acc: 0.9431 - precision: 0.9892 - recall: 0.8921 - f1_score: 0.9375 - val_loss: 0.6277 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6289 - acc: 0.9431 - precision: 0.9895 - recall: 0.8918 - f1_score: 0.9366 - val_loss: 0.6256 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6268 - acc: 0.9431 - precision: 0.9891 - recall: 0.8960 - f1_score: 0.9391 - val_loss: 0.6236 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6247 - acc: 0.9431 - precision: 0.9899 - recall: 0.8904 - f1_score: 0.9361 - val_loss: 0.6215 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6226 - acc: 0.9431 - precision: 0.9878 - recall: 0.8925 - f1_score: 0.9366 - val_loss: 0.6194 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6205 - acc: 0.9431 - precision: 0.9900 - recall: 0.8946 - f1_score: 0.9377 - val_loss: 0.6174 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6184 - acc: 0.9431 - precision: 0.9882 - recall: 0.8901 - f1_score: 0.9360 - val_loss: 0.6153 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6163 - acc: 0.9431 - precision: 0.9908 - recall: 0.8880 - f1_score: 0.9358 - val_loss: 0.6133 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6142 - acc: 0.9431 - precision: 0.9900 - recall: 0.8916 - f1_score: 0.9368 - val_loss: 0.6113 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6122 - acc: 0.9431 - precision: 0.9899 - recall: 0.8866 - f1_score: 0.9337 - val_loss: 0.6093 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6101 - acc: 0.9431 - precision: 0.9895 - recall: 0.8909 - f1_score: 0.9363 - val_loss: 0.6073 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6081 - acc: 0.9431 - precision: 0.9886 - recall: 0.8912 - f1_score: 0.9357 - val_loss: 0.6053 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6061 - acc: 0.9431 - precision: 0.9887 - recall: 0.8961 - f1_score: 0.9389 - val_loss: 0.6033 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6041 - acc: 0.9431 - precision: 0.9887 - recall: 0.8915 - f1_score: 0.9363 - val_loss: 0.6013 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6021 - acc: 0.9431 - precision: 0.9874 - recall: 0.8883 - f1_score: 0.9332 - val_loss: 0.5994 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6001 - acc: 0.9431 - precision: 0.9899 - recall: 0.8899 - f1_score: 0.9359 - val_loss: 0.5974 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5981 - acc: 0.9431 - precision: 0.9895 - recall: 0.8904 - f1_score: 0.9355 - val_loss: 0.5955 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.5928 - acc: 0.9455 - precision: 0.9870 - recall: 0.8943 - f1_score: 0.937 - 0s - loss: 0.5961 - acc: 0.9431 - precision: 0.9887 - recall: 0.8915 - f1_score: 0.9370 - val_loss: 0.5936 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5941 - acc: 0.9431 - precision: 0.9887 - recall: 0.8936 - f1_score: 0.9382 - val_loss: 0.5916 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5922 - acc: 0.9431 - precision: 0.9893 - recall: 0.8885 - f1_score: 0.9358 - val_loss: 0.5897 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 527/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5902 - acc: 0.9431 - precision: 0.9887 - recall: 0.8948 - f1_score: 0.9384 - val_loss: 0.5878 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5883 - acc: 0.9431 - precision: 0.9892 - recall: 0.8871 - f1_score: 0.9340 - val_loss: 0.5859 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5864 - acc: 0.9431 - precision: 0.9886 - recall: 0.8877 - f1_score: 0.9338 - val_loss: 0.5841 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5845 - acc: 0.9431 - precision: 0.9897 - recall: 0.8923 - f1_score: 0.9365 - val_loss: 0.5822 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5825 - acc: 0.9431 - precision: 0.9897 - recall: 0.8928 - f1_score: 0.9378 - val_loss: 0.5803 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5806 - acc: 0.9431 - precision: 0.9900 - recall: 0.8896 - f1_score: 0.9358 - val_loss: 0.5785 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5788 - acc: 0.9431 - precision: 0.9905 - recall: 0.8922 - f1_score: 0.9373 - val_loss: 0.5766 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5769 - acc: 0.9431 - precision: 0.9894 - recall: 0.8921 - f1_score: 0.9370 - val_loss: 0.5748 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5750 - acc: 0.9431 - precision: 0.9899 - recall: 0.8944 - f1_score: 0.9387 - val_loss: 0.5730 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5731 - acc: 0.9431 - precision: 0.9894 - recall: 0.8876 - f1_score: 0.9343 - val_loss: 0.5711 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5713 - acc: 0.9431 - precision: 0.9879 - recall: 0.8888 - f1_score: 0.9350 - val_loss: 0.5693 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5695 - acc: 0.9431 - precision: 0.9891 - recall: 0.8973 - f1_score: 0.9385 - val_loss: 0.5675 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5676 - acc: 0.9431 - precision: 0.9879 - recall: 0.8899 - f1_score: 0.9359 - val_loss: 0.5657 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5658 - acc: 0.9431 - precision: 0.9888 - recall: 0.8937 - f1_score: 0.9379 - val_loss: 0.5640 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5640 - acc: 0.9431 - precision: 0.9883 - recall: 0.8917 - f1_score: 0.9369 - val_loss: 0.5622 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5622 - acc: 0.9431 - precision: 0.9898 - recall: 0.8904 - f1_score: 0.9356 - val_loss: 0.5604 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5604 - acc: 0.9431 - precision: 0.9891 - recall: 0.8923 - f1_score: 0.9371 - val_loss: 0.5587 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5586 - acc: 0.9431 - precision: 0.9884 - recall: 0.8914 - f1_score: 0.9364 - val_loss: 0.5569 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5568 - acc: 0.9431 - precision: 0.9897 - recall: 0.8944 - f1_score: 0.9381 - val_loss: 0.5552 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5550 - acc: 0.9431 - precision: 0.9903 - recall: 0.8882 - f1_score: 0.9351 - val_loss: 0.5535 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5533 - acc: 0.9431 - precision: 0.9898 - recall: 0.8931 - f1_score: 0.9379 - val_loss: 0.5518 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5515 - acc: 0.9431 - precision: 0.9894 - recall: 0.8890 - f1_score: 0.9333 - val_loss: 0.5500 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5498 - acc: 0.9431 - precision: 0.9895 - recall: 0.8895 - f1_score: 0.9348 - val_loss: 0.5484 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5480 - acc: 0.9431 - precision: 0.9897 - recall: 0.8898 - f1_score: 0.9362 - val_loss: 0.5467 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5463 - acc: 0.9431 - precision: 0.9905 - recall: 0.8894 - f1_score: 0.9353 - val_loss: 0.5450 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5446 - acc: 0.9431 - precision: 0.9893 - recall: 0.8912 - f1_score: 0.9361 - val_loss: 0.5433 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5429 - acc: 0.9431 - precision: 0.9893 - recall: 0.8930 - f1_score: 0.9367 - val_loss: 0.5416 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5412 - acc: 0.9431 - precision: 0.9901 - recall: 0.8981 - f1_score: 0.9398 - val_loss: 0.5400 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5395 - acc: 0.9431 - precision: 0.9873 - recall: 0.8922 - f1_score: 0.9358 - val_loss: 0.5383 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5378 - acc: 0.9431 - precision: 0.9894 - recall: 0.8920 - f1_score: 0.9371 - val_loss: 0.5367 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5361 - acc: 0.9431 - precision: 0.9875 - recall: 0.8901 - f1_score: 0.9352 - val_loss: 0.5350 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5345 - acc: 0.9431 - precision: 0.9901 - recall: 0.8910 - f1_score: 0.9371 - val_loss: 0.5334 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5328 - acc: 0.9431 - precision: 0.9898 - recall: 0.8907 - f1_score: 0.9362 - val_loss: 0.5318 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5311 - acc: 0.9431 - precision: 0.9899 - recall: 0.8920 - f1_score: 0.9373 - val_loss: 0.5302 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5295 - acc: 0.9431 - precision: 0.9868 - recall: 0.8904 - f1_score: 0.9346 - val_loss: 0.5286 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5279 - acc: 0.9431 - precision: 0.9882 - recall: 0.8888 - f1_score: 0.9344 - val_loss: 0.5270 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5262 - acc: 0.9431 - precision: 0.9875 - recall: 0.8895 - f1_score: 0.9353 - val_loss: 0.5254 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5246 - acc: 0.9431 - precision: 0.9873 - recall: 0.8916 - f1_score: 0.9361 - val_loss: 0.5238 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5230 - acc: 0.9431 - precision: 0.9892 - recall: 0.8911 - f1_score: 0.9367 - val_loss: 0.5223 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5214 - acc: 0.9431 - precision: 0.9906 - recall: 0.8902 - f1_score: 0.9359 - val_loss: 0.5207 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5198 - acc: 0.9431 - precision: 0.9894 - recall: 0.8897 - f1_score: 0.9353 - val_loss: 0.5191 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5182 - acc: 0.9431 - precision: 0.9886 - recall: 0.8901 - f1_score: 0.9355 - val_loss: 0.5176 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5166 - acc: 0.9431 - precision: 0.9883 - recall: 0.8942 - f1_score: 0.9379 - val_loss: 0.5161 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5151 - acc: 0.9431 - precision: 0.9900 - recall: 0.8905 - f1_score: 0.9363 - val_loss: 0.5145 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5135 - acc: 0.9431 - precision: 0.9895 - recall: 0.8922 - f1_score: 0.9372 - val_loss: 0.5130 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5119 - acc: 0.9431 - precision: 0.9866 - recall: 0.8889 - f1_score: 0.9346 - val_loss: 0.5115 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5104 - acc: 0.9431 - precision: 0.9909 - recall: 0.8915 - f1_score: 0.9373 - val_loss: 0.5100 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5089 - acc: 0.9431 - precision: 0.9890 - recall: 0.8898 - f1_score: 0.9361 - val_loss: 0.5085 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5073 - acc: 0.9431 - precision: 0.9906 - recall: 0.8819 - f1_score: 0.9305 - val_loss: 0.5070 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5058 - acc: 0.9431 - precision: 0.9888 - recall: 0.8907 - f1_score: 0.9359 - val_loss: 0.5055 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5043 - acc: 0.9431 - precision: 0.9886 - recall: 0.8891 - f1_score: 0.9353 - val_loss: 0.5040 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5028 - acc: 0.9431 - precision: 0.9861 - recall: 0.8848 - f1_score: 0.9315 - val_loss: 0.5026 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5013 - acc: 0.9431 - precision: 0.9869 - recall: 0.8887 - f1_score: 0.9346 - val_loss: 0.5011 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4998 - acc: 0.9431 - precision: 0.9884 - recall: 0.8891 - f1_score: 0.9345 - val_loss: 0.4996 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4983 - acc: 0.9431 - precision: 0.9881 - recall: 0.8887 - f1_score: 0.9347 - val_loss: 0.4982 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4968 - acc: 0.9431 - precision: 0.9880 - recall: 0.8910 - f1_score: 0.9352 - val_loss: 0.4967 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4953 - acc: 0.9431 - precision: 0.9881 - recall: 0.8899 - f1_score: 0.9356 - val_loss: 0.4953 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4938 - acc: 0.9431 - precision: 0.9884 - recall: 0.8897 - f1_score: 0.9351 - val_loss: 0.4939 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4924 - acc: 0.9431 - precision: 0.9897 - recall: 0.8915 - f1_score: 0.9371 - val_loss: 0.4925 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4909 - acc: 0.9431 - precision: 0.9901 - recall: 0.8902 - f1_score: 0.9371 - val_loss: 0.4911 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4895 - acc: 0.9431 - precision: 0.9886 - recall: 0.8948 - f1_score: 0.9387 - val_loss: 0.4896 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4880 - acc: 0.9431 - precision: 0.9878 - recall: 0.8889 - f1_score: 0.9343 - val_loss: 0.4883 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4866 - acc: 0.9431 - precision: 0.9881 - recall: 0.8834 - f1_score: 0.9281 - val_loss: 0.4869 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4852 - acc: 0.9431 - precision: 0.9892 - recall: 0.8945 - f1_score: 0.9377 - val_loss: 0.4855 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4838 - acc: 0.9431 - precision: 0.9882 - recall: 0.8930 - f1_score: 0.9373 - val_loss: 0.4841 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4823 - acc: 0.9431 - precision: 0.9899 - recall: 0.8923 - f1_score: 0.9370 - val_loss: 0.4827 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4809 - acc: 0.9431 - precision: 0.9897 - recall: 0.8897 - f1_score: 0.9360 - val_loss: 0.4814 - val_acc: 0.9430 - val_precision: 0.9878 - val_recall: 0.9131 - val_f1_score: 0.9486\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4795 - acc: 0.9431 - precision: 0.9891 - recall: 0.8931 - f1_score: 0.9376 - val_loss: 0.4800 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4782 - acc: 0.9431 - precision: 0.9888 - recall: 0.8878 - f1_score: 0.9335 - val_loss: 0.4786 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4768 - acc: 0.9431 - precision: 0.9879 - recall: 0.8916 - f1_score: 0.9361 - val_loss: 0.4773 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4754 - acc: 0.9431 - precision: 0.9898 - recall: 0.8902 - f1_score: 0.9363 - val_loss: 0.4760 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4740 - acc: 0.9431 - precision: 0.9884 - recall: 0.8914 - f1_score: 0.9362 - val_loss: 0.4746 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4727 - acc: 0.9431 - precision: 0.9902 - recall: 0.8911 - f1_score: 0.9368 - val_loss: 0.4733 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4713 - acc: 0.9431 - precision: 0.9892 - recall: 0.8905 - f1_score: 0.9356 - val_loss: 0.4720 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4699 - acc: 0.9431 - precision: 0.9881 - recall: 0.8920 - f1_score: 0.9365 - val_loss: 0.4707 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4686 - acc: 0.9431 - precision: 0.9887 - recall: 0.8904 - f1_score: 0.9350 - val_loss: 0.4694 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4673 - acc: 0.9431 - precision: 0.9902 - recall: 0.8907 - f1_score: 0.9366 - val_loss: 0.4681 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4659 - acc: 0.9431 - precision: 0.9906 - recall: 0.8889 - f1_score: 0.9357 - val_loss: 0.4668 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4646 - acc: 0.9431 - precision: 0.9895 - recall: 0.8885 - f1_score: 0.9354 - val_loss: 0.4655 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4633 - acc: 0.9431 - precision: 0.9887 - recall: 0.8914 - f1_score: 0.9368 - val_loss: 0.4642 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4620 - acc: 0.9431 - precision: 0.9883 - recall: 0.8878 - f1_score: 0.9342 - val_loss: 0.4629 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4607 - acc: 0.9431 - precision: 0.9883 - recall: 0.8908 - f1_score: 0.9360 - val_loss: 0.4617 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4594 - acc: 0.9431 - precision: 0.9894 - recall: 0.8897 - f1_score: 0.9346 - val_loss: 0.4604 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4581 - acc: 0.9431 - precision: 0.9900 - recall: 0.8924 - f1_score: 0.9379 - val_loss: 0.4592 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4568 - acc: 0.9431 - precision: 0.9888 - recall: 0.8908 - f1_score: 0.9362 - val_loss: 0.4579 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4555 - acc: 0.9431 - precision: 0.9870 - recall: 0.8863 - f1_score: 0.9333 - val_loss: 0.4567 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4542 - acc: 0.9431 - precision: 0.9885 - recall: 0.8922 - f1_score: 0.9353 - val_loss: 0.4554 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4530 - acc: 0.9431 - precision: 0.9900 - recall: 0.8913 - f1_score: 0.9367 - val_loss: 0.4542 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4517 - acc: 0.9431 - precision: 0.9890 - recall: 0.8911 - f1_score: 0.9368 - val_loss: 0.4530 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4505 - acc: 0.9431 - precision: 0.9878 - recall: 0.8902 - f1_score: 0.9357 - val_loss: 0.4517 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4492 - acc: 0.9431 - precision: 0.9892 - recall: 0.8950 - f1_score: 0.9388 - val_loss: 0.4505 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4480 - acc: 0.9431 - precision: 0.9892 - recall: 0.8926 - f1_score: 0.9377 - val_loss: 0.4493 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4467 - acc: 0.9431 - precision: 0.9908 - recall: 0.8902 - f1_score: 0.9357 - val_loss: 0.4481 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4455 - acc: 0.9431 - precision: 0.9894 - recall: 0.8929 - f1_score: 0.9373 - val_loss: 0.4469 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4443 - acc: 0.9431 - precision: 0.9883 - recall: 0.9022 - f1_score: 0.9409 - val_loss: 0.4457 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4431 - acc: 0.9431 - precision: 0.9898 - recall: 0.8880 - f1_score: 0.9332 - val_loss: 0.4446 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4418 - acc: 0.9431 - precision: 0.9899 - recall: 0.8911 - f1_score: 0.9370 - val_loss: 0.4434 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4406 - acc: 0.9431 - precision: 0.9892 - recall: 0.8908 - f1_score: 0.9371 - val_loss: 0.4422 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4394 - acc: 0.9431 - precision: 0.9886 - recall: 0.8894 - f1_score: 0.9355 - val_loss: 0.4410 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4382 - acc: 0.9431 - precision: 0.9897 - recall: 0.8885 - f1_score: 0.9345 - val_loss: 0.4399 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4371 - acc: 0.9431 - precision: 0.9903 - recall: 0.8890 - f1_score: 0.9360 - val_loss: 0.4387 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4359 - acc: 0.9431 - precision: 0.9887 - recall: 0.8925 - f1_score: 0.9372 - val_loss: 0.4376 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4347 - acc: 0.9431 - precision: 0.9877 - recall: 0.8887 - f1_score: 0.9346 - val_loss: 0.4364 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4335 - acc: 0.9431 - precision: 0.9890 - recall: 0.8874 - f1_score: 0.9344 - val_loss: 0.4353 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4324 - acc: 0.9431 - precision: 0.9901 - recall: 0.8992 - f1_score: 0.9418 - val_loss: 0.4342 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4312 - acc: 0.9431 - precision: 0.9871 - recall: 0.8892 - f1_score: 0.9337 - val_loss: 0.4330 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4300 - acc: 0.9431 - precision: 0.9900 - recall: 0.8872 - f1_score: 0.9340 - val_loss: 0.4319 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4289 - acc: 0.9431 - precision: 0.9890 - recall: 0.8880 - f1_score: 0.9345 - val_loss: 0.4308 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4277 - acc: 0.9431 - precision: 0.9904 - recall: 0.8849 - f1_score: 0.9322 - val_loss: 0.4297 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4266 - acc: 0.9431 - precision: 0.9887 - recall: 0.8902 - f1_score: 0.9357 - val_loss: 0.4286 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4255 - acc: 0.9431 - precision: 0.9883 - recall: 0.8902 - f1_score: 0.9351 - val_loss: 0.4275 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4243 - acc: 0.9431 - precision: 0.9894 - recall: 0.8927 - f1_score: 0.9365 - val_loss: 0.4264 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4232 - acc: 0.9431 - precision: 0.9894 - recall: 0.8911 - f1_score: 0.9355 - val_loss: 0.4253 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4221 - acc: 0.9431 - precision: 0.9887 - recall: 0.8885 - f1_score: 0.9349 - val_loss: 0.4242 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4210 - acc: 0.9431 - precision: 0.9896 - recall: 0.8878 - f1_score: 0.9339 - val_loss: 0.4231 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4199 - acc: 0.9431 - precision: 0.9890 - recall: 0.8899 - f1_score: 0.9361 - val_loss: 0.4221 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4188 - acc: 0.9431 - precision: 0.9903 - recall: 0.8899 - f1_score: 0.9359 - val_loss: 0.4210 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4177 - acc: 0.9431 - precision: 0.9886 - recall: 0.8924 - f1_score: 0.9373 - val_loss: 0.4199 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4166 - acc: 0.9431 - precision: 0.9889 - recall: 0.8927 - f1_score: 0.9371 - val_loss: 0.4189 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4155 - acc: 0.9431 - precision: 0.9878 - recall: 0.8855 - f1_score: 0.9316 - val_loss: 0.4178 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4144 - acc: 0.9431 - precision: 0.9892 - recall: 0.8906 - f1_score: 0.9360 - val_loss: 0.4168 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4134 - acc: 0.9431 - precision: 0.9891 - recall: 0.8932 - f1_score: 0.9378 - val_loss: 0.4158 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4123 - acc: 0.9431 - precision: 0.9867 - recall: 0.8873 - f1_score: 0.9338 - val_loss: 0.4147 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4112 - acc: 0.9431 - precision: 0.9884 - recall: 0.8928 - f1_score: 0.9362 - val_loss: 0.4137 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4102 - acc: 0.9431 - precision: 0.9870 - recall: 0.8881 - f1_score: 0.9339 - val_loss: 0.4127 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4091 - acc: 0.9431 - precision: 0.9874 - recall: 0.8816 - f1_score: 0.9301 - val_loss: 0.4117 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4081 - acc: 0.9431 - precision: 0.9904 - recall: 0.8882 - f1_score: 0.9340 - val_loss: 0.4106 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4070 - acc: 0.9431 - precision: 0.9881 - recall: 0.8883 - f1_score: 0.9349 - val_loss: 0.4096 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 655/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4060 - acc: 0.9431 - precision: 0.9886 - recall: 0.8952 - f1_score: 0.9383 - val_loss: 0.4086 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4050 - acc: 0.9431 - precision: 0.9897 - recall: 0.8908 - f1_score: 0.9362 - val_loss: 0.4076 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4039 - acc: 0.9431 - precision: 0.9889 - recall: 0.8936 - f1_score: 0.9374 - val_loss: 0.4066 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4029 - acc: 0.9431 - precision: 0.9883 - recall: 0.8844 - f1_score: 0.9309 - val_loss: 0.4056 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4019 - acc: 0.9431 - precision: 0.9895 - recall: 0.8939 - f1_score: 0.9379 - val_loss: 0.4046 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4009 - acc: 0.9431 - precision: 0.9888 - recall: 0.8899 - f1_score: 0.9357 - val_loss: 0.4037 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3999 - acc: 0.9431 - precision: 0.9887 - recall: 0.8930 - f1_score: 0.9375 - val_loss: 0.4027 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3989 - acc: 0.9431 - precision: 0.9898 - recall: 0.8918 - f1_score: 0.9373 - val_loss: 0.4017 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3979 - acc: 0.9431 - precision: 0.9894 - recall: 0.8915 - f1_score: 0.9360 - val_loss: 0.4008 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3969 - acc: 0.9431 - precision: 0.9894 - recall: 0.8876 - f1_score: 0.9345 - val_loss: 0.3998 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3959 - acc: 0.9431 - precision: 0.9887 - recall: 0.8913 - f1_score: 0.9371 - val_loss: 0.3989 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3949 - acc: 0.9431 - precision: 0.9897 - recall: 0.8888 - f1_score: 0.9348 - val_loss: 0.3979 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3939 - acc: 0.9431 - precision: 0.9889 - recall: 0.8918 - f1_score: 0.9367 - val_loss: 0.3970 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3929 - acc: 0.9431 - precision: 0.9890 - recall: 0.8919 - f1_score: 0.9366 - val_loss: 0.3960 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3919 - acc: 0.9431 - precision: 0.9890 - recall: 0.8970 - f1_score: 0.9383 - val_loss: 0.3951 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3910 - acc: 0.9431 - precision: 0.9881 - recall: 0.8940 - f1_score: 0.9379 - val_loss: 0.3942 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3900 - acc: 0.9431 - precision: 0.9878 - recall: 0.8871 - f1_score: 0.9341 - val_loss: 0.3932 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3891 - acc: 0.9431 - precision: 0.9881 - recall: 0.8892 - f1_score: 0.9358 - val_loss: 0.3923 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9431 - precision: 0.9889 - recall: 0.8925 - f1_score: 0.9373 - val_loss: 0.3914 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3872 - acc: 0.9431 - precision: 0.9890 - recall: 0.8878 - f1_score: 0.9346 - val_loss: 0.3905 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3862 - acc: 0.9431 - precision: 0.9890 - recall: 0.8905 - f1_score: 0.9365 - val_loss: 0.3896 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3853 - acc: 0.9431 - precision: 0.9879 - recall: 0.8931 - f1_score: 0.9373 - val_loss: 0.3887 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3843 - acc: 0.9431 - precision: 0.9885 - recall: 0.8900 - f1_score: 0.9358 - val_loss: 0.3878 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3834 - acc: 0.9431 - precision: 0.9869 - recall: 0.8861 - f1_score: 0.9325 - val_loss: 0.3869 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3825 - acc: 0.9431 - precision: 0.9891 - recall: 0.8929 - f1_score: 0.9377 - val_loss: 0.3860 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3815 - acc: 0.9431 - precision: 0.9903 - recall: 0.8924 - f1_score: 0.9369 - val_loss: 0.3851 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3806 - acc: 0.9431 - precision: 0.9890 - recall: 0.8870 - f1_score: 0.9347 - val_loss: 0.3842 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3797 - acc: 0.9431 - precision: 0.9875 - recall: 0.8922 - f1_score: 0.9369 - val_loss: 0.3834 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3788 - acc: 0.9431 - precision: 0.9892 - recall: 0.8936 - f1_score: 0.9385 - val_loss: 0.3825 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3779 - acc: 0.9431 - precision: 0.9878 - recall: 0.8855 - f1_score: 0.9325 - val_loss: 0.3816 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3770 - acc: 0.9431 - precision: 0.9896 - recall: 0.8902 - f1_score: 0.9361 - val_loss: 0.3807 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3761 - acc: 0.9431 - precision: 0.9896 - recall: 0.8939 - f1_score: 0.9379 - val_loss: 0.3799 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3752 - acc: 0.9431 - precision: 0.9896 - recall: 0.8894 - f1_score: 0.9364 - val_loss: 0.3790 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3743 - acc: 0.9431 - precision: 0.9884 - recall: 0.8922 - f1_score: 0.9366 - val_loss: 0.3782 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3734 - acc: 0.9431 - precision: 0.9906 - recall: 0.8894 - f1_score: 0.9351 - val_loss: 0.3773 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3726 - acc: 0.9431 - precision: 0.9906 - recall: 0.8919 - f1_score: 0.9380 - val_loss: 0.3765 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3717 - acc: 0.9431 - precision: 0.9896 - recall: 0.8909 - f1_score: 0.9366 - val_loss: 0.3756 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3708 - acc: 0.9431 - precision: 0.9892 - recall: 0.8871 - f1_score: 0.9343 - val_loss: 0.3748 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3699 - acc: 0.9431 - precision: 0.9887 - recall: 0.8917 - f1_score: 0.9370 - val_loss: 0.3740 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3691 - acc: 0.9431 - precision: 0.9898 - recall: 0.8911 - f1_score: 0.9368 - val_loss: 0.3731 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3682 - acc: 0.9431 - precision: 0.9894 - recall: 0.8910 - f1_score: 0.9367 - val_loss: 0.3723 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3674 - acc: 0.9431 - precision: 0.9864 - recall: 0.8923 - f1_score: 0.9358 - val_loss: 0.3715 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3665 - acc: 0.9431 - precision: 0.9893 - recall: 0.8888 - f1_score: 0.9343 - val_loss: 0.3707 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3657 - acc: 0.9431 - precision: 0.9894 - recall: 0.8881 - f1_score: 0.9345 - val_loss: 0.3699 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3648 - acc: 0.9431 - precision: 0.9899 - recall: 0.8909 - f1_score: 0.9362 - val_loss: 0.3691 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3640 - acc: 0.9431 - precision: 0.9891 - recall: 0.8906 - f1_score: 0.9366 - val_loss: 0.3682 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3632 - acc: 0.9431 - precision: 0.9895 - recall: 0.8912 - f1_score: 0.9361 - val_loss: 0.3674 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3623 - acc: 0.9431 - precision: 0.9893 - recall: 0.8874 - f1_score: 0.9344 - val_loss: 0.3666 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3615 - acc: 0.9431 - precision: 0.9876 - recall: 0.8932 - f1_score: 0.9372 - val_loss: 0.3658 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3607 - acc: 0.9431 - precision: 0.9887 - recall: 0.8847 - f1_score: 0.9316 - val_loss: 0.3651 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3599 - acc: 0.9431 - precision: 0.9879 - recall: 0.8908 - f1_score: 0.9356 - val_loss: 0.3643 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3590 - acc: 0.9431 - precision: 0.9853 - recall: 0.8927 - f1_score: 0.9348 - val_loss: 0.3635 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3582 - acc: 0.9431 - precision: 0.9892 - recall: 0.8938 - f1_score: 0.9379 - val_loss: 0.3627 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3574 - acc: 0.9431 - precision: 0.9881 - recall: 0.8887 - f1_score: 0.9347 - val_loss: 0.3619 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3566 - acc: 0.9431 - precision: 0.9905 - recall: 0.8929 - f1_score: 0.9377 - val_loss: 0.3612 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3558 - acc: 0.9431 - precision: 0.9882 - recall: 0.8957 - f1_score: 0.9383 - val_loss: 0.3604 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3550 - acc: 0.9431 - precision: 0.9893 - recall: 0.8907 - f1_score: 0.9363 - val_loss: 0.3596 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3542 - acc: 0.9431 - precision: 0.9909 - recall: 0.8902 - f1_score: 0.9370 - val_loss: 0.3589 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3534 - acc: 0.9431 - precision: 0.9874 - recall: 0.8881 - f1_score: 0.9345 - val_loss: 0.3581 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3527 - acc: 0.9431 - precision: 0.9900 - recall: 0.8915 - f1_score: 0.9373 - val_loss: 0.3574 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3519 - acc: 0.9431 - precision: 0.9881 - recall: 0.8913 - f1_score: 0.9365 - val_loss: 0.3566 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3511 - acc: 0.9431 - precision: 0.9894 - recall: 0.8908 - f1_score: 0.9365 - val_loss: 0.3559 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3503 - acc: 0.9431 - precision: 0.9892 - recall: 0.8941 - f1_score: 0.9378 - val_loss: 0.3551 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3496 - acc: 0.9431 - precision: 0.9901 - recall: 0.8935 - f1_score: 0.9380 - val_loss: 0.3544 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3488 - acc: 0.9431 - precision: 0.9893 - recall: 0.8937 - f1_score: 0.9383 - val_loss: 0.3537 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3480 - acc: 0.9431 - precision: 0.9891 - recall: 0.8864 - f1_score: 0.9335 - val_loss: 0.3529 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3473 - acc: 0.9431 - precision: 0.9894 - recall: 0.8857 - f1_score: 0.9323 - val_loss: 0.3522 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3465 - acc: 0.9431 - precision: 0.9885 - recall: 0.8943 - f1_score: 0.9382 - val_loss: 0.3515 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3458 - acc: 0.9431 - precision: 0.9889 - recall: 0.8897 - f1_score: 0.9356 - val_loss: 0.3508 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3450 - acc: 0.9431 - precision: 0.9887 - recall: 0.8906 - f1_score: 0.9366 - val_loss: 0.3500 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3443 - acc: 0.9431 - precision: 0.9907 - recall: 0.8853 - f1_score: 0.9321 - val_loss: 0.3493 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3435 - acc: 0.9431 - precision: 0.9889 - recall: 0.8922 - f1_score: 0.9365 - val_loss: 0.3486 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3428 - acc: 0.9431 - precision: 0.9897 - recall: 0.8905 - f1_score: 0.9362 - val_loss: 0.3479 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3421 - acc: 0.9431 - precision: 0.9904 - recall: 0.8903 - f1_score: 0.9369 - val_loss: 0.3472 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3413 - acc: 0.9431 - precision: 0.9888 - recall: 0.8927 - f1_score: 0.9372 - val_loss: 0.3465 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3406 - acc: 0.9431 - precision: 0.9893 - recall: 0.8925 - f1_score: 0.9373 - val_loss: 0.3458 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3399 - acc: 0.9431 - precision: 0.9886 - recall: 0.8891 - f1_score: 0.9343 - val_loss: 0.3451 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3392 - acc: 0.9431 - precision: 0.9893 - recall: 0.8931 - f1_score: 0.9369 - val_loss: 0.3444 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3384 - acc: 0.9431 - precision: 0.9862 - recall: 0.8885 - f1_score: 0.9331 - val_loss: 0.3437 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3377 - acc: 0.9431 - precision: 0.9890 - recall: 0.8937 - f1_score: 0.9377 - val_loss: 0.3430 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3370 - acc: 0.9431 - precision: 0.9895 - recall: 0.8949 - f1_score: 0.9384 - val_loss: 0.3424 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3363 - acc: 0.9431 - precision: 0.9897 - recall: 0.8887 - f1_score: 0.9359 - val_loss: 0.3417 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3356 - acc: 0.9431 - precision: 0.9894 - recall: 0.8898 - f1_score: 0.9354 - val_loss: 0.3410 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3349 - acc: 0.9431 - precision: 0.9895 - recall: 0.8905 - f1_score: 0.9368 - val_loss: 0.3403 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3342 - acc: 0.9431 - precision: 0.9884 - recall: 0.8908 - f1_score: 0.9358 - val_loss: 0.3397 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3335 - acc: 0.9431 - precision: 0.9860 - recall: 0.8892 - f1_score: 0.9342 - val_loss: 0.3390 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3328 - acc: 0.9431 - precision: 0.9870 - recall: 0.8884 - f1_score: 0.9347 - val_loss: 0.3383 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3321 - acc: 0.9431 - precision: 0.9899 - recall: 0.8961 - f1_score: 0.9392 - val_loss: 0.3377 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9431 - precision: 0.9886 - recall: 0.8911 - f1_score: 0.9370 - val_loss: 0.3370 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3308 - acc: 0.9431 - precision: 0.9906 - recall: 0.8893 - f1_score: 0.9358 - val_loss: 0.3364 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3301 - acc: 0.9431 - precision: 0.9899 - recall: 0.8918 - f1_score: 0.9372 - val_loss: 0.3357 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3294 - acc: 0.9431 - precision: 0.9877 - recall: 0.8947 - f1_score: 0.9374 - val_loss: 0.3351 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3287 - acc: 0.9431 - precision: 0.9903 - recall: 0.8904 - f1_score: 0.9370 - val_loss: 0.3345 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3281 - acc: 0.9431 - precision: 0.9890 - recall: 0.8941 - f1_score: 0.9379 - val_loss: 0.3338 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3274 - acc: 0.9431 - precision: 0.9895 - recall: 0.8981 - f1_score: 0.9404 - val_loss: 0.3332 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3267 - acc: 0.9431 - precision: 0.9885 - recall: 0.8924 - f1_score: 0.9368 - val_loss: 0.3325 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3261 - acc: 0.9431 - precision: 0.9895 - recall: 0.8894 - f1_score: 0.9357 - val_loss: 0.3319 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3254 - acc: 0.9431 - precision: 0.9873 - recall: 0.8889 - f1_score: 0.9338 - val_loss: 0.3313 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3248 - acc: 0.9431 - precision: 0.9871 - recall: 0.8889 - f1_score: 0.9342 - val_loss: 0.3306 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3241 - acc: 0.9431 - precision: 0.9891 - recall: 0.8951 - f1_score: 0.9388 - val_loss: 0.3300 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3235 - acc: 0.9431 - precision: 0.9898 - recall: 0.8915 - f1_score: 0.9370 - val_loss: 0.3294 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3228 - acc: 0.9431 - precision: 0.9893 - recall: 0.8888 - f1_score: 0.9354 - val_loss: 0.3288 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3222 - acc: 0.9431 - precision: 0.9904 - recall: 0.8824 - f1_score: 0.9301 - val_loss: 0.3282 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3216 - acc: 0.9431 - precision: 0.9888 - recall: 0.8925 - f1_score: 0.9376 - val_loss: 0.3276 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3209 - acc: 0.9431 - precision: 0.9886 - recall: 0.8888 - f1_score: 0.9351 - val_loss: 0.3270 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3203 - acc: 0.9431 - precision: 0.9898 - recall: 0.8897 - f1_score: 0.9360 - val_loss: 0.3264 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3197 - acc: 0.9431 - precision: 0.9889 - recall: 0.8916 - f1_score: 0.9363 - val_loss: 0.3258 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3190 - acc: 0.9431 - precision: 0.9898 - recall: 0.8949 - f1_score: 0.9394 - val_loss: 0.3252 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3184 - acc: 0.9431 - precision: 0.9885 - recall: 0.8947 - f1_score: 0.9376 - val_loss: 0.3246 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3178 - acc: 0.9431 - precision: 0.9888 - recall: 0.8871 - f1_score: 0.9339 - val_loss: 0.3240 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9431 - precision: 0.9898 - recall: 0.8878 - f1_score: 0.9352 - val_loss: 0.3234 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3166 - acc: 0.9431 - precision: 0.9897 - recall: 0.8947 - f1_score: 0.9388 - val_loss: 0.3228 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3159 - acc: 0.9431 - precision: 0.9893 - recall: 0.8931 - f1_score: 0.9369 - val_loss: 0.3222 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3153 - acc: 0.9431 - precision: 0.9887 - recall: 0.8926 - f1_score: 0.9360 - val_loss: 0.3217 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3147 - acc: 0.9431 - precision: 0.9871 - recall: 0.8888 - f1_score: 0.9345 - val_loss: 0.3211 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3141 - acc: 0.9431 - precision: 0.9894 - recall: 0.8924 - f1_score: 0.9374 - val_loss: 0.3205 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3135 - acc: 0.9431 - precision: 0.9896 - recall: 0.8893 - f1_score: 0.9357 - val_loss: 0.3199 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3129 - acc: 0.9431 - precision: 0.9883 - recall: 0.8886 - f1_score: 0.9347 - val_loss: 0.3194 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3123 - acc: 0.9431 - precision: 0.9897 - recall: 0.8947 - f1_score: 0.9381 - val_loss: 0.3188 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3117 - acc: 0.9431 - precision: 0.9886 - recall: 0.8917 - f1_score: 0.9360 - val_loss: 0.3183 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3111 - acc: 0.9431 - precision: 0.9882 - recall: 0.8916 - f1_score: 0.9363 - val_loss: 0.3177 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3106 - acc: 0.9431 - precision: 0.9900 - recall: 0.8943 - f1_score: 0.9391 - val_loss: 0.3171 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3100 - acc: 0.9431 - precision: 0.9898 - recall: 0.8913 - f1_score: 0.9369 - val_loss: 0.3166 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3094 - acc: 0.9431 - precision: 0.9901 - recall: 0.8886 - f1_score: 0.9357 - val_loss: 0.3160 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3088 - acc: 0.9431 - precision: 0.9889 - recall: 0.8890 - f1_score: 0.9349 - val_loss: 0.3155 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3082 - acc: 0.9431 - precision: 0.9903 - recall: 0.8905 - f1_score: 0.9364 - val_loss: 0.3149 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3077 - acc: 0.9431 - precision: 0.9886 - recall: 0.8940 - f1_score: 0.9376 - val_loss: 0.3144 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3071 - acc: 0.9431 - precision: 0.9903 - recall: 0.8922 - f1_score: 0.9379 - val_loss: 0.3139 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3065 - acc: 0.9431 - precision: 0.9882 - recall: 0.8904 - f1_score: 0.9355 - val_loss: 0.3133 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3060 - acc: 0.9431 - precision: 0.9890 - recall: 0.8914 - f1_score: 0.9365 - val_loss: 0.3128 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3054 - acc: 0.9431 - precision: 0.9890 - recall: 0.8880 - f1_score: 0.9344 - val_loss: 0.3122 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3048 - acc: 0.9431 - precision: 0.9902 - recall: 0.8879 - f1_score: 0.9353 - val_loss: 0.3117 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3043 - acc: 0.9431 - precision: 0.9884 - recall: 0.8890 - f1_score: 0.9347 - val_loss: 0.3112 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3037 - acc: 0.9431 - precision: 0.9896 - recall: 0.8899 - f1_score: 0.9357 - val_loss: 0.3106 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3032 - acc: 0.9431 - precision: 0.9893 - recall: 0.8901 - f1_score: 0.9366 - val_loss: 0.3101 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3026 - acc: 0.9431 - precision: 0.9886 - recall: 0.8960 - f1_score: 0.9384 - val_loss: 0.3096 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3021 - acc: 0.9431 - precision: 0.9902 - recall: 0.8915 - f1_score: 0.9374 - val_loss: 0.3091 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3015 - acc: 0.9431 - precision: 0.9886 - recall: 0.8923 - f1_score: 0.9366 - val_loss: 0.3085 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3010 - acc: 0.9431 - precision: 0.9893 - recall: 0.8925 - f1_score: 0.9370 - val_loss: 0.3080 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3004 - acc: 0.9431 - precision: 0.9872 - recall: 0.8932 - f1_score: 0.9372 - val_loss: 0.3075 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2999 - acc: 0.9431 - precision: 0.9868 - recall: 0.8860 - f1_score: 0.9324 - val_loss: 0.3070 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2994 - acc: 0.9431 - precision: 0.9886 - recall: 0.8934 - f1_score: 0.9372 - val_loss: 0.3065 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2988 - acc: 0.9431 - precision: 0.9883 - recall: 0.8940 - f1_score: 0.9376 - val_loss: 0.3060 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2983 - acc: 0.9431 - precision: 0.9893 - recall: 0.8906 - f1_score: 0.9361 - val_loss: 0.3055 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9431 - precision: 0.9875 - recall: 0.8868 - f1_score: 0.9331 - val_loss: 0.3050 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2973 - acc: 0.9431 - precision: 0.9887 - recall: 0.8954 - f1_score: 0.9369 - val_loss: 0.3045 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2967 - acc: 0.9431 - precision: 0.9896 - recall: 0.8863 - f1_score: 0.9327 - val_loss: 0.3040 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2962 - acc: 0.9431 - precision: 0.9880 - recall: 0.8876 - f1_score: 0.9346 - val_loss: 0.3035 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2957 - acc: 0.9431 - precision: 0.9879 - recall: 0.8905 - f1_score: 0.9356 - val_loss: 0.3030 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2952 - acc: 0.9431 - precision: 0.9897 - recall: 0.8880 - f1_score: 0.9337 - val_loss: 0.3025 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2947 - acc: 0.9431 - precision: 0.9867 - recall: 0.8888 - f1_score: 0.9347 - val_loss: 0.3020 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2942 - acc: 0.9431 - precision: 0.9884 - recall: 0.8869 - f1_score: 0.9340 - val_loss: 0.3015 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2937 - acc: 0.9431 - precision: 0.9893 - recall: 0.8824 - f1_score: 0.9300 - val_loss: 0.3011 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2931 - acc: 0.9431 - precision: 0.9878 - recall: 0.8866 - f1_score: 0.9339 - val_loss: 0.3006 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2926 - acc: 0.9431 - precision: 0.9891 - recall: 0.8953 - f1_score: 0.9387 - val_loss: 0.3001 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2921 - acc: 0.9431 - precision: 0.9900 - recall: 0.8891 - f1_score: 0.9349 - val_loss: 0.2996 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2916 - acc: 0.9431 - precision: 0.9889 - recall: 0.8869 - f1_score: 0.9339 - val_loss: 0.2992 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2911 - acc: 0.9431 - precision: 0.9898 - recall: 0.8900 - f1_score: 0.9365 - val_loss: 0.2987 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2906 - acc: 0.9431 - precision: 0.9902 - recall: 0.8951 - f1_score: 0.9390 - val_loss: 0.2982 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2902 - acc: 0.9431 - precision: 0.9888 - recall: 0.8893 - f1_score: 0.9353 - val_loss: 0.2977 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 815/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2897 - acc: 0.9431 - precision: 0.9885 - recall: 0.8901 - f1_score: 0.9350 - val_loss: 0.2973 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2892 - acc: 0.9431 - precision: 0.9908 - recall: 0.8912 - f1_score: 0.9371 - val_loss: 0.2968 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2887 - acc: 0.9431 - precision: 0.9893 - recall: 0.8926 - f1_score: 0.9374 - val_loss: 0.2964 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2882 - acc: 0.9431 - precision: 0.9891 - recall: 0.8954 - f1_score: 0.9386 - val_loss: 0.2959 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2877 - acc: 0.9431 - precision: 0.9876 - recall: 0.8897 - f1_score: 0.9343 - val_loss: 0.2955 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2872 - acc: 0.9447 - precision: 0.9884 - recall: 0.8959 - f1_score: 0.9380 - val_loss: 0.2950 - val_acc: 0.9367 - val_precision: 0.9746 - val_recall: 0.9131 - val_f1_score: 0.9422\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2868 - acc: 0.9447 - precision: 0.9874 - recall: 0.8915 - f1_score: 0.9357 - val_loss: 0.2945 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2863 - acc: 0.9447 - precision: 0.9889 - recall: 0.8899 - f1_score: 0.9354 - val_loss: 0.2941 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2858 - acc: 0.9447 - precision: 0.9855 - recall: 0.8951 - f1_score: 0.9371 - val_loss: 0.2936 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2853 - acc: 0.9447 - precision: 0.9890 - recall: 0.8939 - f1_score: 0.9377 - val_loss: 0.2932 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2849 - acc: 0.9447 - precision: 0.9901 - recall: 0.8950 - f1_score: 0.9389 - val_loss: 0.2927 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2844 - acc: 0.9447 - precision: 0.9900 - recall: 0.8939 - f1_score: 0.9382 - val_loss: 0.2923 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2839 - acc: 0.9447 - precision: 0.9899 - recall: 0.8947 - f1_score: 0.9384 - val_loss: 0.2919 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2835 - acc: 0.9447 - precision: 0.9882 - recall: 0.8923 - f1_score: 0.9361 - val_loss: 0.2914 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2830 - acc: 0.9447 - precision: 0.9890 - recall: 0.8933 - f1_score: 0.9380 - val_loss: 0.2910 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2826 - acc: 0.9447 - precision: 0.9893 - recall: 0.8944 - f1_score: 0.9387 - val_loss: 0.2906 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2821 - acc: 0.9447 - precision: 0.9906 - recall: 0.8946 - f1_score: 0.9380 - val_loss: 0.2901 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2816 - acc: 0.9447 - precision: 0.9876 - recall: 0.8979 - f1_score: 0.9393 - val_loss: 0.2897 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2812 - acc: 0.9447 - precision: 0.9906 - recall: 0.8981 - f1_score: 0.9412 - val_loss: 0.2893 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2807 - acc: 0.9447 - precision: 0.9884 - recall: 0.8944 - f1_score: 0.9382 - val_loss: 0.2888 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2803 - acc: 0.9447 - precision: 0.9881 - recall: 0.8966 - f1_score: 0.9390 - val_loss: 0.2884 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2799 - acc: 0.9447 - precision: 0.9887 - recall: 0.8961 - f1_score: 0.9396 - val_loss: 0.2880 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2794 - acc: 0.9447 - precision: 0.9875 - recall: 0.8949 - f1_score: 0.9371 - val_loss: 0.2876 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2790 - acc: 0.9447 - precision: 0.9895 - recall: 0.8936 - f1_score: 0.9380 - val_loss: 0.2871 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9447 - precision: 0.9878 - recall: 0.8938 - f1_score: 0.9374 - val_loss: 0.2867 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2781 - acc: 0.9447 - precision: 0.9892 - recall: 0.8944 - f1_score: 0.9383 - val_loss: 0.2863 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2777 - acc: 0.9447 - precision: 0.9905 - recall: 0.8981 - f1_score: 0.9407 - val_loss: 0.2859 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2772 - acc: 0.9447 - precision: 0.9881 - recall: 0.8931 - f1_score: 0.9373 - val_loss: 0.2855 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2768 - acc: 0.9447 - precision: 0.9873 - recall: 0.8925 - f1_score: 0.9369 - val_loss: 0.2851 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2764 - acc: 0.9447 - precision: 0.9911 - recall: 0.8947 - f1_score: 0.9391 - val_loss: 0.2847 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2759 - acc: 0.9447 - precision: 0.9876 - recall: 0.8933 - f1_score: 0.9370 - val_loss: 0.2843 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2755 - acc: 0.9447 - precision: 0.9878 - recall: 0.8951 - f1_score: 0.9380 - val_loss: 0.2839 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2751 - acc: 0.9447 - precision: 0.9904 - recall: 0.8963 - f1_score: 0.9399 - val_loss: 0.2835 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2747 - acc: 0.9447 - precision: 0.9902 - recall: 0.8963 - f1_score: 0.9394 - val_loss: 0.2831 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2742 - acc: 0.9447 - precision: 0.9866 - recall: 0.8944 - f1_score: 0.9376 - val_loss: 0.2827 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2738 - acc: 0.9447 - precision: 0.9886 - recall: 0.8950 - f1_score: 0.9384 - val_loss: 0.2823 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2734 - acc: 0.9447 - precision: 0.9875 - recall: 0.8914 - f1_score: 0.9357 - val_loss: 0.2819 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2730 - acc: 0.9447 - precision: 0.9889 - recall: 0.8963 - f1_score: 0.9391 - val_loss: 0.2815 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2726 - acc: 0.9447 - precision: 0.9898 - recall: 0.8907 - f1_score: 0.9366 - val_loss: 0.2811 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2722 - acc: 0.9447 - precision: 0.9898 - recall: 0.8919 - f1_score: 0.9372 - val_loss: 0.2807 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2718 - acc: 0.9447 - precision: 0.9882 - recall: 0.8945 - f1_score: 0.9379 - val_loss: 0.2804 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2714 - acc: 0.9447 - precision: 0.9900 - recall: 0.8909 - f1_score: 0.9351 - val_loss: 0.2800 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2709 - acc: 0.9447 - precision: 0.9889 - recall: 0.8967 - f1_score: 0.9386 - val_loss: 0.2796 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2705 - acc: 0.9447 - precision: 0.9862 - recall: 0.8892 - f1_score: 0.9341 - val_loss: 0.2792 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9447 - precision: 0.9887 - recall: 0.8944 - f1_score: 0.9384 - val_loss: 0.2788 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9447 - precision: 0.9899 - recall: 0.9029 - f1_score: 0.9430 - val_loss: 0.2784 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9447 - precision: 0.9890 - recall: 0.8921 - f1_score: 0.9369 - val_loss: 0.2781 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2689 - acc: 0.9447 - precision: 0.9891 - recall: 0.8920 - f1_score: 0.9375 - val_loss: 0.2777 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2685 - acc: 0.9447 - precision: 0.9905 - recall: 0.8948 - f1_score: 0.9394 - val_loss: 0.2773 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2682 - acc: 0.9447 - precision: 0.9884 - recall: 0.8952 - f1_score: 0.9388 - val_loss: 0.2770 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2678 - acc: 0.9447 - precision: 0.9894 - recall: 0.8944 - f1_score: 0.9389 - val_loss: 0.2766 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2674 - acc: 0.9447 - precision: 0.9904 - recall: 0.8935 - f1_score: 0.9388 - val_loss: 0.2762 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2670 - acc: 0.9447 - precision: 0.9907 - recall: 0.8918 - f1_score: 0.9369 - val_loss: 0.2759 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2666 - acc: 0.9447 - precision: 0.9874 - recall: 0.8939 - f1_score: 0.9373 - val_loss: 0.2755 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2662 - acc: 0.9447 - precision: 0.9891 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 0.2751 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2658 - acc: 0.9447 - precision: 0.9900 - recall: 0.8942 - f1_score: 0.9388 - val_loss: 0.2748 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2655 - acc: 0.9447 - precision: 0.9879 - recall: 0.8944 - f1_score: 0.9377 - val_loss: 0.2744 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2651 - acc: 0.9447 - precision: 0.9881 - recall: 0.8966 - f1_score: 0.9390 - val_loss: 0.2741 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2647 - acc: 0.9447 - precision: 0.9886 - recall: 0.8975 - f1_score: 0.9389 - val_loss: 0.2737 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2643 - acc: 0.9447 - precision: 0.9900 - recall: 0.8949 - f1_score: 0.9390 - val_loss: 0.2733 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2640 - acc: 0.9447 - precision: 0.9895 - recall: 0.8937 - f1_score: 0.9381 - val_loss: 0.2730 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2636 - acc: 0.9447 - precision: 0.9897 - recall: 0.8942 - f1_score: 0.9380 - val_loss: 0.2727 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2632 - acc: 0.9447 - precision: 0.9889 - recall: 0.8947 - f1_score: 0.9385 - val_loss: 0.2723 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2628 - acc: 0.9447 - precision: 0.9895 - recall: 0.8978 - f1_score: 0.9400 - val_loss: 0.2720 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 879/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2625 - acc: 0.9447 - precision: 0.9895 - recall: 0.8933 - f1_score: 0.9368 - val_loss: 0.2716 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2621 - acc: 0.9447 - precision: 0.9888 - recall: 0.8926 - f1_score: 0.9370 - val_loss: 0.2713 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2617 - acc: 0.9447 - precision: 0.9892 - recall: 0.8959 - f1_score: 0.9397 - val_loss: 0.2709 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2614 - acc: 0.9447 - precision: 0.9896 - recall: 0.8959 - f1_score: 0.9390 - val_loss: 0.2706 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2610 - acc: 0.9447 - precision: 0.9891 - recall: 0.8930 - f1_score: 0.9378 - val_loss: 0.2703 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2607 - acc: 0.9447 - precision: 0.9890 - recall: 0.8923 - f1_score: 0.9368 - val_loss: 0.2699 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2603 - acc: 0.9447 - precision: 0.9876 - recall: 0.8927 - f1_score: 0.9371 - val_loss: 0.2696 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2599 - acc: 0.9447 - precision: 0.9870 - recall: 0.8880 - f1_score: 0.9340 - val_loss: 0.2693 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2596 - acc: 0.9447 - precision: 0.9895 - recall: 0.8964 - f1_score: 0.9402 - val_loss: 0.2689 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2592 - acc: 0.9447 - precision: 0.9884 - recall: 0.8960 - f1_score: 0.9388 - val_loss: 0.2686 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2589 - acc: 0.9447 - precision: 0.9901 - recall: 0.8947 - f1_score: 0.9385 - val_loss: 0.2683 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9447 - precision: 0.9906 - recall: 0.8918 - f1_score: 0.9371 - val_loss: 0.2680 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2582 - acc: 0.9447 - precision: 0.9890 - recall: 0.8996 - f1_score: 0.9408 - val_loss: 0.2676 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9447 - precision: 0.9904 - recall: 0.8896 - f1_score: 0.9363 - val_loss: 0.2673 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9447 - precision: 0.9889 - recall: 0.8927 - f1_score: 0.9376 - val_loss: 0.2670 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9447 - precision: 0.9898 - recall: 0.8919 - f1_score: 0.9367 - val_loss: 0.2667 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2568 - acc: 0.9447 - precision: 0.9891 - recall: 0.8978 - f1_score: 0.9401 - val_loss: 0.2663 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9447 - precision: 0.9896 - recall: 0.8952 - f1_score: 0.9391 - val_loss: 0.2660 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2561 - acc: 0.9447 - precision: 0.9902 - recall: 0.8966 - f1_score: 0.9404 - val_loss: 0.2657 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2558 - acc: 0.9447 - precision: 0.9899 - recall: 0.8889 - f1_score: 0.9351 - val_loss: 0.2654 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2555 - acc: 0.9447 - precision: 0.9906 - recall: 0.8953 - f1_score: 0.9394 - val_loss: 0.2651 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2551 - acc: 0.9447 - precision: 0.9894 - recall: 0.8921 - f1_score: 0.9371 - val_loss: 0.2648 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2548 - acc: 0.9447 - precision: 0.9874 - recall: 0.8966 - f1_score: 0.9378 - val_loss: 0.2644 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2545 - acc: 0.9447 - precision: 0.9905 - recall: 0.8922 - f1_score: 0.9377 - val_loss: 0.2641 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2541 - acc: 0.9447 - precision: 0.9879 - recall: 0.8877 - f1_score: 0.9332 - val_loss: 0.2638 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2538 - acc: 0.9447 - precision: 0.9887 - recall: 0.8953 - f1_score: 0.9387 - val_loss: 0.2635 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2535 - acc: 0.9447 - precision: 0.9910 - recall: 0.8936 - f1_score: 0.9382 - val_loss: 0.2632 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2532 - acc: 0.9447 - precision: 0.9891 - recall: 0.8971 - f1_score: 0.9397 - val_loss: 0.2629 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2528 - acc: 0.9447 - precision: 0.9890 - recall: 0.8981 - f1_score: 0.9396 - val_loss: 0.2626 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2525 - acc: 0.9447 - precision: 0.9898 - recall: 0.8897 - f1_score: 0.9360 - val_loss: 0.2623 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2522 - acc: 0.9447 - precision: 0.9898 - recall: 0.8940 - f1_score: 0.9387 - val_loss: 0.2620 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2519 - acc: 0.9447 - precision: 0.9885 - recall: 0.8879 - f1_score: 0.9333 - val_loss: 0.2617 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 911/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2515 - acc: 0.9447 - precision: 0.9892 - recall: 0.8980 - f1_score: 0.9397 - val_loss: 0.2614 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2512 - acc: 0.9447 - precision: 0.9861 - recall: 0.8915 - f1_score: 0.9348 - val_loss: 0.2611 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2509 - acc: 0.9447 - precision: 0.9871 - recall: 0.8877 - f1_score: 0.9332 - val_loss: 0.2608 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2506 - acc: 0.9447 - precision: 0.9889 - recall: 0.8956 - f1_score: 0.9389 - val_loss: 0.2605 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9447 - precision: 0.9887 - recall: 0.8926 - f1_score: 0.9371 - val_loss: 0.2602 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2500 - acc: 0.9447 - precision: 0.9901 - recall: 0.8917 - f1_score: 0.9356 - val_loss: 0.2599 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2497 - acc: 0.9447 - precision: 0.9909 - recall: 0.8954 - f1_score: 0.9393 - val_loss: 0.2596 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2494 - acc: 0.9447 - precision: 0.9889 - recall: 0.8935 - f1_score: 0.9380 - val_loss: 0.2593 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2491 - acc: 0.9447 - precision: 0.9900 - recall: 0.8974 - f1_score: 0.9401 - val_loss: 0.2590 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2487 - acc: 0.9447 - precision: 0.9906 - recall: 0.8914 - f1_score: 0.9363 - val_loss: 0.2588 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9447 - precision: 0.9879 - recall: 0.8920 - f1_score: 0.9359 - val_loss: 0.2585 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2481 - acc: 0.9447 - precision: 0.9899 - recall: 0.8980 - f1_score: 0.9406 - val_loss: 0.2582 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9447 - precision: 0.9899 - recall: 0.9019 - f1_score: 0.9415 - val_loss: 0.2579 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2475 - acc: 0.9447 - precision: 0.9886 - recall: 0.8984 - f1_score: 0.9403 - val_loss: 0.2576 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2473 - acc: 0.9447 - precision: 0.9888 - recall: 0.8960 - f1_score: 0.9385 - val_loss: 0.2574 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9447 - precision: 0.9891 - recall: 0.8983 - f1_score: 0.9395 - val_loss: 0.2571 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9447 - precision: 0.9901 - recall: 0.8913 - f1_score: 0.9364 - val_loss: 0.2568 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9447 - precision: 0.9909 - recall: 0.8903 - f1_score: 0.9351 - val_loss: 0.2565 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2461 - acc: 0.9447 - precision: 0.9860 - recall: 0.8902 - f1_score: 0.9342 - val_loss: 0.2563 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2458 - acc: 0.9447 - precision: 0.9895 - recall: 0.8958 - f1_score: 0.9385 - val_loss: 0.2560 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2455 - acc: 0.9447 - precision: 0.9897 - recall: 0.8974 - f1_score: 0.9399 - val_loss: 0.2557 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2452 - acc: 0.9447 - precision: 0.9899 - recall: 0.8990 - f1_score: 0.9405 - val_loss: 0.2554 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2449 - acc: 0.9447 - precision: 0.9877 - recall: 0.8941 - f1_score: 0.9368 - val_loss: 0.2552 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2446 - acc: 0.9447 - precision: 0.9875 - recall: 0.8930 - f1_score: 0.9370 - val_loss: 0.2549 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2443 - acc: 0.9447 - precision: 0.9895 - recall: 0.8980 - f1_score: 0.9408 - val_loss: 0.2546 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2441 - acc: 0.9447 - precision: 0.9893 - recall: 0.8907 - f1_score: 0.9350 - val_loss: 0.2544 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2438 - acc: 0.9447 - precision: 0.9898 - recall: 0.8974 - f1_score: 0.9400 - val_loss: 0.2541 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2435 - acc: 0.9447 - precision: 0.9892 - recall: 0.8975 - f1_score: 0.9400 - val_loss: 0.2538 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2432 - acc: 0.9463 - precision: 0.9891 - recall: 0.8956 - f1_score: 0.9385 - val_loss: 0.2536 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9447 - precision: 0.9891 - recall: 0.8938 - f1_score: 0.9381 - val_loss: 0.2533 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9463 - precision: 0.9889 - recall: 0.8958 - f1_score: 0.9392 - val_loss: 0.2530 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2424 - acc: 0.9463 - precision: 0.9886 - recall: 0.8988 - f1_score: 0.9402 - val_loss: 0.2528 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2421 - acc: 0.9463 - precision: 0.9894 - recall: 0.8958 - f1_score: 0.9388 - val_loss: 0.2525 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2418 - acc: 0.9463 - precision: 0.9895 - recall: 0.8977 - f1_score: 0.9409 - val_loss: 0.2523 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2416 - acc: 0.9463 - precision: 0.9891 - recall: 0.8991 - f1_score: 0.9397 - val_loss: 0.2520 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2413 - acc: 0.9463 - precision: 0.9880 - recall: 0.8958 - f1_score: 0.9380 - val_loss: 0.2518 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2410 - acc: 0.9463 - precision: 0.9899 - recall: 0.8985 - f1_score: 0.9409 - val_loss: 0.2515 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2407 - acc: 0.9463 - precision: 0.9891 - recall: 0.8968 - f1_score: 0.9390 - val_loss: 0.2513 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2405 - acc: 0.9463 - precision: 0.9892 - recall: 0.8953 - f1_score: 0.9386 - val_loss: 0.2510 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9463 - precision: 0.9898 - recall: 0.8978 - f1_score: 0.9393 - val_loss: 0.2508 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9463 - precision: 0.9896 - recall: 0.8981 - f1_score: 0.9413 - val_loss: 0.2505 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2397 - acc: 0.9463 - precision: 0.9898 - recall: 0.8993 - f1_score: 0.9417 - val_loss: 0.2503 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2394 - acc: 0.9463 - precision: 0.9892 - recall: 0.8980 - f1_score: 0.9399 - val_loss: 0.2500 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2391 - acc: 0.9463 - precision: 0.9880 - recall: 0.8949 - f1_score: 0.9375 - val_loss: 0.2498 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9463 - precision: 0.9889 - recall: 0.8991 - f1_score: 0.9412 - val_loss: 0.2496 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9463 - precision: 0.9863 - recall: 0.8882 - f1_score: 0.9329 - val_loss: 0.2493 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9463 - precision: 0.9879 - recall: 0.8994 - f1_score: 0.9394 - val_loss: 0.2491 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2381 - acc: 0.9463 - precision: 0.9876 - recall: 0.8963 - f1_score: 0.9389 - val_loss: 0.2488 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2378 - acc: 0.9463 - precision: 0.9894 - recall: 0.8971 - f1_score: 0.9401 - val_loss: 0.2486 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2376 - acc: 0.9463 - precision: 0.9890 - recall: 0.8985 - f1_score: 0.9400 - val_loss: 0.2484 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2373 - acc: 0.9463 - precision: 0.9897 - recall: 0.8968 - f1_score: 0.9396 - val_loss: 0.2481 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2371 - acc: 0.9463 - precision: 0.9895 - recall: 0.9015 - f1_score: 0.9423 - val_loss: 0.2479 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2368 - acc: 0.9463 - precision: 0.9875 - recall: 0.8948 - f1_score: 0.9373 - val_loss: 0.2477 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2366 - acc: 0.9463 - precision: 0.9915 - recall: 0.8978 - f1_score: 0.9411 - val_loss: 0.2475 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2363 - acc: 0.9463 - precision: 0.9892 - recall: 0.8983 - f1_score: 0.9407 - val_loss: 0.2472 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9463 - precision: 0.9903 - recall: 0.8972 - f1_score: 0.9389 - val_loss: 0.2470 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9463 - precision: 0.9885 - recall: 0.8993 - f1_score: 0.9409 - val_loss: 0.2468 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2356 - acc: 0.9463 - precision: 0.9890 - recall: 0.8966 - f1_score: 0.9393 - val_loss: 0.2466 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9463 - precision: 0.9887 - recall: 0.9011 - f1_score: 0.9422 - val_loss: 0.2463 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2351 - acc: 0.9463 - precision: 0.9889 - recall: 0.8995 - f1_score: 0.9408 - val_loss: 0.2461 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2349 - acc: 0.9463 - precision: 0.9893 - recall: 0.8989 - f1_score: 0.9407 - val_loss: 0.2458 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9463 - precision: 0.9893 - recall: 0.8992 - f1_score: 0.9412 - val_loss: 0.2456 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9463 - precision: 0.9885 - recall: 0.8934 - f1_score: 0.9378 - val_loss: 0.2454 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9463 - precision: 0.9898 - recall: 0.8941 - f1_score: 0.9384 - val_loss: 0.2452 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 975/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9463 - precision: 0.9878 - recall: 0.9030 - f1_score: 0.9416 - val_loss: 0.2450 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9463 - precision: 0.9898 - recall: 0.8971 - f1_score: 0.9406 - val_loss: 0.2447 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9463 - precision: 0.9890 - recall: 0.8969 - f1_score: 0.9395 - val_loss: 0.2445 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9463 - precision: 0.9894 - recall: 0.8992 - f1_score: 0.9403 - val_loss: 0.2443 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2330 - acc: 0.9463 - precision: 0.9894 - recall: 0.8952 - f1_score: 0.9385 - val_loss: 0.2441 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9463 - precision: 0.9879 - recall: 0.8987 - f1_score: 0.9401 - val_loss: 0.2438 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9463 - precision: 0.9903 - recall: 0.8943 - f1_score: 0.9386 - val_loss: 0.2436 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9463 - precision: 0.9893 - recall: 0.8976 - f1_score: 0.9408 - val_loss: 0.2434 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2320 - acc: 0.9463 - precision: 0.9893 - recall: 0.8980 - f1_score: 0.9403 - val_loss: 0.2432 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2318 - acc: 0.9463 - precision: 0.9897 - recall: 0.9021 - f1_score: 0.9422 - val_loss: 0.2430 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2316 - acc: 0.9463 - precision: 0.9875 - recall: 0.8919 - f1_score: 0.9361 - val_loss: 0.2428 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2313 - acc: 0.9463 - precision: 0.9907 - recall: 0.8975 - f1_score: 0.9407 - val_loss: 0.2426 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2311 - acc: 0.9463 - precision: 0.9879 - recall: 0.8973 - f1_score: 0.9396 - val_loss: 0.2423 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2309 - acc: 0.9463 - precision: 0.9910 - recall: 0.8977 - f1_score: 0.9411 - val_loss: 0.2421 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2306 - acc: 0.9463 - precision: 0.9904 - recall: 0.8974 - f1_score: 0.9406 - val_loss: 0.2419 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2304 - acc: 0.9463 - precision: 0.9880 - recall: 0.8904 - f1_score: 0.9347 - val_loss: 0.2417 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2302 - acc: 0.9463 - precision: 0.9900 - recall: 0.8998 - f1_score: 0.9417 - val_loss: 0.2415 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2300 - acc: 0.9463 - precision: 0.9883 - recall: 0.8979 - f1_score: 0.9389 - val_loss: 0.2413 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2298 - acc: 0.9463 - precision: 0.9895 - recall: 0.8977 - f1_score: 0.9410 - val_loss: 0.2411 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2295 - acc: 0.9463 - precision: 0.9902 - recall: 0.8962 - f1_score: 0.9400 - val_loss: 0.2409 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2293 - acc: 0.9463 - precision: 0.9889 - recall: 0.8933 - f1_score: 0.9375 - val_loss: 0.2407 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2291 - acc: 0.9463 - precision: 0.9897 - recall: 0.9002 - f1_score: 0.9411 - val_loss: 0.2405 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1682 - acc: 0.9800 - precision: 1.0000 - recall: 0.9643 - f1_score: 0.981 - 0s - loss: 0.2289 - acc: 0.9463 - precision: 0.9883 - recall: 0.8937 - f1_score: 0.9373 - val_loss: 0.2403 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2287 - acc: 0.9463 - precision: 0.9895 - recall: 0.8964 - f1_score: 0.9400 - val_loss: 0.2401 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2284 - acc: 0.9463 - precision: 0.9884 - recall: 0.8957 - f1_score: 0.9387 - val_loss: 0.2399 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2282 - acc: 0.9463 - precision: 0.9886 - recall: 0.8976 - f1_score: 0.9405 - val_loss: 0.2397 - val_acc: 0.9430 - val_precision: 0.9752 - val_recall: 0.9263 - val_f1_score: 0.9489\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.0559 - acc: 0.6066 - precision: 0.5608 - recall: 0.9235 - f1_score: 0.6957 - val_loss: 6.0093 - val_acc: 0.6203 - val_precision: 0.5675 - val_recall: 0.9747 - val_f1_score: 0.7165\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9783 - acc: 0.6256 - precision: 0.5713 - recall: 0.9637 - f1_score: 0.7150 - val_loss: 5.9526 - val_acc: 0.6329 - val_precision: 0.5756 - val_recall: 0.9873 - val_f1_score: 0.7264\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9286 - acc: 0.6303 - precision: 0.5757 - recall: 0.9714 - f1_score: 0.7205 - val_loss: 5.9079 - val_acc: 0.6392 - val_precision: 0.5808 - val_recall: 0.9873 - val_f1_score: 0.7302\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8867 - acc: 0.6398 - precision: 0.5809 - recall: 0.9728 - f1_score: 0.7248 - val_loss: 5.8683 - val_acc: 0.6392 - val_precision: 0.5814 - val_recall: 0.9742 - val_f1_score: 0.7273\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8484 - acc: 0.6430 - precision: 0.5848 - recall: 0.9701 - f1_score: 0.7278 - val_loss: 5.8312 - val_acc: 0.6519 - val_precision: 0.5911 - val_recall: 0.9742 - val_f1_score: 0.7346\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.8120 - acc: 0.6493 - precision: 0.5899 - recall: 0.9695 - f1_score: 0.7282 - val_loss: 5.7958 - val_acc: 0.6582 - val_precision: 0.5956 - val_recall: 0.9742 - val_f1_score: 0.7379\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7770 - acc: 0.6588 - precision: 0.5967 - recall: 0.9614 - f1_score: 0.7343 - val_loss: 5.7614 - val_acc: 0.6646 - val_precision: 0.6016 - val_recall: 0.9742 - val_f1_score: 0.7417\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7428 - acc: 0.6746 - precision: 0.6076 - recall: 0.9541 - f1_score: 0.7372 - val_loss: 5.7278 - val_acc: 0.6709 - val_precision: 0.6058 - val_recall: 0.9742 - val_f1_score: 0.7451\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7094 - acc: 0.6919 - precision: 0.6249 - recall: 0.9562 - f1_score: 0.7540 - val_loss: 5.6949 - val_acc: 0.6835 - val_precision: 0.6160 - val_recall: 0.9742 - val_f1_score: 0.7526\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6766 - acc: 0.7125 - precision: 0.6393 - recall: 0.9528 - f1_score: 0.7628 - val_loss: 5.6626 - val_acc: 0.6835 - val_precision: 0.6160 - val_recall: 0.9742 - val_f1_score: 0.7526\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6443 - acc: 0.7346 - precision: 0.6627 - recall: 0.9472 - f1_score: 0.7786 - val_loss: 5.6306 - val_acc: 0.6962 - val_precision: 0.6269 - val_recall: 0.9615 - val_f1_score: 0.7571\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6124 - acc: 0.7536 - precision: 0.6801 - recall: 0.9513 - f1_score: 0.7905 - val_loss: 5.5991 - val_acc: 0.7089 - val_precision: 0.6376 - val_recall: 0.9615 - val_f1_score: 0.7650\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5809 - acc: 0.7694 - precision: 0.6923 - recall: 0.9408 - f1_score: 0.7953 - val_loss: 5.5679 - val_acc: 0.7342 - val_precision: 0.6606 - val_recall: 0.9615 - val_f1_score: 0.7811\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5498 - acc: 0.7773 - precision: 0.7061 - recall: 0.9399 - f1_score: 0.8053 - val_loss: 5.5371 - val_acc: 0.7595 - val_precision: 0.6849 - val_recall: 0.9615 - val_f1_score: 0.7979\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5190 - acc: 0.7946 - precision: 0.7262 - recall: 0.9364 - f1_score: 0.8154 - val_loss: 5.5066 - val_acc: 0.7658 - val_precision: 0.6918 - val_recall: 0.9615 - val_f1_score: 0.8025\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4885 - acc: 0.8009 - precision: 0.7372 - recall: 0.9326 - f1_score: 0.8219 - val_loss: 5.4763 - val_acc: 0.7848 - val_precision: 0.7143 - val_recall: 0.9615 - val_f1_score: 0.8165\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4583 - acc: 0.8073 - precision: 0.7429 - recall: 0.9274 - f1_score: 0.8239 - val_loss: 5.4464 - val_acc: 0.7911 - val_precision: 0.7223 - val_recall: 0.9488 - val_f1_score: 0.8176\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4284 - acc: 0.8152 - precision: 0.7531 - recall: 0.9272 - f1_score: 0.8272 - val_loss: 5.4167 - val_acc: 0.8228 - val_precision: 0.7550 - val_recall: 0.9488 - val_f1_score: 0.8399\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3987 - acc: 0.8325 - precision: 0.7788 - recall: 0.9315 - f1_score: 0.8466 - val_loss: 5.3873 - val_acc: 0.8228 - val_precision: 0.7609 - val_recall: 0.9357 - val_f1_score: 0.8383\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3694 - acc: 0.8420 - precision: 0.7872 - recall: 0.9219 - f1_score: 0.8462 - val_loss: 5.3581 - val_acc: 0.8228 - val_precision: 0.7668 - val_recall: 0.9230 - val_f1_score: 0.8362\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3402 - acc: 0.8436 - precision: 0.7947 - recall: 0.9237 - f1_score: 0.8536 - val_loss: 5.3292 - val_acc: 0.8481 - val_precision: 0.7993 - val_recall: 0.9230 - val_f1_score: 0.8562\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3114 - acc: 0.8547 - precision: 0.8113 - recall: 0.9237 - f1_score: 0.8632 - val_loss: 5.3006 - val_acc: 0.8418 - val_precision: 0.7969 - val_recall: 0.9098 - val_f1_score: 0.8493\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2828 - acc: 0.8626 - precision: 0.8203 - recall: 0.9230 - f1_score: 0.8675 - val_loss: 5.2721 - val_acc: 0.8544 - val_precision: 0.8158 - val_recall: 0.9098 - val_f1_score: 0.8601\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2544 - acc: 0.8720 - precision: 0.8342 - recall: 0.9205 - f1_score: 0.8729 - val_loss: 5.2439 - val_acc: 0.8544 - val_precision: 0.8158 - val_recall: 0.9098 - val_f1_score: 0.8601\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2263 - acc: 0.8799 - precision: 0.8541 - recall: 0.9142 - f1_score: 0.8822 - val_loss: 5.2159 - val_acc: 0.8671 - val_precision: 0.8356 - val_recall: 0.9098 - val_f1_score: 0.8708\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1984 - acc: 0.8863 - precision: 0.8596 - recall: 0.9114 - f1_score: 0.8831 - val_loss: 5.1882 - val_acc: 0.8734 - val_precision: 0.8458 - val_recall: 0.9098 - val_f1_score: 0.8760\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1707 - acc: 0.8878 - precision: 0.8687 - recall: 0.9151 - f1_score: 0.8891 - val_loss: 5.1606 - val_acc: 0.8797 - val_precision: 0.8570 - val_recall: 0.9098 - val_f1_score: 0.8820\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1432 - acc: 0.8989 - precision: 0.8870 - recall: 0.9156 - f1_score: 0.8988 - val_loss: 5.1333 - val_acc: 0.8861 - val_precision: 0.8654 - val_recall: 0.9098 - val_f1_score: 0.8866\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1160 - acc: 0.9036 - precision: 0.8923 - recall: 0.9127 - f1_score: 0.9007 - val_loss: 5.1062 - val_acc: 0.8861 - val_precision: 0.8654 - val_recall: 0.9098 - val_f1_score: 0.8866\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0889 - acc: 0.9084 - precision: 0.9030 - recall: 0.9124 - f1_score: 0.9063 - val_loss: 5.0792 - val_acc: 0.8861 - val_precision: 0.8654 - val_recall: 0.9098 - val_f1_score: 0.8866\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0620 - acc: 0.9100 - precision: 0.9035 - recall: 0.9105 - f1_score: 0.9049 - val_loss: 5.0524 - val_acc: 0.8987 - val_precision: 0.8864 - val_recall: 0.9098 - val_f1_score: 0.8974\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0354 - acc: 0.9147 - precision: 0.9175 - recall: 0.9108 - f1_score: 0.9118 - val_loss: 5.0259 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0089 - acc: 0.9163 - precision: 0.9269 - recall: 0.9073 - f1_score: 0.9149 - val_loss: 4.9995 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9826 - acc: 0.9210 - precision: 0.9355 - recall: 0.9030 - f1_score: 0.9179 - val_loss: 4.9733 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9565 - acc: 0.9194 - precision: 0.9367 - recall: 0.8989 - f1_score: 0.9157 - val_loss: 4.9474 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9306 - acc: 0.9210 - precision: 0.9401 - recall: 0.8967 - f1_score: 0.9154 - val_loss: 4.9215 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9049 - acc: 0.9210 - precision: 0.9415 - recall: 0.8915 - f1_score: 0.9144 - val_loss: 4.8959 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.8794 - acc: 0.9242 - precision: 0.9502 - recall: 0.8973 - f1_score: 0.9224 - val_loss: 4.8704 - val_acc: 0.9177 - val_precision: 0.9208 - val_recall: 0.9098 - val_f1_score: 0.9147\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8540 - acc: 0.9258 - precision: 0.9484 - recall: 0.8927 - f1_score: 0.9182 - val_loss: 4.8451 - val_acc: 0.9114 - val_precision: 0.9196 - val_recall: 0.8966 - val_f1_score: 0.9074\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8288 - acc: 0.9273 - precision: 0.9585 - recall: 0.8947 - f1_score: 0.9244 - val_loss: 4.8200 - val_acc: 0.9114 - val_precision: 0.9196 - val_recall: 0.8966 - val_f1_score: 0.9074\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8037 - acc: 0.9289 - precision: 0.9596 - recall: 0.8956 - f1_score: 0.9254 - val_loss: 4.7950 - val_acc: 0.9114 - val_precision: 0.9196 - val_recall: 0.8966 - val_f1_score: 0.9074\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7789 - acc: 0.9289 - precision: 0.9621 - recall: 0.8934 - f1_score: 0.9251 - val_loss: 4.7702 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7542 - acc: 0.9289 - precision: 0.9578 - recall: 0.8921 - f1_score: 0.9230 - val_loss: 4.7456 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7297 - acc: 0.9289 - precision: 0.9611 - recall: 0.8975 - f1_score: 0.9273 - val_loss: 4.7211 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7053 - acc: 0.9289 - precision: 0.9588 - recall: 0.8917 - f1_score: 0.9226 - val_loss: 4.6968 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6811 - acc: 0.9305 - precision: 0.9632 - recall: 0.8934 - f1_score: 0.9257 - val_loss: 4.6727 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6570 - acc: 0.9305 - precision: 0.9617 - recall: 0.8904 - f1_score: 0.9237 - val_loss: 4.6487 - val_acc: 0.9177 - val_precision: 0.9328 - val_recall: 0.8966 - val_f1_score: 0.9133\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6331 - acc: 0.9321 - precision: 0.9637 - recall: 0.8900 - f1_score: 0.9245 - val_loss: 4.6248 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6094 - acc: 0.9321 - precision: 0.9654 - recall: 0.8970 - f1_score: 0.9290 - val_loss: 4.6011 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5857 - acc: 0.9321 - precision: 0.9670 - recall: 0.8958 - f1_score: 0.9284 - val_loss: 4.5775 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5623 - acc: 0.9336 - precision: 0.9663 - recall: 0.8952 - f1_score: 0.9280 - val_loss: 4.5541 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5390 - acc: 0.9305 - precision: 0.9699 - recall: 0.8908 - f1_score: 0.9269 - val_loss: 4.5309 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5158 - acc: 0.9305 - precision: 0.9690 - recall: 0.8899 - f1_score: 0.9269 - val_loss: 4.5078 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4928 - acc: 0.9305 - precision: 0.9715 - recall: 0.8872 - f1_score: 0.9259 - val_loss: 4.4848 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4699 - acc: 0.9305 - precision: 0.9688 - recall: 0.8911 - f1_score: 0.9277 - val_loss: 4.4620 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4472 - acc: 0.9336 - precision: 0.9746 - recall: 0.8899 - f1_score: 0.9290 - val_loss: 4.4393 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4246 - acc: 0.9336 - precision: 0.9727 - recall: 0.8896 - f1_score: 0.9269 - val_loss: 4.4168 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4022 - acc: 0.9336 - precision: 0.9743 - recall: 0.8908 - f1_score: 0.9286 - val_loss: 4.3944 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3798 - acc: 0.9336 - precision: 0.9757 - recall: 0.8884 - f1_score: 0.9290 - val_loss: 4.3721 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3576 - acc: 0.9336 - precision: 0.9766 - recall: 0.8923 - f1_score: 0.9310 - val_loss: 4.3500 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3356 - acc: 0.9336 - precision: 0.9748 - recall: 0.8857 - f1_score: 0.9274 - val_loss: 4.3280 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3137 - acc: 0.9336 - precision: 0.9751 - recall: 0.8886 - f1_score: 0.9286 - val_loss: 4.3061 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2919 - acc: 0.9352 - precision: 0.9784 - recall: 0.8887 - f1_score: 0.9297 - val_loss: 4.2844 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2702 - acc: 0.9352 - precision: 0.9783 - recall: 0.8907 - f1_score: 0.9318 - val_loss: 4.2628 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2487 - acc: 0.9352 - precision: 0.9793 - recall: 0.8853 - f1_score: 0.9266 - val_loss: 4.2413 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2273 - acc: 0.9352 - precision: 0.9794 - recall: 0.8899 - f1_score: 0.9306 - val_loss: 4.2199 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2060 - acc: 0.9368 - precision: 0.9828 - recall: 0.8880 - f1_score: 0.9316 - val_loss: 4.1987 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1849 - acc: 0.9384 - precision: 0.9858 - recall: 0.8892 - f1_score: 0.9341 - val_loss: 4.1776 - val_acc: 0.9241 - val_precision: 0.9459 - val_recall: 0.8966 - val_f1_score: 0.9194\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1638 - acc: 0.9400 - precision: 0.9882 - recall: 0.8888 - f1_score: 0.9343 - val_loss: 4.1566 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.1429 - acc: 0.9415 - precision: 0.9911 - recall: 0.8845 - f1_score: 0.9330 - val_loss: 4.1358 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1221 - acc: 0.9415 - precision: 0.9937 - recall: 0.8837 - f1_score: 0.9331 - val_loss: 4.1151 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1015 - acc: 0.9415 - precision: 0.9931 - recall: 0.8898 - f1_score: 0.9378 - val_loss: 4.0944 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0809 - acc: 0.9415 - precision: 0.9917 - recall: 0.8853 - f1_score: 0.9342 - val_loss: 4.0740 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0605 - acc: 0.9415 - precision: 0.9926 - recall: 0.8913 - f1_score: 0.9383 - val_loss: 4.0536 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0402 - acc: 0.9415 - precision: 0.9922 - recall: 0.8890 - f1_score: 0.9370 - val_loss: 4.0333 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0200 - acc: 0.9415 - precision: 0.9937 - recall: 0.8876 - f1_score: 0.9371 - val_loss: 4.0132 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0000 - acc: 0.9415 - precision: 0.9928 - recall: 0.8879 - f1_score: 0.9363 - val_loss: 3.9932 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9800 - acc: 0.9415 - precision: 0.9937 - recall: 0.8940 - f1_score: 0.9401 - val_loss: 3.9733 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9602 - acc: 0.9415 - precision: 0.9919 - recall: 0.8866 - f1_score: 0.9353 - val_loss: 3.9535 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9404 - acc: 0.9415 - precision: 0.9937 - recall: 0.8900 - f1_score: 0.9377 - val_loss: 3.9338 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9208 - acc: 0.9415 - precision: 0.9931 - recall: 0.8902 - f1_score: 0.9379 - val_loss: 3.9142 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9013 - acc: 0.9415 - precision: 0.9941 - recall: 0.8866 - f1_score: 0.9361 - val_loss: 3.8948 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8820 - acc: 0.9415 - precision: 0.9925 - recall: 0.8852 - f1_score: 0.9346 - val_loss: 3.8755 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8627 - acc: 0.9415 - precision: 0.9937 - recall: 0.8898 - f1_score: 0.9382 - val_loss: 3.8563 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8435 - acc: 0.9415 - precision: 0.9936 - recall: 0.8824 - f1_score: 0.9317 - val_loss: 3.8371 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8244 - acc: 0.9415 - precision: 0.9922 - recall: 0.8867 - f1_score: 0.9351 - val_loss: 3.8181 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8055 - acc: 0.9415 - precision: 0.9922 - recall: 0.8836 - f1_score: 0.9327 - val_loss: 3.7992 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7866 - acc: 0.9415 - precision: 0.9933 - recall: 0.8873 - f1_score: 0.9365 - val_loss: 3.7804 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7679 - acc: 0.9400 - precision: 0.9940 - recall: 0.8801 - f1_score: 0.9326 - val_loss: 3.7617 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7492 - acc: 0.9400 - precision: 0.9919 - recall: 0.8847 - f1_score: 0.9341 - val_loss: 3.7431 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7307 - acc: 0.9400 - precision: 0.9929 - recall: 0.8849 - f1_score: 0.9343 - val_loss: 3.7247 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7123 - acc: 0.9400 - precision: 0.9931 - recall: 0.8817 - f1_score: 0.9318 - val_loss: 3.7063 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6940 - acc: 0.9400 - precision: 0.9930 - recall: 0.8838 - f1_score: 0.9335 - val_loss: 3.6880 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6757 - acc: 0.9400 - precision: 0.9928 - recall: 0.8838 - f1_score: 0.9331 - val_loss: 3.6698 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6576 - acc: 0.9400 - precision: 0.9934 - recall: 0.8848 - f1_score: 0.9349 - val_loss: 3.6517 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6396 - acc: 0.9400 - precision: 0.9925 - recall: 0.8854 - f1_score: 0.9337 - val_loss: 3.6338 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6217 - acc: 0.9400 - precision: 0.9938 - recall: 0.8846 - f1_score: 0.9345 - val_loss: 3.6159 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6038 - acc: 0.9400 - precision: 0.9920 - recall: 0.8816 - f1_score: 0.9308 - val_loss: 3.5981 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5861 - acc: 0.9415 - precision: 0.9961 - recall: 0.8852 - f1_score: 0.9362 - val_loss: 3.5804 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5685 - acc: 0.9384 - precision: 0.9970 - recall: 0.8714 - f1_score: 0.9274 - val_loss: 3.5628 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5509 - acc: 0.9384 - precision: 0.9961 - recall: 0.8730 - f1_score: 0.9288 - val_loss: 3.5454 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.5335 - acc: 0.9384 - precision: 0.9966 - recall: 0.8852 - f1_score: 0.9362 - val_loss: 3.5280 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5162 - acc: 0.9384 - precision: 0.9967 - recall: 0.8775 - f1_score: 0.9324 - val_loss: 3.5107 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4989 - acc: 0.9384 - precision: 0.9964 - recall: 0.8786 - f1_score: 0.9315 - val_loss: 3.4935 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4818 - acc: 0.9384 - precision: 0.9970 - recall: 0.8799 - f1_score: 0.9341 - val_loss: 3.4764 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4647 - acc: 0.9384 - precision: 0.9958 - recall: 0.8796 - f1_score: 0.9327 - val_loss: 3.4594 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4478 - acc: 0.9384 - precision: 0.9973 - recall: 0.8791 - f1_score: 0.9320 - val_loss: 3.4425 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4309 - acc: 0.9384 - precision: 0.9967 - recall: 0.8760 - f1_score: 0.9301 - val_loss: 3.4257 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4141 - acc: 0.9384 - precision: 0.9964 - recall: 0.8779 - f1_score: 0.9322 - val_loss: 3.4090 - val_acc: 0.9304 - val_precision: 0.9580 - val_recall: 0.8966 - val_f1_score: 0.9256\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3974 - acc: 0.9384 - precision: 0.9970 - recall: 0.8741 - f1_score: 0.9295 - val_loss: 3.3923 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3809 - acc: 0.9384 - precision: 0.9966 - recall: 0.8800 - f1_score: 0.9333 - val_loss: 3.3758 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3644 - acc: 0.9384 - precision: 0.9967 - recall: 0.8732 - f1_score: 0.9282 - val_loss: 3.3594 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3480 - acc: 0.9384 - precision: 0.9966 - recall: 0.8775 - f1_score: 0.9315 - val_loss: 3.3430 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3316 - acc: 0.9384 - precision: 0.9975 - recall: 0.8788 - f1_score: 0.9334 - val_loss: 3.3267 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3154 - acc: 0.9384 - precision: 0.9972 - recall: 0.8772 - f1_score: 0.9324 - val_loss: 3.3106 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2993 - acc: 0.9384 - precision: 0.9971 - recall: 0.8775 - f1_score: 0.9314 - val_loss: 3.2945 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2832 - acc: 0.9384 - precision: 0.9968 - recall: 0.8765 - f1_score: 0.9312 - val_loss: 3.2785 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2672 - acc: 0.9384 - precision: 0.9966 - recall: 0.8834 - f1_score: 0.9350 - val_loss: 3.2625 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2513 - acc: 0.9384 - precision: 0.9966 - recall: 0.8795 - f1_score: 0.9330 - val_loss: 3.2467 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2356 - acc: 0.9384 - precision: 0.9967 - recall: 0.8770 - f1_score: 0.9323 - val_loss: 3.2310 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2198 - acc: 0.9384 - precision: 0.9963 - recall: 0.8806 - f1_score: 0.9336 - val_loss: 3.2153 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2042 - acc: 0.9384 - precision: 0.9961 - recall: 0.8756 - f1_score: 0.9286 - val_loss: 3.1997 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1887 - acc: 0.9384 - precision: 0.9972 - recall: 0.8788 - f1_score: 0.9331 - val_loss: 3.1842 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1732 - acc: 0.9384 - precision: 0.9965 - recall: 0.8804 - f1_score: 0.9330 - val_loss: 3.1688 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1578 - acc: 0.9384 - precision: 0.9970 - recall: 0.8805 - f1_score: 0.9335 - val_loss: 3.1535 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1425 - acc: 0.9384 - precision: 0.9968 - recall: 0.8795 - f1_score: 0.9325 - val_loss: 3.1382 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1273 - acc: 0.9384 - precision: 0.9962 - recall: 0.8779 - f1_score: 0.9325 - val_loss: 3.1231 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1122 - acc: 0.9384 - precision: 0.9967 - recall: 0.8774 - f1_score: 0.9325 - val_loss: 3.1080 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0971 - acc: 0.9384 - precision: 0.9968 - recall: 0.8754 - f1_score: 0.9304 - val_loss: 3.0930 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0822 - acc: 0.9384 - precision: 0.9974 - recall: 0.8770 - f1_score: 0.9322 - val_loss: 3.0781 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0673 - acc: 0.9384 - precision: 0.9962 - recall: 0.8764 - f1_score: 0.9313 - val_loss: 3.0632 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0525 - acc: 0.9384 - precision: 0.9961 - recall: 0.8779 - f1_score: 0.9319 - val_loss: 3.0485 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0378 - acc: 0.9384 - precision: 0.9974 - recall: 0.8787 - f1_score: 0.9335 - val_loss: 3.0338 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.0231 - acc: 0.9384 - precision: 0.9968 - recall: 0.8780 - f1_score: 0.9331 - val_loss: 3.0192 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0085 - acc: 0.9384 - precision: 0.9967 - recall: 0.8806 - f1_score: 0.9336 - val_loss: 3.0047 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9941 - acc: 0.9384 - precision: 0.9973 - recall: 0.8784 - f1_score: 0.9334 - val_loss: 2.9902 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9797 - acc: 0.9384 - precision: 0.9968 - recall: 0.8792 - f1_score: 0.9326 - val_loss: 2.9759 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9653 - acc: 0.9384 - precision: 0.9967 - recall: 0.8778 - f1_score: 0.9323 - val_loss: 2.9616 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9511 - acc: 0.9384 - precision: 0.9968 - recall: 0.8787 - f1_score: 0.9320 - val_loss: 2.9474 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9369 - acc: 0.9384 - precision: 0.9970 - recall: 0.8748 - f1_score: 0.9311 - val_loss: 2.9332 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9228 - acc: 0.9384 - precision: 0.9961 - recall: 0.8783 - f1_score: 0.9324 - val_loss: 2.9192 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9087 - acc: 0.9384 - precision: 0.9954 - recall: 0.8791 - f1_score: 0.9319 - val_loss: 2.9052 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8948 - acc: 0.9384 - precision: 0.9962 - recall: 0.8774 - f1_score: 0.9326 - val_loss: 2.8913 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8809 - acc: 0.9384 - precision: 0.9962 - recall: 0.8796 - f1_score: 0.9331 - val_loss: 2.8775 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8671 - acc: 0.9384 - precision: 0.9958 - recall: 0.8759 - f1_score: 0.9302 - val_loss: 2.8637 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8534 - acc: 0.9384 - precision: 0.9970 - recall: 0.8788 - f1_score: 0.9332 - val_loss: 2.8500 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8397 - acc: 0.9384 - precision: 0.9956 - recall: 0.8781 - f1_score: 0.9319 - val_loss: 2.8364 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8261 - acc: 0.9384 - precision: 0.9967 - recall: 0.8798 - f1_score: 0.9332 - val_loss: 2.8229 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8126 - acc: 0.9384 - precision: 0.9956 - recall: 0.8825 - f1_score: 0.9350 - val_loss: 2.8094 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7991 - acc: 0.9384 - precision: 0.9967 - recall: 0.8815 - f1_score: 0.9340 - val_loss: 2.7960 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7858 - acc: 0.9384 - precision: 0.9964 - recall: 0.8777 - f1_score: 0.9307 - val_loss: 2.7827 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7725 - acc: 0.9384 - precision: 0.9956 - recall: 0.8779 - f1_score: 0.9321 - val_loss: 2.7694 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7592 - acc: 0.9384 - precision: 0.9966 - recall: 0.8800 - f1_score: 0.9328 - val_loss: 2.7562 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7461 - acc: 0.9384 - precision: 0.9966 - recall: 0.8776 - f1_score: 0.9324 - val_loss: 2.7431 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7330 - acc: 0.9384 - precision: 0.9966 - recall: 0.8780 - f1_score: 0.9318 - val_loss: 2.7301 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7200 - acc: 0.9384 - precision: 0.9958 - recall: 0.8775 - f1_score: 0.9318 - val_loss: 2.7171 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7070 - acc: 0.9384 - precision: 0.9956 - recall: 0.8776 - f1_score: 0.9319 - val_loss: 2.7042 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6941 - acc: 0.9384 - precision: 0.9964 - recall: 0.8810 - f1_score: 0.9339 - val_loss: 2.6913 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6813 - acc: 0.9384 - precision: 0.9972 - recall: 0.8756 - f1_score: 0.9309 - val_loss: 2.6786 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6686 - acc: 0.9384 - precision: 0.9972 - recall: 0.8785 - f1_score: 0.9330 - val_loss: 2.6659 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6559 - acc: 0.9384 - precision: 0.9966 - recall: 0.8797 - f1_score: 0.9330 - val_loss: 2.6532 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6433 - acc: 0.9384 - precision: 0.9951 - recall: 0.8776 - f1_score: 0.9320 - val_loss: 2.6407 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6307 - acc: 0.9384 - precision: 0.9968 - recall: 0.8765 - f1_score: 0.9312 - val_loss: 2.6282 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6182 - acc: 0.9384 - precision: 0.9967 - recall: 0.8809 - f1_score: 0.9341 - val_loss: 2.6157 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6058 - acc: 0.9384 - precision: 0.9958 - recall: 0.8804 - f1_score: 0.9340 - val_loss: 2.6033 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.5935 - acc: 0.9384 - precision: 0.9962 - recall: 0.8789 - f1_score: 0.9327 - val_loss: 2.5910 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5812 - acc: 0.9384 - precision: 0.9960 - recall: 0.8794 - f1_score: 0.9328 - val_loss: 2.5788 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5690 - acc: 0.9384 - precision: 0.9954 - recall: 0.8799 - f1_score: 0.9329 - val_loss: 2.5666 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5568 - acc: 0.9384 - precision: 0.9967 - recall: 0.8810 - f1_score: 0.9337 - val_loss: 2.5545 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5447 - acc: 0.9384 - precision: 0.9964 - recall: 0.8774 - f1_score: 0.9321 - val_loss: 2.5425 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5327 - acc: 0.9384 - precision: 0.9958 - recall: 0.8770 - f1_score: 0.9322 - val_loss: 2.5305 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5207 - acc: 0.9384 - precision: 0.9956 - recall: 0.8806 - f1_score: 0.9327 - val_loss: 2.5186 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5088 - acc: 0.9384 - precision: 0.9971 - recall: 0.8802 - f1_score: 0.9342 - val_loss: 2.5067 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4970 - acc: 0.9384 - precision: 0.9971 - recall: 0.8770 - f1_score: 0.9315 - val_loss: 2.4949 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4852 - acc: 0.9384 - precision: 0.9970 - recall: 0.8788 - f1_score: 0.9336 - val_loss: 2.4832 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4735 - acc: 0.9384 - precision: 0.9966 - recall: 0.8823 - f1_score: 0.9346 - val_loss: 2.4715 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4619 - acc: 0.9384 - precision: 0.9947 - recall: 0.8776 - f1_score: 0.9312 - val_loss: 2.4599 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4503 - acc: 0.9384 - precision: 0.9961 - recall: 0.8798 - f1_score: 0.9325 - val_loss: 2.4484 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4388 - acc: 0.9384 - precision: 0.9971 - recall: 0.8781 - f1_score: 0.9316 - val_loss: 2.4369 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4273 - acc: 0.9384 - precision: 0.9962 - recall: 0.8802 - f1_score: 0.9340 - val_loss: 2.4255 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4159 - acc: 0.9384 - precision: 0.9964 - recall: 0.8769 - f1_score: 0.9315 - val_loss: 2.4141 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4045 - acc: 0.9384 - precision: 0.9967 - recall: 0.8828 - f1_score: 0.9354 - val_loss: 2.4028 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3932 - acc: 0.9384 - precision: 0.9958 - recall: 0.8746 - f1_score: 0.9296 - val_loss: 2.3915 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3820 - acc: 0.9384 - precision: 0.9956 - recall: 0.8754 - f1_score: 0.9305 - val_loss: 2.3804 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3708 - acc: 0.9384 - precision: 0.9970 - recall: 0.8792 - f1_score: 0.9338 - val_loss: 2.3692 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3597 - acc: 0.9384 - precision: 0.9970 - recall: 0.8759 - f1_score: 0.9312 - val_loss: 2.3582 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3487 - acc: 0.9384 - precision: 0.9970 - recall: 0.8763 - f1_score: 0.9306 - val_loss: 2.3471 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3377 - acc: 0.9384 - precision: 0.9956 - recall: 0.8770 - f1_score: 0.9304 - val_loss: 2.3362 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3267 - acc: 0.9384 - precision: 0.9974 - recall: 0.8786 - f1_score: 0.9306 - val_loss: 2.3253 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3159 - acc: 0.9384 - precision: 0.9966 - recall: 0.8771 - f1_score: 0.9314 - val_loss: 2.3145 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3050 - acc: 0.9384 - precision: 0.9977 - recall: 0.8814 - f1_score: 0.9338 - val_loss: 2.3037 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2943 - acc: 0.9384 - precision: 0.9964 - recall: 0.8812 - f1_score: 0.9337 - val_loss: 2.2930 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2836 - acc: 0.9400 - precision: 0.9967 - recall: 0.8796 - f1_score: 0.9332 - val_loss: 2.2823 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2729 - acc: 0.9400 - precision: 0.9968 - recall: 0.8850 - f1_score: 0.9351 - val_loss: 2.2717 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2623 - acc: 0.9400 - precision: 0.9968 - recall: 0.8826 - f1_score: 0.9349 - val_loss: 2.2611 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.3190 - acc: 0.8400 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.809 - 0s - loss: 2.2518 - acc: 0.9400 - precision: 0.9968 - recall: 0.8824 - f1_score: 0.9343 - val_loss: 2.2506 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2413 - acc: 0.9400 - precision: 0.9964 - recall: 0.8858 - f1_score: 0.9362 - val_loss: 2.2402 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 198/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.2309 - acc: 0.9400 - precision: 0.9963 - recall: 0.8827 - f1_score: 0.9354 - val_loss: 2.2298 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2205 - acc: 0.9400 - precision: 0.9968 - recall: 0.8814 - f1_score: 0.9343 - val_loss: 2.2194 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2101 - acc: 0.9400 - precision: 0.9961 - recall: 0.8867 - f1_score: 0.9366 - val_loss: 2.2091 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1999 - acc: 0.9400 - precision: 0.9970 - recall: 0.8785 - f1_score: 0.9315 - val_loss: 2.1989 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1897 - acc: 0.9400 - precision: 0.9961 - recall: 0.8836 - f1_score: 0.9357 - val_loss: 2.1887 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1795 - acc: 0.9400 - precision: 0.9958 - recall: 0.8842 - f1_score: 0.9353 - val_loss: 2.1786 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1694 - acc: 0.9400 - precision: 0.9956 - recall: 0.8827 - f1_score: 0.9341 - val_loss: 2.1686 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1594 - acc: 0.9400 - precision: 0.9954 - recall: 0.8841 - f1_score: 0.9338 - val_loss: 2.1585 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1493 - acc: 0.9400 - precision: 0.9958 - recall: 0.8849 - f1_score: 0.9364 - val_loss: 2.1486 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1394 - acc: 0.9400 - precision: 0.9970 - recall: 0.8790 - f1_score: 0.9330 - val_loss: 2.1386 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1295 - acc: 0.9400 - precision: 0.9958 - recall: 0.8827 - f1_score: 0.9351 - val_loss: 2.1288 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1196 - acc: 0.9400 - precision: 0.9966 - recall: 0.8836 - f1_score: 0.9356 - val_loss: 2.1190 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1098 - acc: 0.9400 - precision: 0.9961 - recall: 0.8820 - f1_score: 0.9349 - val_loss: 2.1092 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1001 - acc: 0.9400 - precision: 0.9962 - recall: 0.8824 - f1_score: 0.9345 - val_loss: 2.0995 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0904 - acc: 0.9400 - precision: 0.9964 - recall: 0.8796 - f1_score: 0.9326 - val_loss: 2.0899 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0808 - acc: 0.9400 - precision: 0.9972 - recall: 0.8790 - f1_score: 0.9330 - val_loss: 2.0803 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0712 - acc: 0.9400 - precision: 0.9962 - recall: 0.8854 - f1_score: 0.9360 - val_loss: 2.0707 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0616 - acc: 0.9400 - precision: 0.9968 - recall: 0.8824 - f1_score: 0.9351 - val_loss: 2.0612 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0521 - acc: 0.9400 - precision: 0.9970 - recall: 0.8842 - f1_score: 0.9350 - val_loss: 2.0517 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0427 - acc: 0.9400 - precision: 0.9956 - recall: 0.8799 - f1_score: 0.9327 - val_loss: 2.0423 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0333 - acc: 0.9400 - precision: 0.9962 - recall: 0.8858 - f1_score: 0.9369 - val_loss: 2.0330 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0240 - acc: 0.9400 - precision: 0.9962 - recall: 0.8807 - f1_score: 0.9331 - val_loss: 2.0237 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0147 - acc: 0.9400 - precision: 0.9971 - recall: 0.8810 - f1_score: 0.9350 - val_loss: 2.0144 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0054 - acc: 0.9400 - precision: 0.9968 - recall: 0.8834 - f1_score: 0.9356 - val_loss: 2.0052 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9962 - acc: 0.9400 - precision: 0.9968 - recall: 0.8786 - f1_score: 0.9325 - val_loss: 1.9960 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9871 - acc: 0.9400 - precision: 0.9956 - recall: 0.8786 - f1_score: 0.9330 - val_loss: 1.9869 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9780 - acc: 0.9400 - precision: 0.9956 - recall: 0.8795 - f1_score: 0.9329 - val_loss: 1.9778 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9689 - acc: 0.9400 - precision: 0.9966 - recall: 0.8843 - f1_score: 0.9358 - val_loss: 1.9688 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9599 - acc: 0.9400 - precision: 0.9954 - recall: 0.8809 - f1_score: 0.9329 - val_loss: 1.9598 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9509 - acc: 0.9400 - precision: 0.9961 - recall: 0.8812 - f1_score: 0.9343 - val_loss: 1.9509 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9420 - acc: 0.9400 - precision: 0.9966 - recall: 0.8848 - f1_score: 0.9361 - val_loss: 1.9420 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9332 - acc: 0.9400 - precision: 0.9956 - recall: 0.8841 - f1_score: 0.9354 - val_loss: 1.9332 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.9243 - acc: 0.9400 - precision: 0.9958 - recall: 0.8796 - f1_score: 0.9333 - val_loss: 1.9244 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9156 - acc: 0.9400 - precision: 0.9970 - recall: 0.8839 - f1_score: 0.9358 - val_loss: 1.9157 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9068 - acc: 0.9400 - precision: 0.9958 - recall: 0.8857 - f1_score: 0.9360 - val_loss: 1.9070 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8981 - acc: 0.9400 - precision: 0.9966 - recall: 0.8821 - f1_score: 0.9345 - val_loss: 1.8983 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8895 - acc: 0.9400 - precision: 0.9958 - recall: 0.8841 - f1_score: 0.9356 - val_loss: 1.8897 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8809 - acc: 0.9400 - precision: 0.9958 - recall: 0.8836 - f1_score: 0.9357 - val_loss: 1.8811 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8724 - acc: 0.9400 - precision: 0.9972 - recall: 0.8841 - f1_score: 0.9357 - val_loss: 1.8726 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8639 - acc: 0.9400 - precision: 0.9967 - recall: 0.8850 - f1_score: 0.9363 - val_loss: 1.8642 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8554 - acc: 0.9400 - precision: 0.9967 - recall: 0.8811 - f1_score: 0.9348 - val_loss: 1.8557 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8470 - acc: 0.9400 - precision: 0.9967 - recall: 0.8809 - f1_score: 0.9345 - val_loss: 1.8473 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8386 - acc: 0.9400 - precision: 0.9963 - recall: 0.8833 - f1_score: 0.9353 - val_loss: 1.8390 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8303 - acc: 0.9400 - precision: 0.9966 - recall: 0.8821 - f1_score: 0.9335 - val_loss: 1.8307 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8220 - acc: 0.9400 - precision: 0.9968 - recall: 0.8844 - f1_score: 0.9351 - val_loss: 1.8224 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8137 - acc: 0.9400 - precision: 0.9958 - recall: 0.8796 - f1_score: 0.9322 - val_loss: 1.8142 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8055 - acc: 0.9400 - precision: 0.9966 - recall: 0.8827 - f1_score: 0.9353 - val_loss: 1.8061 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7974 - acc: 0.9400 - precision: 0.9958 - recall: 0.8832 - f1_score: 0.9349 - val_loss: 1.7979 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7892 - acc: 0.9400 - precision: 0.9968 - recall: 0.8806 - f1_score: 0.9345 - val_loss: 1.7898 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7812 - acc: 0.9400 - precision: 0.9962 - recall: 0.8834 - f1_score: 0.9350 - val_loss: 1.7818 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7731 - acc: 0.9400 - precision: 0.9964 - recall: 0.8782 - f1_score: 0.9323 - val_loss: 1.7738 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7651 - acc: 0.9400 - precision: 0.9951 - recall: 0.8790 - f1_score: 0.9324 - val_loss: 1.7658 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7572 - acc: 0.9400 - precision: 0.9967 - recall: 0.8803 - f1_score: 0.9339 - val_loss: 1.7579 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7493 - acc: 0.9400 - precision: 0.9962 - recall: 0.8800 - f1_score: 0.9341 - val_loss: 1.7500 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7414 - acc: 0.9400 - precision: 0.9966 - recall: 0.8792 - f1_score: 0.9334 - val_loss: 1.7422 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7336 - acc: 0.9400 - precision: 0.9964 - recall: 0.8861 - f1_score: 0.9366 - val_loss: 1.7344 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7258 - acc: 0.9400 - precision: 0.9970 - recall: 0.8779 - f1_score: 0.9322 - val_loss: 1.7267 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7180 - acc: 0.9400 - precision: 0.9961 - recall: 0.8819 - f1_score: 0.9349 - val_loss: 1.7189 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7103 - acc: 0.9400 - precision: 0.9967 - recall: 0.8797 - f1_score: 0.9332 - val_loss: 1.7113 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7027 - acc: 0.9400 - precision: 0.9962 - recall: 0.8803 - f1_score: 0.9335 - val_loss: 1.7036 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6951 - acc: 0.9400 - precision: 0.9966 - recall: 0.8821 - f1_score: 0.9347 - val_loss: 1.6960 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6875 - acc: 0.9400 - precision: 0.9962 - recall: 0.8806 - f1_score: 0.9336 - val_loss: 1.6885 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6799 - acc: 0.9400 - precision: 0.9972 - recall: 0.8804 - f1_score: 0.9331 - val_loss: 1.6809 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6724 - acc: 0.9400 - precision: 0.9958 - recall: 0.8832 - f1_score: 0.9356 - val_loss: 1.6735 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 262/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.6649 - acc: 0.9400 - precision: 0.9962 - recall: 0.8787 - f1_score: 0.9309 - val_loss: 1.6660 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6575 - acc: 0.9400 - precision: 0.9966 - recall: 0.8881 - f1_score: 0.9384 - val_loss: 1.6586 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6501 - acc: 0.9400 - precision: 0.9971 - recall: 0.8804 - f1_score: 0.9338 - val_loss: 1.6512 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6428 - acc: 0.9400 - precision: 0.9961 - recall: 0.8865 - f1_score: 0.9367 - val_loss: 1.6439 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6354 - acc: 0.9400 - precision: 0.9961 - recall: 0.8809 - f1_score: 0.9340 - val_loss: 1.6366 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6282 - acc: 0.9400 - precision: 0.9964 - recall: 0.8775 - f1_score: 0.9318 - val_loss: 1.6294 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6209 - acc: 0.9400 - precision: 0.9967 - recall: 0.8832 - f1_score: 0.9352 - val_loss: 1.6222 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6137 - acc: 0.9400 - precision: 0.9966 - recall: 0.8852 - f1_score: 0.9370 - val_loss: 1.6150 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6065 - acc: 0.9400 - precision: 0.9965 - recall: 0.8823 - f1_score: 0.9350 - val_loss: 1.6078 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5994 - acc: 0.9400 - precision: 0.9966 - recall: 0.8802 - f1_score: 0.9339 - val_loss: 1.6007 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5923 - acc: 0.9400 - precision: 0.9975 - recall: 0.8783 - f1_score: 0.9324 - val_loss: 1.5937 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5853 - acc: 0.9415 - precision: 0.9961 - recall: 0.8837 - f1_score: 0.9359 - val_loss: 1.5866 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5783 - acc: 0.9415 - precision: 0.9968 - recall: 0.8871 - f1_score: 0.9371 - val_loss: 1.5796 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5713 - acc: 0.9415 - precision: 0.9962 - recall: 0.8827 - f1_score: 0.9353 - val_loss: 1.5727 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5643 - acc: 0.9415 - precision: 0.9968 - recall: 0.8869 - f1_score: 0.9379 - val_loss: 1.5658 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5574 - acc: 0.9415 - precision: 0.9954 - recall: 0.8849 - f1_score: 0.9360 - val_loss: 1.5589 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5505 - acc: 0.9431 - precision: 0.9962 - recall: 0.8885 - f1_score: 0.9386 - val_loss: 1.5520 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5437 - acc: 0.9431 - precision: 0.9970 - recall: 0.8880 - f1_score: 0.9384 - val_loss: 1.5452 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5369 - acc: 0.9431 - precision: 0.9961 - recall: 0.8862 - f1_score: 0.9372 - val_loss: 1.5384 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5301 - acc: 0.9431 - precision: 0.9971 - recall: 0.8955 - f1_score: 0.9422 - val_loss: 1.5317 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5234 - acc: 0.9431 - precision: 0.9954 - recall: 0.8896 - f1_score: 0.9380 - val_loss: 1.5250 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5167 - acc: 0.9431 - precision: 0.9967 - recall: 0.8880 - f1_score: 0.9381 - val_loss: 1.5183 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5100 - acc: 0.9431 - precision: 0.9968 - recall: 0.8884 - f1_score: 0.9391 - val_loss: 1.5117 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5034 - acc: 0.9431 - precision: 0.9966 - recall: 0.8862 - f1_score: 0.9372 - val_loss: 1.5051 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4968 - acc: 0.9431 - precision: 0.9962 - recall: 0.8931 - f1_score: 0.9405 - val_loss: 1.4985 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4902 - acc: 0.9431 - precision: 0.9956 - recall: 0.8873 - f1_score: 0.9367 - val_loss: 1.4920 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4837 - acc: 0.9431 - precision: 0.9964 - recall: 0.8892 - f1_score: 0.9386 - val_loss: 1.4855 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4772 - acc: 0.9431 - precision: 0.9974 - recall: 0.8887 - f1_score: 0.9388 - val_loss: 1.4790 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4708 - acc: 0.9431 - precision: 0.9962 - recall: 0.8865 - f1_score: 0.9373 - val_loss: 1.4726 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4643 - acc: 0.9431 - precision: 0.9961 - recall: 0.8843 - f1_score: 0.9355 - val_loss: 1.4661 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4579 - acc: 0.9431 - precision: 0.9972 - recall: 0.8892 - f1_score: 0.9390 - val_loss: 1.4598 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4516 - acc: 0.9431 - precision: 0.9966 - recall: 0.8884 - f1_score: 0.9385 - val_loss: 1.4534 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4452 - acc: 0.9431 - precision: 0.9972 - recall: 0.8858 - f1_score: 0.9363 - val_loss: 1.4471 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4389 - acc: 0.9431 - precision: 0.9962 - recall: 0.8878 - f1_score: 0.9377 - val_loss: 1.4409 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4327 - acc: 0.9431 - precision: 0.9964 - recall: 0.8891 - f1_score: 0.9384 - val_loss: 1.4346 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4265 - acc: 0.9431 - precision: 0.9968 - recall: 0.8898 - f1_score: 0.9394 - val_loss: 1.4284 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4202 - acc: 0.9431 - precision: 0.9961 - recall: 0.8918 - f1_score: 0.9397 - val_loss: 1.4222 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4141 - acc: 0.9431 - precision: 0.9967 - recall: 0.8823 - f1_score: 0.9348 - val_loss: 1.4161 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4079 - acc: 0.9431 - precision: 0.9961 - recall: 0.8921 - f1_score: 0.9399 - val_loss: 1.4100 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4018 - acc: 0.9431 - precision: 0.9939 - recall: 0.8915 - f1_score: 0.9390 - val_loss: 1.4039 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3958 - acc: 0.9431 - precision: 0.9961 - recall: 0.8870 - f1_score: 0.9375 - val_loss: 1.3978 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3897 - acc: 0.9431 - precision: 0.9967 - recall: 0.8892 - f1_score: 0.9385 - val_loss: 1.3918 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3837 - acc: 0.9431 - precision: 0.9964 - recall: 0.8914 - f1_score: 0.9391 - val_loss: 1.3858 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3777 - acc: 0.9431 - precision: 0.9962 - recall: 0.8924 - f1_score: 0.9394 - val_loss: 1.3799 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3718 - acc: 0.9431 - precision: 0.9962 - recall: 0.8865 - f1_score: 0.9375 - val_loss: 1.3739 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3659 - acc: 0.9431 - precision: 0.9972 - recall: 0.8908 - f1_score: 0.9393 - val_loss: 1.3680 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3600 - acc: 0.9431 - precision: 0.9973 - recall: 0.8878 - f1_score: 0.9384 - val_loss: 1.3622 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3541 - acc: 0.9431 - precision: 0.9958 - recall: 0.8855 - f1_score: 0.9364 - val_loss: 1.3563 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3483 - acc: 0.9431 - precision: 0.9964 - recall: 0.8918 - f1_score: 0.9400 - val_loss: 1.3505 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3425 - acc: 0.9431 - precision: 0.9958 - recall: 0.8870 - f1_score: 0.9354 - val_loss: 1.3448 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3367 - acc: 0.9431 - precision: 0.9966 - recall: 0.8873 - f1_score: 0.9372 - val_loss: 1.3390 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3310 - acc: 0.9431 - precision: 0.9966 - recall: 0.8867 - f1_score: 0.9373 - val_loss: 1.3333 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3253 - acc: 0.9431 - precision: 0.9964 - recall: 0.8872 - f1_score: 0.9377 - val_loss: 1.3276 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3196 - acc: 0.9431 - precision: 0.9964 - recall: 0.8901 - f1_score: 0.9386 - val_loss: 1.3219 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3140 - acc: 0.9447 - precision: 0.9968 - recall: 0.8924 - f1_score: 0.9405 - val_loss: 1.3163 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3083 - acc: 0.9447 - precision: 0.9968 - recall: 0.8974 - f1_score: 0.9428 - val_loss: 1.3107 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3027 - acc: 0.9447 - precision: 0.9966 - recall: 0.8895 - f1_score: 0.9391 - val_loss: 1.3052 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2972 - acc: 0.9447 - precision: 0.9972 - recall: 0.8920 - f1_score: 0.9411 - val_loss: 1.2996 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2917 - acc: 0.9447 - precision: 0.9964 - recall: 0.8924 - f1_score: 0.9403 - val_loss: 1.2941 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2861 - acc: 0.9447 - precision: 0.9961 - recall: 0.8917 - f1_score: 0.9394 - val_loss: 1.2886 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2807 - acc: 0.9447 - precision: 0.9964 - recall: 0.9003 - f1_score: 0.9449 - val_loss: 1.2832 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2752 - acc: 0.9447 - precision: 0.9971 - recall: 0.8933 - f1_score: 0.9411 - val_loss: 1.2777 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2698 - acc: 0.9447 - precision: 0.9974 - recall: 0.8911 - f1_score: 0.9409 - val_loss: 1.2723 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2644 - acc: 0.9447 - precision: 0.9967 - recall: 0.8920 - f1_score: 0.9396 - val_loss: 1.2670 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 326/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2590 - acc: 0.9447 - precision: 0.9961 - recall: 0.8919 - f1_score: 0.9391 - val_loss: 1.2616 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2537 - acc: 0.9447 - precision: 0.9971 - recall: 0.8900 - f1_score: 0.9395 - val_loss: 1.2563 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2484 - acc: 0.9447 - precision: 0.9951 - recall: 0.8957 - f1_score: 0.9415 - val_loss: 1.2510 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2431 - acc: 0.9447 - precision: 0.9958 - recall: 0.8915 - f1_score: 0.9397 - val_loss: 1.2457 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2378 - acc: 0.9447 - precision: 0.9969 - recall: 0.8918 - f1_score: 0.9404 - val_loss: 1.2405 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2326 - acc: 0.9447 - precision: 0.9966 - recall: 0.8898 - f1_score: 0.9383 - val_loss: 1.2353 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2274 - acc: 0.9447 - precision: 0.9970 - recall: 0.8919 - f1_score: 0.9395 - val_loss: 1.2301 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2222 - acc: 0.9447 - precision: 0.9966 - recall: 0.8945 - f1_score: 0.9418 - val_loss: 1.2249 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2171 - acc: 0.9447 - precision: 0.9967 - recall: 0.8895 - f1_score: 0.9387 - val_loss: 1.2198 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2120 - acc: 0.9447 - precision: 0.9968 - recall: 0.8921 - f1_score: 0.9408 - val_loss: 1.2147 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2069 - acc: 0.9447 - precision: 0.9951 - recall: 0.8922 - f1_score: 0.9399 - val_loss: 1.2096 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2018 - acc: 0.9447 - precision: 0.9964 - recall: 0.8908 - f1_score: 0.9398 - val_loss: 1.2046 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1967 - acc: 0.9447 - precision: 0.9966 - recall: 0.8950 - f1_score: 0.9416 - val_loss: 1.1995 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1917 - acc: 0.9447 - precision: 0.9970 - recall: 0.8923 - f1_score: 0.9410 - val_loss: 1.1946 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1867 - acc: 0.9447 - precision: 0.9954 - recall: 0.8876 - f1_score: 0.9366 - val_loss: 1.1896 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1818 - acc: 0.9447 - precision: 0.9967 - recall: 0.8919 - f1_score: 0.9407 - val_loss: 1.1846 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1768 - acc: 0.9447 - precision: 0.9966 - recall: 0.8906 - f1_score: 0.9395 - val_loss: 1.1797 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1719 - acc: 0.9447 - precision: 0.9956 - recall: 0.8888 - f1_score: 0.9380 - val_loss: 1.1748 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1670 - acc: 0.9447 - precision: 0.9971 - recall: 0.8914 - f1_score: 0.9408 - val_loss: 1.1699 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1621 - acc: 0.9447 - precision: 0.9964 - recall: 0.8921 - f1_score: 0.9400 - val_loss: 1.1651 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1573 - acc: 0.9447 - precision: 0.9961 - recall: 0.8918 - f1_score: 0.9405 - val_loss: 1.1602 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1525 - acc: 0.9447 - precision: 0.9967 - recall: 0.8950 - f1_score: 0.9407 - val_loss: 1.1554 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1477 - acc: 0.9447 - precision: 0.9973 - recall: 0.8901 - f1_score: 0.9395 - val_loss: 1.1507 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1429 - acc: 0.9447 - precision: 0.9951 - recall: 0.8906 - f1_score: 0.9385 - val_loss: 1.1459 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1382 - acc: 0.9447 - precision: 0.9967 - recall: 0.8927 - f1_score: 0.9400 - val_loss: 1.1412 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1335 - acc: 0.9447 - precision: 0.9970 - recall: 0.8907 - f1_score: 0.9399 - val_loss: 1.1365 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1288 - acc: 0.9447 - precision: 0.9968 - recall: 0.8901 - f1_score: 0.9389 - val_loss: 1.1318 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1241 - acc: 0.9447 - precision: 0.9964 - recall: 0.8926 - f1_score: 0.9405 - val_loss: 1.1271 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1194 - acc: 0.9447 - precision: 0.9964 - recall: 0.8950 - f1_score: 0.9422 - val_loss: 1.1225 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1148 - acc: 0.9447 - precision: 0.9958 - recall: 0.8917 - f1_score: 0.9402 - val_loss: 1.1179 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1102 - acc: 0.9447 - precision: 0.9966 - recall: 0.8915 - f1_score: 0.9398 - val_loss: 1.1133 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1056 - acc: 0.9447 - precision: 0.9961 - recall: 0.8881 - f1_score: 0.9377 - val_loss: 1.1088 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 358/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1011 - acc: 0.9447 - precision: 0.9964 - recall: 0.8850 - f1_score: 0.9355 - val_loss: 1.1042 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0966 - acc: 0.9447 - precision: 0.9966 - recall: 0.8890 - f1_score: 0.9389 - val_loss: 1.0997 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0921 - acc: 0.9447 - precision: 0.9966 - recall: 0.8914 - f1_score: 0.9389 - val_loss: 1.0952 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0876 - acc: 0.9447 - precision: 0.9970 - recall: 0.8938 - f1_score: 0.9417 - val_loss: 1.0908 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0831 - acc: 0.9447 - precision: 0.9971 - recall: 0.8891 - f1_score: 0.9391 - val_loss: 1.0863 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0787 - acc: 0.9447 - precision: 0.9958 - recall: 0.8933 - f1_score: 0.9400 - val_loss: 1.0819 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0743 - acc: 0.9447 - precision: 0.9963 - recall: 0.8879 - f1_score: 0.9379 - val_loss: 1.0775 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0699 - acc: 0.9447 - precision: 0.9967 - recall: 0.8901 - f1_score: 0.9393 - val_loss: 1.0731 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0655 - acc: 0.9447 - precision: 0.9974 - recall: 0.8908 - f1_score: 0.9396 - val_loss: 1.0688 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0611 - acc: 0.9447 - precision: 0.9968 - recall: 0.8893 - f1_score: 0.9390 - val_loss: 1.0644 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0568 - acc: 0.9447 - precision: 0.9958 - recall: 0.8872 - f1_score: 0.9375 - val_loss: 1.0601 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0525 - acc: 0.9447 - precision: 0.9961 - recall: 0.8942 - f1_score: 0.9415 - val_loss: 1.0558 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0482 - acc: 0.9447 - precision: 0.9968 - recall: 0.8906 - f1_score: 0.9393 - val_loss: 1.0516 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0440 - acc: 0.9447 - precision: 0.9968 - recall: 0.8899 - f1_score: 0.9387 - val_loss: 1.0473 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0397 - acc: 0.9447 - precision: 0.9962 - recall: 0.8903 - f1_score: 0.9385 - val_loss: 1.0431 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0355 - acc: 0.9447 - precision: 0.9966 - recall: 0.8968 - f1_score: 0.9427 - val_loss: 1.0389 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0313 - acc: 0.9447 - precision: 0.9967 - recall: 0.8887 - f1_score: 0.9384 - val_loss: 1.0347 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0271 - acc: 0.9447 - precision: 0.9966 - recall: 0.8912 - f1_score: 0.9397 - val_loss: 1.0306 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0230 - acc: 0.9447 - precision: 0.9973 - recall: 0.8903 - f1_score: 0.9397 - val_loss: 1.0264 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0189 - acc: 0.9447 - precision: 0.9967 - recall: 0.8930 - f1_score: 0.9413 - val_loss: 1.0223 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0148 - acc: 0.9447 - precision: 0.9968 - recall: 0.8930 - f1_score: 0.9408 - val_loss: 1.0182 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0107 - acc: 0.9447 - precision: 0.9951 - recall: 0.8912 - f1_score: 0.9397 - val_loss: 1.0141 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0066 - acc: 0.9447 - precision: 0.9957 - recall: 0.8948 - f1_score: 0.9414 - val_loss: 1.0101 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0025 - acc: 0.9447 - precision: 0.9964 - recall: 0.8893 - f1_score: 0.9387 - val_loss: 1.0061 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9985 - acc: 0.9447 - precision: 0.9974 - recall: 0.8921 - f1_score: 0.9412 - val_loss: 1.0021 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9945 - acc: 0.9447 - precision: 0.9962 - recall: 0.8925 - f1_score: 0.9404 - val_loss: 0.9981 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9905 - acc: 0.9447 - precision: 0.9970 - recall: 0.8896 - f1_score: 0.9389 - val_loss: 0.9941 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9866 - acc: 0.9447 - precision: 0.9963 - recall: 0.8929 - f1_score: 0.9405 - val_loss: 0.9901 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9826 - acc: 0.9447 - precision: 0.9961 - recall: 0.8908 - f1_score: 0.9396 - val_loss: 0.9862 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9787 - acc: 0.9447 - precision: 0.9962 - recall: 0.8915 - f1_score: 0.9402 - val_loss: 0.9823 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9748 - acc: 0.9447 - precision: 0.9972 - recall: 0.8916 - f1_score: 0.9407 - val_loss: 0.9784 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9709 - acc: 0.9447 - precision: 0.9961 - recall: 0.8910 - f1_score: 0.9396 - val_loss: 0.9745 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9670 - acc: 0.9447 - precision: 0.9973 - recall: 0.8915 - f1_score: 0.9402 - val_loss: 0.9707 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9632 - acc: 0.9447 - precision: 0.9962 - recall: 0.8912 - f1_score: 0.9391 - val_loss: 0.9669 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9594 - acc: 0.9447 - precision: 0.9973 - recall: 0.8902 - f1_score: 0.9399 - val_loss: 0.9630 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9555 - acc: 0.9447 - precision: 0.9967 - recall: 0.8857 - f1_score: 0.9351 - val_loss: 0.9592 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9518 - acc: 0.9447 - precision: 0.9977 - recall: 0.8901 - f1_score: 0.9400 - val_loss: 0.9555 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9480 - acc: 0.9447 - precision: 0.9969 - recall: 0.8920 - f1_score: 0.9406 - val_loss: 0.9517 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9442 - acc: 0.9447 - precision: 0.9967 - recall: 0.8894 - f1_score: 0.9389 - val_loss: 0.9480 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9405 - acc: 0.9447 - precision: 0.9962 - recall: 0.8906 - f1_score: 0.9395 - val_loss: 0.9443 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9368 - acc: 0.9447 - precision: 0.9970 - recall: 0.8893 - f1_score: 0.9394 - val_loss: 0.9406 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9331 - acc: 0.9447 - precision: 0.9966 - recall: 0.8927 - f1_score: 0.9412 - val_loss: 0.9369 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.9240 - acc: 0.9600 - precision: 1.0000 - recall: 0.9231 - f1_score: 0.960 - 0s - loss: 0.9294 - acc: 0.9447 - precision: 0.9964 - recall: 0.8921 - f1_score: 0.9402 - val_loss: 0.9332 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9258 - acc: 0.9447 - precision: 0.9964 - recall: 0.8881 - f1_score: 0.9377 - val_loss: 0.9296 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9221 - acc: 0.9447 - precision: 0.9967 - recall: 0.8931 - f1_score: 0.9411 - val_loss: 0.9260 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9185 - acc: 0.9447 - precision: 0.9971 - recall: 0.8944 - f1_score: 0.9423 - val_loss: 0.9224 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9149 - acc: 0.9447 - precision: 0.9968 - recall: 0.8912 - f1_score: 0.9405 - val_loss: 0.9188 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9113 - acc: 0.9447 - precision: 0.9967 - recall: 0.8916 - f1_score: 0.9403 - val_loss: 0.9152 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9078 - acc: 0.9447 - precision: 0.9961 - recall: 0.8915 - f1_score: 0.9401 - val_loss: 0.9116 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9042 - acc: 0.9447 - precision: 0.9956 - recall: 0.8937 - f1_score: 0.9409 - val_loss: 0.9081 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9007 - acc: 0.9447 - precision: 0.9971 - recall: 0.8924 - f1_score: 0.9399 - val_loss: 0.9046 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8972 - acc: 0.9447 - precision: 0.9964 - recall: 0.8938 - f1_score: 0.9416 - val_loss: 0.9011 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8937 - acc: 0.9447 - precision: 0.9965 - recall: 0.8900 - f1_score: 0.9395 - val_loss: 0.8976 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8902 - acc: 0.9447 - precision: 0.9961 - recall: 0.8919 - f1_score: 0.9402 - val_loss: 0.8942 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8868 - acc: 0.9447 - precision: 0.9961 - recall: 0.8935 - f1_score: 0.9414 - val_loss: 0.8907 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8833 - acc: 0.9447 - precision: 0.9958 - recall: 0.8919 - f1_score: 0.9399 - val_loss: 0.8873 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8799 - acc: 0.9447 - precision: 0.9967 - recall: 0.8913 - f1_score: 0.9405 - val_loss: 0.8839 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8765 - acc: 0.9447 - precision: 0.9966 - recall: 0.8925 - f1_score: 0.9391 - val_loss: 0.8805 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8731 - acc: 0.9447 - precision: 0.9968 - recall: 0.8917 - f1_score: 0.9399 - val_loss: 0.8771 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8697 - acc: 0.9447 - precision: 0.9966 - recall: 0.8915 - f1_score: 0.9399 - val_loss: 0.8738 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8664 - acc: 0.9447 - precision: 0.9961 - recall: 0.8935 - f1_score: 0.9405 - val_loss: 0.8704 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8630 - acc: 0.9447 - precision: 0.9957 - recall: 0.8923 - f1_score: 0.9406 - val_loss: 0.8671 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8597 - acc: 0.9447 - precision: 0.9970 - recall: 0.8900 - f1_score: 0.9399 - val_loss: 0.8638 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8564 - acc: 0.9447 - precision: 0.9970 - recall: 0.8929 - f1_score: 0.9413 - val_loss: 0.8605 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8531 - acc: 0.9447 - precision: 0.9962 - recall: 0.8932 - f1_score: 0.9409 - val_loss: 0.8572 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8499 - acc: 0.9447 - precision: 0.9967 - recall: 0.8885 - f1_score: 0.9371 - val_loss: 0.8540 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8466 - acc: 0.9447 - precision: 0.9962 - recall: 0.8937 - f1_score: 0.9408 - val_loss: 0.8507 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8434 - acc: 0.9447 - precision: 0.9970 - recall: 0.8888 - f1_score: 0.9380 - val_loss: 0.8475 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8401 - acc: 0.9447 - precision: 0.9961 - recall: 0.8920 - f1_score: 0.9400 - val_loss: 0.8443 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8369 - acc: 0.9447 - precision: 0.9966 - recall: 0.8928 - f1_score: 0.9408 - val_loss: 0.8411 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8337 - acc: 0.9447 - precision: 0.9971 - recall: 0.8925 - f1_score: 0.9404 - val_loss: 0.8379 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8306 - acc: 0.9447 - precision: 0.9961 - recall: 0.8919 - f1_score: 0.9405 - val_loss: 0.8348 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8274 - acc: 0.9447 - precision: 0.9966 - recall: 0.8910 - f1_score: 0.9399 - val_loss: 0.8316 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8243 - acc: 0.9447 - precision: 0.9958 - recall: 0.8861 - f1_score: 0.9364 - val_loss: 0.8285 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8212 - acc: 0.9447 - precision: 0.9962 - recall: 0.8917 - f1_score: 0.9407 - val_loss: 0.8254 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8180 - acc: 0.9447 - precision: 0.9962 - recall: 0.8924 - f1_score: 0.9401 - val_loss: 0.8223 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8150 - acc: 0.9447 - precision: 0.9954 - recall: 0.8958 - f1_score: 0.9419 - val_loss: 0.8192 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8119 - acc: 0.9447 - precision: 0.9958 - recall: 0.8923 - f1_score: 0.9399 - val_loss: 0.8162 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8088 - acc: 0.9447 - precision: 0.9970 - recall: 0.8907 - f1_score: 0.9382 - val_loss: 0.8131 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8058 - acc: 0.9447 - precision: 0.9956 - recall: 0.8896 - f1_score: 0.9379 - val_loss: 0.8101 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8027 - acc: 0.9447 - precision: 0.9970 - recall: 0.8936 - f1_score: 0.9418 - val_loss: 0.8071 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7997 - acc: 0.9447 - precision: 0.9961 - recall: 0.8922 - f1_score: 0.9405 - val_loss: 0.8041 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7967 - acc: 0.9447 - precision: 0.9961 - recall: 0.8934 - f1_score: 0.9410 - val_loss: 0.8011 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7937 - acc: 0.9447 - precision: 0.9954 - recall: 0.8895 - f1_score: 0.9380 - val_loss: 0.7981 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7908 - acc: 0.9447 - precision: 0.9967 - recall: 0.8929 - f1_score: 0.9412 - val_loss: 0.7952 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7878 - acc: 0.9447 - precision: 0.9967 - recall: 0.8910 - f1_score: 0.9396 - val_loss: 0.7922 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7849 - acc: 0.9447 - precision: 0.9968 - recall: 0.8939 - f1_score: 0.9414 - val_loss: 0.7893 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7820 - acc: 0.9447 - precision: 0.9966 - recall: 0.8900 - f1_score: 0.9392 - val_loss: 0.7864 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7790 - acc: 0.9447 - precision: 0.9963 - recall: 0.8890 - f1_score: 0.9383 - val_loss: 0.7835 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7761 - acc: 0.9447 - precision: 0.9966 - recall: 0.8905 - f1_score: 0.9398 - val_loss: 0.7806 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7733 - acc: 0.9447 - precision: 0.9971 - recall: 0.8899 - f1_score: 0.9389 - val_loss: 0.7777 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7704 - acc: 0.9447 - precision: 0.9958 - recall: 0.8909 - f1_score: 0.9395 - val_loss: 0.7749 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7675 - acc: 0.9447 - precision: 0.9964 - recall: 0.8929 - f1_score: 0.9409 - val_loss: 0.7720 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7647 - acc: 0.9447 - precision: 0.9964 - recall: 0.8917 - f1_score: 0.9403 - val_loss: 0.7692 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7619 - acc: 0.9447 - precision: 0.9970 - recall: 0.8913 - f1_score: 0.9401 - val_loss: 0.7664 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7591 - acc: 0.9447 - precision: 0.9975 - recall: 0.8924 - f1_score: 0.9410 - val_loss: 0.7636 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7563 - acc: 0.9447 - precision: 0.9958 - recall: 0.8937 - f1_score: 0.9411 - val_loss: 0.7608 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7535 - acc: 0.9447 - precision: 0.9964 - recall: 0.8937 - f1_score: 0.9407 - val_loss: 0.7580 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7507 - acc: 0.9447 - precision: 0.9964 - recall: 0.8929 - f1_score: 0.9412 - val_loss: 0.7553 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7480 - acc: 0.9447 - precision: 0.9958 - recall: 0.8926 - f1_score: 0.9406 - val_loss: 0.7526 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7452 - acc: 0.9447 - precision: 0.9961 - recall: 0.8937 - f1_score: 0.9409 - val_loss: 0.7498 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7425 - acc: 0.9447 - precision: 0.9966 - recall: 0.8892 - f1_score: 0.9386 - val_loss: 0.7471 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7398 - acc: 0.9447 - precision: 0.9967 - recall: 0.8916 - f1_score: 0.9405 - val_loss: 0.7444 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7371 - acc: 0.9447 - precision: 0.9973 - recall: 0.8881 - f1_score: 0.9371 - val_loss: 0.7417 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7344 - acc: 0.9447 - precision: 0.9967 - recall: 0.8937 - f1_score: 0.9408 - val_loss: 0.7391 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7317 - acc: 0.9447 - precision: 0.9958 - recall: 0.8915 - f1_score: 0.9404 - val_loss: 0.7364 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7291 - acc: 0.9447 - precision: 0.9970 - recall: 0.8964 - f1_score: 0.9429 - val_loss: 0.7337 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7264 - acc: 0.9447 - precision: 0.9968 - recall: 0.8901 - f1_score: 0.9390 - val_loss: 0.7311 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7238 - acc: 0.9447 - precision: 0.9967 - recall: 0.8881 - f1_score: 0.9382 - val_loss: 0.7285 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7212 - acc: 0.9447 - precision: 0.9956 - recall: 0.8930 - f1_score: 0.9403 - val_loss: 0.7259 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7186 - acc: 0.9447 - precision: 0.9962 - recall: 0.8926 - f1_score: 0.9406 - val_loss: 0.7233 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7160 - acc: 0.9447 - precision: 0.9966 - recall: 0.8903 - f1_score: 0.9395 - val_loss: 0.7207 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7134 - acc: 0.9447 - precision: 0.9951 - recall: 0.8901 - f1_score: 0.9389 - val_loss: 0.7182 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.7504 - acc: 0.9000 - precision: 1.0000 - recall: 0.8148 - f1_score: 0.898 - 0s - loss: 0.7109 - acc: 0.9447 - precision: 0.9958 - recall: 0.8868 - f1_score: 0.9367 - val_loss: 0.7156 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7083 - acc: 0.9447 - precision: 0.9947 - recall: 0.8959 - f1_score: 0.9417 - val_loss: 0.7131 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7058 - acc: 0.9447 - precision: 0.9970 - recall: 0.8883 - f1_score: 0.9383 - val_loss: 0.7105 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7032 - acc: 0.9447 - precision: 0.9968 - recall: 0.8877 - f1_score: 0.9384 - val_loss: 0.7080 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7007 - acc: 0.9447 - precision: 0.9964 - recall: 0.8879 - f1_score: 0.9380 - val_loss: 0.7055 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6982 - acc: 0.9447 - precision: 0.9971 - recall: 0.8885 - f1_score: 0.9387 - val_loss: 0.7030 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6957 - acc: 0.9447 - precision: 0.9967 - recall: 0.8947 - f1_score: 0.9416 - val_loss: 0.7005 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6933 - acc: 0.9447 - precision: 0.9956 - recall: 0.8929 - f1_score: 0.9403 - val_loss: 0.6981 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6908 - acc: 0.9447 - precision: 0.9964 - recall: 0.8900 - f1_score: 0.9394 - val_loss: 0.6956 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6883 - acc: 0.9447 - precision: 0.9964 - recall: 0.8922 - f1_score: 0.9404 - val_loss: 0.6932 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6859 - acc: 0.9447 - precision: 0.9967 - recall: 0.8953 - f1_score: 0.9422 - val_loss: 0.6907 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6835 - acc: 0.9447 - precision: 0.9967 - recall: 0.8896 - f1_score: 0.9391 - val_loss: 0.6883 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6811 - acc: 0.9447 - precision: 0.9968 - recall: 0.8913 - f1_score: 0.9397 - val_loss: 0.6859 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6787 - acc: 0.9447 - precision: 0.9967 - recall: 0.8903 - f1_score: 0.9397 - val_loss: 0.6835 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6763 - acc: 0.9447 - precision: 0.9971 - recall: 0.8927 - f1_score: 0.9415 - val_loss: 0.6812 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 486/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6739 - acc: 0.9447 - precision: 0.9967 - recall: 0.8906 - f1_score: 0.9401 - val_loss: 0.6788 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6715 - acc: 0.9447 - precision: 0.9963 - recall: 0.8907 - f1_score: 0.9398 - val_loss: 0.6764 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6692 - acc: 0.9447 - precision: 0.9967 - recall: 0.8964 - f1_score: 0.9428 - val_loss: 0.6741 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6668 - acc: 0.9447 - precision: 0.9973 - recall: 0.8922 - f1_score: 0.9409 - val_loss: 0.6718 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6645 - acc: 0.9447 - precision: 0.9968 - recall: 0.8914 - f1_score: 0.9393 - val_loss: 0.6694 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6622 - acc: 0.9447 - precision: 0.9947 - recall: 0.8918 - f1_score: 0.9399 - val_loss: 0.6671 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6599 - acc: 0.9447 - precision: 0.9972 - recall: 0.8909 - f1_score: 0.9391 - val_loss: 0.6648 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6576 - acc: 0.9447 - precision: 0.9964 - recall: 0.8889 - f1_score: 0.9385 - val_loss: 0.6625 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6553 - acc: 0.9447 - precision: 0.9958 - recall: 0.8920 - f1_score: 0.9398 - val_loss: 0.6603 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6530 - acc: 0.9447 - precision: 0.9966 - recall: 0.8909 - f1_score: 0.9403 - val_loss: 0.6580 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6507 - acc: 0.9447 - precision: 0.9967 - recall: 0.8931 - f1_score: 0.9408 - val_loss: 0.6558 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6485 - acc: 0.9447 - precision: 0.9958 - recall: 0.8888 - f1_score: 0.9376 - val_loss: 0.6535 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6463 - acc: 0.9447 - precision: 0.9970 - recall: 0.8891 - f1_score: 0.9390 - val_loss: 0.6513 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6440 - acc: 0.9447 - precision: 0.9961 - recall: 0.8911 - f1_score: 0.9392 - val_loss: 0.6491 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6418 - acc: 0.9447 - precision: 0.9969 - recall: 0.8920 - f1_score: 0.9399 - val_loss: 0.6469 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6396 - acc: 0.9447 - precision: 0.9968 - recall: 0.8902 - f1_score: 0.9384 - val_loss: 0.6447 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6374 - acc: 0.9447 - precision: 0.9954 - recall: 0.8910 - f1_score: 0.9393 - val_loss: 0.6425 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6352 - acc: 0.9447 - precision: 0.9967 - recall: 0.8900 - f1_score: 0.9395 - val_loss: 0.6403 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6331 - acc: 0.9447 - precision: 0.9961 - recall: 0.8869 - f1_score: 0.9370 - val_loss: 0.6381 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6309 - acc: 0.9447 - precision: 0.9968 - recall: 0.8931 - f1_score: 0.9412 - val_loss: 0.6360 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6287 - acc: 0.9447 - precision: 0.9968 - recall: 0.8959 - f1_score: 0.9424 - val_loss: 0.6338 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6266 - acc: 0.9447 - precision: 0.9966 - recall: 0.8897 - f1_score: 0.9383 - val_loss: 0.6317 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6245 - acc: 0.9447 - precision: 0.9956 - recall: 0.8902 - f1_score: 0.9390 - val_loss: 0.6296 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6223 - acc: 0.9447 - precision: 0.9958 - recall: 0.8944 - f1_score: 0.9415 - val_loss: 0.6275 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6202 - acc: 0.9447 - precision: 0.9956 - recall: 0.8934 - f1_score: 0.9401 - val_loss: 0.6254 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6181 - acc: 0.9447 - precision: 0.9967 - recall: 0.8907 - f1_score: 0.9399 - val_loss: 0.6233 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6160 - acc: 0.9447 - precision: 0.9970 - recall: 0.8907 - f1_score: 0.9399 - val_loss: 0.6212 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6140 - acc: 0.9447 - precision: 0.9966 - recall: 0.8933 - f1_score: 0.9414 - val_loss: 0.6192 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6119 - acc: 0.9447 - precision: 0.9967 - recall: 0.8963 - f1_score: 0.9420 - val_loss: 0.6171 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6098 - acc: 0.9447 - precision: 0.9956 - recall: 0.8908 - f1_score: 0.9397 - val_loss: 0.6150 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6078 - acc: 0.9447 - precision: 0.9968 - recall: 0.8904 - f1_score: 0.9390 - val_loss: 0.6130 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6058 - acc: 0.9447 - precision: 0.9965 - recall: 0.8940 - f1_score: 0.9416 - val_loss: 0.6110 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 518/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6037 - acc: 0.9447 - precision: 0.9970 - recall: 0.8926 - f1_score: 0.9412 - val_loss: 0.6090 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6017 - acc: 0.9447 - precision: 0.9961 - recall: 0.8898 - f1_score: 0.9391 - val_loss: 0.6070 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5997 - acc: 0.9447 - precision: 0.9958 - recall: 0.8936 - f1_score: 0.9410 - val_loss: 0.6050 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5977 - acc: 0.9447 - precision: 0.9962 - recall: 0.8917 - f1_score: 0.9391 - val_loss: 0.6030 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5957 - acc: 0.9447 - precision: 0.9970 - recall: 0.8909 - f1_score: 0.9405 - val_loss: 0.6010 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5938 - acc: 0.9447 - precision: 0.9967 - recall: 0.8921 - f1_score: 0.9407 - val_loss: 0.5990 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5918 - acc: 0.9447 - precision: 0.9958 - recall: 0.8937 - f1_score: 0.9408 - val_loss: 0.5971 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5898 - acc: 0.9447 - precision: 0.9954 - recall: 0.8926 - f1_score: 0.9402 - val_loss: 0.5951 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5879 - acc: 0.9447 - precision: 0.9962 - recall: 0.8930 - f1_score: 0.9405 - val_loss: 0.5932 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5859 - acc: 0.9447 - precision: 0.9971 - recall: 0.8901 - f1_score: 0.9385 - val_loss: 0.5913 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5840 - acc: 0.9447 - precision: 0.9964 - recall: 0.8937 - f1_score: 0.9413 - val_loss: 0.5893 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5821 - acc: 0.9447 - precision: 0.9971 - recall: 0.8916 - f1_score: 0.9395 - val_loss: 0.5874 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5802 - acc: 0.9447 - precision: 0.9962 - recall: 0.8916 - f1_score: 0.9399 - val_loss: 0.5855 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5783 - acc: 0.9447 - precision: 0.9956 - recall: 0.8900 - f1_score: 0.9389 - val_loss: 0.5836 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5764 - acc: 0.9447 - precision: 0.9967 - recall: 0.8941 - f1_score: 0.9420 - val_loss: 0.5818 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5745 - acc: 0.9447 - precision: 0.9970 - recall: 0.8941 - f1_score: 0.9419 - val_loss: 0.5799 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5726 - acc: 0.9447 - precision: 0.9966 - recall: 0.8896 - f1_score: 0.9388 - val_loss: 0.5780 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5708 - acc: 0.9447 - precision: 0.9967 - recall: 0.8863 - f1_score: 0.9366 - val_loss: 0.5762 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5689 - acc: 0.9447 - precision: 0.9958 - recall: 0.8909 - f1_score: 0.9398 - val_loss: 0.5743 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5671 - acc: 0.9447 - precision: 0.9951 - recall: 0.8903 - f1_score: 0.9391 - val_loss: 0.5725 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5653 - acc: 0.9447 - precision: 0.9971 - recall: 0.8890 - f1_score: 0.9371 - val_loss: 0.5707 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5634 - acc: 0.9447 - precision: 0.9953 - recall: 0.8953 - f1_score: 0.9410 - val_loss: 0.5689 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5616 - acc: 0.9447 - precision: 0.9970 - recall: 0.8935 - f1_score: 0.9413 - val_loss: 0.5671 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5598 - acc: 0.9447 - precision: 0.9951 - recall: 0.8963 - f1_score: 0.9418 - val_loss: 0.5653 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5580 - acc: 0.9447 - precision: 0.9967 - recall: 0.8898 - f1_score: 0.9394 - val_loss: 0.5635 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5562 - acc: 0.9447 - precision: 0.9968 - recall: 0.8924 - f1_score: 0.9406 - val_loss: 0.5617 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5544 - acc: 0.9447 - precision: 0.9971 - recall: 0.8923 - f1_score: 0.9407 - val_loss: 0.5599 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5527 - acc: 0.9447 - precision: 0.9964 - recall: 0.8910 - f1_score: 0.9394 - val_loss: 0.5582 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5509 - acc: 0.9447 - precision: 0.9963 - recall: 0.8905 - f1_score: 0.9393 - val_loss: 0.5564 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5491 - acc: 0.9447 - precision: 0.9968 - recall: 0.8936 - f1_score: 0.9406 - val_loss: 0.5547 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5474 - acc: 0.9447 - precision: 0.9967 - recall: 0.8921 - f1_score: 0.9409 - val_loss: 0.5529 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5457 - acc: 0.9447 - precision: 0.9966 - recall: 0.8918 - f1_score: 0.9404 - val_loss: 0.5512 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 550/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5439 - acc: 0.9447 - precision: 0.9970 - recall: 0.8868 - f1_score: 0.9373 - val_loss: 0.5495 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5422 - acc: 0.9447 - precision: 0.9964 - recall: 0.8964 - f1_score: 0.9425 - val_loss: 0.5478 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5405 - acc: 0.9431 - precision: 0.9931 - recall: 0.8884 - f1_score: 0.9366 - val_loss: 0.5461 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5388 - acc: 0.9447 - precision: 0.9961 - recall: 0.8907 - f1_score: 0.9386 - val_loss: 0.5444 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5371 - acc: 0.9431 - precision: 0.9939 - recall: 0.8887 - f1_score: 0.9372 - val_loss: 0.5427 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5354 - acc: 0.9431 - precision: 0.9921 - recall: 0.8922 - f1_score: 0.9386 - val_loss: 0.5410 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5337 - acc: 0.9431 - precision: 0.9933 - recall: 0.8926 - f1_score: 0.9395 - val_loss: 0.5393 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5321 - acc: 0.9431 - precision: 0.9941 - recall: 0.8940 - f1_score: 0.9401 - val_loss: 0.5377 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5304 - acc: 0.9447 - precision: 0.9938 - recall: 0.8930 - f1_score: 0.9385 - val_loss: 0.5360 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5288 - acc: 0.9431 - precision: 0.9928 - recall: 0.8957 - f1_score: 0.9403 - val_loss: 0.5344 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5271 - acc: 0.9447 - precision: 0.9939 - recall: 0.9011 - f1_score: 0.9440 - val_loss: 0.5328 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5255 - acc: 0.9447 - precision: 0.9937 - recall: 0.8947 - f1_score: 0.9406 - val_loss: 0.5311 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5238 - acc: 0.9447 - precision: 0.9923 - recall: 0.8946 - f1_score: 0.9396 - val_loss: 0.5295 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5222 - acc: 0.9447 - precision: 0.9933 - recall: 0.8936 - f1_score: 0.9398 - val_loss: 0.5279 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5206 - acc: 0.9447 - precision: 0.9931 - recall: 0.8949 - f1_score: 0.9401 - val_loss: 0.5263 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5190 - acc: 0.9447 - precision: 0.9931 - recall: 0.8951 - f1_score: 0.9407 - val_loss: 0.5247 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5174 - acc: 0.9447 - precision: 0.9928 - recall: 0.8922 - f1_score: 0.9385 - val_loss: 0.5231 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5158 - acc: 0.9447 - precision: 0.9930 - recall: 0.8970 - f1_score: 0.9422 - val_loss: 0.5215 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5142 - acc: 0.9447 - precision: 0.9923 - recall: 0.8942 - f1_score: 0.9399 - val_loss: 0.5199 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5127 - acc: 0.9447 - precision: 0.9933 - recall: 0.8956 - f1_score: 0.9411 - val_loss: 0.5184 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5111 - acc: 0.9447 - precision: 0.9941 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 0.5168 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5095 - acc: 0.9447 - precision: 0.9912 - recall: 0.8890 - f1_score: 0.9364 - val_loss: 0.5153 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5080 - acc: 0.9447 - precision: 0.9939 - recall: 0.8955 - f1_score: 0.9412 - val_loss: 0.5137 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5065 - acc: 0.9447 - precision: 0.9941 - recall: 0.8958 - f1_score: 0.9410 - val_loss: 0.5122 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5049 - acc: 0.9447 - precision: 0.9919 - recall: 0.8949 - f1_score: 0.9401 - val_loss: 0.5107 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5034 - acc: 0.9447 - precision: 0.9924 - recall: 0.8918 - f1_score: 0.9368 - val_loss: 0.5091 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5019 - acc: 0.9447 - precision: 0.9931 - recall: 0.8954 - f1_score: 0.9409 - val_loss: 0.5076 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5004 - acc: 0.9447 - precision: 0.9931 - recall: 0.9032 - f1_score: 0.9441 - val_loss: 0.5061 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4989 - acc: 0.9447 - precision: 0.9923 - recall: 0.8934 - f1_score: 0.9391 - val_loss: 0.5046 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4974 - acc: 0.9447 - precision: 0.9928 - recall: 0.8958 - f1_score: 0.9404 - val_loss: 0.5031 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4959 - acc: 0.9447 - precision: 0.9928 - recall: 0.8957 - f1_score: 0.9411 - val_loss: 0.5017 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4944 - acc: 0.9447 - precision: 0.9943 - recall: 0.8937 - f1_score: 0.9402 - val_loss: 0.5002 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 582/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4929 - acc: 0.9447 - precision: 0.9928 - recall: 0.8961 - f1_score: 0.9412 - val_loss: 0.4987 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4914 - acc: 0.9447 - precision: 0.9935 - recall: 0.8939 - f1_score: 0.9396 - val_loss: 0.4973 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4900 - acc: 0.9447 - precision: 0.9924 - recall: 0.9014 - f1_score: 0.9437 - val_loss: 0.4958 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4885 - acc: 0.9447 - precision: 0.9924 - recall: 0.8897 - f1_score: 0.9372 - val_loss: 0.4944 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4871 - acc: 0.9447 - precision: 0.9938 - recall: 0.8962 - f1_score: 0.9414 - val_loss: 0.4929 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4856 - acc: 0.9447 - precision: 0.9949 - recall: 0.8970 - f1_score: 0.9421 - val_loss: 0.4915 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4842 - acc: 0.9447 - precision: 0.9933 - recall: 0.8953 - f1_score: 0.9407 - val_loss: 0.4901 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4828 - acc: 0.9447 - precision: 0.9934 - recall: 0.8934 - f1_score: 0.9396 - val_loss: 0.4886 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4814 - acc: 0.9447 - precision: 0.9928 - recall: 0.9002 - f1_score: 0.9421 - val_loss: 0.4872 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4799 - acc: 0.9447 - precision: 0.9933 - recall: 0.8962 - f1_score: 0.9417 - val_loss: 0.4858 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4785 - acc: 0.9447 - precision: 0.9942 - recall: 0.8944 - f1_score: 0.9404 - val_loss: 0.4844 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4771 - acc: 0.9447 - precision: 0.9930 - recall: 0.8952 - f1_score: 0.9404 - val_loss: 0.4830 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4757 - acc: 0.9447 - precision: 0.9917 - recall: 0.8927 - f1_score: 0.9388 - val_loss: 0.4817 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4744 - acc: 0.9447 - precision: 0.9934 - recall: 0.8968 - f1_score: 0.9409 - val_loss: 0.4803 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4730 - acc: 0.9447 - precision: 0.9935 - recall: 0.8938 - f1_score: 0.9405 - val_loss: 0.4789 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4716 - acc: 0.9447 - precision: 0.9936 - recall: 0.8928 - f1_score: 0.9385 - val_loss: 0.4776 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4703 - acc: 0.9447 - precision: 0.9931 - recall: 0.8973 - f1_score: 0.9416 - val_loss: 0.4762 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4689 - acc: 0.9447 - precision: 0.9928 - recall: 0.8918 - f1_score: 0.9386 - val_loss: 0.4748 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4675 - acc: 0.9447 - precision: 0.9930 - recall: 0.8942 - f1_score: 0.9400 - val_loss: 0.4735 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4662 - acc: 0.9447 - precision: 0.9917 - recall: 0.8903 - f1_score: 0.9370 - val_loss: 0.4722 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4649 - acc: 0.9447 - precision: 0.9939 - recall: 0.8936 - f1_score: 0.9398 - val_loss: 0.4708 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4635 - acc: 0.9447 - precision: 0.9926 - recall: 0.8898 - f1_score: 0.9370 - val_loss: 0.4695 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4622 - acc: 0.9447 - precision: 0.9933 - recall: 0.8945 - f1_score: 0.9407 - val_loss: 0.4682 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4609 - acc: 0.9447 - precision: 0.9924 - recall: 0.8952 - f1_score: 0.9407 - val_loss: 0.4669 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4596 - acc: 0.9447 - precision: 0.9936 - recall: 0.8938 - f1_score: 0.9398 - val_loss: 0.4656 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4583 - acc: 0.9447 - precision: 0.9941 - recall: 0.8898 - f1_score: 0.9375 - val_loss: 0.4643 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4570 - acc: 0.9447 - precision: 0.9945 - recall: 0.8911 - f1_score: 0.9387 - val_loss: 0.4630 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4557 - acc: 0.9447 - precision: 0.9940 - recall: 0.9017 - f1_score: 0.9440 - val_loss: 0.4617 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4544 - acc: 0.9447 - precision: 0.9928 - recall: 0.8978 - f1_score: 0.9420 - val_loss: 0.4604 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4632 - acc: 0.9380 - precision: 0.9900 - recall: 0.8833 - f1_score: 0.932 - 0s - loss: 0.4531 - acc: 0.9447 - precision: 0.9921 - recall: 0.8955 - f1_score: 0.9404 - val_loss: 0.4592 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4518 - acc: 0.9447 - precision: 0.9932 - recall: 0.8963 - f1_score: 0.9401 - val_loss: 0.4579 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4506 - acc: 0.9447 - precision: 0.9926 - recall: 0.8962 - f1_score: 0.9415 - val_loss: 0.4566 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4493 - acc: 0.9447 - precision: 0.9926 - recall: 0.8965 - f1_score: 0.9417 - val_loss: 0.4554 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4481 - acc: 0.9447 - precision: 0.9935 - recall: 0.8980 - f1_score: 0.9417 - val_loss: 0.4541 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4468 - acc: 0.9447 - precision: 0.9913 - recall: 0.8957 - f1_score: 0.9404 - val_loss: 0.4529 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4456 - acc: 0.9447 - precision: 0.9934 - recall: 0.8914 - f1_score: 0.9383 - val_loss: 0.4517 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4443 - acc: 0.9447 - precision: 0.9917 - recall: 0.8897 - f1_score: 0.9363 - val_loss: 0.4504 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4431 - acc: 0.9447 - precision: 0.9928 - recall: 0.8955 - f1_score: 0.9407 - val_loss: 0.4492 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4419 - acc: 0.9447 - precision: 0.9934 - recall: 0.8884 - f1_score: 0.9361 - val_loss: 0.4480 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4406 - acc: 0.9447 - precision: 0.9920 - recall: 0.8964 - f1_score: 0.9414 - val_loss: 0.4468 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4394 - acc: 0.9447 - precision: 0.9935 - recall: 0.8890 - f1_score: 0.9371 - val_loss: 0.4456 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4382 - acc: 0.9447 - precision: 0.9937 - recall: 0.8965 - f1_score: 0.9419 - val_loss: 0.4444 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4370 - acc: 0.9447 - precision: 0.9925 - recall: 0.8941 - f1_score: 0.9402 - val_loss: 0.4432 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4358 - acc: 0.9447 - precision: 0.9916 - recall: 0.8933 - f1_score: 0.9388 - val_loss: 0.4420 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4346 - acc: 0.9447 - precision: 0.9933 - recall: 0.8937 - f1_score: 0.9397 - val_loss: 0.4408 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4334 - acc: 0.9447 - precision: 0.9936 - recall: 0.8965 - f1_score: 0.9409 - val_loss: 0.4396 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4323 - acc: 0.9447 - precision: 0.9919 - recall: 0.8955 - f1_score: 0.9397 - val_loss: 0.4384 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4311 - acc: 0.9447 - precision: 0.9933 - recall: 0.8906 - f1_score: 0.9362 - val_loss: 0.4373 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4299 - acc: 0.9447 - precision: 0.9919 - recall: 0.8936 - f1_score: 0.9397 - val_loss: 0.4361 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4288 - acc: 0.9447 - precision: 0.9939 - recall: 0.8934 - f1_score: 0.9403 - val_loss: 0.4350 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4276 - acc: 0.9447 - precision: 0.9942 - recall: 0.8961 - f1_score: 0.9418 - val_loss: 0.4338 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4265 - acc: 0.9447 - precision: 0.9931 - recall: 0.8954 - f1_score: 0.9408 - val_loss: 0.4327 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4253 - acc: 0.9447 - precision: 0.9916 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 0.4315 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4242 - acc: 0.9447 - precision: 0.9935 - recall: 0.8960 - f1_score: 0.9412 - val_loss: 0.4304 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4230 - acc: 0.9447 - precision: 0.9935 - recall: 0.8897 - f1_score: 0.9364 - val_loss: 0.4293 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4219 - acc: 0.9447 - precision: 0.9944 - recall: 0.8919 - f1_score: 0.9384 - val_loss: 0.4281 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4208 - acc: 0.9447 - precision: 0.9937 - recall: 0.8959 - f1_score: 0.9412 - val_loss: 0.4270 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4197 - acc: 0.9447 - precision: 0.9934 - recall: 0.8928 - f1_score: 0.9385 - val_loss: 0.4259 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4185 - acc: 0.9447 - precision: 0.9940 - recall: 0.8908 - f1_score: 0.9390 - val_loss: 0.4248 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4174 - acc: 0.9447 - precision: 0.9925 - recall: 0.8955 - f1_score: 0.9396 - val_loss: 0.4237 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4163 - acc: 0.9447 - precision: 0.9927 - recall: 0.8999 - f1_score: 0.9427 - val_loss: 0.4226 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4152 - acc: 0.9447 - precision: 0.9933 - recall: 0.9004 - f1_score: 0.9435 - val_loss: 0.4215 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4141 - acc: 0.9447 - precision: 0.9939 - recall: 0.8975 - f1_score: 0.9422 - val_loss: 0.4204 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4131 - acc: 0.9447 - precision: 0.9934 - recall: 0.8948 - f1_score: 0.9402 - val_loss: 0.4194 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 646/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4120 - acc: 0.9447 - precision: 0.9928 - recall: 0.8974 - f1_score: 0.9416 - val_loss: 0.4183 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4109 - acc: 0.9447 - precision: 0.9928 - recall: 0.8906 - f1_score: 0.9365 - val_loss: 0.4172 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4098 - acc: 0.9447 - precision: 0.9918 - recall: 0.8973 - f1_score: 0.9411 - val_loss: 0.4161 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4088 - acc: 0.9447 - precision: 0.9941 - recall: 0.8974 - f1_score: 0.9415 - val_loss: 0.4151 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4077 - acc: 0.9447 - precision: 0.9933 - recall: 0.8965 - f1_score: 0.9412 - val_loss: 0.4140 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4067 - acc: 0.9447 - precision: 0.9930 - recall: 0.8947 - f1_score: 0.9404 - val_loss: 0.4130 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4056 - acc: 0.9447 - precision: 0.9937 - recall: 0.8959 - f1_score: 0.9415 - val_loss: 0.4119 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4046 - acc: 0.9447 - precision: 0.9931 - recall: 0.8959 - f1_score: 0.9414 - val_loss: 0.4109 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4035 - acc: 0.9447 - precision: 0.9944 - recall: 0.8918 - f1_score: 0.9376 - val_loss: 0.4099 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4025 - acc: 0.9447 - precision: 0.9930 - recall: 0.8968 - f1_score: 0.9414 - val_loss: 0.4089 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4015 - acc: 0.9447 - precision: 0.9922 - recall: 0.8930 - f1_score: 0.9392 - val_loss: 0.4078 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4004 - acc: 0.9447 - precision: 0.9934 - recall: 0.8977 - f1_score: 0.9422 - val_loss: 0.4068 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3994 - acc: 0.9447 - precision: 0.9933 - recall: 0.8941 - f1_score: 0.9406 - val_loss: 0.4058 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3984 - acc: 0.9447 - precision: 0.9918 - recall: 0.8968 - f1_score: 0.9399 - val_loss: 0.4048 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3974 - acc: 0.9447 - precision: 0.9938 - recall: 0.8920 - f1_score: 0.9389 - val_loss: 0.4038 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3964 - acc: 0.9447 - precision: 0.9943 - recall: 0.9020 - f1_score: 0.9445 - val_loss: 0.4028 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3954 - acc: 0.9447 - precision: 0.9916 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 0.4018 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3944 - acc: 0.9447 - precision: 0.9927 - recall: 0.8916 - f1_score: 0.9381 - val_loss: 0.4008 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3934 - acc: 0.9447 - precision: 0.9934 - recall: 0.8967 - f1_score: 0.9415 - val_loss: 0.3998 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3924 - acc: 0.9447 - precision: 0.9923 - recall: 0.8954 - f1_score: 0.9399 - val_loss: 0.3988 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3914 - acc: 0.9447 - precision: 0.9939 - recall: 0.8957 - f1_score: 0.9412 - val_loss: 0.3979 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3904 - acc: 0.9447 - precision: 0.9931 - recall: 0.8945 - f1_score: 0.9405 - val_loss: 0.3969 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3895 - acc: 0.9447 - precision: 0.9939 - recall: 0.8963 - f1_score: 0.9413 - val_loss: 0.3959 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3885 - acc: 0.9447 - precision: 0.9937 - recall: 0.8968 - f1_score: 0.9420 - val_loss: 0.3950 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3875 - acc: 0.9447 - precision: 0.9921 - recall: 0.8893 - f1_score: 0.9370 - val_loss: 0.3940 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3866 - acc: 0.9447 - precision: 0.9923 - recall: 0.8924 - f1_score: 0.9385 - val_loss: 0.3931 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3856 - acc: 0.9447 - precision: 0.9935 - recall: 0.8972 - f1_score: 0.9421 - val_loss: 0.3921 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3847 - acc: 0.9447 - precision: 0.9936 - recall: 0.8971 - f1_score: 0.9410 - val_loss: 0.3912 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3837 - acc: 0.9447 - precision: 0.9932 - recall: 0.8962 - f1_score: 0.9415 - val_loss: 0.3902 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3828 - acc: 0.9447 - precision: 0.9931 - recall: 0.8957 - f1_score: 0.9405 - val_loss: 0.3893 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3819 - acc: 0.9447 - precision: 0.9924 - recall: 0.8937 - f1_score: 0.9395 - val_loss: 0.3884 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3809 - acc: 0.9447 - precision: 0.9935 - recall: 0.8911 - f1_score: 0.9386 - val_loss: 0.3874 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 678/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3800 - acc: 0.9447 - precision: 0.9926 - recall: 0.8970 - f1_score: 0.9414 - val_loss: 0.3865 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3791 - acc: 0.9447 - precision: 0.9931 - recall: 0.8974 - f1_score: 0.9416 - val_loss: 0.3856 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3782 - acc: 0.9447 - precision: 0.9929 - recall: 0.8907 - f1_score: 0.9373 - val_loss: 0.3847 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3772 - acc: 0.9447 - precision: 0.9927 - recall: 0.8930 - f1_score: 0.9394 - val_loss: 0.3838 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3763 - acc: 0.9447 - precision: 0.9928 - recall: 0.8959 - f1_score: 0.9408 - val_loss: 0.3829 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3754 - acc: 0.9447 - precision: 0.9926 - recall: 0.8937 - f1_score: 0.9397 - val_loss: 0.3820 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3745 - acc: 0.9447 - precision: 0.9944 - recall: 0.8956 - f1_score: 0.9411 - val_loss: 0.3811 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3736 - acc: 0.9447 - precision: 0.9928 - recall: 0.8975 - f1_score: 0.9412 - val_loss: 0.3802 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3727 - acc: 0.9447 - precision: 0.9914 - recall: 0.8931 - f1_score: 0.9388 - val_loss: 0.3793 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3719 - acc: 0.9447 - precision: 0.9937 - recall: 0.8951 - f1_score: 0.9399 - val_loss: 0.3784 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3710 - acc: 0.9447 - precision: 0.9919 - recall: 0.8959 - f1_score: 0.9387 - val_loss: 0.3776 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3701 - acc: 0.9447 - precision: 0.9931 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 0.3767 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3692 - acc: 0.9447 - precision: 0.9916 - recall: 0.8931 - f1_score: 0.9388 - val_loss: 0.3758 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3684 - acc: 0.9447 - precision: 0.9925 - recall: 0.8914 - f1_score: 0.9386 - val_loss: 0.3750 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3675 - acc: 0.9447 - precision: 0.9923 - recall: 0.8948 - f1_score: 0.9399 - val_loss: 0.3741 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3666 - acc: 0.9447 - precision: 0.9938 - recall: 0.8908 - f1_score: 0.9382 - val_loss: 0.3733 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3658 - acc: 0.9447 - precision: 0.9927 - recall: 0.8942 - f1_score: 0.9395 - val_loss: 0.3724 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3649 - acc: 0.9447 - precision: 0.9931 - recall: 0.8971 - f1_score: 0.9416 - val_loss: 0.3716 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3641 - acc: 0.9447 - precision: 0.9931 - recall: 0.8966 - f1_score: 0.9411 - val_loss: 0.3707 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3850 - acc: 0.9400 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.918 - 0s - loss: 0.3632 - acc: 0.9447 - precision: 0.9913 - recall: 0.8911 - f1_score: 0.9381 - val_loss: 0.3699 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3624 - acc: 0.9447 - precision: 0.9917 - recall: 0.8948 - f1_score: 0.9398 - val_loss: 0.3690 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3615 - acc: 0.9447 - precision: 0.9933 - recall: 0.8952 - f1_score: 0.9407 - val_loss: 0.3682 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3607 - acc: 0.9447 - precision: 0.9940 - recall: 0.8960 - f1_score: 0.9413 - val_loss: 0.3674 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3599 - acc: 0.9447 - precision: 0.9934 - recall: 0.8938 - f1_score: 0.9406 - val_loss: 0.3666 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3590 - acc: 0.9447 - precision: 0.9930 - recall: 0.8962 - f1_score: 0.9404 - val_loss: 0.3657 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3582 - acc: 0.9447 - precision: 0.9935 - recall: 0.8958 - f1_score: 0.9405 - val_loss: 0.3649 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3574 - acc: 0.9447 - precision: 0.9915 - recall: 0.8969 - f1_score: 0.9407 - val_loss: 0.3641 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3566 - acc: 0.9447 - precision: 0.9934 - recall: 0.8910 - f1_score: 0.9386 - val_loss: 0.3633 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3558 - acc: 0.9447 - precision: 0.9938 - recall: 0.8943 - f1_score: 0.9404 - val_loss: 0.3625 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3550 - acc: 0.9447 - precision: 0.9931 - recall: 0.8983 - f1_score: 0.9404 - val_loss: 0.3617 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3542 - acc: 0.9447 - precision: 0.9929 - recall: 0.8952 - f1_score: 0.9407 - val_loss: 0.3609 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3534 - acc: 0.9447 - precision: 0.9934 - recall: 0.8948 - f1_score: 0.9408 - val_loss: 0.3601 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3526 - acc: 0.9447 - precision: 0.9936 - recall: 0.8928 - f1_score: 0.9395 - val_loss: 0.3593 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3518 - acc: 0.9447 - precision: 0.9912 - recall: 0.8968 - f1_score: 0.9400 - val_loss: 0.3585 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3510 - acc: 0.9447 - precision: 0.9925 - recall: 0.8878 - f1_score: 0.9350 - val_loss: 0.3577 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3502 - acc: 0.9447 - precision: 0.9929 - recall: 0.8965 - f1_score: 0.9415 - val_loss: 0.3570 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3494 - acc: 0.9447 - precision: 0.9927 - recall: 0.8937 - f1_score: 0.9399 - val_loss: 0.3562 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3486 - acc: 0.9447 - precision: 0.9942 - recall: 0.8921 - f1_score: 0.9394 - val_loss: 0.3554 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3479 - acc: 0.9447 - precision: 0.9935 - recall: 0.8918 - f1_score: 0.9387 - val_loss: 0.3547 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3471 - acc: 0.9447 - precision: 0.9934 - recall: 0.8969 - f1_score: 0.9409 - val_loss: 0.3539 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3463 - acc: 0.9447 - precision: 0.9921 - recall: 0.8970 - f1_score: 0.9411 - val_loss: 0.3531 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3456 - acc: 0.9447 - precision: 0.9927 - recall: 0.8968 - f1_score: 0.9417 - val_loss: 0.3524 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3448 - acc: 0.9447 - precision: 0.9914 - recall: 0.8952 - f1_score: 0.9401 - val_loss: 0.3516 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3440 - acc: 0.9447 - precision: 0.9913 - recall: 0.8924 - f1_score: 0.9376 - val_loss: 0.3509 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3433 - acc: 0.9447 - precision: 0.9913 - recall: 0.8958 - f1_score: 0.9400 - val_loss: 0.3501 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3425 - acc: 0.9447 - precision: 0.9927 - recall: 0.8972 - f1_score: 0.9419 - val_loss: 0.3494 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3418 - acc: 0.9447 - precision: 0.9931 - recall: 0.8968 - f1_score: 0.9417 - val_loss: 0.3486 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3411 - acc: 0.9447 - precision: 0.9931 - recall: 0.8950 - f1_score: 0.9408 - val_loss: 0.3479 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3403 - acc: 0.9447 - precision: 0.9921 - recall: 0.8966 - f1_score: 0.9405 - val_loss: 0.3472 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3396 - acc: 0.9447 - precision: 0.9935 - recall: 0.8956 - f1_score: 0.9406 - val_loss: 0.3465 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3389 - acc: 0.9447 - precision: 0.9931 - recall: 0.8957 - f1_score: 0.9413 - val_loss: 0.3457 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3381 - acc: 0.9447 - precision: 0.9928 - recall: 0.8946 - f1_score: 0.9402 - val_loss: 0.3450 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3374 - acc: 0.9447 - precision: 0.9929 - recall: 0.8905 - f1_score: 0.9373 - val_loss: 0.3443 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3367 - acc: 0.9447 - precision: 0.9927 - recall: 0.8945 - f1_score: 0.9398 - val_loss: 0.3436 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3360 - acc: 0.9447 - precision: 0.9923 - recall: 0.8962 - f1_score: 0.9407 - val_loss: 0.3429 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3353 - acc: 0.9447 - precision: 0.9944 - recall: 0.8909 - f1_score: 0.9383 - val_loss: 0.3422 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3345 - acc: 0.9447 - precision: 0.9934 - recall: 0.8975 - f1_score: 0.9420 - val_loss: 0.3415 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3338 - acc: 0.9447 - precision: 0.9939 - recall: 0.8974 - f1_score: 0.9423 - val_loss: 0.3408 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3331 - acc: 0.9447 - precision: 0.9931 - recall: 0.8903 - f1_score: 0.9373 - val_loss: 0.3401 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3324 - acc: 0.9447 - precision: 0.9940 - recall: 0.8973 - f1_score: 0.9422 - val_loss: 0.3394 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3317 - acc: 0.9447 - precision: 0.9923 - recall: 0.8954 - f1_score: 0.9396 - val_loss: 0.3387 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3310 - acc: 0.9447 - precision: 0.9938 - recall: 0.8950 - f1_score: 0.9407 - val_loss: 0.3380 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3303 - acc: 0.9447 - precision: 0.9934 - recall: 0.8946 - f1_score: 0.9401 - val_loss: 0.3373 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3297 - acc: 0.9447 - precision: 0.9937 - recall: 0.8937 - f1_score: 0.9405 - val_loss: 0.3366 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3290 - acc: 0.9447 - precision: 0.9924 - recall: 0.8974 - f1_score: 0.9409 - val_loss: 0.3360 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3283 - acc: 0.9447 - precision: 0.9929 - recall: 0.8965 - f1_score: 0.9417 - val_loss: 0.3353 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3276 - acc: 0.9447 - precision: 0.9934 - recall: 0.8954 - f1_score: 0.9411 - val_loss: 0.3346 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3269 - acc: 0.9447 - precision: 0.9928 - recall: 0.8941 - f1_score: 0.9392 - val_loss: 0.3339 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3263 - acc: 0.9447 - precision: 0.9941 - recall: 0.8918 - f1_score: 0.9388 - val_loss: 0.3333 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3256 - acc: 0.9447 - precision: 0.9928 - recall: 0.8968 - f1_score: 0.9413 - val_loss: 0.3326 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3249 - acc: 0.9447 - precision: 0.9937 - recall: 0.8926 - f1_score: 0.9393 - val_loss: 0.3319 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3243 - acc: 0.9447 - precision: 0.9935 - recall: 0.8987 - f1_score: 0.9425 - val_loss: 0.3313 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3236 - acc: 0.9447 - precision: 0.9912 - recall: 0.8973 - f1_score: 0.9407 - val_loss: 0.3306 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3230 - acc: 0.9447 - precision: 0.9927 - recall: 0.8959 - f1_score: 0.9406 - val_loss: 0.3300 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3223 - acc: 0.9447 - precision: 0.9934 - recall: 0.8943 - f1_score: 0.9400 - val_loss: 0.3293 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3216 - acc: 0.9447 - precision: 0.9931 - recall: 0.8957 - f1_score: 0.9411 - val_loss: 0.3287 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3210 - acc: 0.9447 - precision: 0.9911 - recall: 0.8922 - f1_score: 0.9380 - val_loss: 0.3280 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3204 - acc: 0.9447 - precision: 0.9930 - recall: 0.8938 - f1_score: 0.9399 - val_loss: 0.3274 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3197 - acc: 0.9447 - precision: 0.9939 - recall: 0.8921 - f1_score: 0.9389 - val_loss: 0.3268 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3191 - acc: 0.9447 - precision: 0.9940 - recall: 0.8956 - f1_score: 0.9416 - val_loss: 0.3261 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3184 - acc: 0.9447 - precision: 0.9928 - recall: 0.8971 - f1_score: 0.9412 - val_loss: 0.3255 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3178 - acc: 0.9447 - precision: 0.9909 - recall: 0.8944 - f1_score: 0.9392 - val_loss: 0.3249 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9447 - precision: 0.9926 - recall: 0.8925 - f1_score: 0.9390 - val_loss: 0.3243 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3166 - acc: 0.9447 - precision: 0.9919 - recall: 0.8954 - f1_score: 0.9403 - val_loss: 0.3236 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3159 - acc: 0.9447 - precision: 0.9935 - recall: 0.8930 - f1_score: 0.9397 - val_loss: 0.3230 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3153 - acc: 0.9447 - precision: 0.9931 - recall: 0.8970 - f1_score: 0.9413 - val_loss: 0.3224 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3147 - acc: 0.9447 - precision: 0.9944 - recall: 0.8927 - f1_score: 0.9393 - val_loss: 0.3218 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3141 - acc: 0.9447 - precision: 0.9930 - recall: 0.8964 - f1_score: 0.9411 - val_loss: 0.3212 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3135 - acc: 0.9447 - precision: 0.9911 - recall: 0.8926 - f1_score: 0.9387 - val_loss: 0.3206 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3129 - acc: 0.9447 - precision: 0.9931 - recall: 0.8965 - f1_score: 0.9421 - val_loss: 0.3200 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3123 - acc: 0.9447 - precision: 0.9940 - recall: 0.8949 - f1_score: 0.9405 - val_loss: 0.3194 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3116 - acc: 0.9447 - precision: 0.9925 - recall: 0.8942 - f1_score: 0.9404 - val_loss: 0.3188 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3110 - acc: 0.9447 - precision: 0.9920 - recall: 0.8980 - f1_score: 0.9412 - val_loss: 0.3182 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3104 - acc: 0.9447 - precision: 0.9928 - recall: 0.8930 - f1_score: 0.9394 - val_loss: 0.3176 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3099 - acc: 0.9447 - precision: 0.9934 - recall: 0.8896 - f1_score: 0.9367 - val_loss: 0.3170 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3093 - acc: 0.9447 - precision: 0.9926 - recall: 0.8928 - f1_score: 0.9388 - val_loss: 0.3164 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3087 - acc: 0.9447 - precision: 0.9929 - recall: 0.8946 - f1_score: 0.9407 - val_loss: 0.3158 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3081 - acc: 0.9447 - precision: 0.9946 - recall: 0.8952 - f1_score: 0.9414 - val_loss: 0.3152 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3075 - acc: 0.9447 - precision: 0.9931 - recall: 0.8968 - f1_score: 0.9411 - val_loss: 0.3147 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3069 - acc: 0.9447 - precision: 0.9933 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 0.3141 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3063 - acc: 0.9447 - precision: 0.9919 - recall: 0.8935 - f1_score: 0.9391 - val_loss: 0.3135 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9447 - precision: 0.9942 - recall: 0.8910 - f1_score: 0.9387 - val_loss: 0.3129 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3052 - acc: 0.9447 - precision: 0.9940 - recall: 0.8930 - f1_score: 0.9398 - val_loss: 0.3124 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3046 - acc: 0.9447 - precision: 0.9926 - recall: 0.8951 - f1_score: 0.9402 - val_loss: 0.3118 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3041 - acc: 0.9447 - precision: 0.9927 - recall: 0.8944 - f1_score: 0.9400 - val_loss: 0.3113 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3035 - acc: 0.9447 - precision: 0.9932 - recall: 0.8927 - f1_score: 0.9389 - val_loss: 0.3107 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3029 - acc: 0.9447 - precision: 0.9938 - recall: 0.8926 - f1_score: 0.9392 - val_loss: 0.3101 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3024 - acc: 0.9447 - precision: 0.9925 - recall: 0.8963 - f1_score: 0.9408 - val_loss: 0.3096 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3018 - acc: 0.9447 - precision: 0.9923 - recall: 0.8944 - f1_score: 0.9392 - val_loss: 0.3090 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3012 - acc: 0.9447 - precision: 0.9932 - recall: 0.8949 - f1_score: 0.9409 - val_loss: 0.3085 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3007 - acc: 0.9447 - precision: 0.9924 - recall: 0.8914 - f1_score: 0.9386 - val_loss: 0.3079 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3001 - acc: 0.9447 - precision: 0.9931 - recall: 0.8924 - f1_score: 0.9385 - val_loss: 0.3074 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2996 - acc: 0.9447 - precision: 0.9926 - recall: 0.8955 - f1_score: 0.9404 - val_loss: 0.3069 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2990 - acc: 0.9447 - precision: 0.9929 - recall: 0.8918 - f1_score: 0.9384 - val_loss: 0.3063 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2985 - acc: 0.9447 - precision: 0.9938 - recall: 0.9000 - f1_score: 0.9437 - val_loss: 0.3058 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2980 - acc: 0.9447 - precision: 0.9926 - recall: 0.8988 - f1_score: 0.9425 - val_loss: 0.3053 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2974 - acc: 0.9447 - precision: 0.9939 - recall: 0.8911 - f1_score: 0.9380 - val_loss: 0.3047 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2969 - acc: 0.9447 - precision: 0.9935 - recall: 0.8916 - f1_score: 0.9387 - val_loss: 0.3042 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2964 - acc: 0.9447 - precision: 0.9920 - recall: 0.8950 - f1_score: 0.9406 - val_loss: 0.3037 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2958 - acc: 0.9447 - precision: 0.9933 - recall: 0.8950 - f1_score: 0.9408 - val_loss: 0.3031 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2953 - acc: 0.9447 - precision: 0.9930 - recall: 0.8977 - f1_score: 0.9412 - val_loss: 0.3026 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2948 - acc: 0.9447 - precision: 0.9936 - recall: 0.8926 - f1_score: 0.9392 - val_loss: 0.3021 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2942 - acc: 0.9447 - precision: 0.9927 - recall: 0.8932 - f1_score: 0.9395 - val_loss: 0.3016 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2937 - acc: 0.9447 - precision: 0.9928 - recall: 0.8963 - f1_score: 0.9410 - val_loss: 0.3011 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2932 - acc: 0.9447 - precision: 0.9931 - recall: 0.8917 - f1_score: 0.9392 - val_loss: 0.3006 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2927 - acc: 0.9447 - precision: 0.9940 - recall: 0.8933 - f1_score: 0.9399 - val_loss: 0.3001 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2922 - acc: 0.9447 - precision: 0.9924 - recall: 0.8936 - f1_score: 0.9393 - val_loss: 0.2996 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2917 - acc: 0.9447 - precision: 0.9931 - recall: 0.8929 - f1_score: 0.9388 - val_loss: 0.2991 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 806/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2912 - acc: 0.9447 - precision: 0.9935 - recall: 0.8948 - f1_score: 0.9408 - val_loss: 0.2986 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2906 - acc: 0.9447 - precision: 0.9917 - recall: 0.8912 - f1_score: 0.9368 - val_loss: 0.2980 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2901 - acc: 0.9447 - precision: 0.9921 - recall: 0.8897 - f1_score: 0.9367 - val_loss: 0.2976 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2896 - acc: 0.9447 - precision: 0.9931 - recall: 0.8934 - f1_score: 0.9397 - val_loss: 0.2971 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2891 - acc: 0.9447 - precision: 0.9935 - recall: 0.8815 - f1_score: 0.9299 - val_loss: 0.2966 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2886 - acc: 0.9447 - precision: 0.9923 - recall: 0.8953 - f1_score: 0.9404 - val_loss: 0.2961 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2881 - acc: 0.9447 - precision: 0.9917 - recall: 0.8909 - f1_score: 0.9377 - val_loss: 0.2956 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2876 - acc: 0.9447 - precision: 0.9931 - recall: 0.8941 - f1_score: 0.9406 - val_loss: 0.2951 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2872 - acc: 0.9447 - precision: 0.9912 - recall: 0.8960 - f1_score: 0.9399 - val_loss: 0.2946 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2867 - acc: 0.9447 - precision: 0.9922 - recall: 0.8932 - f1_score: 0.9392 - val_loss: 0.2941 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2862 - acc: 0.9447 - precision: 0.9928 - recall: 0.8942 - f1_score: 0.9401 - val_loss: 0.2937 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2857 - acc: 0.9447 - precision: 0.9917 - recall: 0.8917 - f1_score: 0.9380 - val_loss: 0.2932 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2852 - acc: 0.9447 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9389 - val_loss: 0.2927 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2847 - acc: 0.9447 - precision: 0.9937 - recall: 0.8967 - f1_score: 0.9422 - val_loss: 0.2922 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9447 - precision: 0.9923 - recall: 0.8940 - f1_score: 0.9401 - val_loss: 0.2918 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2838 - acc: 0.9447 - precision: 0.9911 - recall: 0.8937 - f1_score: 0.9390 - val_loss: 0.2913 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2833 - acc: 0.9447 - precision: 0.9921 - recall: 0.8956 - f1_score: 0.9402 - val_loss: 0.2908 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2828 - acc: 0.9447 - precision: 0.9920 - recall: 0.8940 - f1_score: 0.9400 - val_loss: 0.2904 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2824 - acc: 0.9447 - precision: 0.9928 - recall: 0.8986 - f1_score: 0.9424 - val_loss: 0.2899 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2819 - acc: 0.9447 - precision: 0.9931 - recall: 0.8963 - f1_score: 0.9405 - val_loss: 0.2895 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2814 - acc: 0.9447 - precision: 0.9934 - recall: 0.8926 - f1_score: 0.9388 - val_loss: 0.2890 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2810 - acc: 0.9447 - precision: 0.9939 - recall: 0.8934 - f1_score: 0.9399 - val_loss: 0.2886 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2805 - acc: 0.9447 - precision: 0.9910 - recall: 0.8923 - f1_score: 0.9383 - val_loss: 0.2881 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2801 - acc: 0.9447 - precision: 0.9917 - recall: 0.8915 - f1_score: 0.9386 - val_loss: 0.2877 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2796 - acc: 0.9447 - precision: 0.9947 - recall: 0.8894 - f1_score: 0.9378 - val_loss: 0.2872 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2791 - acc: 0.9447 - precision: 0.9926 - recall: 0.8942 - f1_score: 0.9394 - val_loss: 0.2868 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2787 - acc: 0.9447 - precision: 0.9937 - recall: 0.8925 - f1_score: 0.9384 - val_loss: 0.2863 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2782 - acc: 0.9447 - precision: 0.9929 - recall: 0.8944 - f1_score: 0.9401 - val_loss: 0.2859 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2778 - acc: 0.9447 - precision: 0.9916 - recall: 0.8952 - f1_score: 0.9395 - val_loss: 0.2854 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2773 - acc: 0.9447 - precision: 0.9924 - recall: 0.8950 - f1_score: 0.9395 - val_loss: 0.2850 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2769 - acc: 0.9447 - precision: 0.9925 - recall: 0.8963 - f1_score: 0.9413 - val_loss: 0.2846 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2765 - acc: 0.9447 - precision: 0.9923 - recall: 0.8968 - f1_score: 0.9417 - val_loss: 0.2841 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9447 - precision: 0.9936 - recall: 0.8956 - f1_score: 0.9417 - val_loss: 0.2837 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2756 - acc: 0.9447 - precision: 0.9925 - recall: 0.8946 - f1_score: 0.9395 - val_loss: 0.2833 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2752 - acc: 0.9447 - precision: 0.9924 - recall: 0.8945 - f1_score: 0.9399 - val_loss: 0.2828 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2747 - acc: 0.9447 - precision: 0.9928 - recall: 0.8934 - f1_score: 0.9401 - val_loss: 0.2824 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2743 - acc: 0.9447 - precision: 0.9935 - recall: 0.8892 - f1_score: 0.9372 - val_loss: 0.2820 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2739 - acc: 0.9447 - precision: 0.9941 - recall: 0.8889 - f1_score: 0.9368 - val_loss: 0.2816 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2734 - acc: 0.9447 - precision: 0.9940 - recall: 0.8929 - f1_score: 0.9398 - val_loss: 0.2811 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2730 - acc: 0.9447 - precision: 0.9940 - recall: 0.8954 - f1_score: 0.9402 - val_loss: 0.2807 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2726 - acc: 0.9447 - precision: 0.9928 - recall: 0.8932 - f1_score: 0.9394 - val_loss: 0.2803 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9447 - precision: 0.9926 - recall: 0.8966 - f1_score: 0.9408 - val_loss: 0.2799 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2717 - acc: 0.9447 - precision: 0.9928 - recall: 0.8937 - f1_score: 0.9396 - val_loss: 0.2795 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2713 - acc: 0.9447 - precision: 0.9938 - recall: 0.8943 - f1_score: 0.9395 - val_loss: 0.2791 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2709 - acc: 0.9447 - precision: 0.9933 - recall: 0.8954 - f1_score: 0.9410 - val_loss: 0.2787 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2705 - acc: 0.9447 - precision: 0.9919 - recall: 0.8900 - f1_score: 0.9371 - val_loss: 0.2783 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9447 - precision: 0.9938 - recall: 0.8937 - f1_score: 0.9406 - val_loss: 0.2779 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2696 - acc: 0.9447 - precision: 0.9931 - recall: 0.8957 - f1_score: 0.9408 - val_loss: 0.2775 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2692 - acc: 0.9447 - precision: 0.9936 - recall: 0.8904 - f1_score: 0.9377 - val_loss: 0.2771 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2688 - acc: 0.9447 - precision: 0.9929 - recall: 0.8949 - f1_score: 0.9405 - val_loss: 0.2767 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2684 - acc: 0.9447 - precision: 0.9944 - recall: 0.8944 - f1_score: 0.9407 - val_loss: 0.2763 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2680 - acc: 0.9447 - precision: 0.9932 - recall: 0.8983 - f1_score: 0.9416 - val_loss: 0.2759 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2676 - acc: 0.9447 - precision: 0.9921 - recall: 0.8995 - f1_score: 0.9423 - val_loss: 0.2755 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2672 - acc: 0.9447 - precision: 0.9928 - recall: 0.8927 - f1_score: 0.9391 - val_loss: 0.2751 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2668 - acc: 0.9447 - precision: 0.9924 - recall: 0.8954 - f1_score: 0.9402 - val_loss: 0.2747 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2664 - acc: 0.9447 - precision: 0.9931 - recall: 0.8947 - f1_score: 0.9402 - val_loss: 0.2743 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2660 - acc: 0.9447 - precision: 0.9936 - recall: 0.8938 - f1_score: 0.9404 - val_loss: 0.2739 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2656 - acc: 0.9447 - precision: 0.9921 - recall: 0.8965 - f1_score: 0.9407 - val_loss: 0.2735 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9447 - precision: 0.9925 - recall: 0.8936 - f1_score: 0.9395 - val_loss: 0.2732 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2649 - acc: 0.9447 - precision: 0.9930 - recall: 0.8944 - f1_score: 0.9396 - val_loss: 0.2728 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2645 - acc: 0.9447 - precision: 0.9937 - recall: 0.8927 - f1_score: 0.9391 - val_loss: 0.2724 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2641 - acc: 0.9447 - precision: 0.9930 - recall: 0.8931 - f1_score: 0.9391 - val_loss: 0.2720 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2637 - acc: 0.9447 - precision: 0.9929 - recall: 0.8957 - f1_score: 0.9410 - val_loss: 0.2716 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2633 - acc: 0.9447 - precision: 0.9929 - recall: 0.8934 - f1_score: 0.9403 - val_loss: 0.2713 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 870/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2629 - acc: 0.9447 - precision: 0.9926 - recall: 0.8971 - f1_score: 0.9406 - val_loss: 0.2709 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2626 - acc: 0.9447 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9410 - val_loss: 0.2705 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2622 - acc: 0.9447 - precision: 0.9942 - recall: 0.8948 - f1_score: 0.9411 - val_loss: 0.2702 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2618 - acc: 0.9447 - precision: 0.9931 - recall: 0.8977 - f1_score: 0.9421 - val_loss: 0.2698 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2614 - acc: 0.9447 - precision: 0.9930 - recall: 0.8923 - f1_score: 0.9394 - val_loss: 0.2694 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2611 - acc: 0.9447 - precision: 0.9940 - recall: 0.8907 - f1_score: 0.9386 - val_loss: 0.2691 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2607 - acc: 0.9447 - precision: 0.9926 - recall: 0.8909 - f1_score: 0.9377 - val_loss: 0.2687 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2603 - acc: 0.9447 - precision: 0.9927 - recall: 0.8943 - f1_score: 0.9397 - val_loss: 0.2683 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2599 - acc: 0.9447 - precision: 0.9942 - recall: 0.8865 - f1_score: 0.9337 - val_loss: 0.2680 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2596 - acc: 0.9447 - precision: 0.9937 - recall: 0.8917 - f1_score: 0.9395 - val_loss: 0.2676 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2592 - acc: 0.9447 - precision: 0.9929 - recall: 0.8945 - f1_score: 0.9405 - val_loss: 0.2673 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2588 - acc: 0.9447 - precision: 0.9930 - recall: 0.8980 - f1_score: 0.9415 - val_loss: 0.2669 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9447 - precision: 0.9937 - recall: 0.8930 - f1_score: 0.9389 - val_loss: 0.2666 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9447 - precision: 0.9935 - recall: 0.8946 - f1_score: 0.9395 - val_loss: 0.2662 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9447 - precision: 0.9933 - recall: 0.9002 - f1_score: 0.9428 - val_loss: 0.2659 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2574 - acc: 0.9447 - precision: 0.9922 - recall: 0.8923 - f1_score: 0.9388 - val_loss: 0.2655 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2571 - acc: 0.9447 - precision: 0.9926 - recall: 0.8974 - f1_score: 0.9415 - val_loss: 0.2652 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2567 - acc: 0.9447 - precision: 0.9919 - recall: 0.8941 - f1_score: 0.9392 - val_loss: 0.2648 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2564 - acc: 0.9447 - precision: 0.9933 - recall: 0.8958 - f1_score: 0.9411 - val_loss: 0.2645 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2560 - acc: 0.9447 - precision: 0.9920 - recall: 0.8960 - f1_score: 0.9407 - val_loss: 0.2641 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2557 - acc: 0.9447 - precision: 0.9911 - recall: 0.8901 - f1_score: 0.9370 - val_loss: 0.2638 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2553 - acc: 0.9447 - precision: 0.9931 - recall: 0.8963 - f1_score: 0.9417 - val_loss: 0.2635 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2550 - acc: 0.9447 - precision: 0.9926 - recall: 0.8923 - f1_score: 0.9389 - val_loss: 0.2631 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2546 - acc: 0.9447 - precision: 0.9938 - recall: 0.8907 - f1_score: 0.9372 - val_loss: 0.2628 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2543 - acc: 0.9447 - precision: 0.9933 - recall: 0.8982 - f1_score: 0.9423 - val_loss: 0.2625 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2539 - acc: 0.9447 - precision: 0.9931 - recall: 0.8983 - f1_score: 0.9425 - val_loss: 0.2621 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2536 - acc: 0.9447 - precision: 0.9929 - recall: 0.8973 - f1_score: 0.9414 - val_loss: 0.2618 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2532 - acc: 0.9447 - precision: 0.9923 - recall: 0.8948 - f1_score: 0.9402 - val_loss: 0.2615 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2529 - acc: 0.9447 - precision: 0.9909 - recall: 0.8937 - f1_score: 0.9381 - val_loss: 0.2611 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9447 - precision: 0.9928 - recall: 0.8976 - f1_score: 0.9420 - val_loss: 0.2608 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2522 - acc: 0.9447 - precision: 0.9919 - recall: 0.8929 - f1_score: 0.9387 - val_loss: 0.2605 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2519 - acc: 0.9447 - precision: 0.9925 - recall: 0.8947 - f1_score: 0.9407 - val_loss: 0.2602 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2516 - acc: 0.9447 - precision: 0.9917 - recall: 0.8947 - f1_score: 0.9402 - val_loss: 0.2598 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2513 - acc: 0.9447 - precision: 0.9934 - recall: 0.8976 - f1_score: 0.9422 - val_loss: 0.2595 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2509 - acc: 0.9447 - precision: 0.9937 - recall: 0.8923 - f1_score: 0.9390 - val_loss: 0.2592 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2506 - acc: 0.9447 - precision: 0.9888 - recall: 0.8865 - f1_score: 0.9332 - val_loss: 0.2589 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9447 - precision: 0.9940 - recall: 0.8920 - f1_score: 0.9389 - val_loss: 0.2586 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2500 - acc: 0.9447 - precision: 0.9931 - recall: 0.8957 - f1_score: 0.9414 - val_loss: 0.2583 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9447 - precision: 0.9933 - recall: 0.8937 - f1_score: 0.9400 - val_loss: 0.2579 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9447 - precision: 0.9927 - recall: 0.8964 - f1_score: 0.9411 - val_loss: 0.2576 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2490 - acc: 0.9447 - precision: 0.9928 - recall: 0.8941 - f1_score: 0.9402 - val_loss: 0.2573 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2487 - acc: 0.9447 - precision: 0.9939 - recall: 0.9023 - f1_score: 0.9445 - val_loss: 0.2570 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9447 - precision: 0.9936 - recall: 0.8935 - f1_score: 0.9404 - val_loss: 0.2567 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2480 - acc: 0.9447 - precision: 0.9933 - recall: 0.8947 - f1_score: 0.9403 - val_loss: 0.2564 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2477 - acc: 0.9447 - precision: 0.9935 - recall: 0.8948 - f1_score: 0.9411 - val_loss: 0.2561 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2474 - acc: 0.9447 - precision: 0.9941 - recall: 0.8972 - f1_score: 0.9409 - val_loss: 0.2558 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2471 - acc: 0.9447 - precision: 0.9916 - recall: 0.8921 - f1_score: 0.9381 - val_loss: 0.2555 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2468 - acc: 0.9447 - precision: 0.9923 - recall: 0.8937 - f1_score: 0.9397 - val_loss: 0.2552 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2465 - acc: 0.9447 - precision: 0.9933 - recall: 0.8947 - f1_score: 0.9404 - val_loss: 0.2549 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2462 - acc: 0.9447 - precision: 0.9931 - recall: 0.8970 - f1_score: 0.9407 - val_loss: 0.2546 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9447 - precision: 0.9926 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.2543 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9447 - precision: 0.9924 - recall: 0.8916 - f1_score: 0.9382 - val_loss: 0.2540 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9447 - precision: 0.9924 - recall: 0.8909 - f1_score: 0.9374 - val_loss: 0.2537 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9447 - precision: 0.9931 - recall: 0.8953 - f1_score: 0.9411 - val_loss: 0.2534 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2447 - acc: 0.9447 - precision: 0.9923 - recall: 0.8956 - f1_score: 0.9404 - val_loss: 0.2531 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2444 - acc: 0.9447 - precision: 0.9923 - recall: 0.8932 - f1_score: 0.9395 - val_loss: 0.2528 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2441 - acc: 0.9447 - precision: 0.9934 - recall: 0.8978 - f1_score: 0.9428 - val_loss: 0.2526 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2438 - acc: 0.9447 - precision: 0.9931 - recall: 0.8908 - f1_score: 0.9380 - val_loss: 0.2523 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2435 - acc: 0.9447 - precision: 0.9934 - recall: 0.9015 - f1_score: 0.9431 - val_loss: 0.2520 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2432 - acc: 0.9447 - precision: 0.9925 - recall: 0.8972 - f1_score: 0.9405 - val_loss: 0.2517 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9447 - precision: 0.9931 - recall: 0.8955 - f1_score: 0.9409 - val_loss: 0.2514 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9447 - precision: 0.9925 - recall: 0.8944 - f1_score: 0.9401 - val_loss: 0.2511 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9447 - precision: 0.9917 - recall: 0.8913 - f1_score: 0.9377 - val_loss: 0.2508 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2420 - acc: 0.9447 - precision: 0.9921 - recall: 0.8922 - f1_score: 0.9381 - val_loss: 0.2506 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 934/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2417 - acc: 0.9447 - precision: 0.9912 - recall: 0.8937 - f1_score: 0.9390 - val_loss: 0.2503 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2415 - acc: 0.9447 - precision: 0.9938 - recall: 0.8910 - f1_score: 0.9381 - val_loss: 0.2500 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2412 - acc: 0.9447 - precision: 0.9937 - recall: 0.8950 - f1_score: 0.9411 - val_loss: 0.2497 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9447 - precision: 0.9938 - recall: 0.8950 - f1_score: 0.9408 - val_loss: 0.2495 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9447 - precision: 0.9930 - recall: 0.8909 - f1_score: 0.9373 - val_loss: 0.2492 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2403 - acc: 0.9447 - precision: 0.9934 - recall: 0.8959 - f1_score: 0.9411 - val_loss: 0.2489 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2400 - acc: 0.9447 - precision: 0.9933 - recall: 0.8952 - f1_score: 0.9408 - val_loss: 0.2486 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2398 - acc: 0.9447 - precision: 0.9930 - recall: 0.8918 - f1_score: 0.9391 - val_loss: 0.2484 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2395 - acc: 0.9447 - precision: 0.9913 - recall: 0.8959 - f1_score: 0.9402 - val_loss: 0.2481 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9447 - precision: 0.9938 - recall: 0.8936 - f1_score: 0.9399 - val_loss: 0.2478 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9447 - precision: 0.9933 - recall: 0.8934 - f1_score: 0.9397 - val_loss: 0.2476 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2387 - acc: 0.9447 - precision: 0.9929 - recall: 0.8980 - f1_score: 0.9421 - val_loss: 0.2473 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9447 - precision: 0.9930 - recall: 0.8927 - f1_score: 0.9396 - val_loss: 0.2470 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2381 - acc: 0.9447 - precision: 0.9928 - recall: 0.8953 - f1_score: 0.9407 - val_loss: 0.2468 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2378 - acc: 0.9447 - precision: 0.9924 - recall: 0.8964 - f1_score: 0.9410 - val_loss: 0.2465 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2376 - acc: 0.9447 - precision: 0.9945 - recall: 0.8942 - f1_score: 0.9402 - val_loss: 0.2462 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2373 - acc: 0.9447 - precision: 0.9925 - recall: 0.8930 - f1_score: 0.9388 - val_loss: 0.2460 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9447 - precision: 0.9931 - recall: 0.8914 - f1_score: 0.9378 - val_loss: 0.2457 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2368 - acc: 0.9447 - precision: 0.9894 - recall: 0.8891 - f1_score: 0.9350 - val_loss: 0.2455 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2365 - acc: 0.9447 - precision: 0.9926 - recall: 0.8978 - f1_score: 0.9421 - val_loss: 0.2452 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2362 - acc: 0.9447 - precision: 0.9940 - recall: 0.8909 - f1_score: 0.9381 - val_loss: 0.2450 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9447 - precision: 0.9928 - recall: 0.8933 - f1_score: 0.9391 - val_loss: 0.2447 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2357 - acc: 0.9447 - precision: 0.9918 - recall: 0.8956 - f1_score: 0.9407 - val_loss: 0.2445 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9447 - precision: 0.9934 - recall: 0.8920 - f1_score: 0.9394 - val_loss: 0.2442 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2352 - acc: 0.9447 - precision: 0.9933 - recall: 0.8962 - f1_score: 0.9411 - val_loss: 0.2440 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2349 - acc: 0.9447 - precision: 0.9935 - recall: 0.8930 - f1_score: 0.9382 - val_loss: 0.2437 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2347 - acc: 0.9447 - precision: 0.9925 - recall: 0.8955 - f1_score: 0.9398 - val_loss: 0.2435 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9447 - precision: 0.9932 - recall: 0.8908 - f1_score: 0.9375 - val_loss: 0.2432 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2342 - acc: 0.9447 - precision: 0.9930 - recall: 0.8911 - f1_score: 0.9370 - val_loss: 0.2430 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9447 - precision: 0.9940 - recall: 0.8972 - f1_score: 0.9424 - val_loss: 0.2427 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9447 - precision: 0.9929 - recall: 0.8936 - f1_score: 0.9393 - val_loss: 0.2425 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9447 - precision: 0.9931 - recall: 0.8929 - f1_score: 0.9397 - val_loss: 0.2423 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 966/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9447 - precision: 0.9929 - recall: 0.8980 - f1_score: 0.9421 - val_loss: 0.2420 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2329 - acc: 0.9447 - precision: 0.9912 - recall: 0.8951 - f1_score: 0.9397 - val_loss: 0.2418 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9447 - precision: 0.9922 - recall: 0.8954 - f1_score: 0.9402 - val_loss: 0.2415 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2324 - acc: 0.9447 - precision: 0.9936 - recall: 0.8938 - f1_score: 0.9402 - val_loss: 0.2413 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9447 - precision: 0.9931 - recall: 0.8940 - f1_score: 0.9394 - val_loss: 0.2411 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9447 - precision: 0.9923 - recall: 0.8948 - f1_score: 0.9401 - val_loss: 0.2408 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2317 - acc: 0.9447 - precision: 0.9926 - recall: 0.8936 - f1_score: 0.9379 - val_loss: 0.2406 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2314 - acc: 0.9447 - precision: 0.9935 - recall: 0.8936 - f1_score: 0.9401 - val_loss: 0.2404 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2312 - acc: 0.9447 - precision: 0.9936 - recall: 0.8973 - f1_score: 0.9419 - val_loss: 0.2401 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9447 - precision: 0.9938 - recall: 0.8939 - f1_score: 0.9404 - val_loss: 0.2399 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9447 - precision: 0.9931 - recall: 0.8958 - f1_score: 0.9403 - val_loss: 0.2397 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2305 - acc: 0.9447 - precision: 0.9934 - recall: 0.8961 - f1_score: 0.9409 - val_loss: 0.2394 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2302 - acc: 0.9447 - precision: 0.9922 - recall: 0.8948 - f1_score: 0.9401 - val_loss: 0.2392 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2300 - acc: 0.9447 - precision: 0.9919 - recall: 0.8966 - f1_score: 0.9401 - val_loss: 0.2390 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2298 - acc: 0.9447 - precision: 0.9929 - recall: 0.8929 - f1_score: 0.9396 - val_loss: 0.2388 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2295 - acc: 0.9447 - precision: 0.9926 - recall: 0.8945 - f1_score: 0.9405 - val_loss: 0.2385 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2293 - acc: 0.9447 - precision: 0.9934 - recall: 0.8993 - f1_score: 0.9419 - val_loss: 0.2383 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2291 - acc: 0.9447 - precision: 0.9929 - recall: 0.8949 - f1_score: 0.9398 - val_loss: 0.2381 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2289 - acc: 0.9447 - precision: 0.9928 - recall: 0.8916 - f1_score: 0.9388 - val_loss: 0.2379 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2286 - acc: 0.9447 - precision: 0.9926 - recall: 0.8956 - f1_score: 0.9412 - val_loss: 0.2376 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2284 - acc: 0.9447 - precision: 0.9916 - recall: 0.8938 - f1_score: 0.9386 - val_loss: 0.2374 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2282 - acc: 0.9447 - precision: 0.9922 - recall: 0.8996 - f1_score: 0.9421 - val_loss: 0.2372 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2279 - acc: 0.9447 - precision: 0.9934 - recall: 0.8954 - f1_score: 0.9403 - val_loss: 0.2370 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2277 - acc: 0.9447 - precision: 0.9925 - recall: 0.8947 - f1_score: 0.9401 - val_loss: 0.2368 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2275 - acc: 0.9447 - precision: 0.9930 - recall: 0.8959 - f1_score: 0.9412 - val_loss: 0.2366 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2273 - acc: 0.9447 - precision: 0.9928 - recall: 0.8932 - f1_score: 0.9390 - val_loss: 0.2363 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2270 - acc: 0.9447 - precision: 0.9932 - recall: 0.8930 - f1_score: 0.9392 - val_loss: 0.2361 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2268 - acc: 0.9447 - precision: 0.9924 - recall: 0.8947 - f1_score: 0.9404 - val_loss: 0.2359 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2266 - acc: 0.9447 - precision: 0.9928 - recall: 0.8945 - f1_score: 0.9402 - val_loss: 0.2357 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2263 - acc: 0.9447 - precision: 0.9941 - recall: 0.8937 - f1_score: 0.9405 - val_loss: 0.2355 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2261 - acc: 0.9447 - precision: 0.9917 - recall: 0.8945 - f1_score: 0.9400 - val_loss: 0.2353 - val_acc: 0.9367 - val_precision: 0.9712 - val_recall: 0.8966 - val_f1_score: 0.9321\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2259 - acc: 0.9447 - precision: 0.9934 - recall: 0.8937 - f1_score: 0.9401 - val_loss: 0.2351 - val_acc: 0.9430 - val_precision: 0.9719 - val_recall: 0.9093 - val_f1_score: 0.9394\n",
      "Epoch 998/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2257 - acc: 0.9447 - precision: 0.9927 - recall: 0.8882 - f1_score: 0.9356 - val_loss: 0.2349 - val_acc: 0.9430 - val_precision: 0.9719 - val_recall: 0.9093 - val_f1_score: 0.9394\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2255 - acc: 0.9447 - precision: 0.9940 - recall: 0.8900 - f1_score: 0.9378 - val_loss: 0.2346 - val_acc: 0.9430 - val_precision: 0.9719 - val_recall: 0.9093 - val_f1_score: 0.9394\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2253 - acc: 0.9447 - precision: 0.9921 - recall: 0.8969 - f1_score: 0.9408 - val_loss: 0.2344 - val_acc: 0.9430 - val_precision: 0.9719 - val_recall: 0.9093 - val_f1_score: 0.9394\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.2076 - acc: 0.6430 - precision: 0.6163 - recall: 0.5488 - f1_score: 0.5656 - val_loss: 5.9590 - val_acc: 0.7848 - val_precision: 0.7766 - val_recall: 0.8126 - val_f1_score: 0.7924\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9105 - acc: 0.7773 - precision: 0.7232 - recall: 0.8909 - f1_score: 0.7939 - val_loss: 5.8800 - val_acc: 0.8038 - val_precision: 0.7731 - val_recall: 0.8759 - val_f1_score: 0.8195\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8511 - acc: 0.7804 - precision: 0.7230 - recall: 0.9080 - f1_score: 0.8008 - val_loss: 5.8343 - val_acc: 0.7975 - val_precision: 0.7632 - val_recall: 0.8759 - val_f1_score: 0.8143\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8099 - acc: 0.7820 - precision: 0.7216 - recall: 0.9045 - f1_score: 0.8007 - val_loss: 5.7957 - val_acc: 0.7975 - val_precision: 0.7632 - val_recall: 0.8759 - val_f1_score: 0.8143\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7734 - acc: 0.7867 - precision: 0.7242 - recall: 0.9093 - f1_score: 0.8043 - val_loss: 5.7603 - val_acc: 0.8165 - val_precision: 0.7871 - val_recall: 0.8759 - val_f1_score: 0.8282\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7390 - acc: 0.7946 - precision: 0.7314 - recall: 0.9130 - f1_score: 0.8103 - val_loss: 5.7266 - val_acc: 0.8228 - val_precision: 0.7896 - val_recall: 0.8880 - val_f1_score: 0.8353\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7058 - acc: 0.7994 - precision: 0.7401 - recall: 0.9104 - f1_score: 0.8150 - val_loss: 5.6940 - val_acc: 0.8291 - val_precision: 0.7980 - val_recall: 0.8880 - val_f1_score: 0.8402\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6734 - acc: 0.8088 - precision: 0.7477 - recall: 0.9123 - f1_score: 0.8200 - val_loss: 5.6621 - val_acc: 0.8354 - val_precision: 0.8069 - val_recall: 0.8880 - val_f1_score: 0.8453\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6417 - acc: 0.8120 - precision: 0.7509 - recall: 0.9125 - f1_score: 0.8223 - val_loss: 5.6308 - val_acc: 0.8354 - val_precision: 0.8069 - val_recall: 0.8880 - val_f1_score: 0.8453\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6104 - acc: 0.8278 - precision: 0.7726 - recall: 0.9138 - f1_score: 0.8361 - val_loss: 5.6001 - val_acc: 0.8354 - val_precision: 0.8144 - val_recall: 0.8759 - val_f1_score: 0.8435\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5795 - acc: 0.8341 - precision: 0.7798 - recall: 0.9161 - f1_score: 0.8398 - val_loss: 5.5698 - val_acc: 0.8418 - val_precision: 0.8251 - val_recall: 0.8759 - val_f1_score: 0.8489\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5490 - acc: 0.8389 - precision: 0.7901 - recall: 0.9161 - f1_score: 0.8463 - val_loss: 5.5399 - val_acc: 0.8354 - val_precision: 0.8230 - val_recall: 0.8632 - val_f1_score: 0.8420\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5188 - acc: 0.8420 - precision: 0.7929 - recall: 0.9164 - f1_score: 0.8488 - val_loss: 5.5102 - val_acc: 0.8481 - val_precision: 0.8436 - val_recall: 0.8632 - val_f1_score: 0.8527\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4889 - acc: 0.8436 - precision: 0.7997 - recall: 0.9166 - f1_score: 0.8522 - val_loss: 5.4809 - val_acc: 0.8481 - val_precision: 0.8436 - val_recall: 0.8632 - val_f1_score: 0.8527\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4592 - acc: 0.8499 - precision: 0.8078 - recall: 0.9146 - f1_score: 0.8549 - val_loss: 5.4518 - val_acc: 0.8481 - val_precision: 0.8436 - val_recall: 0.8632 - val_f1_score: 0.8527\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4299 - acc: 0.8626 - precision: 0.8236 - recall: 0.9134 - f1_score: 0.8649 - val_loss: 5.4230 - val_acc: 0.8608 - val_precision: 0.8633 - val_recall: 0.8632 - val_f1_score: 0.8626\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4007 - acc: 0.8720 - precision: 0.8379 - recall: 0.9155 - f1_score: 0.8720 - val_loss: 5.3944 - val_acc: 0.8608 - val_precision: 0.8633 - val_recall: 0.8632 - val_f1_score: 0.8626\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3719 - acc: 0.8784 - precision: 0.8490 - recall: 0.9076 - f1_score: 0.8755 - val_loss: 5.3661 - val_acc: 0.8671 - val_precision: 0.8749 - val_recall: 0.8632 - val_f1_score: 0.8683\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3432 - acc: 0.8878 - precision: 0.8698 - recall: 0.9136 - f1_score: 0.8888 - val_loss: 5.3380 - val_acc: 0.8797 - val_precision: 0.8991 - val_recall: 0.8632 - val_f1_score: 0.8799\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3148 - acc: 0.8973 - precision: 0.8773 - recall: 0.9075 - f1_score: 0.8901 - val_loss: 5.3101 - val_acc: 0.8924 - val_precision: 0.9137 - val_recall: 0.8754 - val_f1_score: 0.8929\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2865 - acc: 0.9005 - precision: 0.8871 - recall: 0.9121 - f1_score: 0.8967 - val_loss: 5.2824 - val_acc: 0.8924 - val_precision: 0.9137 - val_recall: 0.8754 - val_f1_score: 0.8929\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2585 - acc: 0.9084 - precision: 0.9050 - recall: 0.9107 - f1_score: 0.9049 - val_loss: 5.2550 - val_acc: 0.9051 - val_precision: 0.9345 - val_recall: 0.8754 - val_f1_score: 0.9038\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2307 - acc: 0.9131 - precision: 0.9114 - recall: 0.9126 - f1_score: 0.9113 - val_loss: 5.2277 - val_acc: 0.9114 - val_precision: 0.9483 - val_recall: 0.8754 - val_f1_score: 0.9100\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2032 - acc: 0.9163 - precision: 0.9169 - recall: 0.9158 - f1_score: 0.9150 - val_loss: 5.2007 - val_acc: 0.9114 - val_precision: 0.9483 - val_recall: 0.8754 - val_f1_score: 0.9100\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1757 - acc: 0.9194 - precision: 0.9207 - recall: 0.9124 - f1_score: 0.9153 - val_loss: 5.1738 - val_acc: 0.9114 - val_precision: 0.9483 - val_recall: 0.8754 - val_f1_score: 0.9100\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1486 - acc: 0.9210 - precision: 0.9265 - recall: 0.9074 - f1_score: 0.9157 - val_loss: 5.1471 - val_acc: 0.9114 - val_precision: 0.9483 - val_recall: 0.8754 - val_f1_score: 0.9100\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1215 - acc: 0.9226 - precision: 0.9313 - recall: 0.9089 - f1_score: 0.9189 - val_loss: 5.1206 - val_acc: 0.9051 - val_precision: 0.9467 - val_recall: 0.8632 - val_f1_score: 0.9028\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0947 - acc: 0.9226 - precision: 0.9325 - recall: 0.9080 - f1_score: 0.9188 - val_loss: 5.0943 - val_acc: 0.9051 - val_precision: 0.9467 - val_recall: 0.8632 - val_f1_score: 0.9028\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0680 - acc: 0.9273 - precision: 0.9382 - recall: 0.9083 - f1_score: 0.9223 - val_loss: 5.0682 - val_acc: 0.9051 - val_precision: 0.9467 - val_recall: 0.8632 - val_f1_score: 0.9028\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.0416 - acc: 0.9273 - precision: 0.9448 - recall: 0.9069 - f1_score: 0.9242 - val_loss: 5.0422 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0153 - acc: 0.9289 - precision: 0.9443 - recall: 0.9102 - f1_score: 0.9243 - val_loss: 5.0164 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9892 - acc: 0.9289 - precision: 0.9474 - recall: 0.9088 - f1_score: 0.9269 - val_loss: 4.9908 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9632 - acc: 0.9321 - precision: 0.9550 - recall: 0.9017 - f1_score: 0.9253 - val_loss: 4.9653 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9375 - acc: 0.9305 - precision: 0.9564 - recall: 0.8959 - f1_score: 0.9248 - val_loss: 4.9400 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9119 - acc: 0.9305 - precision: 0.9559 - recall: 0.8945 - f1_score: 0.9235 - val_loss: 4.9149 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8864 - acc: 0.9305 - precision: 0.9621 - recall: 0.8934 - f1_score: 0.9255 - val_loss: 4.8900 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8612 - acc: 0.9321 - precision: 0.9663 - recall: 0.8948 - f1_score: 0.9278 - val_loss: 4.8651 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8361 - acc: 0.9336 - precision: 0.9687 - recall: 0.8960 - f1_score: 0.9296 - val_loss: 4.8405 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8111 - acc: 0.9336 - precision: 0.9653 - recall: 0.8928 - f1_score: 0.9269 - val_loss: 4.8160 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7864 - acc: 0.9336 - precision: 0.9703 - recall: 0.8923 - f1_score: 0.9269 - val_loss: 4.7917 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7617 - acc: 0.9352 - precision: 0.9729 - recall: 0.8980 - f1_score: 0.9328 - val_loss: 4.7675 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7373 - acc: 0.9352 - precision: 0.9713 - recall: 0.8942 - f1_score: 0.9301 - val_loss: 4.7435 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7130 - acc: 0.9352 - precision: 0.9701 - recall: 0.8943 - f1_score: 0.9298 - val_loss: 4.7196 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6888 - acc: 0.9368 - precision: 0.9719 - recall: 0.8964 - f1_score: 0.9317 - val_loss: 4.6959 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6648 - acc: 0.9368 - precision: 0.9732 - recall: 0.8948 - f1_score: 0.9305 - val_loss: 4.6722 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6409 - acc: 0.9384 - precision: 0.9752 - recall: 0.8939 - f1_score: 0.9315 - val_loss: 4.6488 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6172 - acc: 0.9384 - precision: 0.9791 - recall: 0.8915 - f1_score: 0.9318 - val_loss: 4.6255 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5936 - acc: 0.9400 - precision: 0.9823 - recall: 0.8950 - f1_score: 0.9356 - val_loss: 4.6023 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5702 - acc: 0.9400 - precision: 0.9823 - recall: 0.8947 - f1_score: 0.9351 - val_loss: 4.5793 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5469 - acc: 0.9400 - precision: 0.9831 - recall: 0.8959 - f1_score: 0.9362 - val_loss: 4.5564 - val_acc: 0.9051 - val_precision: 0.9575 - val_recall: 0.8510 - val_f1_score: 0.9007\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5237 - acc: 0.9400 - precision: 0.9845 - recall: 0.8935 - f1_score: 0.9346 - val_loss: 4.5336 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5007 - acc: 0.9415 - precision: 0.9851 - recall: 0.8925 - f1_score: 0.9348 - val_loss: 4.5110 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4779 - acc: 0.9415 - precision: 0.9859 - recall: 0.8910 - f1_score: 0.9350 - val_loss: 4.4885 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4552 - acc: 0.9400 - precision: 0.9830 - recall: 0.8923 - f1_score: 0.9345 - val_loss: 4.4662 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4326 - acc: 0.9400 - precision: 0.9810 - recall: 0.8956 - f1_score: 0.9338 - val_loss: 4.4440 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4101 - acc: 0.9400 - precision: 0.9834 - recall: 0.8944 - f1_score: 0.9357 - val_loss: 4.4219 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3878 - acc: 0.9400 - precision: 0.9815 - recall: 0.8945 - f1_score: 0.9349 - val_loss: 4.3999 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3656 - acc: 0.9400 - precision: 0.9815 - recall: 0.8935 - f1_score: 0.9344 - val_loss: 4.3781 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3435 - acc: 0.9400 - precision: 0.9806 - recall: 0.8927 - f1_score: 0.9340 - val_loss: 4.3564 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3216 - acc: 0.9400 - precision: 0.9827 - recall: 0.8921 - f1_score: 0.9340 - val_loss: 4.3348 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2998 - acc: 0.9400 - precision: 0.9799 - recall: 0.8933 - f1_score: 0.9339 - val_loss: 4.3133 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.2781 - acc: 0.9400 - precision: 0.9817 - recall: 0.8920 - f1_score: 0.9340 - val_loss: 4.2920 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2566 - acc: 0.9400 - precision: 0.9820 - recall: 0.8957 - f1_score: 0.9356 - val_loss: 4.2708 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2351 - acc: 0.9400 - precision: 0.9818 - recall: 0.8917 - f1_score: 0.9339 - val_loss: 4.2497 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2138 - acc: 0.9400 - precision: 0.9821 - recall: 0.8974 - f1_score: 0.9358 - val_loss: 4.2287 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1926 - acc: 0.9400 - precision: 0.9837 - recall: 0.8918 - f1_score: 0.9346 - val_loss: 4.2079 - val_acc: 0.8987 - val_precision: 0.9575 - val_recall: 0.8384 - val_f1_score: 0.8934\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1716 - acc: 0.9400 - precision: 0.9814 - recall: 0.8913 - f1_score: 0.9331 - val_loss: 4.1871 - val_acc: 0.9051 - val_precision: 0.9712 - val_recall: 0.8384 - val_f1_score: 0.8990\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1506 - acc: 0.9400 - precision: 0.9819 - recall: 0.8942 - f1_score: 0.9347 - val_loss: 4.1665 - val_acc: 0.9051 - val_precision: 0.9712 - val_recall: 0.8384 - val_f1_score: 0.8990\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1298 - acc: 0.9400 - precision: 0.9822 - recall: 0.8964 - f1_score: 0.9364 - val_loss: 4.1460 - val_acc: 0.9051 - val_precision: 0.9712 - val_recall: 0.8384 - val_f1_score: 0.8990\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1091 - acc: 0.9400 - precision: 0.9801 - recall: 0.8934 - f1_score: 0.9340 - val_loss: 4.1256 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0885 - acc: 0.9400 - precision: 0.9830 - recall: 0.8935 - f1_score: 0.9352 - val_loss: 4.1054 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0681 - acc: 0.9400 - precision: 0.9810 - recall: 0.8994 - f1_score: 0.9369 - val_loss: 4.0852 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0477 - acc: 0.9400 - precision: 0.9843 - recall: 0.8927 - f1_score: 0.9352 - val_loss: 4.0652 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0275 - acc: 0.9384 - precision: 0.9823 - recall: 0.8915 - f1_score: 0.9332 - val_loss: 4.0452 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0074 - acc: 0.9384 - precision: 0.9821 - recall: 0.8900 - f1_score: 0.9332 - val_loss: 4.0254 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9874 - acc: 0.9400 - precision: 0.9849 - recall: 0.8897 - f1_score: 0.9337 - val_loss: 4.0057 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9675 - acc: 0.9400 - precision: 0.9846 - recall: 0.8951 - f1_score: 0.9356 - val_loss: 3.9862 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9477 - acc: 0.9400 - precision: 0.9849 - recall: 0.8919 - f1_score: 0.9348 - val_loss: 3.9667 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9280 - acc: 0.9415 - precision: 0.9866 - recall: 0.8934 - f1_score: 0.9361 - val_loss: 3.9473 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9085 - acc: 0.9415 - precision: 0.9860 - recall: 0.8895 - f1_score: 0.9342 - val_loss: 3.9280 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8890 - acc: 0.9415 - precision: 0.9862 - recall: 0.8968 - f1_score: 0.9386 - val_loss: 3.9089 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8697 - acc: 0.9415 - precision: 0.9835 - recall: 0.8907 - f1_score: 0.9328 - val_loss: 3.8898 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8505 - acc: 0.9415 - precision: 0.9860 - recall: 0.8927 - f1_score: 0.9353 - val_loss: 3.8709 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8314 - acc: 0.9415 - precision: 0.9865 - recall: 0.8933 - f1_score: 0.9364 - val_loss: 3.8521 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8124 - acc: 0.9415 - precision: 0.9860 - recall: 0.8956 - f1_score: 0.9366 - val_loss: 3.8333 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7935 - acc: 0.9415 - precision: 0.9856 - recall: 0.8948 - f1_score: 0.9369 - val_loss: 3.8147 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7747 - acc: 0.9415 - precision: 0.9855 - recall: 0.8962 - f1_score: 0.9380 - val_loss: 3.7961 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7560 - acc: 0.9415 - precision: 0.9861 - recall: 0.8956 - f1_score: 0.9377 - val_loss: 3.7777 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7374 - acc: 0.9415 - precision: 0.9866 - recall: 0.8961 - f1_score: 0.9378 - val_loss: 3.7594 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7189 - acc: 0.9415 - precision: 0.9857 - recall: 0.8948 - f1_score: 0.9366 - val_loss: 3.7412 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7005 - acc: 0.9415 - precision: 0.9864 - recall: 0.8951 - f1_score: 0.9380 - val_loss: 3.7230 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6822 - acc: 0.9415 - precision: 0.9851 - recall: 0.8925 - f1_score: 0.9358 - val_loss: 3.7050 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6640 - acc: 0.9415 - precision: 0.9858 - recall: 0.8963 - f1_score: 0.9380 - val_loss: 3.6871 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 94/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.6460 - acc: 0.9415 - precision: 0.9848 - recall: 0.8923 - f1_score: 0.9346 - val_loss: 3.6693 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6280 - acc: 0.9415 - precision: 0.9839 - recall: 0.8974 - f1_score: 0.9372 - val_loss: 3.6515 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6101 - acc: 0.9415 - precision: 0.9861 - recall: 0.8988 - f1_score: 0.9394 - val_loss: 3.6339 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5923 - acc: 0.9415 - precision: 0.9867 - recall: 0.8978 - f1_score: 0.9394 - val_loss: 3.6164 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5746 - acc: 0.9431 - precision: 0.9905 - recall: 0.8947 - f1_score: 0.9397 - val_loss: 3.5989 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5571 - acc: 0.9431 - precision: 0.9867 - recall: 0.8950 - f1_score: 0.9378 - val_loss: 3.5816 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5395 - acc: 0.9431 - precision: 0.9891 - recall: 0.8918 - f1_score: 0.9369 - val_loss: 3.5643 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5222 - acc: 0.9431 - precision: 0.9887 - recall: 0.8976 - f1_score: 0.9401 - val_loss: 3.5472 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5048 - acc: 0.9431 - precision: 0.9893 - recall: 0.8964 - f1_score: 0.9383 - val_loss: 3.5301 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4876 - acc: 0.9431 - precision: 0.9907 - recall: 0.8977 - f1_score: 0.9407 - val_loss: 3.5131 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4705 - acc: 0.9431 - precision: 0.9904 - recall: 0.8923 - f1_score: 0.9381 - val_loss: 3.4962 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4535 - acc: 0.9431 - precision: 0.9899 - recall: 0.8940 - f1_score: 0.9380 - val_loss: 3.4795 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4366 - acc: 0.9431 - precision: 0.9888 - recall: 0.8955 - f1_score: 0.9391 - val_loss: 3.4627 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4197 - acc: 0.9431 - precision: 0.9895 - recall: 0.8947 - f1_score: 0.9387 - val_loss: 3.4461 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4030 - acc: 0.9431 - precision: 0.9892 - recall: 0.8948 - f1_score: 0.9384 - val_loss: 3.4296 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3864 - acc: 0.9431 - precision: 0.9881 - recall: 0.8962 - f1_score: 0.9391 - val_loss: 3.4132 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3698 - acc: 0.9431 - precision: 0.9897 - recall: 0.8919 - f1_score: 0.9378 - val_loss: 3.3968 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3533 - acc: 0.9431 - precision: 0.9892 - recall: 0.8919 - f1_score: 0.9374 - val_loss: 3.3806 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3369 - acc: 0.9431 - precision: 0.9895 - recall: 0.8933 - f1_score: 0.9381 - val_loss: 3.3644 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3206 - acc: 0.9431 - precision: 0.9890 - recall: 0.8939 - f1_score: 0.9380 - val_loss: 3.3483 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3044 - acc: 0.9431 - precision: 0.9880 - recall: 0.8888 - f1_score: 0.9332 - val_loss: 3.3323 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2883 - acc: 0.9431 - precision: 0.9904 - recall: 0.8973 - f1_score: 0.9394 - val_loss: 3.3164 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2723 - acc: 0.9431 - precision: 0.9865 - recall: 0.8939 - f1_score: 0.9373 - val_loss: 3.3006 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2563 - acc: 0.9431 - precision: 0.9880 - recall: 0.8940 - f1_score: 0.9384 - val_loss: 3.2848 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2405 - acc: 0.9431 - precision: 0.9876 - recall: 0.8925 - f1_score: 0.9363 - val_loss: 3.2692 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2247 - acc: 0.9431 - precision: 0.9881 - recall: 0.8968 - f1_score: 0.9390 - val_loss: 3.2536 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2090 - acc: 0.9431 - precision: 0.9871 - recall: 0.8920 - f1_score: 0.9360 - val_loss: 3.2381 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1934 - acc: 0.9431 - precision: 0.9889 - recall: 0.8953 - f1_score: 0.9389 - val_loss: 3.2227 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1779 - acc: 0.9431 - precision: 0.9898 - recall: 0.9002 - f1_score: 0.9410 - val_loss: 3.2074 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1624 - acc: 0.9431 - precision: 0.9897 - recall: 0.8942 - f1_score: 0.9384 - val_loss: 3.1922 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1471 - acc: 0.9431 - precision: 0.9894 - recall: 0.8959 - f1_score: 0.9390 - val_loss: 3.1770 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1318 - acc: 0.9431 - precision: 0.9878 - recall: 0.8954 - f1_score: 0.9382 - val_loss: 3.1619 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.1166 - acc: 0.9431 - precision: 0.9891 - recall: 0.8973 - f1_score: 0.9392 - val_loss: 3.1469 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1015 - acc: 0.9431 - precision: 0.9884 - recall: 0.8934 - f1_score: 0.9376 - val_loss: 3.1320 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0865 - acc: 0.9431 - precision: 0.9894 - recall: 0.8968 - f1_score: 0.9401 - val_loss: 3.1172 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0715 - acc: 0.9431 - precision: 0.9889 - recall: 0.8913 - f1_score: 0.9362 - val_loss: 3.1024 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0567 - acc: 0.9431 - precision: 0.9884 - recall: 0.8936 - f1_score: 0.9377 - val_loss: 3.0877 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0419 - acc: 0.9431 - precision: 0.9894 - recall: 0.8922 - f1_score: 0.9367 - val_loss: 3.0731 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0272 - acc: 0.9431 - precision: 0.9879 - recall: 0.8943 - f1_score: 0.9379 - val_loss: 3.0586 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0126 - acc: 0.9431 - precision: 0.9892 - recall: 0.8940 - f1_score: 0.9373 - val_loss: 3.0442 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9980 - acc: 0.9431 - precision: 0.9880 - recall: 0.8942 - f1_score: 0.9384 - val_loss: 3.0298 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9835 - acc: 0.9431 - precision: 0.9892 - recall: 0.8902 - f1_score: 0.9363 - val_loss: 3.0155 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9691 - acc: 0.9431 - precision: 0.9882 - recall: 0.8934 - f1_score: 0.9375 - val_loss: 3.0013 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9548 - acc: 0.9431 - precision: 0.9892 - recall: 0.8954 - f1_score: 0.9386 - val_loss: 2.9871 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9406 - acc: 0.9431 - precision: 0.9896 - recall: 0.8906 - f1_score: 0.9355 - val_loss: 2.9731 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9264 - acc: 0.9431 - precision: 0.9900 - recall: 0.8951 - f1_score: 0.9396 - val_loss: 2.9591 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9123 - acc: 0.9431 - precision: 0.9884 - recall: 0.8951 - f1_score: 0.9377 - val_loss: 2.9451 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8983 - acc: 0.9431 - precision: 0.9888 - recall: 0.8935 - f1_score: 0.9385 - val_loss: 2.9313 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8844 - acc: 0.9431 - precision: 0.9894 - recall: 0.8984 - f1_score: 0.9406 - val_loss: 2.9175 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8705 - acc: 0.9431 - precision: 0.9886 - recall: 0.8920 - f1_score: 0.9370 - val_loss: 2.9038 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8567 - acc: 0.9431 - precision: 0.9894 - recall: 0.8936 - f1_score: 0.9381 - val_loss: 2.8902 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8430 - acc: 0.9431 - precision: 0.9893 - recall: 0.8947 - f1_score: 0.9389 - val_loss: 2.8766 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8293 - acc: 0.9431 - precision: 0.9883 - recall: 0.8919 - f1_score: 0.9360 - val_loss: 2.8631 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8157 - acc: 0.9431 - precision: 0.9883 - recall: 0.8966 - f1_score: 0.9392 - val_loss: 2.8497 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8022 - acc: 0.9447 - precision: 0.9899 - recall: 0.8974 - f1_score: 0.9398 - val_loss: 2.8364 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7888 - acc: 0.9447 - precision: 0.9908 - recall: 0.8949 - f1_score: 0.9393 - val_loss: 2.8231 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7754 - acc: 0.9447 - precision: 0.9881 - recall: 0.8942 - f1_score: 0.9368 - val_loss: 2.8099 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7622 - acc: 0.9447 - precision: 0.9900 - recall: 0.8977 - f1_score: 0.9409 - val_loss: 2.7968 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7489 - acc: 0.9447 - precision: 0.9887 - recall: 0.8981 - f1_score: 0.9407 - val_loss: 2.7837 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7358 - acc: 0.9447 - precision: 0.9897 - recall: 0.9027 - f1_score: 0.9431 - val_loss: 2.7707 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7227 - acc: 0.9447 - precision: 0.9905 - recall: 0.8963 - f1_score: 0.9390 - val_loss: 2.7578 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7097 - acc: 0.9447 - precision: 0.9888 - recall: 0.8987 - f1_score: 0.9413 - val_loss: 2.7449 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6967 - acc: 0.9447 - precision: 0.9903 - recall: 0.8946 - f1_score: 0.9389 - val_loss: 2.7321 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6839 - acc: 0.9447 - precision: 0.9905 - recall: 0.8968 - f1_score: 0.9398 - val_loss: 2.7194 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.6711 - acc: 0.9447 - precision: 0.9885 - recall: 0.8968 - f1_score: 0.9397 - val_loss: 2.7067 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6583 - acc: 0.9447 - precision: 0.9890 - recall: 0.8935 - f1_score: 0.9378 - val_loss: 2.6942 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6457 - acc: 0.9447 - precision: 0.9882 - recall: 0.8992 - f1_score: 0.9403 - val_loss: 2.6816 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6331 - acc: 0.9447 - precision: 0.9907 - recall: 0.8964 - f1_score: 0.9401 - val_loss: 2.6692 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6205 - acc: 0.9447 - precision: 0.9897 - recall: 0.9002 - f1_score: 0.9414 - val_loss: 2.6568 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6080 - acc: 0.9447 - precision: 0.9896 - recall: 0.8994 - f1_score: 0.9418 - val_loss: 2.6445 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5956 - acc: 0.9447 - precision: 0.9895 - recall: 0.8956 - f1_score: 0.9392 - val_loss: 2.6322 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5833 - acc: 0.9447 - precision: 0.9879 - recall: 0.8977 - f1_score: 0.9396 - val_loss: 2.6200 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5710 - acc: 0.9447 - precision: 0.9891 - recall: 0.8946 - f1_score: 0.9370 - val_loss: 2.6079 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5588 - acc: 0.9447 - precision: 0.9894 - recall: 0.8989 - f1_score: 0.9405 - val_loss: 2.5958 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5467 - acc: 0.9447 - precision: 0.9896 - recall: 0.8989 - f1_score: 0.9408 - val_loss: 2.5838 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5346 - acc: 0.9447 - precision: 0.9901 - recall: 0.8963 - f1_score: 0.9397 - val_loss: 2.5718 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5226 - acc: 0.9447 - precision: 0.9898 - recall: 0.8927 - f1_score: 0.9378 - val_loss: 2.5599 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5106 - acc: 0.9447 - precision: 0.9903 - recall: 0.8988 - f1_score: 0.9401 - val_loss: 2.5481 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4988 - acc: 0.9447 - precision: 0.9902 - recall: 0.8973 - f1_score: 0.9410 - val_loss: 2.5364 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4869 - acc: 0.9447 - precision: 0.9897 - recall: 0.8962 - f1_score: 0.9398 - val_loss: 2.5247 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4752 - acc: 0.9447 - precision: 0.9888 - recall: 0.8942 - f1_score: 0.9386 - val_loss: 2.5130 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4635 - acc: 0.9447 - precision: 0.9899 - recall: 0.8926 - f1_score: 0.9377 - val_loss: 2.5015 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4518 - acc: 0.9447 - precision: 0.9901 - recall: 0.8976 - f1_score: 0.9400 - val_loss: 2.4900 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4402 - acc: 0.9447 - precision: 0.9884 - recall: 0.8948 - f1_score: 0.9382 - val_loss: 2.4785 - val_acc: 0.9114 - val_precision: 0.9849 - val_recall: 0.8384 - val_f1_score: 0.9052\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4287 - acc: 0.9447 - precision: 0.9890 - recall: 0.8985 - f1_score: 0.9397 - val_loss: 2.4671 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4173 - acc: 0.9447 - precision: 0.9897 - recall: 0.8978 - f1_score: 0.9403 - val_loss: 2.4558 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4059 - acc: 0.9447 - precision: 0.9886 - recall: 0.8962 - f1_score: 0.9390 - val_loss: 2.4445 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3945 - acc: 0.9447 - precision: 0.9879 - recall: 0.8959 - f1_score: 0.9391 - val_loss: 2.4333 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3832 - acc: 0.9447 - precision: 0.9900 - recall: 0.9007 - f1_score: 0.9422 - val_loss: 2.4221 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3720 - acc: 0.9447 - precision: 0.9902 - recall: 0.8974 - f1_score: 0.9397 - val_loss: 2.4110 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3609 - acc: 0.9447 - precision: 0.9911 - recall: 0.8981 - f1_score: 0.9414 - val_loss: 2.4000 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3498 - acc: 0.9447 - precision: 0.9897 - recall: 0.8967 - f1_score: 0.9400 - val_loss: 2.3890 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3387 - acc: 0.9447 - precision: 0.9882 - recall: 0.9022 - f1_score: 0.9415 - val_loss: 2.3781 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3277 - acc: 0.9447 - precision: 0.9906 - recall: 0.8963 - f1_score: 0.9396 - val_loss: 2.3672 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3168 - acc: 0.9447 - precision: 0.9894 - recall: 0.8928 - f1_score: 0.9372 - val_loss: 2.3564 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3059 - acc: 0.9447 - precision: 0.9873 - recall: 0.8968 - f1_score: 0.9381 - val_loss: 2.3457 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 190/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.2951 - acc: 0.9447 - precision: 0.9884 - recall: 0.8997 - f1_score: 0.9407 - val_loss: 2.3349 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2843 - acc: 0.9447 - precision: 0.9903 - recall: 0.8959 - f1_score: 0.9396 - val_loss: 2.3243 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2736 - acc: 0.9447 - precision: 0.9885 - recall: 0.8965 - f1_score: 0.9391 - val_loss: 2.3137 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2630 - acc: 0.9447 - precision: 0.9911 - recall: 0.8977 - f1_score: 0.9412 - val_loss: 2.3032 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2524 - acc: 0.9447 - precision: 0.9899 - recall: 0.8990 - f1_score: 0.9405 - val_loss: 2.2927 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2419 - acc: 0.9447 - precision: 0.9889 - recall: 0.9004 - f1_score: 0.9413 - val_loss: 2.2823 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2314 - acc: 0.9447 - precision: 0.9900 - recall: 0.8959 - f1_score: 0.9394 - val_loss: 2.2719 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2210 - acc: 0.9447 - precision: 0.9897 - recall: 0.9015 - f1_score: 0.9418 - val_loss: 2.2616 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2106 - acc: 0.9447 - precision: 0.9901 - recall: 0.8997 - f1_score: 0.9416 - val_loss: 2.2513 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2003 - acc: 0.9447 - precision: 0.9890 - recall: 0.8967 - f1_score: 0.9393 - val_loss: 2.2411 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1900 - acc: 0.9447 - precision: 0.9892 - recall: 0.8989 - f1_score: 0.9413 - val_loss: 2.2310 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1798 - acc: 0.9447 - precision: 0.9891 - recall: 0.8964 - f1_score: 0.9400 - val_loss: 2.2209 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1696 - acc: 0.9463 - precision: 0.9905 - recall: 0.9002 - f1_score: 0.9423 - val_loss: 2.2108 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1595 - acc: 0.9463 - precision: 0.9881 - recall: 0.9007 - f1_score: 0.9416 - val_loss: 2.2008 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1495 - acc: 0.9463 - precision: 0.9903 - recall: 0.9042 - f1_score: 0.9446 - val_loss: 2.1909 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1395 - acc: 0.9463 - precision: 0.9880 - recall: 0.9011 - f1_score: 0.9411 - val_loss: 2.1810 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1296 - acc: 0.9463 - precision: 0.9893 - recall: 0.8992 - f1_score: 0.9412 - val_loss: 2.1712 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1197 - acc: 0.9463 - precision: 0.9895 - recall: 0.9006 - f1_score: 0.9421 - val_loss: 2.1614 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1098 - acc: 0.9463 - precision: 0.9903 - recall: 0.9024 - f1_score: 0.9434 - val_loss: 2.1516 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1000 - acc: 0.9463 - precision: 0.9858 - recall: 0.8917 - f1_score: 0.9353 - val_loss: 2.1420 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0903 - acc: 0.9463 - precision: 0.9870 - recall: 0.8999 - f1_score: 0.9398 - val_loss: 2.1323 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0806 - acc: 0.9463 - precision: 0.9892 - recall: 0.9009 - f1_score: 0.9420 - val_loss: 2.1227 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0710 - acc: 0.9463 - precision: 0.9898 - recall: 0.8963 - f1_score: 0.9393 - val_loss: 2.1132 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0614 - acc: 0.9463 - precision: 0.9885 - recall: 0.8992 - f1_score: 0.9405 - val_loss: 2.1037 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0518 - acc: 0.9463 - precision: 0.9909 - recall: 0.9015 - f1_score: 0.9429 - val_loss: 2.0943 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0424 - acc: 0.9463 - precision: 0.9902 - recall: 0.8970 - f1_score: 0.9394 - val_loss: 2.0849 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0329 - acc: 0.9463 - precision: 0.9890 - recall: 0.9030 - f1_score: 0.9429 - val_loss: 2.0755 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0235 - acc: 0.9463 - precision: 0.9904 - recall: 0.9054 - f1_score: 0.9448 - val_loss: 2.0662 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0142 - acc: 0.9463 - precision: 0.9900 - recall: 0.8975 - f1_score: 0.9408 - val_loss: 2.0570 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0049 - acc: 0.9463 - precision: 0.9883 - recall: 0.8979 - f1_score: 0.9405 - val_loss: 2.0478 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9956 - acc: 0.9463 - precision: 0.9889 - recall: 0.8910 - f1_score: 0.9341 - val_loss: 2.0387 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9865 - acc: 0.9463 - precision: 0.9904 - recall: 0.9020 - f1_score: 0.9423 - val_loss: 2.0296 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.9773 - acc: 0.9463 - precision: 0.9889 - recall: 0.9009 - f1_score: 0.9424 - val_loss: 2.0205 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9682 - acc: 0.9463 - precision: 0.9890 - recall: 0.9025 - f1_score: 0.9423 - val_loss: 2.0115 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9592 - acc: 0.9463 - precision: 0.9886 - recall: 0.9006 - f1_score: 0.9419 - val_loss: 2.0025 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9502 - acc: 0.9463 - precision: 0.9894 - recall: 0.8980 - f1_score: 0.9408 - val_loss: 1.9936 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9412 - acc: 0.9463 - precision: 0.9890 - recall: 0.8948 - f1_score: 0.9388 - val_loss: 1.9848 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9323 - acc: 0.9463 - precision: 0.9882 - recall: 0.9029 - f1_score: 0.9420 - val_loss: 1.9759 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9234 - acc: 0.9463 - precision: 0.9906 - recall: 0.9022 - f1_score: 0.9436 - val_loss: 1.9672 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9146 - acc: 0.9463 - precision: 0.9897 - recall: 0.9000 - f1_score: 0.9415 - val_loss: 1.9584 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9058 - acc: 0.9479 - precision: 0.9896 - recall: 0.9039 - f1_score: 0.9437 - val_loss: 1.9497 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8971 - acc: 0.9479 - precision: 0.9911 - recall: 0.9048 - f1_score: 0.9455 - val_loss: 1.9411 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8884 - acc: 0.9479 - precision: 0.9895 - recall: 0.9032 - f1_score: 0.9429 - val_loss: 1.9325 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8798 - acc: 0.9479 - precision: 0.9900 - recall: 0.9028 - f1_score: 0.9421 - val_loss: 1.9240 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8712 - acc: 0.9479 - precision: 0.9898 - recall: 0.9039 - f1_score: 0.9443 - val_loss: 1.9154 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8626 - acc: 0.9479 - precision: 0.9891 - recall: 0.9021 - f1_score: 0.9427 - val_loss: 1.9070 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8541 - acc: 0.9479 - precision: 0.9903 - recall: 0.9017 - f1_score: 0.9421 - val_loss: 1.8986 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8457 - acc: 0.9479 - precision: 0.9884 - recall: 0.9004 - f1_score: 0.9417 - val_loss: 1.8902 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8373 - acc: 0.9479 - precision: 0.9905 - recall: 0.9069 - f1_score: 0.9460 - val_loss: 1.8819 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8289 - acc: 0.9479 - precision: 0.9894 - recall: 0.9045 - f1_score: 0.9443 - val_loss: 1.8736 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8206 - acc: 0.9479 - precision: 0.9899 - recall: 0.9027 - f1_score: 0.9432 - val_loss: 1.8653 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8123 - acc: 0.9479 - precision: 0.9894 - recall: 0.9058 - f1_score: 0.9449 - val_loss: 1.8571 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8040 - acc: 0.9479 - precision: 0.9897 - recall: 0.9046 - f1_score: 0.9436 - val_loss: 1.8490 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7958 - acc: 0.9479 - precision: 0.9894 - recall: 0.9043 - f1_score: 0.9428 - val_loss: 1.8408 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7877 - acc: 0.9479 - precision: 0.9895 - recall: 0.9040 - f1_score: 0.9441 - val_loss: 1.8328 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7796 - acc: 0.9479 - precision: 0.9898 - recall: 0.9050 - f1_score: 0.9443 - val_loss: 1.8247 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7715 - acc: 0.9479 - precision: 0.9897 - recall: 0.9076 - f1_score: 0.9462 - val_loss: 1.8167 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7635 - acc: 0.9479 - precision: 0.9895 - recall: 0.9050 - f1_score: 0.9442 - val_loss: 1.8088 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7555 - acc: 0.9479 - precision: 0.9889 - recall: 0.9053 - f1_score: 0.9446 - val_loss: 1.8009 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7475 - acc: 0.9479 - precision: 0.9896 - recall: 0.9060 - f1_score: 0.9446 - val_loss: 1.7930 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7396 - acc: 0.9479 - precision: 0.9896 - recall: 0.9041 - f1_score: 0.9442 - val_loss: 1.7852 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7318 - acc: 0.9479 - precision: 0.9897 - recall: 0.9084 - f1_score: 0.9456 - val_loss: 1.7774 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7239 - acc: 0.9479 - precision: 0.9905 - recall: 0.9055 - f1_score: 0.9451 - val_loss: 1.7697 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.7423 - acc: 0.9400 - precision: 1.0000 - recall: 0.8636 - f1_score: 0.926 - 0s - loss: 1.7162 - acc: 0.9479 - precision: 0.9915 - recall: 0.9041 - f1_score: 0.9448 - val_loss: 1.7620 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 254/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.7084 - acc: 0.9479 - precision: 0.9896 - recall: 0.9047 - f1_score: 0.9441 - val_loss: 1.7543 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7007 - acc: 0.9479 - precision: 0.9883 - recall: 0.9037 - f1_score: 0.9429 - val_loss: 1.7467 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6930 - acc: 0.9479 - precision: 0.9890 - recall: 0.9049 - f1_score: 0.9440 - val_loss: 1.7391 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6854 - acc: 0.9479 - precision: 0.9888 - recall: 0.9051 - f1_score: 0.9433 - val_loss: 1.7315 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6778 - acc: 0.9479 - precision: 0.9892 - recall: 0.9050 - f1_score: 0.9439 - val_loss: 1.7240 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6703 - acc: 0.9479 - precision: 0.9899 - recall: 0.9055 - f1_score: 0.9437 - val_loss: 1.7165 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6628 - acc: 0.9479 - precision: 0.9901 - recall: 0.9104 - f1_score: 0.9466 - val_loss: 1.7091 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6553 - acc: 0.9479 - precision: 0.9891 - recall: 0.9043 - f1_score: 0.9438 - val_loss: 1.7017 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6479 - acc: 0.9479 - precision: 0.9896 - recall: 0.9057 - f1_score: 0.9450 - val_loss: 1.6944 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6405 - acc: 0.9479 - precision: 0.9897 - recall: 0.9055 - f1_score: 0.9450 - val_loss: 1.6870 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6332 - acc: 0.9479 - precision: 0.9905 - recall: 0.9029 - f1_score: 0.9437 - val_loss: 1.6798 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6258 - acc: 0.9479 - precision: 0.9894 - recall: 0.9034 - f1_score: 0.9433 - val_loss: 1.6725 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6186 - acc: 0.9479 - precision: 0.9892 - recall: 0.9093 - f1_score: 0.9461 - val_loss: 1.6653 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6113 - acc: 0.9479 - precision: 0.9891 - recall: 0.8998 - f1_score: 0.9401 - val_loss: 1.6581 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6041 - acc: 0.9479 - precision: 0.9869 - recall: 0.9057 - f1_score: 0.9432 - val_loss: 1.6510 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5970 - acc: 0.9479 - precision: 0.9899 - recall: 0.9031 - f1_score: 0.9433 - val_loss: 1.6439 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5898 - acc: 0.9479 - precision: 0.9893 - recall: 0.9092 - f1_score: 0.9460 - val_loss: 1.6368 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5828 - acc: 0.9479 - precision: 0.9895 - recall: 0.9030 - f1_score: 0.9424 - val_loss: 1.6298 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5757 - acc: 0.9479 - precision: 0.9900 - recall: 0.9006 - f1_score: 0.9420 - val_loss: 1.6228 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5687 - acc: 0.9479 - precision: 0.9889 - recall: 0.9013 - f1_score: 0.9423 - val_loss: 1.6159 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5617 - acc: 0.9479 - precision: 0.9892 - recall: 0.8970 - f1_score: 0.9390 - val_loss: 1.6090 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5548 - acc: 0.9479 - precision: 0.9906 - recall: 0.9011 - f1_score: 0.9422 - val_loss: 1.6021 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5479 - acc: 0.9479 - precision: 0.9908 - recall: 0.9036 - f1_score: 0.9439 - val_loss: 1.5952 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5410 - acc: 0.9479 - precision: 0.9897 - recall: 0.9063 - f1_score: 0.9454 - val_loss: 1.5884 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5341 - acc: 0.9479 - precision: 0.9892 - recall: 0.9046 - f1_score: 0.9441 - val_loss: 1.5817 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5273 - acc: 0.9479 - precision: 0.9912 - recall: 0.9002 - f1_score: 0.9425 - val_loss: 1.5749 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5206 - acc: 0.9479 - precision: 0.9892 - recall: 0.9036 - f1_score: 0.9439 - val_loss: 1.5682 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5138 - acc: 0.9479 - precision: 0.9889 - recall: 0.9055 - f1_score: 0.9438 - val_loss: 1.5616 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5071 - acc: 0.9479 - precision: 0.9904 - recall: 0.9002 - f1_score: 0.9421 - val_loss: 1.5549 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5005 - acc: 0.9479 - precision: 0.9911 - recall: 0.9015 - f1_score: 0.9434 - val_loss: 1.5483 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4939 - acc: 0.9479 - precision: 0.9900 - recall: 0.9049 - f1_score: 0.9449 - val_loss: 1.5418 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4873 - acc: 0.9479 - precision: 0.9904 - recall: 0.9022 - f1_score: 0.9426 - val_loss: 1.5352 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4807 - acc: 0.9479 - precision: 0.9887 - recall: 0.9004 - f1_score: 0.9416 - val_loss: 1.5287 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4742 - acc: 0.9479 - precision: 0.9898 - recall: 0.9051 - f1_score: 0.9438 - val_loss: 1.5223 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4677 - acc: 0.9479 - precision: 0.9910 - recall: 0.9017 - f1_score: 0.9429 - val_loss: 1.5158 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4612 - acc: 0.9479 - precision: 0.9880 - recall: 0.9071 - f1_score: 0.9449 - val_loss: 1.5095 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4548 - acc: 0.9479 - precision: 0.9896 - recall: 0.9041 - f1_score: 0.9440 - val_loss: 1.5031 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4484 - acc: 0.9494 - precision: 0.9906 - recall: 0.9080 - f1_score: 0.9465 - val_loss: 1.4968 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4420 - acc: 0.9494 - precision: 0.9906 - recall: 0.9081 - f1_score: 0.9470 - val_loss: 1.4905 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4357 - acc: 0.9494 - precision: 0.9864 - recall: 0.9017 - f1_score: 0.9411 - val_loss: 1.4842 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4294 - acc: 0.9494 - precision: 0.9898 - recall: 0.9081 - f1_score: 0.9460 - val_loss: 1.4780 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4232 - acc: 0.9494 - precision: 0.9899 - recall: 0.9064 - f1_score: 0.9439 - val_loss: 1.4718 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4169 - acc: 0.9494 - precision: 0.9881 - recall: 0.9055 - f1_score: 0.9440 - val_loss: 1.4656 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4107 - acc: 0.9494 - precision: 0.9903 - recall: 0.9055 - f1_score: 0.9453 - val_loss: 1.4594 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4046 - acc: 0.9494 - precision: 0.9900 - recall: 0.9068 - f1_score: 0.9460 - val_loss: 1.4533 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3984 - acc: 0.9494 - precision: 0.9894 - recall: 0.9098 - f1_score: 0.9462 - val_loss: 1.4472 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3923 - acc: 0.9494 - precision: 0.9900 - recall: 0.9076 - f1_score: 0.9463 - val_loss: 1.4412 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3863 - acc: 0.9494 - precision: 0.9897 - recall: 0.9064 - f1_score: 0.9453 - val_loss: 1.4352 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3802 - acc: 0.9494 - precision: 0.9896 - recall: 0.9057 - f1_score: 0.9449 - val_loss: 1.4292 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3742 - acc: 0.9494 - precision: 0.9901 - recall: 0.9059 - f1_score: 0.9457 - val_loss: 1.4233 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3682 - acc: 0.9494 - precision: 0.9895 - recall: 0.9071 - f1_score: 0.9456 - val_loss: 1.4173 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3623 - acc: 0.9494 - precision: 0.9892 - recall: 0.9086 - f1_score: 0.9463 - val_loss: 1.4114 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3564 - acc: 0.9494 - precision: 0.9904 - recall: 0.9038 - f1_score: 0.9439 - val_loss: 1.4056 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3505 - acc: 0.9494 - precision: 0.9898 - recall: 0.9041 - f1_score: 0.9441 - val_loss: 1.3997 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3446 - acc: 0.9494 - precision: 0.9887 - recall: 0.9087 - f1_score: 0.9459 - val_loss: 1.3939 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3388 - acc: 0.9494 - precision: 0.9899 - recall: 0.9107 - f1_score: 0.9479 - val_loss: 1.3882 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3330 - acc: 0.9494 - precision: 0.9885 - recall: 0.9057 - f1_score: 0.9438 - val_loss: 1.3824 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3272 - acc: 0.9494 - precision: 0.9893 - recall: 0.9053 - f1_score: 0.9443 - val_loss: 1.3767 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3215 - acc: 0.9494 - precision: 0.9902 - recall: 0.9065 - f1_score: 0.9454 - val_loss: 1.3710 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3158 - acc: 0.9494 - precision: 0.9888 - recall: 0.9041 - f1_score: 0.9418 - val_loss: 1.3654 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3101 - acc: 0.9494 - precision: 0.9901 - recall: 0.9043 - f1_score: 0.9434 - val_loss: 1.3597 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3045 - acc: 0.9494 - precision: 0.9899 - recall: 0.9068 - f1_score: 0.9447 - val_loss: 1.3542 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2988 - acc: 0.9494 - precision: 0.9893 - recall: 0.9069 - f1_score: 0.9459 - val_loss: 1.3486 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2933 - acc: 0.9494 - precision: 0.9887 - recall: 0.9101 - f1_score: 0.9468 - val_loss: 1.3430 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2877 - acc: 0.9494 - precision: 0.9898 - recall: 0.9062 - f1_score: 0.9456 - val_loss: 1.3375 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.2890 - acc: 0.9600 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.941 - 0s - loss: 1.2822 - acc: 0.9494 - precision: 0.9886 - recall: 0.9093 - f1_score: 0.9462 - val_loss: 1.3320 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2767 - acc: 0.9494 - precision: 0.9913 - recall: 0.9063 - f1_score: 0.9458 - val_loss: 1.3266 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2712 - acc: 0.9494 - precision: 0.9882 - recall: 0.9005 - f1_score: 0.9410 - val_loss: 1.3212 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2657 - acc: 0.9494 - precision: 0.9897 - recall: 0.9053 - f1_score: 0.9448 - val_loss: 1.3158 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2603 - acc: 0.9494 - precision: 0.9903 - recall: 0.9088 - f1_score: 0.9471 - val_loss: 1.3104 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2549 - acc: 0.9494 - precision: 0.9905 - recall: 0.9083 - f1_score: 0.9468 - val_loss: 1.3051 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2495 - acc: 0.9494 - precision: 0.9905 - recall: 0.9058 - f1_score: 0.9451 - val_loss: 1.2998 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2442 - acc: 0.9494 - precision: 0.9900 - recall: 0.9083 - f1_score: 0.9460 - val_loss: 1.2945 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2389 - acc: 0.9494 - precision: 0.9909 - recall: 0.9077 - f1_score: 0.9452 - val_loss: 1.2892 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2336 - acc: 0.9494 - precision: 0.9890 - recall: 0.9051 - f1_score: 0.9444 - val_loss: 1.2840 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2284 - acc: 0.9494 - precision: 0.9899 - recall: 0.9093 - f1_score: 0.9475 - val_loss: 1.2788 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2231 - acc: 0.9494 - precision: 0.9888 - recall: 0.9074 - f1_score: 0.9456 - val_loss: 1.2736 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2179 - acc: 0.9494 - precision: 0.9904 - recall: 0.9052 - f1_score: 0.9445 - val_loss: 1.2684 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2128 - acc: 0.9494 - precision: 0.9895 - recall: 0.9068 - f1_score: 0.9458 - val_loss: 1.2633 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2076 - acc: 0.9494 - precision: 0.9904 - recall: 0.9049 - f1_score: 0.9454 - val_loss: 1.2582 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2025 - acc: 0.9494 - precision: 0.9895 - recall: 0.9097 - f1_score: 0.9467 - val_loss: 1.2531 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1974 - acc: 0.9494 - precision: 0.9894 - recall: 0.9066 - f1_score: 0.9451 - val_loss: 1.2481 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1923 - acc: 0.9494 - precision: 0.9888 - recall: 0.9079 - f1_score: 0.9449 - val_loss: 1.2430 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1873 - acc: 0.9494 - precision: 0.9890 - recall: 0.9085 - f1_score: 0.9462 - val_loss: 1.2381 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1823 - acc: 0.9494 - precision: 0.9883 - recall: 0.9043 - f1_score: 0.9438 - val_loss: 1.2331 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1773 - acc: 0.9494 - precision: 0.9900 - recall: 0.9070 - f1_score: 0.9457 - val_loss: 1.2281 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1723 - acc: 0.9494 - precision: 0.9875 - recall: 0.9043 - f1_score: 0.9427 - val_loss: 1.2232 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1674 - acc: 0.9494 - precision: 0.9911 - recall: 0.9022 - f1_score: 0.9435 - val_loss: 1.2183 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1624 - acc: 0.9494 - precision: 0.9887 - recall: 0.9054 - f1_score: 0.9445 - val_loss: 1.2134 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1576 - acc: 0.9494 - precision: 0.9898 - recall: 0.9076 - f1_score: 0.9461 - val_loss: 1.2086 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1527 - acc: 0.9494 - precision: 0.9874 - recall: 0.9053 - f1_score: 0.9433 - val_loss: 1.2038 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1478 - acc: 0.9494 - precision: 0.9895 - recall: 0.9051 - f1_score: 0.9437 - val_loss: 1.1990 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1430 - acc: 0.9494 - precision: 0.9889 - recall: 0.9081 - f1_score: 0.9465 - val_loss: 1.1942 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1382 - acc: 0.9494 - precision: 0.9906 - recall: 0.9105 - f1_score: 0.9483 - val_loss: 1.1895 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1335 - acc: 0.9494 - precision: 0.9881 - recall: 0.9057 - f1_score: 0.9440 - val_loss: 1.1847 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1287 - acc: 0.9494 - precision: 0.9889 - recall: 0.9085 - f1_score: 0.9462 - val_loss: 1.1800 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1240 - acc: 0.9494 - precision: 0.9886 - recall: 0.9060 - f1_score: 0.9447 - val_loss: 1.1754 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1193 - acc: 0.9494 - precision: 0.9890 - recall: 0.9081 - f1_score: 0.9463 - val_loss: 1.1707 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1146 - acc: 0.9494 - precision: 0.9899 - recall: 0.9120 - f1_score: 0.9483 - val_loss: 1.1661 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1100 - acc: 0.9494 - precision: 0.9904 - recall: 0.9088 - f1_score: 0.9470 - val_loss: 1.1615 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1054 - acc: 0.9494 - precision: 0.9903 - recall: 0.9094 - f1_score: 0.9473 - val_loss: 1.1569 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1008 - acc: 0.9494 - precision: 0.9897 - recall: 0.9089 - f1_score: 0.9471 - val_loss: 1.1524 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0962 - acc: 0.9494 - precision: 0.9888 - recall: 0.9074 - f1_score: 0.9455 - val_loss: 1.1478 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0916 - acc: 0.9494 - precision: 0.9887 - recall: 0.9074 - f1_score: 0.9452 - val_loss: 1.1433 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0871 - acc: 0.9494 - precision: 0.9900 - recall: 0.9069 - f1_score: 0.9460 - val_loss: 1.1388 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0826 - acc: 0.9494 - precision: 0.9912 - recall: 0.9049 - f1_score: 0.9452 - val_loss: 1.1344 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0781 - acc: 0.9494 - precision: 0.9900 - recall: 0.9077 - f1_score: 0.9467 - val_loss: 1.1299 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0737 - acc: 0.9494 - precision: 0.9892 - recall: 0.9066 - f1_score: 0.9449 - val_loss: 1.1255 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0692 - acc: 0.9494 - precision: 0.9895 - recall: 0.9065 - f1_score: 0.9451 - val_loss: 1.1211 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0648 - acc: 0.9494 - precision: 0.9873 - recall: 0.9067 - f1_score: 0.9444 - val_loss: 1.1168 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0604 - acc: 0.9494 - precision: 0.9885 - recall: 0.9037 - f1_score: 0.9434 - val_loss: 1.1124 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0561 - acc: 0.9494 - precision: 0.9894 - recall: 0.9051 - f1_score: 0.9445 - val_loss: 1.1081 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0517 - acc: 0.9494 - precision: 0.9895 - recall: 0.9051 - f1_score: 0.9443 - val_loss: 1.1038 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0474 - acc: 0.9494 - precision: 0.9894 - recall: 0.9066 - f1_score: 0.9459 - val_loss: 1.0995 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0431 - acc: 0.9494 - precision: 0.9873 - recall: 0.9057 - f1_score: 0.9442 - val_loss: 1.0952 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0388 - acc: 0.9494 - precision: 0.9890 - recall: 0.9081 - f1_score: 0.9454 - val_loss: 1.0910 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0345 - acc: 0.9494 - precision: 0.9903 - recall: 0.9067 - f1_score: 0.9454 - val_loss: 1.0868 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0303 - acc: 0.9494 - precision: 0.9898 - recall: 0.9046 - f1_score: 0.9443 - val_loss: 1.0826 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0261 - acc: 0.9494 - precision: 0.9905 - recall: 0.9100 - f1_score: 0.9474 - val_loss: 1.0784 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0219 - acc: 0.9494 - precision: 0.9897 - recall: 0.9076 - f1_score: 0.9457 - val_loss: 1.0742 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0177 - acc: 0.9494 - precision: 0.9891 - recall: 0.9067 - f1_score: 0.9448 - val_loss: 1.0701 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0136 - acc: 0.9494 - precision: 0.9878 - recall: 0.9025 - f1_score: 0.9424 - val_loss: 1.0660 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0094 - acc: 0.9494 - precision: 0.9888 - recall: 0.9063 - f1_score: 0.9451 - val_loss: 1.0619 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.0060 - acc: 0.9525 - precision: 0.9837 - recall: 0.9157 - f1_score: 0.948 - 0s - loss: 1.0053 - acc: 0.9494 - precision: 0.9897 - recall: 0.9067 - f1_score: 0.9459 - val_loss: 1.0578 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0012 - acc: 0.9494 - precision: 0.9873 - recall: 0.9077 - f1_score: 0.9449 - val_loss: 1.0538 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9972 - acc: 0.9494 - precision: 0.9896 - recall: 0.9005 - f1_score: 0.9408 - val_loss: 1.0497 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9931 - acc: 0.9494 - precision: 0.9900 - recall: 0.9071 - f1_score: 0.9463 - val_loss: 1.0457 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9891 - acc: 0.9494 - precision: 0.9873 - recall: 0.9057 - f1_score: 0.9427 - val_loss: 1.0417 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9851 - acc: 0.9494 - precision: 0.9899 - recall: 0.9044 - f1_score: 0.9442 - val_loss: 1.0378 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9811 - acc: 0.9494 - precision: 0.9883 - recall: 0.9065 - f1_score: 0.9449 - val_loss: 1.0338 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9771 - acc: 0.9494 - precision: 0.9900 - recall: 0.9073 - f1_score: 0.9440 - val_loss: 1.0299 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9732 - acc: 0.9494 - precision: 0.9905 - recall: 0.9068 - f1_score: 0.9457 - val_loss: 1.0260 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9693 - acc: 0.9494 - precision: 0.9902 - recall: 0.9086 - f1_score: 0.9472 - val_loss: 1.0221 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9654 - acc: 0.9494 - precision: 0.9889 - recall: 0.9063 - f1_score: 0.9453 - val_loss: 1.0182 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9615 - acc: 0.9494 - precision: 0.9904 - recall: 0.9069 - f1_score: 0.9460 - val_loss: 1.0144 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9576 - acc: 0.9494 - precision: 0.9908 - recall: 0.9053 - f1_score: 0.9455 - val_loss: 1.0106 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9538 - acc: 0.9494 - precision: 0.9898 - recall: 0.9147 - f1_score: 0.9495 - val_loss: 1.0067 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9499 - acc: 0.9494 - precision: 0.9894 - recall: 0.9053 - f1_score: 0.9450 - val_loss: 1.0030 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9461 - acc: 0.9494 - precision: 0.9906 - recall: 0.9070 - f1_score: 0.9461 - val_loss: 0.9992 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9423 - acc: 0.9494 - precision: 0.9901 - recall: 0.9068 - f1_score: 0.9462 - val_loss: 0.9954 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9386 - acc: 0.9494 - precision: 0.9905 - recall: 0.9047 - f1_score: 0.9449 - val_loss: 0.9917 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9348 - acc: 0.9494 - precision: 0.9898 - recall: 0.9092 - f1_score: 0.9458 - val_loss: 0.9880 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9311 - acc: 0.9494 - precision: 0.9900 - recall: 0.9073 - f1_score: 0.9459 - val_loss: 0.9843 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9274 - acc: 0.9494 - precision: 0.9899 - recall: 0.9084 - f1_score: 0.9463 - val_loss: 0.9806 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.9275 - acc: 0.9489 - precision: 0.9838 - recall: 0.9102 - f1_score: 0.944 - 0s - loss: 0.9237 - acc: 0.9494 - precision: 0.9885 - recall: 0.9063 - f1_score: 0.9447 - val_loss: 0.9770 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9200 - acc: 0.9494 - precision: 0.9903 - recall: 0.9100 - f1_score: 0.9472 - val_loss: 0.9733 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9164 - acc: 0.9494 - precision: 0.9901 - recall: 0.9072 - f1_score: 0.9457 - val_loss: 0.9697 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9127 - acc: 0.9494 - precision: 0.9884 - recall: 0.9058 - f1_score: 0.9446 - val_loss: 0.9661 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9091 - acc: 0.9494 - precision: 0.9892 - recall: 0.9068 - f1_score: 0.9456 - val_loss: 0.9625 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9055 - acc: 0.9494 - precision: 0.9883 - recall: 0.9083 - f1_score: 0.9448 - val_loss: 0.9590 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9019 - acc: 0.9494 - precision: 0.9896 - recall: 0.9084 - f1_score: 0.9467 - val_loss: 0.9554 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8984 - acc: 0.9494 - precision: 0.9899 - recall: 0.9020 - f1_score: 0.9422 - val_loss: 0.9519 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8948 - acc: 0.9494 - precision: 0.9892 - recall: 0.9059 - f1_score: 0.9453 - val_loss: 0.9484 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8913 - acc: 0.9494 - precision: 0.9903 - recall: 0.9058 - f1_score: 0.9451 - val_loss: 0.9449 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8878 - acc: 0.9494 - precision: 0.9901 - recall: 0.9051 - f1_score: 0.9446 - val_loss: 0.9414 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8843 - acc: 0.9494 - precision: 0.9892 - recall: 0.9085 - f1_score: 0.9464 - val_loss: 0.9380 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8808 - acc: 0.9494 - precision: 0.9902 - recall: 0.9104 - f1_score: 0.9473 - val_loss: 0.9345 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8774 - acc: 0.9494 - precision: 0.9905 - recall: 0.9068 - f1_score: 0.9453 - val_loss: 0.9311 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8739 - acc: 0.9494 - precision: 0.9901 - recall: 0.9075 - f1_score: 0.9464 - val_loss: 0.9277 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8705 - acc: 0.9494 - precision: 0.9898 - recall: 0.9076 - f1_score: 0.9453 - val_loss: 0.9243 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8671 - acc: 0.9494 - precision: 0.9898 - recall: 0.9076 - f1_score: 0.9460 - val_loss: 0.9210 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8637 - acc: 0.9494 - precision: 0.9894 - recall: 0.9059 - f1_score: 0.9450 - val_loss: 0.9176 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8603 - acc: 0.9494 - precision: 0.9887 - recall: 0.9086 - f1_score: 0.9462 - val_loss: 0.9143 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8570 - acc: 0.9494 - precision: 0.9881 - recall: 0.9068 - f1_score: 0.9446 - val_loss: 0.9110 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8536 - acc: 0.9494 - precision: 0.9905 - recall: 0.9031 - f1_score: 0.9440 - val_loss: 0.9076 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8503 - acc: 0.9494 - precision: 0.9897 - recall: 0.9059 - f1_score: 0.9451 - val_loss: 0.9044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8470 - acc: 0.9494 - precision: 0.9885 - recall: 0.9041 - f1_score: 0.9429 - val_loss: 0.9011 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8437 - acc: 0.9494 - precision: 0.9903 - recall: 0.9063 - f1_score: 0.9454 - val_loss: 0.8978 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8405 - acc: 0.9494 - precision: 0.9899 - recall: 0.9084 - f1_score: 0.9465 - val_loss: 0.8946 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8372 - acc: 0.9494 - precision: 0.9893 - recall: 0.9089 - f1_score: 0.9468 - val_loss: 0.8914 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8340 - acc: 0.9494 - precision: 0.9890 - recall: 0.9045 - f1_score: 0.9437 - val_loss: 0.8882 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8308 - acc: 0.9494 - precision: 0.9895 - recall: 0.9090 - f1_score: 0.9451 - val_loss: 0.8850 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8276 - acc: 0.9494 - precision: 0.9904 - recall: 0.9065 - f1_score: 0.9457 - val_loss: 0.8818 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8244 - acc: 0.9494 - precision: 0.9897 - recall: 0.9065 - f1_score: 0.9447 - val_loss: 0.8787 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8212 - acc: 0.9494 - precision: 0.9900 - recall: 0.9063 - f1_score: 0.9453 - val_loss: 0.8755 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8180 - acc: 0.9494 - precision: 0.9900 - recall: 0.9067 - f1_score: 0.9456 - val_loss: 0.8724 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8149 - acc: 0.9494 - precision: 0.9898 - recall: 0.9076 - f1_score: 0.9457 - val_loss: 0.8693 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8118 - acc: 0.9494 - precision: 0.9898 - recall: 0.9066 - f1_score: 0.9443 - val_loss: 0.8662 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8087 - acc: 0.9494 - precision: 0.9904 - recall: 0.9048 - f1_score: 0.9445 - val_loss: 0.8631 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8056 - acc: 0.9494 - precision: 0.9893 - recall: 0.9059 - f1_score: 0.9454 - val_loss: 0.8601 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8025 - acc: 0.9494 - precision: 0.9891 - recall: 0.9071 - f1_score: 0.9457 - val_loss: 0.8570 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7995 - acc: 0.9494 - precision: 0.9899 - recall: 0.9046 - f1_score: 0.9433 - val_loss: 0.8540 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7964 - acc: 0.9494 - precision: 0.9897 - recall: 0.9127 - f1_score: 0.9483 - val_loss: 0.8510 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7934 - acc: 0.9494 - precision: 0.9878 - recall: 0.9009 - f1_score: 0.9415 - val_loss: 0.8480 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7904 - acc: 0.9494 - precision: 0.9875 - recall: 0.9061 - f1_score: 0.9439 - val_loss: 0.8450 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7874 - acc: 0.9494 - precision: 0.9923 - recall: 0.9065 - f1_score: 0.9459 - val_loss: 0.8420 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7844 - acc: 0.9494 - precision: 0.9877 - recall: 0.9067 - f1_score: 0.9447 - val_loss: 0.8391 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7814 - acc: 0.9494 - precision: 0.9910 - recall: 0.9054 - f1_score: 0.9453 - val_loss: 0.8361 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7785 - acc: 0.9494 - precision: 0.9906 - recall: 0.9004 - f1_score: 0.9408 - val_loss: 0.8332 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7755 - acc: 0.9494 - precision: 0.9886 - recall: 0.9053 - f1_score: 0.9446 - val_loss: 0.8303 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7726 - acc: 0.9494 - precision: 0.9903 - recall: 0.9093 - f1_score: 0.9463 - val_loss: 0.8274 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7697 - acc: 0.9494 - precision: 0.9910 - recall: 0.9082 - f1_score: 0.9464 - val_loss: 0.8245 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7668 - acc: 0.9494 - precision: 0.9878 - recall: 0.9075 - f1_score: 0.9451 - val_loss: 0.8216 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7639 - acc: 0.9494 - precision: 0.9895 - recall: 0.9075 - f1_score: 0.9459 - val_loss: 0.8188 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7610 - acc: 0.9494 - precision: 0.9894 - recall: 0.9064 - f1_score: 0.9453 - val_loss: 0.8160 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7582 - acc: 0.9494 - precision: 0.9880 - recall: 0.9089 - f1_score: 0.9452 - val_loss: 0.8131 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7554 - acc: 0.9494 - precision: 0.9896 - recall: 0.9079 - f1_score: 0.9453 - val_loss: 0.8103 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7525 - acc: 0.9494 - precision: 0.9876 - recall: 0.9072 - f1_score: 0.9448 - val_loss: 0.8075 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7497 - acc: 0.9494 - precision: 0.9893 - recall: 0.9053 - f1_score: 0.9448 - val_loss: 0.8048 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7469 - acc: 0.9494 - precision: 0.9901 - recall: 0.9059 - f1_score: 0.9454 - val_loss: 0.8020 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7442 - acc: 0.9494 - precision: 0.9895 - recall: 0.9082 - f1_score: 0.9464 - val_loss: 0.7992 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7414 - acc: 0.9494 - precision: 0.9908 - recall: 0.9147 - f1_score: 0.9504 - val_loss: 0.7965 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7386 - acc: 0.9494 - precision: 0.9905 - recall: 0.9066 - f1_score: 0.9450 - val_loss: 0.7938 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7359 - acc: 0.9494 - precision: 0.9853 - recall: 0.9007 - f1_score: 0.9400 - val_loss: 0.7911 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7332 - acc: 0.9494 - precision: 0.9912 - recall: 0.9064 - f1_score: 0.9462 - val_loss: 0.7884 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7305 - acc: 0.9494 - precision: 0.9900 - recall: 0.9052 - f1_score: 0.9445 - val_loss: 0.7857 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7278 - acc: 0.9494 - precision: 0.9897 - recall: 0.9069 - f1_score: 0.9452 - val_loss: 0.7830 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7251 - acc: 0.9494 - precision: 0.9904 - recall: 0.9046 - f1_score: 0.9444 - val_loss: 0.7804 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7224 - acc: 0.9494 - precision: 0.9887 - recall: 0.9069 - f1_score: 0.9454 - val_loss: 0.7777 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7197 - acc: 0.9494 - precision: 0.9870 - recall: 0.9061 - f1_score: 0.9445 - val_loss: 0.7751 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7171 - acc: 0.9494 - precision: 0.9885 - recall: 0.9069 - f1_score: 0.9452 - val_loss: 0.7725 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7145 - acc: 0.9494 - precision: 0.9901 - recall: 0.9045 - f1_score: 0.9445 - val_loss: 0.7699 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7119 - acc: 0.9494 - precision: 0.9895 - recall: 0.9073 - f1_score: 0.9462 - val_loss: 0.7673 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7092 - acc: 0.9494 - precision: 0.9895 - recall: 0.9101 - f1_score: 0.9470 - val_loss: 0.7647 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7067 - acc: 0.9494 - precision: 0.9891 - recall: 0.9100 - f1_score: 0.9473 - val_loss: 0.7622 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7041 - acc: 0.9494 - precision: 0.9882 - recall: 0.9062 - f1_score: 0.9447 - val_loss: 0.7596 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7015 - acc: 0.9494 - precision: 0.9891 - recall: 0.9077 - f1_score: 0.9464 - val_loss: 0.7571 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6990 - acc: 0.9494 - precision: 0.9894 - recall: 0.9035 - f1_score: 0.9436 - val_loss: 0.7546 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6964 - acc: 0.9494 - precision: 0.9902 - recall: 0.9078 - f1_score: 0.9459 - val_loss: 0.7520 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6939 - acc: 0.9494 - precision: 0.9903 - recall: 0.9102 - f1_score: 0.9481 - val_loss: 0.7496 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6914 - acc: 0.9494 - precision: 0.9900 - recall: 0.9101 - f1_score: 0.9473 - val_loss: 0.7471 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6889 - acc: 0.9494 - precision: 0.9876 - recall: 0.9097 - f1_score: 0.9457 - val_loss: 0.7446 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6864 - acc: 0.9494 - precision: 0.9885 - recall: 0.9053 - f1_score: 0.9444 - val_loss: 0.7421 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6839 - acc: 0.9494 - precision: 0.9893 - recall: 0.9065 - f1_score: 0.9453 - val_loss: 0.7397 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 478/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6814 - acc: 0.9494 - precision: 0.9903 - recall: 0.9054 - f1_score: 0.9452 - val_loss: 0.7373 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6790 - acc: 0.9494 - precision: 0.9893 - recall: 0.9062 - f1_score: 0.9453 - val_loss: 0.7348 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6766 - acc: 0.9494 - precision: 0.9896 - recall: 0.9081 - f1_score: 0.9464 - val_loss: 0.7324 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6741 - acc: 0.9494 - precision: 0.9908 - recall: 0.9053 - f1_score: 0.9451 - val_loss: 0.7300 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6717 - acc: 0.9494 - precision: 0.9896 - recall: 0.9066 - f1_score: 0.9457 - val_loss: 0.7276 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6693 - acc: 0.9494 - precision: 0.9899 - recall: 0.9111 - f1_score: 0.9468 - val_loss: 0.7253 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6669 - acc: 0.9494 - precision: 0.9886 - recall: 0.9106 - f1_score: 0.9467 - val_loss: 0.7229 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6645 - acc: 0.9494 - precision: 0.9880 - recall: 0.9051 - f1_score: 0.9433 - val_loss: 0.7206 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6622 - acc: 0.9494 - precision: 0.9889 - recall: 0.9074 - f1_score: 0.9453 - val_loss: 0.7182 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6598 - acc: 0.9494 - precision: 0.9899 - recall: 0.9065 - f1_score: 0.9447 - val_loss: 0.7159 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6575 - acc: 0.9494 - precision: 0.9887 - recall: 0.9062 - f1_score: 0.9438 - val_loss: 0.7136 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6552 - acc: 0.9494 - precision: 0.9905 - recall: 0.9072 - f1_score: 0.9452 - val_loss: 0.7113 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6528 - acc: 0.9494 - precision: 0.9905 - recall: 0.9035 - f1_score: 0.9438 - val_loss: 0.7090 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6505 - acc: 0.9494 - precision: 0.9905 - recall: 0.9080 - f1_score: 0.9463 - val_loss: 0.7067 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6482 - acc: 0.9494 - precision: 0.9885 - recall: 0.9075 - f1_score: 0.9458 - val_loss: 0.7044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6459 - acc: 0.9494 - precision: 0.9928 - recall: 0.9074 - f1_score: 0.9470 - val_loss: 0.7022 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6437 - acc: 0.9494 - precision: 0.9891 - recall: 0.9058 - f1_score: 0.9452 - val_loss: 0.6999 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6414 - acc: 0.9494 - precision: 0.9887 - recall: 0.9052 - f1_score: 0.9444 - val_loss: 0.6977 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6392 - acc: 0.9494 - precision: 0.9905 - recall: 0.9091 - f1_score: 0.9473 - val_loss: 0.6955 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6369 - acc: 0.9494 - precision: 0.9889 - recall: 0.9016 - f1_score: 0.9417 - val_loss: 0.6933 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6347 - acc: 0.9494 - precision: 0.9902 - recall: 0.9078 - f1_score: 0.9460 - val_loss: 0.6911 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6325 - acc: 0.9494 - precision: 0.9885 - recall: 0.9106 - f1_score: 0.9468 - val_loss: 0.6889 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6303 - acc: 0.9494 - precision: 0.9899 - recall: 0.9085 - f1_score: 0.9470 - val_loss: 0.6867 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6281 - acc: 0.9494 - precision: 0.9892 - recall: 0.9022 - f1_score: 0.9429 - val_loss: 0.6845 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6259 - acc: 0.9494 - precision: 0.9895 - recall: 0.9061 - f1_score: 0.9452 - val_loss: 0.6824 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6237 - acc: 0.9494 - precision: 0.9897 - recall: 0.9068 - f1_score: 0.9455 - val_loss: 0.6802 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6215 - acc: 0.9494 - precision: 0.9897 - recall: 0.9037 - f1_score: 0.9435 - val_loss: 0.6781 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6194 - acc: 0.9494 - precision: 0.9896 - recall: 0.9082 - f1_score: 0.9465 - val_loss: 0.6759 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6172 - acc: 0.9494 - precision: 0.9898 - recall: 0.9067 - f1_score: 0.9459 - val_loss: 0.6738 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6151 - acc: 0.9494 - precision: 0.9902 - recall: 0.9068 - f1_score: 0.9457 - val_loss: 0.6717 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6130 - acc: 0.9494 - precision: 0.9868 - recall: 0.9076 - f1_score: 0.9450 - val_loss: 0.6696 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6109 - acc: 0.9494 - precision: 0.9894 - recall: 0.9082 - f1_score: 0.9461 - val_loss: 0.6676 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 510/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6088 - acc: 0.9494 - precision: 0.9885 - recall: 0.9095 - f1_score: 0.9462 - val_loss: 0.6655 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6067 - acc: 0.9494 - precision: 0.9900 - recall: 0.9067 - f1_score: 0.9458 - val_loss: 0.6634 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6046 - acc: 0.9494 - precision: 0.9899 - recall: 0.9071 - f1_score: 0.9451 - val_loss: 0.6614 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6026 - acc: 0.9494 - precision: 0.9897 - recall: 0.9053 - f1_score: 0.9437 - val_loss: 0.6593 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6005 - acc: 0.9494 - precision: 0.9890 - recall: 0.9059 - f1_score: 0.9446 - val_loss: 0.6573 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5984 - acc: 0.9494 - precision: 0.9898 - recall: 0.9052 - f1_score: 0.9448 - val_loss: 0.6553 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5964 - acc: 0.9494 - precision: 0.9888 - recall: 0.9069 - f1_score: 0.9451 - val_loss: 0.6532 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5944 - acc: 0.9494 - precision: 0.9893 - recall: 0.9104 - f1_score: 0.9477 - val_loss: 0.6512 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5924 - acc: 0.9494 - precision: 0.9892 - recall: 0.9064 - f1_score: 0.9448 - val_loss: 0.6493 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5904 - acc: 0.9494 - precision: 0.9887 - recall: 0.9061 - f1_score: 0.9445 - val_loss: 0.6473 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5884 - acc: 0.9494 - precision: 0.9884 - recall: 0.9076 - f1_score: 0.9455 - val_loss: 0.6453 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5864 - acc: 0.9494 - precision: 0.9887 - recall: 0.9097 - f1_score: 0.9466 - val_loss: 0.6433 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5844 - acc: 0.9494 - precision: 0.9900 - recall: 0.9065 - f1_score: 0.9457 - val_loss: 0.6414 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5824 - acc: 0.9494 - precision: 0.9895 - recall: 0.9020 - f1_score: 0.9416 - val_loss: 0.6394 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5805 - acc: 0.9494 - precision: 0.9889 - recall: 0.9057 - f1_score: 0.9442 - val_loss: 0.6375 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5785 - acc: 0.9494 - precision: 0.9895 - recall: 0.9108 - f1_score: 0.9471 - val_loss: 0.6356 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5766 - acc: 0.9494 - precision: 0.9898 - recall: 0.9062 - f1_score: 0.9449 - val_loss: 0.6337 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5746 - acc: 0.9494 - precision: 0.9876 - recall: 0.9023 - f1_score: 0.9423 - val_loss: 0.6318 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5727 - acc: 0.9494 - precision: 0.9892 - recall: 0.9054 - f1_score: 0.9441 - val_loss: 0.6299 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5708 - acc: 0.9494 - precision: 0.9909 - recall: 0.9055 - f1_score: 0.9452 - val_loss: 0.6280 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5689 - acc: 0.9494 - precision: 0.9880 - recall: 0.9086 - f1_score: 0.9459 - val_loss: 0.6261 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5670 - acc: 0.9494 - precision: 0.9899 - recall: 0.9105 - f1_score: 0.9475 - val_loss: 0.6243 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5651 - acc: 0.9494 - precision: 0.9893 - recall: 0.9076 - f1_score: 0.9462 - val_loss: 0.6224 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5633 - acc: 0.9494 - precision: 0.9905 - recall: 0.9020 - f1_score: 0.9432 - val_loss: 0.6206 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5614 - acc: 0.9494 - precision: 0.9896 - recall: 0.9082 - f1_score: 0.9458 - val_loss: 0.6187 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5596 - acc: 0.9494 - precision: 0.9892 - recall: 0.9068 - f1_score: 0.9454 - val_loss: 0.6169 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5577 - acc: 0.9494 - precision: 0.9908 - recall: 0.9089 - f1_score: 0.9467 - val_loss: 0.6151 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5559 - acc: 0.9494 - precision: 0.9890 - recall: 0.9051 - f1_score: 0.9444 - val_loss: 0.6133 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5541 - acc: 0.9494 - precision: 0.9911 - recall: 0.9071 - f1_score: 0.9458 - val_loss: 0.6115 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5522 - acc: 0.9494 - precision: 0.9905 - recall: 0.9123 - f1_score: 0.9484 - val_loss: 0.6097 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5504 - acc: 0.9494 - precision: 0.9890 - recall: 0.9047 - f1_score: 0.9432 - val_loss: 0.6079 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5486 - acc: 0.9494 - precision: 0.9904 - recall: 0.9085 - f1_score: 0.9467 - val_loss: 0.6061 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5468 - acc: 0.9494 - precision: 0.9878 - recall: 0.9070 - f1_score: 0.9445 - val_loss: 0.6044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5451 - acc: 0.9494 - precision: 0.9898 - recall: 0.9094 - f1_score: 0.9473 - val_loss: 0.6026 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5433 - acc: 0.9494 - precision: 0.9898 - recall: 0.9053 - f1_score: 0.9441 - val_loss: 0.6009 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5415 - acc: 0.9494 - precision: 0.9881 - recall: 0.9036 - f1_score: 0.9433 - val_loss: 0.5991 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5398 - acc: 0.9494 - precision: 0.9872 - recall: 0.9038 - f1_score: 0.9430 - val_loss: 0.5974 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5380 - acc: 0.9494 - precision: 0.9895 - recall: 0.9094 - f1_score: 0.9468 - val_loss: 0.5957 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5363 - acc: 0.9494 - precision: 0.9895 - recall: 0.9064 - f1_score: 0.9453 - val_loss: 0.5940 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5346 - acc: 0.9494 - precision: 0.9889 - recall: 0.9062 - f1_score: 0.9449 - val_loss: 0.5923 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5328 - acc: 0.9494 - precision: 0.9909 - recall: 0.9068 - f1_score: 0.9454 - val_loss: 0.5906 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5311 - acc: 0.9494 - precision: 0.9865 - recall: 0.9019 - f1_score: 0.9410 - val_loss: 0.5889 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5294 - acc: 0.9494 - precision: 0.9904 - recall: 0.9094 - f1_score: 0.9473 - val_loss: 0.5872 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5277 - acc: 0.9494 - precision: 0.9912 - recall: 0.9082 - f1_score: 0.9467 - val_loss: 0.5855 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5260 - acc: 0.9494 - precision: 0.9878 - recall: 0.9021 - f1_score: 0.9424 - val_loss: 0.5838 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5244 - acc: 0.9494 - precision: 0.9898 - recall: 0.9090 - f1_score: 0.9469 - val_loss: 0.5822 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5227 - acc: 0.9494 - precision: 0.9900 - recall: 0.9063 - f1_score: 0.9458 - val_loss: 0.5805 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5210 - acc: 0.9494 - precision: 0.9900 - recall: 0.9061 - f1_score: 0.9457 - val_loss: 0.5789 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5194 - acc: 0.9494 - precision: 0.9901 - recall: 0.9060 - f1_score: 0.9445 - val_loss: 0.5773 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5177 - acc: 0.9494 - precision: 0.9878 - recall: 0.9078 - f1_score: 0.9448 - val_loss: 0.5756 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5161 - acc: 0.9494 - precision: 0.9885 - recall: 0.9072 - f1_score: 0.9456 - val_loss: 0.5740 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5145 - acc: 0.9494 - precision: 0.9879 - recall: 0.9014 - f1_score: 0.9402 - val_loss: 0.5724 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5128 - acc: 0.9494 - precision: 0.9897 - recall: 0.9018 - f1_score: 0.9430 - val_loss: 0.5708 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5112 - acc: 0.9494 - precision: 0.9883 - recall: 0.9066 - f1_score: 0.9444 - val_loss: 0.5692 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5096 - acc: 0.9494 - precision: 0.9905 - recall: 0.9060 - f1_score: 0.9458 - val_loss: 0.5677 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5080 - acc: 0.9494 - precision: 0.9889 - recall: 0.9063 - f1_score: 0.9452 - val_loss: 0.5661 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5064 - acc: 0.9494 - precision: 0.9889 - recall: 0.9103 - f1_score: 0.9471 - val_loss: 0.5645 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5048 - acc: 0.9494 - precision: 0.9889 - recall: 0.9055 - f1_score: 0.9449 - val_loss: 0.5630 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5033 - acc: 0.9494 - precision: 0.9904 - recall: 0.9046 - f1_score: 0.9443 - val_loss: 0.5614 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5017 - acc: 0.9494 - precision: 0.9901 - recall: 0.9099 - f1_score: 0.9476 - val_loss: 0.5599 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5001 - acc: 0.9494 - precision: 0.9901 - recall: 0.9031 - f1_score: 0.9431 - val_loss: 0.5583 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4986 - acc: 0.9494 - precision: 0.9892 - recall: 0.9028 - f1_score: 0.9421 - val_loss: 0.5568 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4970 - acc: 0.9494 - precision: 0.9903 - recall: 0.9081 - f1_score: 0.9468 - val_loss: 0.5553 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4955 - acc: 0.9494 - precision: 0.9892 - recall: 0.9072 - f1_score: 0.9449 - val_loss: 0.5538 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 574/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4940 - acc: 0.9494 - precision: 0.9889 - recall: 0.9100 - f1_score: 0.9470 - val_loss: 0.5523 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4925 - acc: 0.9494 - precision: 0.9886 - recall: 0.9082 - f1_score: 0.9448 - val_loss: 0.5508 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4909 - acc: 0.9494 - precision: 0.9900 - recall: 0.9048 - f1_score: 0.9440 - val_loss: 0.5493 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4894 - acc: 0.9494 - precision: 0.9895 - recall: 0.9093 - f1_score: 0.9468 - val_loss: 0.5478 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4879 - acc: 0.9494 - precision: 0.9894 - recall: 0.9067 - f1_score: 0.9457 - val_loss: 0.5463 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4865 - acc: 0.9494 - precision: 0.9900 - recall: 0.9066 - f1_score: 0.9456 - val_loss: 0.5448 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4850 - acc: 0.9494 - precision: 0.9898 - recall: 0.9058 - f1_score: 0.9449 - val_loss: 0.5434 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4835 - acc: 0.9494 - precision: 0.9900 - recall: 0.9051 - f1_score: 0.9448 - val_loss: 0.5419 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4820 - acc: 0.9494 - precision: 0.9900 - recall: 0.9102 - f1_score: 0.9474 - val_loss: 0.5405 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4806 - acc: 0.9494 - precision: 0.9896 - recall: 0.9076 - f1_score: 0.9457 - val_loss: 0.5390 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4791 - acc: 0.9494 - precision: 0.9887 - recall: 0.9068 - f1_score: 0.9451 - val_loss: 0.5376 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4777 - acc: 0.9494 - precision: 0.9898 - recall: 0.9054 - f1_score: 0.9443 - val_loss: 0.5362 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4762 - acc: 0.9494 - precision: 0.9892 - recall: 0.9061 - f1_score: 0.9453 - val_loss: 0.5348 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4748 - acc: 0.9494 - precision: 0.9903 - recall: 0.9051 - f1_score: 0.9447 - val_loss: 0.5334 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4734 - acc: 0.9494 - precision: 0.9894 - recall: 0.9093 - f1_score: 0.9457 - val_loss: 0.5320 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4719 - acc: 0.9494 - precision: 0.9887 - recall: 0.9084 - f1_score: 0.9457 - val_loss: 0.5306 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4705 - acc: 0.9494 - precision: 0.9894 - recall: 0.9042 - f1_score: 0.9443 - val_loss: 0.5292 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4691 - acc: 0.9494 - precision: 0.9889 - recall: 0.9088 - f1_score: 0.9461 - val_loss: 0.5278 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4677 - acc: 0.9494 - precision: 0.9885 - recall: 0.9065 - f1_score: 0.9449 - val_loss: 0.5264 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4663 - acc: 0.9494 - precision: 0.9903 - recall: 0.9089 - f1_score: 0.9466 - val_loss: 0.5250 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4649 - acc: 0.9494 - precision: 0.9892 - recall: 0.9053 - f1_score: 0.9444 - val_loss: 0.5237 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4636 - acc: 0.9494 - precision: 0.9902 - recall: 0.9062 - f1_score: 0.9459 - val_loss: 0.5223 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4622 - acc: 0.9494 - precision: 0.9897 - recall: 0.9036 - f1_score: 0.9434 - val_loss: 0.5210 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4608 - acc: 0.9494 - precision: 0.9884 - recall: 0.9054 - f1_score: 0.9445 - val_loss: 0.5196 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4595 - acc: 0.9494 - precision: 0.9892 - recall: 0.9047 - f1_score: 0.9436 - val_loss: 0.5183 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4581 - acc: 0.9494 - precision: 0.9914 - recall: 0.9086 - f1_score: 0.9471 - val_loss: 0.5170 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4568 - acc: 0.9494 - precision: 0.9878 - recall: 0.9043 - f1_score: 0.9434 - val_loss: 0.5156 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4554 - acc: 0.9494 - precision: 0.9896 - recall: 0.9085 - f1_score: 0.9465 - val_loss: 0.5143 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4541 - acc: 0.9494 - precision: 0.9914 - recall: 0.9082 - f1_score: 0.9464 - val_loss: 0.5130 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4528 - acc: 0.9494 - precision: 0.9882 - recall: 0.9048 - f1_score: 0.9440 - val_loss: 0.5117 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4514 - acc: 0.9494 - precision: 0.9891 - recall: 0.9054 - f1_score: 0.9434 - val_loss: 0.5104 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4501 - acc: 0.9494 - precision: 0.9903 - recall: 0.9085 - f1_score: 0.9470 - val_loss: 0.5091 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4488 - acc: 0.9494 - precision: 0.9902 - recall: 0.9076 - f1_score: 0.9456 - val_loss: 0.5079 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4475 - acc: 0.9494 - precision: 0.9889 - recall: 0.9088 - f1_score: 0.9459 - val_loss: 0.5066 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4462 - acc: 0.9494 - precision: 0.9890 - recall: 0.9047 - f1_score: 0.9445 - val_loss: 0.5053 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4449 - acc: 0.9494 - precision: 0.9906 - recall: 0.9052 - f1_score: 0.9453 - val_loss: 0.5040 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4437 - acc: 0.9494 - precision: 0.9891 - recall: 0.9069 - f1_score: 0.9452 - val_loss: 0.5028 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4424 - acc: 0.9494 - precision: 0.9897 - recall: 0.9100 - f1_score: 0.9471 - val_loss: 0.5015 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4411 - acc: 0.9494 - precision: 0.9889 - recall: 0.9085 - f1_score: 0.9457 - val_loss: 0.5003 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4398 - acc: 0.9494 - precision: 0.9890 - recall: 0.9047 - f1_score: 0.9438 - val_loss: 0.4990 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4386 - acc: 0.9494 - precision: 0.9868 - recall: 0.9043 - f1_score: 0.9425 - val_loss: 0.4978 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4373 - acc: 0.9494 - precision: 0.9904 - recall: 0.9055 - f1_score: 0.9452 - val_loss: 0.4966 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4361 - acc: 0.9494 - precision: 0.9899 - recall: 0.9073 - f1_score: 0.9451 - val_loss: 0.4953 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4348 - acc: 0.9494 - precision: 0.9866 - recall: 0.9073 - f1_score: 0.9448 - val_loss: 0.4941 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4336 - acc: 0.9494 - precision: 0.9908 - recall: 0.9048 - f1_score: 0.9453 - val_loss: 0.4929 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4324 - acc: 0.9494 - precision: 0.9895 - recall: 0.9079 - f1_score: 0.9461 - val_loss: 0.4917 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4312 - acc: 0.9494 - precision: 0.9899 - recall: 0.9068 - f1_score: 0.9455 - val_loss: 0.4905 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4300 - acc: 0.9494 - precision: 0.9907 - recall: 0.9081 - f1_score: 0.9464 - val_loss: 0.4893 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4287 - acc: 0.9494 - precision: 0.9889 - recall: 0.9044 - f1_score: 0.9439 - val_loss: 0.4881 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4275 - acc: 0.9494 - precision: 0.9901 - recall: 0.9088 - f1_score: 0.9456 - val_loss: 0.4870 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4263 - acc: 0.9494 - precision: 0.9893 - recall: 0.9030 - f1_score: 0.9432 - val_loss: 0.4858 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4252 - acc: 0.9494 - precision: 0.9883 - recall: 0.9086 - f1_score: 0.9460 - val_loss: 0.4846 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4240 - acc: 0.9494 - precision: 0.9906 - recall: 0.9071 - f1_score: 0.9463 - val_loss: 0.4835 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4228 - acc: 0.9494 - precision: 0.9902 - recall: 0.9058 - f1_score: 0.9456 - val_loss: 0.4823 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4216 - acc: 0.9494 - precision: 0.9880 - recall: 0.9073 - f1_score: 0.9452 - val_loss: 0.4812 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4204 - acc: 0.9494 - precision: 0.9888 - recall: 0.9077 - f1_score: 0.9452 - val_loss: 0.4800 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4193 - acc: 0.9494 - precision: 0.9892 - recall: 0.9077 - f1_score: 0.9459 - val_loss: 0.4789 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4181 - acc: 0.9494 - precision: 0.9913 - recall: 0.9069 - f1_score: 0.9465 - val_loss: 0.4778 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4170 - acc: 0.9494 - precision: 0.9870 - recall: 0.9122 - f1_score: 0.9469 - val_loss: 0.4766 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4158 - acc: 0.9494 - precision: 0.9899 - recall: 0.9022 - f1_score: 0.9433 - val_loss: 0.4755 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4147 - acc: 0.9494 - precision: 0.9889 - recall: 0.9063 - f1_score: 0.9451 - val_loss: 0.4744 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4135 - acc: 0.9494 - precision: 0.9894 - recall: 0.9060 - f1_score: 0.9447 - val_loss: 0.4733 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4124 - acc: 0.9494 - precision: 0.9908 - recall: 0.9057 - f1_score: 0.9457 - val_loss: 0.4722 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4113 - acc: 0.9494 - precision: 0.9906 - recall: 0.9052 - f1_score: 0.9447 - val_loss: 0.4711 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 638/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4102 - acc: 0.9494 - precision: 0.9893 - recall: 0.9067 - f1_score: 0.9452 - val_loss: 0.4700 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4091 - acc: 0.9494 - precision: 0.9893 - recall: 0.9081 - f1_score: 0.9465 - val_loss: 0.4689 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4079 - acc: 0.9494 - precision: 0.9889 - recall: 0.9036 - f1_score: 0.9437 - val_loss: 0.4678 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4069 - acc: 0.9494 - precision: 0.9902 - recall: 0.9069 - f1_score: 0.9450 - val_loss: 0.4667 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4057 - acc: 0.9494 - precision: 0.9896 - recall: 0.9064 - f1_score: 0.9454 - val_loss: 0.4656 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4047 - acc: 0.9494 - precision: 0.9893 - recall: 0.9048 - f1_score: 0.9449 - val_loss: 0.4646 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4036 - acc: 0.9494 - precision: 0.9880 - recall: 0.9048 - f1_score: 0.9441 - val_loss: 0.4635 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4025 - acc: 0.9494 - precision: 0.9883 - recall: 0.9085 - f1_score: 0.9460 - val_loss: 0.4625 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4014 - acc: 0.9494 - precision: 0.9896 - recall: 0.9072 - f1_score: 0.9458 - val_loss: 0.4614 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4003 - acc: 0.9494 - precision: 0.9898 - recall: 0.9079 - f1_score: 0.9457 - val_loss: 0.4604 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3993 - acc: 0.9494 - precision: 0.9899 - recall: 0.9091 - f1_score: 0.9458 - val_loss: 0.4593 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3982 - acc: 0.9494 - precision: 0.9891 - recall: 0.9075 - f1_score: 0.9459 - val_loss: 0.4583 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3972 - acc: 0.9494 - precision: 0.9891 - recall: 0.9038 - f1_score: 0.9441 - val_loss: 0.4572 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3961 - acc: 0.9494 - precision: 0.9891 - recall: 0.9053 - f1_score: 0.9448 - val_loss: 0.4562 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3951 - acc: 0.9494 - precision: 0.9894 - recall: 0.9075 - f1_score: 0.9457 - val_loss: 0.4552 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3940 - acc: 0.9494 - precision: 0.9889 - recall: 0.9022 - f1_score: 0.9421 - val_loss: 0.4542 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3930 - acc: 0.9494 - precision: 0.9890 - recall: 0.9052 - f1_score: 0.9443 - val_loss: 0.4532 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3920 - acc: 0.9494 - precision: 0.9897 - recall: 0.9073 - f1_score: 0.9455 - val_loss: 0.4521 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3909 - acc: 0.9494 - precision: 0.9869 - recall: 0.9003 - f1_score: 0.9405 - val_loss: 0.4512 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3899 - acc: 0.9494 - precision: 0.9882 - recall: 0.9076 - f1_score: 0.9453 - val_loss: 0.4501 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3889 - acc: 0.9494 - precision: 0.9906 - recall: 0.9049 - f1_score: 0.9442 - val_loss: 0.4492 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3879 - acc: 0.9494 - precision: 0.9906 - recall: 0.9064 - f1_score: 0.9457 - val_loss: 0.4482 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3869 - acc: 0.9494 - precision: 0.9891 - recall: 0.9076 - f1_score: 0.9458 - val_loss: 0.4472 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3859 - acc: 0.9494 - precision: 0.9875 - recall: 0.9038 - f1_score: 0.9428 - val_loss: 0.4462 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3849 - acc: 0.9494 - precision: 0.9905 - recall: 0.9058 - f1_score: 0.9453 - val_loss: 0.4452 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3839 - acc: 0.9494 - precision: 0.9899 - recall: 0.9048 - f1_score: 0.9448 - val_loss: 0.4443 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3829 - acc: 0.9494 - precision: 0.9890 - recall: 0.9087 - f1_score: 0.9457 - val_loss: 0.4433 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3819 - acc: 0.9494 - precision: 0.9894 - recall: 0.9060 - f1_score: 0.9444 - val_loss: 0.4423 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3809 - acc: 0.9494 - precision: 0.9888 - recall: 0.9063 - f1_score: 0.9456 - val_loss: 0.4414 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3800 - acc: 0.9494 - precision: 0.9895 - recall: 0.9098 - f1_score: 0.9469 - val_loss: 0.4404 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3790 - acc: 0.9494 - precision: 0.9895 - recall: 0.9070 - f1_score: 0.9449 - val_loss: 0.4395 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3780 - acc: 0.9494 - precision: 0.9900 - recall: 0.9078 - f1_score: 0.9462 - val_loss: 0.4385 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3771 - acc: 0.9494 - precision: 0.9882 - recall: 0.9062 - f1_score: 0.9450 - val_loss: 0.4376 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3761 - acc: 0.9494 - precision: 0.9888 - recall: 0.9065 - f1_score: 0.9453 - val_loss: 0.4367 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3752 - acc: 0.9494 - precision: 0.9904 - recall: 0.9072 - f1_score: 0.9455 - val_loss: 0.4357 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3742 - acc: 0.9494 - precision: 0.9912 - recall: 0.9081 - f1_score: 0.9471 - val_loss: 0.4348 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3670 - acc: 0.9578 - precision: 0.9892 - recall: 0.9215 - f1_score: 0.952 - 0s - loss: 0.3733 - acc: 0.9494 - precision: 0.9887 - recall: 0.9079 - f1_score: 0.9454 - val_loss: 0.4339 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3723 - acc: 0.9494 - precision: 0.9895 - recall: 0.9050 - f1_score: 0.9445 - val_loss: 0.4330 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3714 - acc: 0.9494 - precision: 0.9885 - recall: 0.9042 - f1_score: 0.9433 - val_loss: 0.4321 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3705 - acc: 0.9494 - precision: 0.9898 - recall: 0.9015 - f1_score: 0.9426 - val_loss: 0.4312 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3695 - acc: 0.9494 - precision: 0.9892 - recall: 0.9074 - f1_score: 0.9460 - val_loss: 0.4303 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3686 - acc: 0.9494 - precision: 0.9904 - recall: 0.9062 - f1_score: 0.9454 - val_loss: 0.4294 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3677 - acc: 0.9494 - precision: 0.9902 - recall: 0.9070 - f1_score: 0.9454 - val_loss: 0.4285 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3668 - acc: 0.9494 - precision: 0.9883 - recall: 0.9067 - f1_score: 0.9446 - val_loss: 0.4276 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3659 - acc: 0.9494 - precision: 0.9901 - recall: 0.9093 - f1_score: 0.9474 - val_loss: 0.4267 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3650 - acc: 0.9494 - precision: 0.9902 - recall: 0.9066 - f1_score: 0.9459 - val_loss: 0.4258 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3641 - acc: 0.9494 - precision: 0.9898 - recall: 0.9123 - f1_score: 0.9484 - val_loss: 0.4249 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3632 - acc: 0.9494 - precision: 0.9891 - recall: 0.9089 - f1_score: 0.9465 - val_loss: 0.4241 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3623 - acc: 0.9494 - precision: 0.9885 - recall: 0.9082 - f1_score: 0.9459 - val_loss: 0.4232 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3614 - acc: 0.9494 - precision: 0.9884 - recall: 0.9065 - f1_score: 0.9449 - val_loss: 0.4223 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3605 - acc: 0.9494 - precision: 0.9880 - recall: 0.9078 - f1_score: 0.9452 - val_loss: 0.4215 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3597 - acc: 0.9494 - precision: 0.9898 - recall: 0.9091 - f1_score: 0.9469 - val_loss: 0.4206 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3588 - acc: 0.9494 - precision: 0.9880 - recall: 0.9044 - f1_score: 0.9434 - val_loss: 0.4198 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3579 - acc: 0.9494 - precision: 0.9889 - recall: 0.9086 - f1_score: 0.9461 - val_loss: 0.4189 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3571 - acc: 0.9494 - precision: 0.9879 - recall: 0.9086 - f1_score: 0.9457 - val_loss: 0.4181 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3562 - acc: 0.9494 - precision: 0.9894 - recall: 0.9104 - f1_score: 0.9470 - val_loss: 0.4172 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3554 - acc: 0.9494 - precision: 0.9910 - recall: 0.9079 - f1_score: 0.9467 - val_loss: 0.4164 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3545 - acc: 0.9494 - precision: 0.9895 - recall: 0.9034 - f1_score: 0.9434 - val_loss: 0.4156 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3537 - acc: 0.9494 - precision: 0.9879 - recall: 0.9086 - f1_score: 0.9457 - val_loss: 0.4147 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3528 - acc: 0.9494 - precision: 0.9909 - recall: 0.9065 - f1_score: 0.9461 - val_loss: 0.4139 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3520 - acc: 0.9494 - precision: 0.9888 - recall: 0.9078 - f1_score: 0.9456 - val_loss: 0.4131 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3511 - acc: 0.9494 - precision: 0.9896 - recall: 0.9062 - f1_score: 0.9447 - val_loss: 0.4123 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3503 - acc: 0.9494 - precision: 0.9900 - recall: 0.9093 - f1_score: 0.9468 - val_loss: 0.4115 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3495 - acc: 0.9494 - precision: 0.9898 - recall: 0.9100 - f1_score: 0.9473 - val_loss: 0.4107 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 702/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3486 - acc: 0.9494 - precision: 0.9902 - recall: 0.9056 - f1_score: 0.9450 - val_loss: 0.4099 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3478 - acc: 0.9494 - precision: 0.9886 - recall: 0.9090 - f1_score: 0.9461 - val_loss: 0.4091 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3470 - acc: 0.9494 - precision: 0.9899 - recall: 0.9073 - f1_score: 0.9464 - val_loss: 0.4083 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3462 - acc: 0.9494 - precision: 0.9893 - recall: 0.9080 - f1_score: 0.9451 - val_loss: 0.4075 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3454 - acc: 0.9494 - precision: 0.9891 - recall: 0.9051 - f1_score: 0.9444 - val_loss: 0.4067 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3446 - acc: 0.9494 - precision: 0.9891 - recall: 0.9063 - f1_score: 0.9449 - val_loss: 0.4059 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3438 - acc: 0.9494 - precision: 0.9896 - recall: 0.9065 - f1_score: 0.9459 - val_loss: 0.4052 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3430 - acc: 0.9494 - precision: 0.9893 - recall: 0.9066 - f1_score: 0.9454 - val_loss: 0.4044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3422 - acc: 0.9494 - precision: 0.9887 - recall: 0.9083 - f1_score: 0.9453 - val_loss: 0.4036 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3414 - acc: 0.9494 - precision: 0.9896 - recall: 0.9105 - f1_score: 0.9476 - val_loss: 0.4028 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3406 - acc: 0.9494 - precision: 0.9890 - recall: 0.9084 - f1_score: 0.9461 - val_loss: 0.4021 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3398 - acc: 0.9494 - precision: 0.9881 - recall: 0.9057 - f1_score: 0.9435 - val_loss: 0.4013 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3390 - acc: 0.9494 - precision: 0.9901 - recall: 0.9080 - f1_score: 0.9464 - val_loss: 0.4006 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3383 - acc: 0.9494 - precision: 0.9902 - recall: 0.9022 - f1_score: 0.9427 - val_loss: 0.3998 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3375 - acc: 0.9494 - precision: 0.9915 - recall: 0.9029 - f1_score: 0.9441 - val_loss: 0.3991 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3367 - acc: 0.9494 - precision: 0.9888 - recall: 0.9086 - f1_score: 0.9465 - val_loss: 0.3983 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3360 - acc: 0.9494 - precision: 0.9900 - recall: 0.9095 - f1_score: 0.9470 - val_loss: 0.3976 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3352 - acc: 0.9494 - precision: 0.9885 - recall: 0.9040 - f1_score: 0.9435 - val_loss: 0.3968 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3344 - acc: 0.9494 - precision: 0.9899 - recall: 0.9078 - f1_score: 0.9465 - val_loss: 0.3961 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3337 - acc: 0.9494 - precision: 0.9898 - recall: 0.9053 - f1_score: 0.9443 - val_loss: 0.3954 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3329 - acc: 0.9494 - precision: 0.9890 - recall: 0.9074 - f1_score: 0.9458 - val_loss: 0.3946 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3322 - acc: 0.9494 - precision: 0.9911 - recall: 0.9062 - f1_score: 0.9435 - val_loss: 0.3939 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9494 - precision: 0.9890 - recall: 0.9035 - f1_score: 0.9429 - val_loss: 0.3932 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3307 - acc: 0.9494 - precision: 0.9898 - recall: 0.9084 - f1_score: 0.9460 - val_loss: 0.3925 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3300 - acc: 0.9494 - precision: 0.9890 - recall: 0.9056 - f1_score: 0.9448 - val_loss: 0.3917 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3292 - acc: 0.9494 - precision: 0.9887 - recall: 0.9038 - f1_score: 0.9438 - val_loss: 0.3910 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3285 - acc: 0.9494 - precision: 0.9889 - recall: 0.9093 - f1_score: 0.9458 - val_loss: 0.3903 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3278 - acc: 0.9494 - precision: 0.9895 - recall: 0.9090 - f1_score: 0.9465 - val_loss: 0.3896 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3270 - acc: 0.9494 - precision: 0.9883 - recall: 0.9058 - f1_score: 0.9446 - val_loss: 0.3889 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3263 - acc: 0.9494 - precision: 0.9890 - recall: 0.9073 - f1_score: 0.9455 - val_loss: 0.3882 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3256 - acc: 0.9494 - precision: 0.9902 - recall: 0.9079 - f1_score: 0.9459 - val_loss: 0.3875 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3249 - acc: 0.9494 - precision: 0.9904 - recall: 0.9068 - f1_score: 0.9458 - val_loss: 0.3868 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 734/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3242 - acc: 0.9494 - precision: 0.9911 - recall: 0.9075 - f1_score: 0.9469 - val_loss: 0.3861 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3235 - acc: 0.9494 - precision: 0.9881 - recall: 0.9046 - f1_score: 0.9437 - val_loss: 0.3855 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3228 - acc: 0.9494 - precision: 0.9907 - recall: 0.9042 - f1_score: 0.9439 - val_loss: 0.3848 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3221 - acc: 0.9494 - precision: 0.9888 - recall: 0.9088 - f1_score: 0.9461 - val_loss: 0.3841 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3214 - acc: 0.9494 - precision: 0.9892 - recall: 0.9096 - f1_score: 0.9473 - val_loss: 0.3834 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3207 - acc: 0.9494 - precision: 0.9889 - recall: 0.9101 - f1_score: 0.9466 - val_loss: 0.3828 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3200 - acc: 0.9494 - precision: 0.9898 - recall: 0.9038 - f1_score: 0.9438 - val_loss: 0.3821 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3193 - acc: 0.9494 - precision: 0.9911 - recall: 0.9058 - f1_score: 0.9455 - val_loss: 0.3814 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3186 - acc: 0.9494 - precision: 0.9895 - recall: 0.9025 - f1_score: 0.9405 - val_loss: 0.3808 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3180 - acc: 0.9494 - precision: 0.9911 - recall: 0.9051 - f1_score: 0.9449 - val_loss: 0.3801 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3173 - acc: 0.9494 - precision: 0.9887 - recall: 0.9095 - f1_score: 0.9458 - val_loss: 0.3794 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3166 - acc: 0.9494 - precision: 0.9902 - recall: 0.9068 - f1_score: 0.9454 - val_loss: 0.3788 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3159 - acc: 0.9494 - precision: 0.9896 - recall: 0.9058 - f1_score: 0.9452 - val_loss: 0.3781 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3153 - acc: 0.9494 - precision: 0.9894 - recall: 0.9029 - f1_score: 0.9434 - val_loss: 0.3775 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3146 - acc: 0.9494 - precision: 0.9895 - recall: 0.9100 - f1_score: 0.9472 - val_loss: 0.3769 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3139 - acc: 0.9494 - precision: 0.9892 - recall: 0.9074 - f1_score: 0.9448 - val_loss: 0.3762 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3133 - acc: 0.9494 - precision: 0.9905 - recall: 0.9070 - f1_score: 0.9451 - val_loss: 0.3756 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3126 - acc: 0.9494 - precision: 0.9898 - recall: 0.9056 - f1_score: 0.9444 - val_loss: 0.3749 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3120 - acc: 0.9494 - precision: 0.9906 - recall: 0.9085 - f1_score: 0.9469 - val_loss: 0.3743 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3113 - acc: 0.9494 - precision: 0.9878 - recall: 0.9044 - f1_score: 0.9426 - val_loss: 0.3737 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3107 - acc: 0.9494 - precision: 0.9893 - recall: 0.9030 - f1_score: 0.9434 - val_loss: 0.3731 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3100 - acc: 0.9494 - precision: 0.9883 - recall: 0.9076 - f1_score: 0.9455 - val_loss: 0.3724 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3094 - acc: 0.9494 - precision: 0.9901 - recall: 0.9093 - f1_score: 0.9475 - val_loss: 0.3718 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3087 - acc: 0.9494 - precision: 0.9901 - recall: 0.9054 - f1_score: 0.9447 - val_loss: 0.3712 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3081 - acc: 0.9494 - precision: 0.9887 - recall: 0.9053 - f1_score: 0.9444 - val_loss: 0.3706 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3075 - acc: 0.9494 - precision: 0.9893 - recall: 0.9082 - f1_score: 0.9460 - val_loss: 0.3700 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3069 - acc: 0.9494 - precision: 0.9890 - recall: 0.9086 - f1_score: 0.9462 - val_loss: 0.3693 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3062 - acc: 0.9494 - precision: 0.9895 - recall: 0.9060 - f1_score: 0.9456 - val_loss: 0.3687 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3056 - acc: 0.9494 - precision: 0.9886 - recall: 0.9073 - f1_score: 0.9452 - val_loss: 0.3681 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3050 - acc: 0.9494 - precision: 0.9902 - recall: 0.9061 - f1_score: 0.9455 - val_loss: 0.3675 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3044 - acc: 0.9494 - precision: 0.9895 - recall: 0.9067 - f1_score: 0.9457 - val_loss: 0.3670 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3038 - acc: 0.9494 - precision: 0.9892 - recall: 0.9045 - f1_score: 0.9443 - val_loss: 0.3664 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3031 - acc: 0.9494 - precision: 0.9904 - recall: 0.9096 - f1_score: 0.9473 - val_loss: 0.3658 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3025 - acc: 0.9494 - precision: 0.9917 - recall: 0.9085 - f1_score: 0.9469 - val_loss: 0.3652 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3019 - acc: 0.9494 - precision: 0.9885 - recall: 0.9076 - f1_score: 0.9456 - val_loss: 0.3646 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3013 - acc: 0.9494 - precision: 0.9897 - recall: 0.9078 - f1_score: 0.9459 - val_loss: 0.3640 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3007 - acc: 0.9494 - precision: 0.9900 - recall: 0.9032 - f1_score: 0.9421 - val_loss: 0.3635 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3001 - acc: 0.9494 - precision: 0.9890 - recall: 0.9077 - f1_score: 0.9457 - val_loss: 0.3629 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2995 - acc: 0.9494 - precision: 0.9887 - recall: 0.9060 - f1_score: 0.9451 - val_loss: 0.3623 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2989 - acc: 0.9494 - precision: 0.9894 - recall: 0.9060 - f1_score: 0.9446 - val_loss: 0.3617 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2984 - acc: 0.9494 - precision: 0.9875 - recall: 0.9069 - f1_score: 0.9442 - val_loss: 0.3612 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9494 - precision: 0.9868 - recall: 0.9073 - f1_score: 0.9439 - val_loss: 0.3606 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2972 - acc: 0.9494 - precision: 0.9885 - recall: 0.9066 - f1_score: 0.9442 - val_loss: 0.3601 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2966 - acc: 0.9494 - precision: 0.9889 - recall: 0.9061 - f1_score: 0.9449 - val_loss: 0.3595 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2960 - acc: 0.9494 - precision: 0.9887 - recall: 0.9083 - f1_score: 0.9461 - val_loss: 0.3589 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2954 - acc: 0.9494 - precision: 0.9900 - recall: 0.9088 - f1_score: 0.9466 - val_loss: 0.3584 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2949 - acc: 0.9494 - precision: 0.9880 - recall: 0.9083 - f1_score: 0.9456 - val_loss: 0.3578 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2943 - acc: 0.9494 - precision: 0.9890 - recall: 0.9039 - f1_score: 0.9441 - val_loss: 0.3573 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2937 - acc: 0.9494 - precision: 0.9894 - recall: 0.9063 - f1_score: 0.9452 - val_loss: 0.3567 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2932 - acc: 0.9494 - precision: 0.9891 - recall: 0.9075 - f1_score: 0.9459 - val_loss: 0.3562 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2926 - acc: 0.9494 - precision: 0.9900 - recall: 0.9073 - f1_score: 0.9457 - val_loss: 0.3556 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2920 - acc: 0.9494 - precision: 0.9885 - recall: 0.9089 - f1_score: 0.9461 - val_loss: 0.3551 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2915 - acc: 0.9494 - precision: 0.9903 - recall: 0.9113 - f1_score: 0.9476 - val_loss: 0.3546 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2909 - acc: 0.9494 - precision: 0.9911 - recall: 0.9033 - f1_score: 0.9439 - val_loss: 0.3540 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2904 - acc: 0.9494 - precision: 0.9877 - recall: 0.9084 - f1_score: 0.9454 - val_loss: 0.3535 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2898 - acc: 0.9494 - precision: 0.9880 - recall: 0.9041 - f1_score: 0.9434 - val_loss: 0.3530 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2893 - acc: 0.9494 - precision: 0.9885 - recall: 0.9067 - f1_score: 0.9451 - val_loss: 0.3524 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2887 - acc: 0.9494 - precision: 0.9895 - recall: 0.9087 - f1_score: 0.9464 - val_loss: 0.3519 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2882 - acc: 0.9494 - precision: 0.9895 - recall: 0.9091 - f1_score: 0.9467 - val_loss: 0.3514 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2876 - acc: 0.9494 - precision: 0.9885 - recall: 0.9055 - f1_score: 0.9446 - val_loss: 0.3509 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2871 - acc: 0.9494 - precision: 0.9872 - recall: 0.9100 - f1_score: 0.9459 - val_loss: 0.3504 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2866 - acc: 0.9494 - precision: 0.9892 - recall: 0.9073 - f1_score: 0.9456 - val_loss: 0.3499 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2860 - acc: 0.9494 - precision: 0.9893 - recall: 0.9027 - f1_score: 0.9430 - val_loss: 0.3493 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2855 - acc: 0.9494 - precision: 0.9899 - recall: 0.9085 - f1_score: 0.9469 - val_loss: 0.3488 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 798/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2850 - acc: 0.9494 - precision: 0.9902 - recall: 0.9066 - f1_score: 0.9457 - val_loss: 0.3483 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2845 - acc: 0.9494 - precision: 0.9889 - recall: 0.9077 - f1_score: 0.9445 - val_loss: 0.3478 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2839 - acc: 0.9494 - precision: 0.9899 - recall: 0.9050 - f1_score: 0.9447 - val_loss: 0.3473 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2834 - acc: 0.9494 - precision: 0.9900 - recall: 0.9069 - f1_score: 0.9448 - val_loss: 0.3468 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2829 - acc: 0.9494 - precision: 0.9902 - recall: 0.9115 - f1_score: 0.9483 - val_loss: 0.3463 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2824 - acc: 0.9494 - precision: 0.9899 - recall: 0.9089 - f1_score: 0.9466 - val_loss: 0.3458 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2819 - acc: 0.9494 - precision: 0.9894 - recall: 0.9071 - f1_score: 0.9456 - val_loss: 0.3453 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2814 - acc: 0.9494 - precision: 0.9904 - recall: 0.9059 - f1_score: 0.9448 - val_loss: 0.3448 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2808 - acc: 0.9494 - precision: 0.9899 - recall: 0.9126 - f1_score: 0.9483 - val_loss: 0.3444 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2803 - acc: 0.9494 - precision: 0.9885 - recall: 0.9035 - f1_score: 0.9437 - val_loss: 0.3439 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2798 - acc: 0.9494 - precision: 0.9890 - recall: 0.9084 - f1_score: 0.9464 - val_loss: 0.3434 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2793 - acc: 0.9494 - precision: 0.9891 - recall: 0.9089 - f1_score: 0.9457 - val_loss: 0.3429 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2788 - acc: 0.9494 - precision: 0.9905 - recall: 0.9051 - f1_score: 0.9455 - val_loss: 0.3424 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2783 - acc: 0.9494 - precision: 0.9895 - recall: 0.9029 - f1_score: 0.9428 - val_loss: 0.3420 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2778 - acc: 0.9494 - precision: 0.9885 - recall: 0.9062 - f1_score: 0.9443 - val_loss: 0.3415 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2773 - acc: 0.9494 - precision: 0.9907 - recall: 0.9098 - f1_score: 0.9482 - val_loss: 0.3410 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2768 - acc: 0.9494 - precision: 0.9892 - recall: 0.9056 - f1_score: 0.9450 - val_loss: 0.3405 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2764 - acc: 0.9494 - precision: 0.9901 - recall: 0.9046 - f1_score: 0.9445 - val_loss: 0.3401 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2759 - acc: 0.9494 - precision: 0.9884 - recall: 0.9041 - f1_score: 0.9433 - val_loss: 0.3396 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2754 - acc: 0.9494 - precision: 0.9895 - recall: 0.9075 - f1_score: 0.9455 - val_loss: 0.3391 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2749 - acc: 0.9494 - precision: 0.9884 - recall: 0.9078 - f1_score: 0.9448 - val_loss: 0.3387 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9494 - precision: 0.9895 - recall: 0.9056 - f1_score: 0.9450 - val_loss: 0.3382 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9494 - precision: 0.9893 - recall: 0.9044 - f1_score: 0.9439 - val_loss: 0.3377 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2735 - acc: 0.9494 - precision: 0.9893 - recall: 0.9043 - f1_score: 0.9442 - val_loss: 0.3373 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2730 - acc: 0.9494 - precision: 0.9890 - recall: 0.9094 - f1_score: 0.9467 - val_loss: 0.3368 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2725 - acc: 0.9494 - precision: 0.9897 - recall: 0.9074 - f1_score: 0.9461 - val_loss: 0.3364 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9494 - precision: 0.9902 - recall: 0.9079 - f1_score: 0.9463 - val_loss: 0.3359 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2716 - acc: 0.9494 - precision: 0.9893 - recall: 0.9049 - f1_score: 0.9443 - val_loss: 0.3355 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2711 - acc: 0.9494 - precision: 0.9905 - recall: 0.9059 - f1_score: 0.9456 - val_loss: 0.3350 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2707 - acc: 0.9494 - precision: 0.9887 - recall: 0.9064 - f1_score: 0.9452 - val_loss: 0.3346 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2702 - acc: 0.9494 - precision: 0.9894 - recall: 0.9066 - f1_score: 0.9452 - val_loss: 0.3342 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2698 - acc: 0.9494 - precision: 0.9904 - recall: 0.9059 - f1_score: 0.9449 - val_loss: 0.3337 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 830/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9494 - precision: 0.9899 - recall: 0.9061 - f1_score: 0.9452 - val_loss: 0.3333 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2688 - acc: 0.9494 - precision: 0.9897 - recall: 0.9101 - f1_score: 0.9465 - val_loss: 0.3329 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2684 - acc: 0.9494 - precision: 0.9863 - recall: 0.9095 - f1_score: 0.9453 - val_loss: 0.3324 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2679 - acc: 0.9494 - precision: 0.9899 - recall: 0.9100 - f1_score: 0.9476 - val_loss: 0.3320 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2675 - acc: 0.9494 - precision: 0.9894 - recall: 0.9098 - f1_score: 0.9467 - val_loss: 0.3316 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2670 - acc: 0.9494 - precision: 0.9887 - recall: 0.9067 - f1_score: 0.9450 - val_loss: 0.3311 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2666 - acc: 0.9494 - precision: 0.9898 - recall: 0.9100 - f1_score: 0.9474 - val_loss: 0.3307 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2662 - acc: 0.9494 - precision: 0.9901 - recall: 0.9049 - f1_score: 0.9446 - val_loss: 0.3303 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2657 - acc: 0.9494 - precision: 0.9899 - recall: 0.9066 - f1_score: 0.9440 - val_loss: 0.3299 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2653 - acc: 0.9494 - precision: 0.9885 - recall: 0.9108 - f1_score: 0.9469 - val_loss: 0.3295 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9494 - precision: 0.9916 - recall: 0.9064 - f1_score: 0.9450 - val_loss: 0.3290 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2644 - acc: 0.9494 - precision: 0.9901 - recall: 0.9041 - f1_score: 0.9439 - val_loss: 0.3286 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2640 - acc: 0.9494 - precision: 0.9905 - recall: 0.9098 - f1_score: 0.9472 - val_loss: 0.3282 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2636 - acc: 0.9494 - precision: 0.9901 - recall: 0.9073 - f1_score: 0.9460 - val_loss: 0.3278 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2631 - acc: 0.9494 - precision: 0.9903 - recall: 0.9076 - f1_score: 0.9463 - val_loss: 0.3274 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2627 - acc: 0.9494 - precision: 0.9894 - recall: 0.9065 - f1_score: 0.9451 - val_loss: 0.3270 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2623 - acc: 0.9494 - precision: 0.9894 - recall: 0.9098 - f1_score: 0.9471 - val_loss: 0.3266 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2618 - acc: 0.9494 - precision: 0.9902 - recall: 0.9077 - f1_score: 0.9468 - val_loss: 0.3262 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8384 - val_f1_score: 0.9110\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2614 - acc: 0.9494 - precision: 0.9896 - recall: 0.9094 - f1_score: 0.9468 - val_loss: 0.3258 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2610 - acc: 0.9494 - precision: 0.9894 - recall: 0.9045 - f1_score: 0.9437 - val_loss: 0.3254 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2606 - acc: 0.9494 - precision: 0.9902 - recall: 0.9071 - f1_score: 0.9456 - val_loss: 0.3250 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9494 - precision: 0.9900 - recall: 0.9086 - f1_score: 0.9470 - val_loss: 0.3246 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9494 - precision: 0.9898 - recall: 0.9075 - f1_score: 0.9449 - val_loss: 0.3242 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2593 - acc: 0.9494 - precision: 0.9922 - recall: 0.9067 - f1_score: 0.9465 - val_loss: 0.3238 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2589 - acc: 0.9494 - precision: 0.9890 - recall: 0.9050 - f1_score: 0.9442 - val_loss: 0.3234 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9494 - precision: 0.9885 - recall: 0.9066 - f1_score: 0.9449 - val_loss: 0.3230 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9494 - precision: 0.9893 - recall: 0.9084 - f1_score: 0.9458 - val_loss: 0.3226 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2577 - acc: 0.9494 - precision: 0.9895 - recall: 0.9088 - f1_score: 0.9454 - val_loss: 0.3222 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2573 - acc: 0.9494 - precision: 0.9899 - recall: 0.9072 - f1_score: 0.9457 - val_loss: 0.3219 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2569 - acc: 0.9494 - precision: 0.9903 - recall: 0.9077 - f1_score: 0.9448 - val_loss: 0.3215 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9494 - precision: 0.9916 - recall: 0.9095 - f1_score: 0.9485 - val_loss: 0.3211 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2561 - acc: 0.9494 - precision: 0.9902 - recall: 0.9028 - f1_score: 0.9425 - val_loss: 0.3207 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 862/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2557 - acc: 0.9494 - precision: 0.9896 - recall: 0.9028 - f1_score: 0.9426 - val_loss: 0.3204 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2553 - acc: 0.9494 - precision: 0.9902 - recall: 0.9080 - f1_score: 0.9465 - val_loss: 0.3200 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2549 - acc: 0.9494 - precision: 0.9897 - recall: 0.9100 - f1_score: 0.9466 - val_loss: 0.3196 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2545 - acc: 0.9494 - precision: 0.9900 - recall: 0.9071 - f1_score: 0.9457 - val_loss: 0.3192 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2542 - acc: 0.9494 - precision: 0.9898 - recall: 0.9052 - f1_score: 0.9448 - val_loss: 0.3189 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2538 - acc: 0.9494 - precision: 0.9879 - recall: 0.9076 - f1_score: 0.9453 - val_loss: 0.3185 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2534 - acc: 0.9494 - precision: 0.9886 - recall: 0.9108 - f1_score: 0.9469 - val_loss: 0.3182 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2530 - acc: 0.9494 - precision: 0.9892 - recall: 0.9086 - f1_score: 0.9468 - val_loss: 0.3178 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9494 - precision: 0.9884 - recall: 0.9050 - f1_score: 0.9438 - val_loss: 0.3174 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2522 - acc: 0.9494 - precision: 0.9913 - recall: 0.9019 - f1_score: 0.9431 - val_loss: 0.3171 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2519 - acc: 0.9494 - precision: 0.9894 - recall: 0.9063 - f1_score: 0.9451 - val_loss: 0.3167 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2515 - acc: 0.9494 - precision: 0.9901 - recall: 0.9065 - f1_score: 0.9458 - val_loss: 0.3164 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2511 - acc: 0.9494 - precision: 0.9905 - recall: 0.9048 - f1_score: 0.9444 - val_loss: 0.3160 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2507 - acc: 0.9494 - precision: 0.9893 - recall: 0.9063 - f1_score: 0.9447 - val_loss: 0.3157 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2504 - acc: 0.9494 - precision: 0.9890 - recall: 0.9098 - f1_score: 0.9465 - val_loss: 0.3153 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2500 - acc: 0.9494 - precision: 0.9902 - recall: 0.9101 - f1_score: 0.9474 - val_loss: 0.3150 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9494 - precision: 0.9882 - recall: 0.9024 - f1_score: 0.9424 - val_loss: 0.3146 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9494 - precision: 0.9895 - recall: 0.9076 - f1_score: 0.9463 - val_loss: 0.3143 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9494 - precision: 0.9892 - recall: 0.9058 - f1_score: 0.9442 - val_loss: 0.3139 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2485 - acc: 0.9494 - precision: 0.9897 - recall: 0.9084 - f1_score: 0.9464 - val_loss: 0.3136 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2482 - acc: 0.9494 - precision: 0.9907 - recall: 0.9090 - f1_score: 0.9475 - val_loss: 0.3133 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9494 - precision: 0.9898 - recall: 0.9072 - f1_score: 0.9449 - val_loss: 0.3129 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2474 - acc: 0.9494 - precision: 0.9902 - recall: 0.9085 - f1_score: 0.9464 - val_loss: 0.3126 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2471 - acc: 0.9494 - precision: 0.9868 - recall: 0.9055 - f1_score: 0.9430 - val_loss: 0.3123 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9494 - precision: 0.9883 - recall: 0.9091 - f1_score: 0.9453 - val_loss: 0.3120 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9494 - precision: 0.9907 - recall: 0.9042 - f1_score: 0.9439 - val_loss: 0.3116 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2460 - acc: 0.9494 - precision: 0.9883 - recall: 0.9050 - f1_score: 0.9441 - val_loss: 0.3113 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2457 - acc: 0.9494 - precision: 0.9894 - recall: 0.9060 - f1_score: 0.9451 - val_loss: 0.3110 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9494 - precision: 0.9895 - recall: 0.9081 - f1_score: 0.9461 - val_loss: 0.3106 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9494 - precision: 0.9908 - recall: 0.9006 - f1_score: 0.9418 - val_loss: 0.3103 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2446 - acc: 0.9494 - precision: 0.9881 - recall: 0.9049 - f1_score: 0.9441 - val_loss: 0.3100 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2443 - acc: 0.9494 - precision: 0.9872 - recall: 0.9053 - f1_score: 0.9436 - val_loss: 0.3097 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2439 - acc: 0.9494 - precision: 0.9897 - recall: 0.9090 - f1_score: 0.9470 - val_loss: 0.3094 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2436 - acc: 0.9494 - precision: 0.9904 - recall: 0.9035 - f1_score: 0.9436 - val_loss: 0.3090 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2432 - acc: 0.9494 - precision: 0.9885 - recall: 0.9089 - f1_score: 0.9456 - val_loss: 0.3087 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9494 - precision: 0.9875 - recall: 0.9043 - f1_score: 0.9431 - val_loss: 0.3084 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9494 - precision: 0.9900 - recall: 0.9090 - f1_score: 0.9463 - val_loss: 0.3081 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2422 - acc: 0.9494 - precision: 0.9895 - recall: 0.9070 - f1_score: 0.9451 - val_loss: 0.3078 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2419 - acc: 0.9494 - precision: 0.9894 - recall: 0.9103 - f1_score: 0.9476 - val_loss: 0.3074 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2416 - acc: 0.9494 - precision: 0.9894 - recall: 0.9092 - f1_score: 0.9468 - val_loss: 0.3071 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2412 - acc: 0.9494 - precision: 0.9874 - recall: 0.9048 - f1_score: 0.9437 - val_loss: 0.3068 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9494 - precision: 0.9885 - recall: 0.9084 - f1_score: 0.9456 - val_loss: 0.3065 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9494 - precision: 0.9882 - recall: 0.9037 - f1_score: 0.9433 - val_loss: 0.3062 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9494 - precision: 0.9879 - recall: 0.9051 - f1_score: 0.9435 - val_loss: 0.3059 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9494 - precision: 0.9889 - recall: 0.9093 - f1_score: 0.9456 - val_loss: 0.3056 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2396 - acc: 0.9494 - precision: 0.9893 - recall: 0.9070 - f1_score: 0.9457 - val_loss: 0.3053 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2393 - acc: 0.9494 - precision: 0.9894 - recall: 0.9086 - f1_score: 0.9469 - val_loss: 0.3050 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9494 - precision: 0.9901 - recall: 0.9072 - f1_score: 0.9455 - val_loss: 0.3047 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9494 - precision: 0.9890 - recall: 0.9062 - f1_score: 0.9440 - val_loss: 0.3044 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2383 - acc: 0.9494 - precision: 0.9891 - recall: 0.9071 - f1_score: 0.9458 - val_loss: 0.3041 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2380 - acc: 0.9494 - precision: 0.9887 - recall: 0.9061 - f1_score: 0.9453 - val_loss: 0.3038 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9494 - precision: 0.9903 - recall: 0.9051 - f1_score: 0.9452 - val_loss: 0.3035 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2374 - acc: 0.9494 - precision: 0.9910 - recall: 0.9131 - f1_score: 0.9496 - val_loss: 0.3032 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9494 - precision: 0.9887 - recall: 0.9070 - f1_score: 0.9453 - val_loss: 0.3029 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2367 - acc: 0.9494 - precision: 0.9892 - recall: 0.9056 - f1_score: 0.9443 - val_loss: 0.3026 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2364 - acc: 0.9494 - precision: 0.9891 - recall: 0.9065 - f1_score: 0.9446 - val_loss: 0.3023 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9494 - precision: 0.9873 - recall: 0.9054 - f1_score: 0.9442 - val_loss: 0.3020 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9494 - precision: 0.9891 - recall: 0.9081 - f1_score: 0.9460 - val_loss: 0.3018 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9494 - precision: 0.9885 - recall: 0.9077 - f1_score: 0.9457 - val_loss: 0.3015 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2352 - acc: 0.9494 - precision: 0.9904 - recall: 0.9058 - f1_score: 0.9452 - val_loss: 0.3012 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2349 - acc: 0.9494 - precision: 0.9898 - recall: 0.9010 - f1_score: 0.9415 - val_loss: 0.3009 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9494 - precision: 0.9898 - recall: 0.9047 - f1_score: 0.9446 - val_loss: 0.3006 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2343 - acc: 0.9494 - precision: 0.9899 - recall: 0.9082 - f1_score: 0.9461 - val_loss: 0.3003 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2340 - acc: 0.9494 - precision: 0.9902 - recall: 0.9056 - f1_score: 0.9441 - val_loss: 0.3001 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9494 - precision: 0.9897 - recall: 0.9004 - f1_score: 0.9420 - val_loss: 0.2998 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9494 - precision: 0.9883 - recall: 0.9072 - f1_score: 0.9448 - val_loss: 0.2995 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2331 - acc: 0.9494 - precision: 0.9901 - recall: 0.9085 - f1_score: 0.9466 - val_loss: 0.2993 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2328 - acc: 0.9494 - precision: 0.9893 - recall: 0.9041 - f1_score: 0.9441 - val_loss: 0.2990 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9494 - precision: 0.9883 - recall: 0.9040 - f1_score: 0.9438 - val_loss: 0.2987 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9494 - precision: 0.9900 - recall: 0.9044 - f1_score: 0.9447 - val_loss: 0.2984 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9494 - precision: 0.9876 - recall: 0.9065 - f1_score: 0.9444 - val_loss: 0.2982 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2316 - acc: 0.9494 - precision: 0.9894 - recall: 0.9068 - f1_score: 0.9447 - val_loss: 0.2979 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2313 - acc: 0.9494 - precision: 0.9909 - recall: 0.9119 - f1_score: 0.9482 - val_loss: 0.2976 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9494 - precision: 0.9894 - recall: 0.9085 - f1_score: 0.9467 - val_loss: 0.2974 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9494 - precision: 0.9898 - recall: 0.9109 - f1_score: 0.9473 - val_loss: 0.2971 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2305 - acc: 0.9494 - precision: 0.9901 - recall: 0.9101 - f1_score: 0.9472 - val_loss: 0.2969 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2302 - acc: 0.9494 - precision: 0.9891 - recall: 0.9095 - f1_score: 0.9465 - val_loss: 0.2966 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2299 - acc: 0.9494 - precision: 0.9901 - recall: 0.9066 - f1_score: 0.9452 - val_loss: 0.2964 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2296 - acc: 0.9494 - precision: 0.9894 - recall: 0.9062 - f1_score: 0.9456 - val_loss: 0.2961 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2293 - acc: 0.9494 - precision: 0.9899 - recall: 0.9080 - f1_score: 0.9465 - val_loss: 0.2958 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2290 - acc: 0.9494 - precision: 0.9883 - recall: 0.9054 - f1_score: 0.9444 - val_loss: 0.2956 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2288 - acc: 0.9494 - precision: 0.9887 - recall: 0.9039 - f1_score: 0.9433 - val_loss: 0.2953 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2285 - acc: 0.9494 - precision: 0.9909 - recall: 0.9086 - f1_score: 0.9469 - val_loss: 0.2951 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2282 - acc: 0.9494 - precision: 0.9907 - recall: 0.9052 - f1_score: 0.9450 - val_loss: 0.2948 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2279 - acc: 0.9494 - precision: 0.9891 - recall: 0.9068 - f1_score: 0.9457 - val_loss: 0.2946 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2277 - acc: 0.9494 - precision: 0.9904 - recall: 0.9077 - f1_score: 0.9463 - val_loss: 0.2943 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2274 - acc: 0.9494 - precision: 0.9882 - recall: 0.9076 - f1_score: 0.9454 - val_loss: 0.2941 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2271 - acc: 0.9494 - precision: 0.9901 - recall: 0.9073 - f1_score: 0.9461 - val_loss: 0.2938 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2269 - acc: 0.9494 - precision: 0.9896 - recall: 0.9087 - f1_score: 0.9460 - val_loss: 0.2936 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2266 - acc: 0.9494 - precision: 0.9901 - recall: 0.9073 - f1_score: 0.9460 - val_loss: 0.2933 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2263 - acc: 0.9494 - precision: 0.9895 - recall: 0.9066 - f1_score: 0.9446 - val_loss: 0.2931 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2261 - acc: 0.9494 - precision: 0.9901 - recall: 0.9063 - f1_score: 0.9456 - val_loss: 0.2928 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2258 - acc: 0.9494 - precision: 0.9893 - recall: 0.9112 - f1_score: 0.9479 - val_loss: 0.2926 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2255 - acc: 0.9494 - precision: 0.9897 - recall: 0.9047 - f1_score: 0.9442 - val_loss: 0.2923 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2253 - acc: 0.9494 - precision: 0.9876 - recall: 0.9119 - f1_score: 0.9471 - val_loss: 0.2921 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2250 - acc: 0.9494 - precision: 0.9882 - recall: 0.9056 - f1_score: 0.9439 - val_loss: 0.2918 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 958/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2247 - acc: 0.9494 - precision: 0.9904 - recall: 0.9034 - f1_score: 0.9439 - val_loss: 0.2916 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2245 - acc: 0.9494 - precision: 0.9898 - recall: 0.9094 - f1_score: 0.9459 - val_loss: 0.2914 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2242 - acc: 0.9494 - precision: 0.9891 - recall: 0.9060 - f1_score: 0.9452 - val_loss: 0.2911 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2240 - acc: 0.9494 - precision: 0.9901 - recall: 0.9026 - f1_score: 0.9432 - val_loss: 0.2909 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2237 - acc: 0.9494 - precision: 0.9902 - recall: 0.9057 - f1_score: 0.9458 - val_loss: 0.2907 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2235 - acc: 0.9494 - precision: 0.9897 - recall: 0.9102 - f1_score: 0.9470 - val_loss: 0.2904 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2232 - acc: 0.9494 - precision: 0.9900 - recall: 0.9068 - f1_score: 0.9454 - val_loss: 0.2902 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2229 - acc: 0.9494 - precision: 0.9901 - recall: 0.9075 - f1_score: 0.9461 - val_loss: 0.2900 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2227 - acc: 0.9494 - precision: 0.9899 - recall: 0.9061 - f1_score: 0.9450 - val_loss: 0.2897 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2224 - acc: 0.9494 - precision: 0.9897 - recall: 0.9095 - f1_score: 0.9460 - val_loss: 0.2895 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2222 - acc: 0.9494 - precision: 0.9886 - recall: 0.9081 - f1_score: 0.9453 - val_loss: 0.2893 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2219 - acc: 0.9494 - precision: 0.9890 - recall: 0.9001 - f1_score: 0.9398 - val_loss: 0.2891 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2217 - acc: 0.9494 - precision: 0.9908 - recall: 0.9080 - f1_score: 0.9467 - val_loss: 0.2888 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2214 - acc: 0.9494 - precision: 0.9914 - recall: 0.9128 - f1_score: 0.9492 - val_loss: 0.2886 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2212 - acc: 0.9494 - precision: 0.9898 - recall: 0.9105 - f1_score: 0.9474 - val_loss: 0.2884 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2209 - acc: 0.9494 - precision: 0.9895 - recall: 0.9088 - f1_score: 0.9465 - val_loss: 0.2882 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2207 - acc: 0.9494 - precision: 0.9897 - recall: 0.9091 - f1_score: 0.9469 - val_loss: 0.2879 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2205 - acc: 0.9494 - precision: 0.9895 - recall: 0.9096 - f1_score: 0.9469 - val_loss: 0.2877 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2202 - acc: 0.9494 - precision: 0.9916 - recall: 0.9050 - f1_score: 0.9451 - val_loss: 0.2875 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2200 - acc: 0.9494 - precision: 0.9912 - recall: 0.9028 - f1_score: 0.9433 - val_loss: 0.2873 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2197 - acc: 0.9494 - precision: 0.9896 - recall: 0.9033 - f1_score: 0.9428 - val_loss: 0.2871 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2195 - acc: 0.9494 - precision: 0.9903 - recall: 0.9066 - f1_score: 0.9459 - val_loss: 0.2868 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2193 - acc: 0.9494 - precision: 0.9902 - recall: 0.9083 - f1_score: 0.9470 - val_loss: 0.2866 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2190 - acc: 0.9494 - precision: 0.9898 - recall: 0.9065 - f1_score: 0.9454 - val_loss: 0.2864 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2188 - acc: 0.9494 - precision: 0.9902 - recall: 0.9053 - f1_score: 0.9456 - val_loss: 0.2862 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2186 - acc: 0.9494 - precision: 0.9906 - recall: 0.9019 - f1_score: 0.9412 - val_loss: 0.2860 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2183 - acc: 0.9494 - precision: 0.9897 - recall: 0.9069 - f1_score: 0.9457 - val_loss: 0.2858 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2181 - acc: 0.9494 - precision: 0.9906 - recall: 0.9044 - f1_score: 0.9442 - val_loss: 0.2856 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2179 - acc: 0.9494 - precision: 0.9901 - recall: 0.9133 - f1_score: 0.9494 - val_loss: 0.2854 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2176 - acc: 0.9494 - precision: 0.9913 - recall: 0.9095 - f1_score: 0.9470 - val_loss: 0.2852 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2174 - acc: 0.9494 - precision: 0.9898 - recall: 0.9073 - f1_score: 0.9458 - val_loss: 0.2850 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2172 - acc: 0.9494 - precision: 0.9899 - recall: 0.9033 - f1_score: 0.9413 - val_loss: 0.2848 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2169 - acc: 0.9494 - precision: 0.9909 - recall: 0.9102 - f1_score: 0.9479 - val_loss: 0.2845 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2167 - acc: 0.9494 - precision: 0.9893 - recall: 0.9042 - f1_score: 0.9435 - val_loss: 0.2843 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2165 - acc: 0.9494 - precision: 0.9892 - recall: 0.9096 - f1_score: 0.9470 - val_loss: 0.2841 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2163 - acc: 0.9494 - precision: 0.9892 - recall: 0.9063 - f1_score: 0.9451 - val_loss: 0.2839 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2160 - acc: 0.9494 - precision: 0.9887 - recall: 0.9066 - f1_score: 0.9445 - val_loss: 0.2837 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2158 - acc: 0.9494 - precision: 0.9908 - recall: 0.9104 - f1_score: 0.9475 - val_loss: 0.2835 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2156 - acc: 0.9494 - precision: 0.9897 - recall: 0.9032 - f1_score: 0.9432 - val_loss: 0.2833 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2154 - acc: 0.9494 - precision: 0.9874 - recall: 0.9047 - f1_score: 0.9439 - val_loss: 0.2831 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2151 - acc: 0.9494 - precision: 0.9892 - recall: 0.9031 - f1_score: 0.9429 - val_loss: 0.2829 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2149 - acc: 0.9494 - precision: 0.9856 - recall: 0.9089 - f1_score: 0.9445 - val_loss: 0.2827 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2147 - acc: 0.9494 - precision: 0.9895 - recall: 0.9057 - f1_score: 0.9445 - val_loss: 0.2825 - val_acc: 0.9241 - val_precision: 1.0000 - val_recall: 0.8505 - val_f1_score: 0.9186\n",
      " 50/158 [========>.....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# NN model\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FP = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return TP / (TP_plus_FP + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FN = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return TP / (TP_plus_FN + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * prec * rec / (prec + rec + K.epsilon())\n",
    "\n",
    "def nn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(NUMBER_OF_NEURONS,\n",
    "                    input_dim=NUMBER_OF_FEATURES,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(REGULARIZATION_LAMBDA)))\n",
    "#     model.add(layers.Dense(NUMBER_OF_NEURONS, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimazier = optimizers.SGD(lr=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimazier,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', precision, recall, f1_score])\n",
    "    return model\n",
    "\n",
    "train_results = {'models': [], 'history': [], 'score': []}\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS)\n",
    "for train_index, validation_index in kf.split(under_sample_dataset):\n",
    "    k_fold_train, k_fold_validation = under_sample_dataset[train_index], under_sample_dataset[validation_index]\n",
    "\n",
    "    x_train = k_fold_train[:,:-1]\n",
    "    y_train = k_fold_train[:,-1:]\n",
    "        \n",
    "    x_validation = k_fold_validation[:,:-1]\n",
    "    y_validation = k_fold_validation[:,-1:]\n",
    "    \n",
    "    model = nn_model()\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), verbose=1, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    score = model.evaluate(x_validation, y_validation, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    train_results['models'].append(model)\n",
    "    train_results['history'].append(history)\n",
    "    train_results['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.212850</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.942348</td>\n",
       "      <td>0.964548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.255378</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.980222</td>\n",
       "      <td>0.843279</td>\n",
       "      <td>0.904875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.239723</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.975170</td>\n",
       "      <td>0.926300</td>\n",
       "      <td>0.948911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.234441</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.971857</td>\n",
       "      <td>0.909283</td>\n",
       "      <td>0.939378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.282547</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850536</td>\n",
       "      <td>0.918617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Loss  Accuracy  Precision    Recall  F1_score\n",
       "K-fold 1  0.212850  0.962264   0.988769  0.942348  0.964548\n",
       "K-fold 2  0.255378  0.930380   0.980222  0.843279  0.904875\n",
       "K-fold 3  0.239723  0.943038   0.975170  0.926300  0.948911\n",
       "K-fold 4  0.234441  0.943038   0.971857  0.909283  0.939378\n",
       "K-fold 5  0.282547  0.924051   1.000000  0.850536  0.918617"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Loss, Precision, Recall and F1 score in each validation\n",
    "\n",
    "train_results_dict = {'Loss': [i[0] for i in train_results['score']],\n",
    "                      'Accuracy': [i[1] for i in train_results['score']],\n",
    "                      'Precision': [i[2] for i in train_results['score']],\n",
    "                      'Recall': [i[3] for i in train_results['score']],\n",
    "                      'F1_score': [i[4] for i in train_results['score']]}\n",
    "\n",
    "columns = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=train_results_dict, columns=columns, index=indexes)\n",
    "results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nscxexMQCrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3a480dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38ee7f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3a4878da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38ee3b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGET4A4BBhD8AGET4A4BBPzeV4a7XjLVrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38ed51c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves for validation and training data during learning\n",
    "for history in train_results['history']:\n",
    "    show_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION ON TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.986166</td>\n",
       "      <td>0.105626</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.982954</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.157849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.983550</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.164139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.983972</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.167730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.985815</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.183838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision    Recall  F1_score\n",
       "K-fold 1  0.986166   0.105626  0.910891  0.189300\n",
       "K-fold 2  0.982954   0.086502  0.900990  0.157849\n",
       "K-fold 3  0.983550   0.090196  0.910891  0.164139\n",
       "K-fold 4  0.983972   0.092369  0.910891  0.167730\n",
       "K-fold 5  0.985815   0.102362  0.900990  0.183838"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Precision, Recall and F1 score for test dataset for each model from cross validation\n",
    "\n",
    "test_results = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F1_score': []}\n",
    "confusion_matrixes = []\n",
    "for model in train_results['models']:\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    predicted = np.asarray([np.round(j[0]) for j in predicted])\n",
    "    actual = np.asarray([j[0] for j in y_test])\n",
    "        \n",
    "    TP = np.count_nonzero(predicted * actual)\n",
    "    TN = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    FP = np.count_nonzero(predicted * (actual - 1))\n",
    "    FN = np.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "    confusion_matrix_dict = {'actual 1': [TP, FN], 'actual 0': [FP, TN]}\n",
    "    confusion_matrix = pd.DataFrame(data=confusion_matrix_dict, columns =['actual 1', 'actual 0'], index=['predicted 1', 'predicted 0'])\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = metrics.accuracy_score(actual, predicted)\n",
    "    \n",
    "    test_results['Accuracy'].append(accuracy)\n",
    "    test_results['Precision'].append(precision)\n",
    "    test_results['Recall'].append(recall)\n",
    "    test_results['F1_score'].append(f1)\n",
    "    confusion_matrixes.append(confusion_matrix)\n",
    "    \n",
    "columns = ['Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=test_results, columns=columns, index=indexes)\n",
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejpesko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8FHX+x/HXlvRKsgkRgiIQelGI0pFAjBVpwuFhQQ5F\nKYJUQZAmGgRE6qHSDsXCDyycdycYRYEEpCOglACCEEoK6W3L/P6IJgSSsITszu7m83w8fMTdney8\n92ucz858Zz6jURRFQQghhLCCVu0AQgghnIcUDSGEEFaToiGEEMJqUjSEEEJYTYqGEEIIq0nREEII\nYTUpGkIIIawmRUOICgwaNAiNRoNGo0Gn0xEeHs6zzz7LhQsXSi136tQpBg0aRO3atXF3d6dWrVo8\n99xznDp16ob3zM3N5c0336Rly5Z4e3sTFBRE27ZtWbx4Mbm5ufb6aEJUihQNIW6ic+fOXLx4kXPn\nzvHJJ59w4MAB+vXrV/z6gQMHiIyM5Pz583zyySckJiby2WefkZSURGRkJAcPHixeNjMzk44dO7J4\n8WKGDx9OQkIC+/btY9y4caxfv54tW7ao8RGFsJpGrggXonyDBg3i/PnzxMXFFT+3ePFiXnnlFTIy\nMvDz8+Oee+5BURT279+PXq8vXs5kMnHvvfei0+k4cOAAGo2GkSNHsmLFCn799VfuvvvuUutSFIWM\njAwCAwPt9vmEuFWypyHELUhKSmLDhg3odDp0Oh2//PILv/zyCxMmTChVMAD0ej0TJkzg0KFDHD58\nGIvFwrp16xg4cOANBQNAo9FIwRAOT3/zRYSo3n788Ud8fX2xWCzk5eUBMHbsWHx8fDh+/DgAzZo1\nK/N3/3r++PHjhIWFcfXqVZo2bWqf4ELYgBQNIW6ibdu2/Otf/yI/P5/169cTFxfHm2++ecvvI0eC\nhSuQw1NC3ISXlxcNGjSgefPmzJw5k7vvvpuRI0cC0LBhQwCOHDlS5u8ePXoUgEaNGhESEkKNGjX4\n9ddf7RNcCBuQiXAhKlDWRPjJkydp0qQJu3btok2bNrRs2RKNRlPmRHjr1q3RaDQcPHgQjUbDiBEj\nWLlyZbkT4ZmZmQQEBNjt8wlxq2RPQ4hbFBERQY8ePXj99dfRaDSsWbOGs2fP8sgjj7Bt2zb++OMP\ntm/fzqOPPsq5c+dYs2YNGo0GgNmzZxMREUG7du344IMPOHToEGfOnOHLL7/kgQceYOvWrSp/OiEq\nJnMaQlTC+PHj6dixIz/++CNdu3Zl7969vPnmmwwYMIDk5GQMBgMxMTHs27eP+vXrF/9eQEAAO3fu\nZP78+SxevJhRo0bh6elJREQEffr0ISYmRsVPJcTNyeEpIYQQVpPDU0IIIaxml8NTy5YtY//+/QQE\nBDB//vwbXlcUhdWrV3PgwAE8PDwYNmwY9erVs0c0IYQQt8Auexpdu3Zl8uTJ5b5+4MABLl26xKJF\ni3jxxRdZsWKFPWIJIYS4RXYpGk2bNsXX17fc1/fu3UuXLl3QaDQ0bNiQnJwcrl69ao9oQgghboFD\nnD2VlpaGwWAofhwcHExaWho1atS4Ydm4uLjic+ZjY2PtllEIIYSDFI1bER0dTXR0dPHjpKQkFdM4\nDoPBQEpKitoxHIKMBSgKGI0QGGjg0qVUTCYwmTQ3/DQawWwu/fP610seg9FY+j3Kemw2lzxf+cfl\n51AUjd3GUaNRcHMDvV5Bry/66eYGOl3J80WPwc2taBk3N6XCx3+9V+UfV5Sj9GN3d4XQUEvRH4RG\ng8eWLXj+9BM+q1dXekwcomgEBQWV+p88NTWVoKAgFRMJV6YoYLFQ5gazZMN5843rjT9v3IjefEN9\n44azot/9a+N9s2wWy7Ub1jtsPqbXblyv33hdu5EreVy0EfT2Vm5po3krG+eSx0XvERwcQE5O+k1y\nlX6s09l86GxKk56O/9hZmO+8k+xRoyiIiaEgJgaf23hPhygakZGRfPvtt3Ts2JGTJ0/i7e1d5qEp\nYX+KArm5GnJzb/6ttKwNW8Ub5oo3hmX9vHEDe+MyiqKnoCC0giz2+6Z6raKNWekN4fUbu7J++vhY\nbvid69+nvN8NCPCmoCCn1Ib8+p/Xv69136xLP9Y6wcn7BoNCSopR7Rh24/m//xEweTLa1FSyR42q\nsve1S9F47733+PXXX8nKyuKll16if//+mEwmAGJiYrj33nvZv38/r7zyCu7u7gwbNswesVya0QjZ\n2Rqys7VkZWnIySn6mZVV8lzJTw1ZWdobfubkFC1vj8MB5W3QbraB8/C4caPq46PFbC4sdyNb3jfh\nm22Yy/pZ+r3KX1atb6wGgycpKTnqrFyoQpucTMCUKXh98w3GZs1IW7sWY4sWVfb+Tn9FuCvNaSgK\n5OdTxka9ZONe3gY/P9+Nq1ctfz7WkJ9/869+Go2Cr2/RP35+lnJ+Kvj6WvDyutlG9q9vvNZs8G/c\nQGuqsC7JnEYJGYsS1WUs3A4dIrhvX7JfeYXsl18u+p/yOrVq1ar0+zvE4anqQFHg6lUNFy7oOX9e\nV/zPhQtFP5OSdGRkaDGZbr711OuLNupFG/Sif69ZE+rUKSy1offzu3Hjf+1Pb2/FKQ4rCCEqpjt/\nHo/vviP3+ecxtmrF5d27UWw0LyxFo4qYzXD5srbMovBXYcjNLb2F9vKyEB5uJjzcTMuWRmrUsFi1\nwffwuPGbedG3qHQ7fmIhhOosFrzXrsX/rbcAyH/0USw1a9qsYIAUjVumKJCUpOWXX9w5eNCNw4fd\nOHNGT1KS7oa9hBo1igpC/fomunQpIDzcTO3a5uJCUaOGpUoPywghqg9dYiKB48fjsXs3+V27kjFn\nDpaaNW2+XikaN5GcrOXgQTd++cWdQ4fc+OUXN5KTi2Y19XqFRo1MtGlTyBNPlC4ItWub8fFx6uki\nIYSD0uTlYejdG43FwtUFC8jr169qJwYrIEXjGooCx4/r2b7dg59/dufgQXcuXiwqEFqtQkSEia5d\nC7jnnkJatjTStKkRT0+VQwshqg3dqVOY69VD8fIifdEijM2aYQkNtWuGal80LlzQsWOHO9u3e7Bj\nh0fxXsRdd5lo27aAVq2MtGplpHlzo+w5CCHUkZ+P33vv4btsGekLFpDXty8FUVGqRKl2RUNRID7e\nnf/+14vt2z04fbpoCAwGM507F9C5cwGdOhVSu7ZZ5aRCCAHue/YQMHYsbqdOkfu3v5HfvbuqeapN\n0UhL07J+vRcff+zDmTN6vL0ttGtXyDPP5NC5cwGNG5tkUloI4VB8FyzAb/58zLVrk/rJJxQ88IDa\nkVy/aBw+7Mb77/vwn/94UVioITKykFGjrvL443l4eamdTgghyvBng0Fjs2bkDB5M1sSJKD630zGq\n6rh00fj9dx29egXj7g4DB+bw9NO5NG5sUjuWEEKUSXP1KgHTp2OqW5fsV18tbjDoSFy2aCgKjB8f\niJsbxMVdoXZti9qRhBCiXJ7ffEPA66+jTU8na/RoteOUy2WLxiefeJOQ4MGcOelSMIQQDkt7+XJR\ng8H//pfCli1J/eQTTM2aqR2rXC5VNBTlr3YeOmbN8qdDhwIGDsxVO5YQQpRLd/kyHj/+SObrr5P9\n4otFHTwdmGOnuwV5eRAdHcrvvxd9JE9PC3PnpssZUUIIh6P74w88v/uOnMGDMbZsyeU9e1ACA9WO\nZRWXKRrr1vnw++96hg7Nxt/fQseOhdStK9daCCEciNmMz5o1+MXGglZL3uOPYwkNdZqCAS5SNJYt\n82X2bH/aty/gjTcy1Y4jhBA30J88SeC4cbjv3Ut+VFRRg0E7twCpCi5RNP7zn6IGULNmZaicRAgh\nbqTJyyO4T5+iBoMLF5LXt6/dGgxWNZcoGhcv6hgwIIcmTeQaDCGE49AnJmKqX7+oweCSJRibNsUS\nEqJ2rNvi9PdtMxrhyhUtd9whp9UKIRxEXh5+s2cTEhWF1xdfAFDwwANOXzDABfY0Ll/WoSgaatWS\nSW8hhPrcd+0icNw49GfOkPP3v5MfHa12pCrl9EXj55/dAYiIMKqcRAhR3fm++y7+8+djuvNOUj77\njMLOndWOVOWcvmhMm+bPXXeZaNNGioYQQiV/NRhs2ZLsF14ga8IEFG9vtVPZhNMXjatXdQwblonW\n6WdnhBDORpuWhv+0aZjq1StqMBgdTYGLHY66ntNvapcuvcrLL2erHUMIUZ0oCp6bNhHStStemzY5\n7emzleH0exphYebq9N9LCKEy7aVLBEyejNfmzRS2akXqZ59hatpU7Vh24/RFQ6eT+3YLIexHl5yM\nR3w8GVOnkjNkiMM3GKxqTv9p3dzUTiCEcHW6s2fx3LKFnBdewNiiBZd370YJCFA7liqcfk5Dr5c9\nDSGEjZjN+HzwASHduuE3fz7aK1cAqm3BABcoGjqd2gmEEK5If/w4hp49CZgxg8KOHbnyww9O2WCw\nqjn94SkPD9nTEEJULU1eHsF/NhW8unQpeT17VqszpCoiRUMIIf6kP3ECU0QEipcXV5ctw9SsGZbg\nYLVjORSnPzwlE+FCiNulycvDf9YsQrp3x2vjRgAKu3SRglEGp9/TkCvBhRC3wz0hgcDx49H//js5\nTz9NfkyM2pEcmhQNIUS15TdvHn4LFmCqW5eU9esp7NhR7UgOz+mLBsichhDiFv3ZYLDwnnvIHjqU\nrPHjUby81E7lFOxWNA4ePMjq1auxWCx0796dXr16lXo9NzeXRYsWkZqaitlspkePHkRFRd30fWVP\nQwhhLW1qKv5vvIGpfn2yx4ypFg0Gq5pdNrkWi4WVK1cyefJkFixYQHx8POfPny+1zLfffkt4eDhz\n585l+vTprF27FpPp5rdvlaIhhLgpRUH72WeEPPAAXv/5j5xBcxvssslNTEwkLCyMmjVrotfr6dCh\nA3v27Cm1jEajIT8/H0VRyM/Px9fXF60VFUFOnRZCVESblETQoEHon3sOc926JG/eTPbIkWrHclp2\nOTyVlpZG8DWnrgUHB3Py5MlSyzz88MO88847DB06lLy8PF599dUyi0ZcXBxxcXEAxMbGYjAE4+dn\n2/zOQK/XYzAY1I7hEGQsSshYgOb8efS7d2OZPx9efplAaSNxWxxmIvzQoUPcddddvPHGG1y+fJlZ\ns2bRuHFjvK+7+1V0dDTR1xyDTE1NpaBAJsMNBgMpKSlqx3AIMhYlqutY6M6cwfO778h58UUID0ez\nezfBd99dLceiLLVq1ar079rl8FRQUBCpqanFj1NTUwkKCiq1zNatW2nbti0ajYawsDBCQ0NJSkqy\nRzwhhKswmfBZvpzQ6Gj8FixAm5wMgCKHI6qMXYpG/fr1uXjxIleuXMFkMpGQkEBkZGSpZQwGA4cP\nHwYgPT2dpKQkQqU5mBDCSvrffitqMDhrFvlduhQ1GAwJUTuWy7HL4SmdTsfgwYOZPXs2FouFqKgo\n6tSpw5YtWwCIiYmhb9++LFu2jLFjxwIwcOBA/P397RFPCOHkNHl5BPfrB1otacuWkf/EE3KWjI1o\nFEVx6gmBEycu4uvr1B+hSlTXY9dlkbEo4epjoT92DFOjRqDR4L59e1GDwesOff/F1cfiVjj8nIYt\nyZcJIaofTW4u/tOnExIdXdJgsHPncguGqDoOc/aUEEJYw337dgInTEB/7hw5zz1H/kMPqR2pWpGi\nIYRwGn7vvIPfwoWY7r6blI0bKWzXTu1I1Y4UDSGE47NYQKulMDKSrGHDyBozBqTBoCqkaAghHJY2\nJYWAqVMx1a9P1rhxFHTrRkG3bmrHqtacfiJcCOGCFAWvjRsJfeABPL/9VtqWO5Bb3tPIyMggICDA\nFlmEEALthQsEvvYanj/8QGGbNqTPm4epYUO1Y4k/WVU0cnNzWbVqFTt37kSr1fLRRx+xd+9eTp8+\nTf/+/W2dsUJyyq0QrkV79Srue/eSMXMmOYMGgTQYdChWHZ768MMPcXNzY+HChej1RXUmIiKC+Ph4\nm4YTQlQPulOn8Fm+HABT8+Zc3rOHnH/8QwqGA7KqaBw+fJh//OMfpVosBwQEkJ6ebrNgQohqwGTC\nd+lSQh98EL9Fi0oaDPr6qhxMlMeqouHl5UV2dnap51JSUggMDLRJKCGE69MfPYrh8cfxf+st8rt1\n48rWrdJg0AlYNacRFRXFu+++y1NPPYWiKCQmJvLpp5+Wuq+FEEJYS5OXR/Df/gZ6PWkffED+Y4+p\nHUlYyaqi0bt3b9zc3Fi+fDlGo5FFixYRHR3NY/IfWghxC/S//oqpSRMULy+uvv8+xqZNUWrUUDuW\nuAVWFY2srCx69OhBjx49Sj2fmZmpevtyOXtKCMenycnBb84cfFatIn3BAvL69aOwY0e1Y4lKsGpO\nY2Q5N2EfNWpUlYYRQrgej23bCOneHd+VK8kZNIj8Rx5RO5K4DVbtaZR1y438/Hy0WrmgXAhRPr/Y\nWPwWL8ZYvz4pX35J4f33qx1J3KYKi8bw4cPRaDQUFhYyYsSIUq9lZWXRtm1bm4YTQjipvxoM3n8/\nWSNGkPXqq+DpqXYqUQUqLBovvfQSiqLwzjvvMHTo0OLnNRoNAQEB1KlTx+YBhRDOQ3vlCgGvv46p\nYUOyxo+XBoMuqMKi0aJFCwA++OADvL297RJICOGEFAWv9esJmDkTTV4emW3aqJ1I2IhVcxre3t6c\nO3eOY8eOkZmZWeq1J5980ibBhBDOQXf+PAETJuD5008U3H8/6XPnYm7QQO1YwkasKho//PADq1at\nonnz5hw+fJgWLVpw5MgR2jjEt4kbJ+mFEPajycjA/dAh0mfPJvfZZ0FOkHFpVhWNr776ikmTJtGs\nWTOef/55XnvtNfbt28fPP/9s63xCCAekS0zE87vvyHn5ZUzNmnF5924UHx+1Ywk7sOorQUZGBs2a\nNQOKJsEtFgutW7dmz549Ng0nhHAwRiO+ixcTGhOD35IlaFNSAKRgVCNWFY2goCCS/+w+eccdd7B/\n/35OnjxZ3CZdCOH69EeOFDUYjI0lPzqaKz/+iOWazteierBqq9+jRw/++OMPQkJC6NOnD++++y5m\ns5lnn33W1vmEEA5Ak5dH8IAB4OZG2ocfkv/oo2pHEirRKGVd7n0ThYWFmEwmhzgN99SpJOT2wWAw\nGEj581BBdSdjUeJ2x0J/5AimZs1Ao8E9IaGowaCT3hJB/i5K1KpVq9K/W6nTHNzd3TGbzXzyySeV\nXnFVkYaFQlQ9TXY2Aa+/TuhDD+G1YQMAhR06OG3BEFXnpoenfvzxR37//XfuuOMOoqOjKSgoYOPG\njXz33Xc0atTIHhmFEHbksXUrARMnoktKIvsf/5BDUaKUCovGxx9/zLZt22jYsCHx8fGcPHmSEydO\nUK9ePWbOnEndunXtFFMIYQ9+b7+N35IlGCMiSPnqK4yRkWpHEg6mwqIRHx/PjBkzuOOOOzh//jxj\nx45l1KhRdOjQwV75hBD2YDaDTkdh+/Zk6XRkjRoFHh5qpxIOqMI5jdzcXO644w4AwsPDcXd3l4Ih\nhAvRXr5MjSFD8Js/H4CCrl3JmjBBCoYoV4V7GoqilDrbQKfT3XD2gUHO0xbC+fzVYHDGDDQFBWTe\nd5/aiYSTqLBoFBQUMHz48FLPXf/4888/r/pUQgib0f3xB4Hjx+OxfTsFbdsWNRisX1/tWMJJVFg0\nPv30U3vlqDQ55VaIW6PJzMTt8GHS33qL3GeekQaD4pZUWDSq8nauBw8eZPXq1VgsFrp3706vXr1u\nWObo0aOsWbMGs9mMn58fM2bMqLL1C1Gd6U+cwHPLFrJHjChqMLhnD4oDXJwrnI9dmkdZLBZWrlzJ\nlClTCA4OZtKkSURGRhIeHl68TE5ODitWrOD111/HYDCQkZFhj2hCuLbCQnzfew+/hQux+PiQO2AA\nFoNBCoaoNLvslyYmJhIWFkbNmjXR6/V06NDhhg65O3bsoG3btsUT6wEBAfaIJoTLcjt0CH2HDvjP\nnUveI4+QLA0GRRWwy55GWloawcHBxY+Dg4M5efJkqWUuXryIyWRi+vTp5OXl8eijj/LAAw/c8F5x\ncXHExcUBEBsbi8FgkLMDAb1eL2ey/UnGAsjJwe3pp8HTE+OGDeh79CBI7Uwqk7+LqmF10TCbzZw6\ndYq0tDTatWtHYWEhUNSHqiqYzWbOnDnD1KlTKSwsZMqUKURERNzQWCs6Opro6OjixykpKVI0kGZs\n16rOY+F2+DDGZs1Aq8X9ww/x79SJFJMJqul4XKs6/11cz+YNC//44w9Gjx7N4sWLWbp0KQCHDx9m\n2bJlVq0kKCiI1NTU4sepqakEBZX+3hMcHEyrVq3w9PTE39+fJk2acPbs2Zu+t5w9JQRosrIImDSJ\nkIcfxmvjRgAK27UDaTAoqphVRWPFihX07duXxYsXF994qVmzZhw7dsyqldSvX5+LFy9y5coVTCYT\nCQkJRF7X0yYyMpJjx45hNpspKCggMTGR2rVr3+LHEaL68fj+e0KjovD++GOyX3yR/MceUzuScGFW\nHZ46d+7cDfMLnp6eFBQUWLUSnU7H4MGDmT17NhaLhaioKOrUqcOWLVsAiImJITw8nHvuuYdx48ah\n1Wrp1q0bd9555y1+HCGqF7/Zs/Fbtgxjw4akffABxtat1Y4kXJxVRcNgMHDmzBnq1atX/NypU6cI\nCwuzekWtW7em9XV/0DExMaUeP/HEEzzxxBNWv6cQ1ZKigMVS1GCwUyeyPDzIGjlS+kUJu7CqaPzt\nb38jNjaWmJgYTCYTmzZtYvPmzQwZMsTW+YQQ19BevEjA5MmYGjcma+JECh54gIIyzjIUwlasKhqR\nkZEEBgby/fff07hxY5KSkhg9ejQRERG2zieEAFAUvD/5BP9Zs9AYjWRKt2mhEquKRnZ2Ng0aNKBB\ngwa2ziOEuI7u3DkCx47FIyGBgvbtixoM3n232rFENWVV0XjppZdo0aIFnTt3JjIyssquzagKcsqt\ncHWanBz0v/1G+pw55P7979JgUKhKoyiKcrOF0tPTSUhIID4+nvPnzxMZGUmnTp1o1apVlTY1rIyz\nZ5Nwc1M1gkOQC5dKuMJY6I8dK2ow+MorAGjy8lC8vG75fVxhLKqKjEWJ27m4z6qica3Lly+zY8cO\n4uPjycrK4sMPP6z0yquCFI0i8j9ECacei8JCfJcswW/RIix+fiRv3Xpb/aKceiyqmIxFCZtfEX6t\n3NxccnNzycvLw0NO8ROiyrgdPEjII4/gP38+eY8/Lg0GhUOyak4jKSmJ+Ph4duzYQW5uLu3bt2f0\n6NE0atTI1vmEqBY0ubkEDxyI4ulJ6urVFFx3DZMQjsKqojFp0iTuv/9+nn/+eVq2bKn6PIYQrsLt\n0CGMLVqgeHuTtno1xsaNUfz91Y4lRLmsKhoffvihQ50xdS05e0o4I01mJv5vvonPunVcfe898vr1\no/D++9WOJcRNlVs0duzYQadOnQDYuXNnuW9Q1j0vhBDl89iyhcBJk9BeuUL2Sy+R//jjakcSwmrl\nFo2ffvqpuGh8//33ZS6j0WikaAhxC/xnzcJ3+XKMTZqQtnIlxnvuUTuSELfklk+5dTTnziWht8v9\nBx2bnE5YwuHGQlHAbAa9Ho9t23Dbt4/s4cPBDod8HW4sVCRjUcLmp9xOmjSpzOdff/31Sq9YiOpA\nm5RE0KBB+M2bB0BBly5kv/qqXQqGELZgVdG4cOFCmc8nJSVVaRghXIbFgvdHHxEaFYV7fDyW0FC1\nEwlRJSo8sPPX7VxNJtMNt3ZNTk4mPDzcdsmEcFK6s2eLGgzu3ElBp06kv/MO5rvuUjuWEFWiwqJx\n7X28r/13jUZDvXr16OAA7ZnllFvhaDS5uehPnCB93jxyBwyQP1LhUiosGgMGDACgYcOGN9x1TwhR\nQv/bb3hu3kz26NGYmjTh8s8/QyUaDArh6MotGseOHaNx48ZA0f3Af/311zKXa9q0qW2SCeEMCgrw\nW7QI3yVLsAQEkPv000X9oqRgCBdVbtFYvnw57733HgCLFy8u9w3++c9/Vn0qIZyA2759BI4bh9uJ\nE+T27UvG9Oko1xzGFcIVOf11Gn/8kYROp3YK9ck56CXsMRaa3Fxq3ncfFm9vMubMoaBbN5uur7Lk\n76KEjEWJ27lOo1KXxf32229otVrpciuqHbf9+zHecw+Ktzepa9ZgatIExddX7VhC2I1V12lMnz6d\nY8eOAbBp0ybmzZvH/Pnz+eqrr2wazhpyYoqwB01GBgHjxhHSowdeGzcCYLzvPikYotqxqmicO3eO\niIgIAOLi4pg+fTpvvfUWW7ZssWk4IRyB57ffEhoVhff69WQNH06eNBgU1ZhVh6cURUGj0XD58mXM\nZjN16tQBIDs726bhhFCb//Tp+H74IcamTUlbswZjy5ZqRxJCVVYVjYYNG7JmzRquXr3K/X/2/L98\n+TJ+fn42DSeEKq5pMJjfrRuWGjXIHjYMuRm9EFYenho+fDju7u7UqlWL/v37A3D+/Hkefvhhm4YT\nwt50Fy4Q9OyzxQ0GC7t0IXvUKCkYQvzJqj0Nf39/nn766VLPtWnThjZt2tgklBB2Z7HgvXYt/m+9\nBRYL+d27q51ICIdkVdEwm818+eWXbN++nbS0NIKCgujcuTO9evVCLzezEE5Od+ZMUYPBn38mv0sX\nMt55B/Of83ZCiNKs2uKvW7eO48eP89xzzxESEkJycjJffPEFubm5PPvss7bOWCE55VbcLk1BAfrT\np7n67rvk9e8vf1RCVMCqorFz507mzJmDv78/AHXq1KFBgwaMHz9e9aIhRGXojxzBc8sWsseMwdS4\nMZd37QJPT7VjCeHwrJoIt1gsaLWlF9VoNDh5BxJRHeXn4xcbS8ijj+Kzdi3av9pKSMEQwipW7Wm0\nbduWOXPm0L9/fwwGA8nJyWzcuJF27drZOp8QVcZtz56iBoOJieT260fGtGkoNWqoHUsIp2JV0Xjm\nmWf4v//7P5YvX148Ed6xY0eefPJJW+cTokpocnMJHjQIi48PqevWUdC1q9qRhHBKTt/l9sKFJJm3\nRDp4XuvasXDbuxdj69ag1eK2dy+mxo2rVb8o+bsoIWNR4na63FY4p3Hx4kWmTZvG888/z6xZs25r\nwA8ePMiJze5PAAAayUlEQVSoUaMYOXJkhY0OExMTGTBgALt27bLqfaVgiLJo0tMJHDOGkJ498dqw\nAQBjZGS1KhhC2EKFRWPVqlXUqFGD4cOH4+fnx5o1ayq1EovFwsqVK5k8eTILFiwgPj6e8+fPl7nc\nunXraNWqVaXWIwSA5quvCI2KwmvDBrJGjCDviSfUjiSEy6hwTuP06dP885//xN3dnWbNmjF69OhK\nrSQxMZGwsDBq1qwJQIcOHdizZw/h4eGllvvf//5H27ZtOXXqVKXWI4T/tGm4rViBsVkzUj/6CFPz\n5mpHEsKlVFg0TCYT7u7uAHh5eVFYWFiplaSlpREcHFz8ODg4mJMnT96wzO7du5k2bVqFt5CNi4sj\nLi4OgNjYWAwGQ6UyuRq9Xl99x+KaBoOavn2x3H03yqhRBEq/qOr9d3EdGYuqUWHRMBqNbPjzeDBA\nYWFhqcdAlZ1BtWbNGgYOHHjD9SDXi46OJjo6uvixTGwVqa6TfLo//iBg4kSMLVqQNWkStGyJoVu3\najkWZamufxdlkbEoYbPbvbZv356LFy8WP27Xrl2pxxorZ6GDgoJITU0tfpyamkpQUFCpZU6dOsXC\nhQsByMzM5MCBA2i12uJW7EKUYrHgs2YNfm+/DRoN+dJxWQi7qLBojBw5skpWUr9+fS5evMiVK1cI\nCgoiISGBV155pdQyS5cuLfXvbdq0kYIhyqQ7fZrAMWPw2LOH/KgoMmJjMV83PyaEsA27tKjV6XQM\nHjyY2bNnY7FYiIqKok6dOsW3i42JibFHDOEiNEYj+rNnubpwIXl9+8p510LYkdNf3JeUlKR2BIfg\n6sdr9UeO4LV5M1ljxxY9UVAAHh5lLuvqY3ErZCxKyFiUsNnFfUKoLj8fv7ffJuTRR/H++GO0f82N\nlVMwhBC2JUVDOCz33bsJffBB/JYsIe/JJ7mydSuWa07dFkLYn9VzGkeOHCEhIYH09HQmTJjA6dOn\nyc/Pp2nTprbMJ6opTU4OQc8/j8XPj9RPP6WgSxe1IwkhsHJPY/PmzSxfvpzg4GCOHj0KFF0o8+mn\nn9o0nKh+3HfvBosFxceH1LVrSf7+eykYQjgQq4rGN998w9SpU+nbt2/xxXfh4eFcuHDBpuFE9aFJ\nSyPwlVcw9O5d0mCwTRsUHx+VkwkhrmXV4am8vDxCQkJKPWc2m9Hr7XLGrnBlioLnN98QMGUK2vR0\nskaPJq9nT7VTCSHKYdWeRuPGjdm0aVOp5zZv3izzGeK2+U+bRtBLL2GuVYvk//6XrPHj5cwoIRyY\nVbsKgwcPJjY2lu+//578/HzGjBmDXq9n0qRJts4nXJGigMkEbm7kx8RgCQsj+8UXQfZchXB4Vl/c\npygKx48fJyUlBYPBQMOGDW/aXNAe5OK+Is5y4ZLu3DkCJ0ygsGVLsiZPtsk6nGUs7EHGooSMRQmb\nNSy8lkajoXHjxpVekajmzGZ8Vq/GLzYWdDryHn9c7URCiEqwqmgMHz683I62S5YsqdJAwvXoTp2i\nxquv4r5vH/ndupEeG4uldm21YwkhKsGqovHSSy+Venz16lW+/fZbOnbsaJNQwrVozGZ0Fy5wdfFi\n8nr3lgaDQjgxq4pGixYtynzu7bff5rHHHqvyUML5uR06hOfmzWRNmICpYUMuJyTIWVFCuIBKz2S7\nu7tz+fLlqswiXEFeHv5vvonh8cfx/vxzaTAohIuxak/j+lu8FhQUsH//flq1amWTUMI5ue/cSeC4\nceh//52cgQPJfP11lIAAtWMJIaqQVUXj2lu8Anh4ePDQQw/RtWtXW2QSTkiTk0PQkCFYAgJI+fxz\nCjt1UjuSEMIGblo0LBYLLVu2pH379ri7u9sjk3Ai7j//TOF99xU1GPz4Y0yNGqF4e6sdSwhhIzed\n09BqtaxatUoKhihFm5ZG4MiRGPr0KWkweO+9UjCEcHFWTYS3bt2a/fv32zqLcAaKgufXXxPStSte\nmzaRNWaMNBgUohqxak5DURTmz59P48aNCb7uzmnDhg2zSTDhmPzfeAPfVasovOceUj//HFOTJmpH\nEkLYkVVFIywsjB49etg6i3BUigJGI7i7k//ww5hr1ybnhRdAp1M7mRDCziosGjt27KBTp04MGDDA\nXnmEg9H9/juB48djbNWKzClTKOzYkULpBCBEtVXhnMaHH35orxzC0ZjN+Lz/PiHdu+N2+DCm+vXV\nTiSEcAAV7mlY2TVduBh9YiKBo0fjfuAA+Q8+SPrbb2O54w61YwkhHECFRcNisXDkyJEK36B58+ZV\nGkg4AIsF3aVLpC1bRv4TT0iDQSFEsQqLhtFoZPny5eXucWg0GmmN7iLcDhwoajD42mslDQbl2hwh\nxHUqLBqenp5SFFycJi8Pv7lz8fnwQyyhoeS88AKW4GApGEKIMql/v1ahGvf4eEK6d8f3/ffJ/fvf\nubJ1a1HBEEKIcshEeDWlycmhxtChKAEBpPzf/1HYoYPakYQQTqDCorF27Vp75RB24p6QQGG7dig+\nPqT91WDQy0vtWEIIJyGHp6oJbWoqgcOGYejXD6+NGwEw3nOPFAwhxC2xqo2IcGKKgtdXX+E/dSra\nnBwyx4+XBoNCiEqTouHiAqZMwWfNGgpbtyZ1/nxMDRuqHUkI4cSkaLgiiwVMJnB3J++xxzDVrUvO\n4MHSYFAIcdvsVjQOHjzI6tWrsVgsdO/enV69epV6ffv27Xz99dcoioKXlxdDhgyhbt269ornMnSn\nTxM4YUJRg8GpUyns0EHOjBJCVBm7TIRbLBZWrlzJ5MmTWbBgAfHx8Zw/f77UMqGhoUyfPp358+fT\nt29fPvjgA3tEcx0mEz7LlxP64IO4HT2KMSJC7URCCBdklz2NxMREwsLCqFmzJgAdOnRgz549hIeH\nFy/TqFGj4n+PiIggNTXVHtFcgv7kSfRjxxKwbx95Dz1ExltvYQkLUzuWEMIF2aVopKWllbrjX3Bw\nMCdPnix3+R9++IF77723zNfi4uKIi4sDIDY2FoPBULVhnVFyMporVzCtW4eub1+CqnmDQb1eL38X\nf5KxKCFjUTUcbiL8yJEjbN26lZkzZ5b5enR0NNHR0cWPU1JS7BXNobjt24fnli1kTZoEISEYfvuN\nlIwMkD00DAZDtf27uJ6MRQkZixK1atWq9O/aZU4jKCio1OGm1NRUgoKCblju7NmzvP/++4wfPx4/\nPz97RHM6mtxc/KdNw9CzJ15ffIH2r3F1c1M3mBCiWrBL0ahfvz4XL17kypUrmEwmEhISiIyMLLVM\nSkoK8+bNY8SIEbdVBV2Z+7ZthHTrhu+KFeQ+9xzJ0mBQCGFndjk8pdPpGDx4MLNnz8ZisRAVFUWd\nOnXYsmULADExMWzYsIHs7GxWrFhR/DuxsbH2iOcUNDk51Bg2DCUwkJQvvqCwbVu1IwkhqiGN4uSt\nbJOSktSOYFPuO3ZQ2L496HS4/fJL0am0ZfSLkuO1JWQsSshYlJCxKOHwcxri1mmTk6kxdCiGv/2t\npMFgy5ZlFgwhhLAXhzt7qtpTFLw2biRg2jQ0ublkTpxIXu/eaqcSQghAiobDCZg8GZ+1ayls04b0\n+fMxyZXdQggHIkXDEVgsYDSChwd5TzyBKSKCnOeekwaDQgiHI3MaKtMlJhLcty/+c+YAUNi+vXSk\nFUI4LCkaajEa8V2yhNCYGNyOH8fYuLHaiYQQ4qbk8JQK9MePE/jKK7gfOULeo4+SMXs2ltBQtWMJ\nIcRNSdFQg06HNj2dtA8+IP+xx9ROI4QQVpOiYSdue/YUNRh8/XVMDRpwJT4e9DL8QgjnInMaNqbJ\nycF/6lQMvXvjtWkT2rS0ohekYAghnJAUDRvy+OknQrp1w2f1anKef57kH37AUkZ3XyGEcBbydddG\nNDk5BI4YgaVGDVK//JLC++5TO5IQQtw2KRpVzGPbNgo6dkTx8SH1008xNWgAnp5qxxJCiCohh6eq\niPbyZWq88ALBTz2F1xdfAGBq3lwKhhDCpciexu1SFLzWrydgxgw0+flkTp4sDQaFEC5LisZtCnjt\nNXw+/piC++8nfe5czA0aqB1JCCFsRopGZVzbYLB3b4xNmpD77LOglaN9QgjXJlu5W6Q/eRJD7974\n/3kr2sJ27cgdNEgKhhCiWpAtnbWMRnwXLSIkJgZ9YiLG5s3VTiSEEHYnh6esoD9+nBojR+J29Ch5\njz9OxptvYgkJUTuWEELYnRQNKyg6HZqsLNJWrCD/kUfUjiOEEKqRw1PlcP/5Z/xnzgTA3KABV7Zv\nl4IhhKj2pGhcR5OdTcDkyRj69MHzf/+TBoNCCHENKRrX8PjhB0KiovBeu5bsIUNI/v57aTAohBDX\nkK/Pf9JkZxM4ahQWg4GUr7/G2KaN2pGEEMLhVO+ioSh4/PgjBV26oPj6kvrZZ0UNBj081E4mhBAO\nqdoentJevkyNIUMIfvrpkgaDzZpJwRBCiApUvz0NRcHr88+LGgwWFpIxZYo0GBRCCCtVu6IRMHEi\nPuvWUdCuXVGDwXr11I4khBBOo3oUDbO5qMGgpyd5fftibN6c3Kefln5RQghxi1x+q6k/fhxDz54l\nDQbbtpWOtEIIUUmuu+UsLMR3wQJCHnoI3e+/Y7znHrUTCSGE03PJw1P6334rajD422/k9uxJ5qxZ\nWIKD1Y4lhBBOzyWLhuLmhiYvj9TVqymIiVE7jhBCuAyXOTzlvnMn/jNmAH82GNy2TQqGEEJUMbvt\naRw8eJDVq1djsVjo3r07vXr1KvW6oiisXr2aAwcO4OHhwbBhw6hnxemwmqws/GfPxuejjzDddRfZ\nI0cW9YvS6Wz1UYQQotqyy56GxWJh5cqVTJ48mQULFhAfH8/58+dLLXPgwAEuXbrEokWLePHFF1mx\nYoVV7x0aFYX3unVkv/iiNBgUQggbs8ueRmJiImFhYdSsWROADh06sGfPHsLDw4uX2bt3L126dEGj\n0dCwYUNycnK4evUqNWrUqPC9Lf7+pH3wAcbWrW36GYQQQtipaKSlpRF8zdlLwcHBnDx58oZlDAZD\nqWXS0tJuKBpxcXHExcUBEBsbi9uxY8iNV4vUqlVL7QgOQ8aihIxFCRmL2+d0E+HR0dHExsYSGxvL\na6+9pnYchyFjUULGooSMRQkZixK3MxZ2KRpBQUGkpqYWP05NTSXourmHoKAgUlJSKlxGCCGEuuxS\nNOrXr8/Fixe5cuUKJpOJhIQEIiMjSy0TGRnJtm3bUBSFEydO4O3tfdP5DCGEEPalmz59+nRbr0Sr\n1RIWFsbixYv59ttv6dy5M+3atWPLli2cOnWK+vXrExYWxokTJ1izZg0HDx5k6NChVu1pWHNabnUh\nY1FCxqKEjEUJGYsSlR0LjaIoShVnEUII4aKcbiJcCCGEeqRoCCGEsJpTNCy0VQsSZ3Szsdi+fTtf\nf/01iqLg5eXFkCFDqFu3rjphbexmY/GXxMREpkyZwujRo2nXrp2dU9qHNWNx9OhR1qxZg9lsxs/P\njxl/9mpzNTcbi9zcXBYtWkRqaipms5kePXoQFRWlUlrbWbZsGfv37ycgIID58+ff8Hqlt5uKgzOb\nzcqIESOUS5cuKUajURk3bpzyxx9/lFpm3759yuzZsxWLxaIcP35cmTRpkkppbcuasTh27JiSlZWl\nKIqi7N+/v1qPxV/LTZ8+XXnrrbeUnTt3qpDU9qwZi+zsbGX06NFKcnKyoiiKkp6erkZUm7NmLDZu\n3Kh89NFHiqIoSkZGhjJo0CDFaDSqEdemjh49qpw6dUoZM2ZMma9Xdrvp8Ienrm1Botfri1uQXKu8\nFiSuxpqxaNSoEb6+vgBERESUuj7GlVgzFgD/+9//aNu2Lf7+/iqktA9rxmLHjh20bdu2uOtCQECA\nGlFtzpqx0Gg05OfnoygK+fn5+Pr6onXBO3k2bdq0eFtQlspuNx1+pMpqQZKWlnbDMmW1IHE11ozF\ntX744Qfuvfdee0SzO2v/Lnbv3k2Mi7fIt2YsLl68SHZ2NtOnT2fixIn89NNP9o5pF9aMxcMPP8yF\nCxcYOnQoY8eO5fnnn3fJonEzld1uOsWchrh1R44cYevWrcycOVPtKKpZs2YNAwcOrJYbhOuZzWbO\nnDnD1KlTKSwsZMqUKURERFTLXkyHDh3irrvu4o033uDy5cvMmjWLxo0b4+3trXY0p+DwRUNakJSw\nZiwAzp49y/vvv8+kSZPw8/OzZ0S7sWYsTp06xcKFCwHIzMzkwIEDaLVa7r//frtmtTVrxiI4OBg/\nPz88PT3x9PSkSZMmnD171uWKhjVjsXXrVnr16oVGoyEsLIzQ0FCSkpJo0KCBveOqqrLbTYf/CiYt\nSEpYMxYpKSnMmzePESNGuNwG4VrWjMXSpUuL/2nXrh1DhgxxuYIB1v8/cuzYMcxmMwUFBSQmJlK7\ndm2VEtuONWNhMBg4fPgwAOnp6SQlJREaGqpGXFVVdrvpFFeE79+/n3/9619YLBaioqLo06cPW7Zs\nASAmJgZFUVi5ciWHDh3C3d2dYcOGUb9+fZVT28bNxmL58uX8/PPPxccqdTodsbGxaka2mZuNxbWW\nLl1KmzZtXPaUW2vGYtOmTWzduhWtVku3bt147LHH1IxsMzcbi7S0NJYtW1Y86duzZ0+6dOmiZmSb\neO+99/j111/JysoiICCA/v37YzKZgNvbbjpF0RBCCOEYHP7wlBBCCMchRUMIIYTVpGgIIYSwmhQN\nIYQQVpOiIYQQwmpSNITTWbRoEevXr1c7xk2NGjWK3377rdzX33zzTbZv327HRELcPjnlVqhm+PDh\npKenl2rzsXDhwptelbpo0SLCwsLo379/lWVZtGgRO3fuRK/Xo9frqV+/PoMHD66yCyQ/++wzUlNT\nGT58eJW8X3nMZjNPPfUUHh4eAPj4+NCxY0er26n88ssvvP/++yxdutSmOYXzcvg2IsK1TZw4kZYt\nW6odA4DevXvTv39/8vPzWb58Of/85z+ZNWuW2rEqZf78+cXtMaZNm0Z4eLhL3jNC2J8UDeFwLBYL\nCxYs4NixYxiNRurWrcuQIUMIDw+/YdmMjAyWLVvG8ePH0Wg03HnnncU3F0pNTWXVqlUcO3YMT09P\nevTowcMPP3zT9Xt6etKxY8fib9uFhYV8/PHH7Nq1C41GQ4cOHRg4cCB6vb7C9b/00kuMHDmS/Px8\nvv76awB27dpFrVq1mDNnDlOnTqV79+506NCBF154gbfeequ4tUd6ejrDhw9n+fLl+Pn5sXfvXj7/\n/HOSk5OpU6cOL7zwAnfeeedNP0utWrVo1KgRv//+e/Fz33//Pd988w2pqakEBATQq1cvunfvTm5u\nLnPmzMFkMvHMM88AsGTJEvz8/Pjqq6/YunUrubm5tGjRgiFDhlTYdlu4LikawiG1adOGYcOGodPp\n+Oijj1iyZEmZ7VA2bdpEaGgo48ePB+DEiRNAUeGJjY2lffv2vPrqq6SkpDBr1ixq165NixYtKlx3\nXl4eO3bs4O677wZgw4YNnD59mnnz5qEoCnPmzOHLL7+kX79+5a7/+s/Ss2fPcg9Pubu7c9999xEf\nH198yC0hIYEWLVrg5+dHYmIi77//PhMnTqRevXr8+OOPzJ07lwULFqDXV/y/8Pnz5zl+/Dh9+vQp\nfi4gIIDXXnuN0NBQjh49yttvv02DBg246667mDhx4g2Hp/79739z4MABZsyYga+vL6tWrWL16tWM\nHDmywnUL1yQT4UJVc+fOZdCgQQwaNIh33nkHAK1WS9euXfHy8sLd3Z1+/fpx+vRp8vPzb/h9nU7H\n1atXSUlJQa/X07RpU6Bo452Xl0efPn3Q6/WEhYURFRVFfHx8uVm+/vprBg0axKhRozAajbz88stA\n0Q2M+vXrh7+/PwEBATz55JNs27atwvXfqk6dOpXKtmPHDjp16gRAXFwcMTExNGjQoLhvFBTdcKg8\n48eP55lnnmHMmDG0aNGCBx98sPi1yMhIatasiUajoXnz5rRo0aLCCfvvvvuOp556iqCgINzd3Xny\nySfZtWsXFoulUp9VODfZ0xCqGj9+/A1zGhaLhU8++YRdu3aRlZWFRqMBICsrC09Pz1LL9urVi/Xr\n1zNr1iy0Wi0PPvggTzzxBCkpKaSkpDBo0KBS71vRRr1nz55lTq5fvXqVkJCQ4scGg6H4ZjXlrf9W\ntWjRgpycHE6fPo23tzfnz58v7s6akpLCjh07+M9//lO8vMlkqvCGOXPnzsVgMJCQkMDnn39efIc6\ngH379rFx40YuXryIoigUFBRU2KguJSWFOXPmFP93+EtmZiaBgYG3/FmFc5OiIRzOTz/9xIEDB3jj\njTcICQkhKyuLIUOGUNaJft7e3sV7KufOnWPGjBk0aNCA4OBg7rjjDhYsWHDbeWrUqEFycnLxmVQp\nKSnFZ3iVt/5b3ePQ6XS0a9eOHTt24O3tTWRkZHGBDA4O5sknn6RXr1639J5arZZOnTqxZ88evvji\nC5599lkKCwt59913GTVqFK1bt0av1xMbG1s8ttcXhr/W/8orrxAREXFL6xeuSQ5PCYeTl5eHXq/H\nz8+PgoICPvvss3KX3bt3L5cuXUJRFLy9vdFqtcX3PNbr9fz73/+msLAQi8XCuXPnOH369C3n6dix\nIxs2bCAzM5PMzEw2btxI586dK1z/9QIDA0lOTi6z8P2lU6dO7Ny5k/j4+OJDUwDdu3dn8+bNJCYm\nFt/Xeu/evWUeritLr169+O6778jMzMRoNGIymfD390er1bJv377ie0tA0XxHZmYmeXl5xc89+OCD\nfPrpp8U37MnIyGDv3r1WrVu4HtnTEA4nKiqKX375haFDh+Ln50e/fv2Ii4src9mkpCRWrVpFVlYW\nvr6+PPLIIzRp0gSASZMm8a9//YtNmzZhMpmoXbs2AwYMuOU8/fr1Y+3atYwdO7b47KnevXvfdP3X\n6tChAzt27GDw4MGEhYXx9ttv37BMo0aN0Gq1ZGZmljpk17BhQ1544QVWrFjBpUuX8PDwoHHjxjRv\n3tyq/HfffTcNGzZk06ZNPP300zz33HPMmzcPk8nEfffdR5s2bYqXvfPOO2nbti3Dhw/HYrGwcOFC\nHn/8cQBmzpxJeno6AQEBdOzY8YabG4nqQS7uE0IIYTU5PCWEEMJqUjSEEEJYTYqGEEIIq0nREEII\nYTUpGkIIIawmRUMIIYTVpGgIIYSwmhQNIYQQVvt//X/SPLv4mhQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3a4839630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3a4779d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTIqGEEIIh/1/ciDB2zdFNKoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38ed8b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTYqGEEIIq0nREEIIYbX/B91Wc8T6IM5qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38e8ed470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM0kaQgghbCZJQwghhM3+H6+GhPpZa1RJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38eac3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in train_results['models']:\n",
    "    TPR_array = []\n",
    "    FPR_array = []\n",
    "    for i in range(-50,50,5):\n",
    "        predicted = model.predict(x_test)\n",
    "        predicted = np.asarray([np.round(j[0]+i/100) for j in predicted])\n",
    "        actual = np.asarray([j[0] for j in y_test])\n",
    "\n",
    "        TP = np.count_nonzero(np.multiply(predicted, actual))\n",
    "        TN = np.count_nonzero(np.multiply(predicted - 1, actual - 1))\n",
    "        FP = np.count_nonzero(np.multiply(predicted, actual - 1))\n",
    "        FN = np.count_nonzero(np.multiply(predicted - 1, actual))\n",
    "\n",
    "        TPR_array.append(TP / (TP+FN))\n",
    "        FPR_array.append(FP / (FP+TN))\n",
    "\n",
    "    plot_ROC(TPR_array, FPR_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>92</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>9</td>\n",
       "      <td>56082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        92       779\n",
       "predicted 0         9     56082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       961\n",
       "predicted 0        10     55900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>92</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>9</td>\n",
       "      <td>55933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        92       928\n",
       "predicted 0         9     55933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>92</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>9</td>\n",
       "      <td>55957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        92       904\n",
       "predicted 0         9     55957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>56063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       798\n",
       "predicted 0        10     56063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrixes for each valdation\n",
    "for matrix in confusion_matrixes:\n",
    "    display(matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
