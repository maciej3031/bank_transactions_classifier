{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from keras import regularizers, optimizers, layers, models\n",
    "from IPython.display import display\n",
    "import os\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA PARAMETERS\n",
    "DATASET_NAME = os.path.join(\"..\", \"data\", \"creditcard.csv\")\n",
    "NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET = 400\n",
    "N_SPLITS = 5\n",
    "\n",
    "# NN PARAMETERS\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "NUMBER_OF_NEURONS = 1024\n",
    "REGULARIZATION_LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "dataset = pd.read_csv(DATASET_NAME)\n",
    "dataset = dataset.drop(['Time','Amount'],axis=1)\n",
    "\n",
    "NUMBER_OF_FEATURES = dataset.shape[1] - 1 # Minus 1 because of column: 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEXCAYAAACdwyIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XtcVXW+//HX2oAKbBQ2Ny+jlSKZtyAwzcfJ684cLadj\nZVOeUsxyspqwpo7lNM2xcihTC5EujDU1GaWG1DQdzwyiYjKesMJUMkSsHiiEsBEhtM1l/f7w1z6R\nmruCtQ3ez8eDx4P1XZf9+e5Fvvuu9d1rG6ZpmoiIiFjE5usCRESkc1HwiIiIpRQ8IiJiKQWPiIhY\nSsEjIiKWUvCIiIilFDwi/99//Md/MHny5B+9f0lJCYZhsGPHjjas6of5/e9/z6BBg753m5ycHAzD\noKKiwqKqRFpT8IhPzJ49G8MwTvl5/fXXfV1ahzdmzBjKy8uJioryavvZs2fjdDrbuSrpTPx9XYB0\nXpdffjlr165t1RYaGnrabRsbGwkICLCirA6vS5cu9OzZ09dlnJHb7aZLly6+LkPakUY84jPf/AP4\n7Z9u3boB/3fZ6+mnn+a8886ja9euNDY2snHjRsaOHYvD4SA0NJRx48axc+dOzzGbmppOO3IaN24c\nc+fO9SxXV1dz/fXXExwcTHR0NI888ohXNVdUVDB79myioqLo1q0bgwYN4uWXXz7j9gsXLmTQoEEE\nBQXRr18/5s+fz7Fjxzzrjx49yqxZs4iOjqZr167069eP+++/37M+Ly+P0aNHExISQvfu3YmLiyMn\nJ+esdWZlZXHhhRdit9sZP348Bw4c8Kz77qU2t9tNcnIyffr0oWvXrvTq1YuZM2cCJy/dvfzyy2za\ntMkzKn311VcBOHToEDNmzCA0NJTAwEDGjx/PRx991KqOf/zjHwwdOpRu3bpxySWXkJeX1+r8fHN5\nMjMzk8mTJxMUFMR//dd/0dzczNy5cxkwYACBgYEMGDCA3//+97jdbs+xv7msmJmZyYABAwgKCuLa\na6+lvr6edevWERsbS/fu3ZkxYwZ1dXVnfc/EOhrxyDlr+/bt2O123n77bQzDwM/Pj6+++oq77rqL\niy++mMbGRp566ikmT57M/v37CQsL8/rYs2fP5tNPP+Wdd94hMjKSxx9/nL///e+MHj36jPt89dVX\njB07lpCQEDIzM+nfvz8HDhzA5XKdcZ/g4GAyMjLo27cvJSUlzJ8/nwULFrB69WoAHnroIT7++GPe\nfvttevbsSVlZGZ988glwcpR39dVXc/vtt/PKK69gmia7d+8mMDDwe/tWVlZGRkYGmZmZ2Gw2kpKS\nmDt3Lps3bz7t9k8//TRZWVm89tprXHDBBVRUVPCvf/0LOBmc+/fvp7y83DM6DQ0NxTRNpk2bhmma\nvPvuu9jtdhYvXozT6WT//v04HA6++OILpk2bxqxZs1i3bh2HDh3innvuOW0NDzzwAE8++STPPvss\nhmHQ0tJCr169eO2114iOjqawsJB58+bRtWtXHn744VZ9zczMJDs7m+rqaq699lquvfZaAgICWL9+\nPUePHuXaa68lJSWFxx9//HvfN7GQKeIDs2bNMv38/Mzg4GDPT2xsrGf9zJkzzbCwMPOrr7763uM0\nNTWZISEh5uuvv26apmk2NjaagJmZmdlqu7Fjx5q33nqraZqm+cknn5iAmZub61l//PhxMzo62rzy\nyivP+FrPPfecGRgYaB4+fPi06/fv328C5r/+9a8zHmPt2rVmYGCg2dLSYpqmaU6ZMsVT13dVVlaa\ngLlt27YzHu+7Fi1aZPr7+5tVVVWetldffdW02Wym2+02TdM0//nPf5qAWV5ebpqmac6fP990Op2e\nmr5r1qxZ5sSJE1u1bdy40QTMffv2edoaGhrMqKgo8/HHHzdN0zQfeOABs3///mZzc7Nnm7/97W+t\nzs8379mSJUvO2rcnn3zSHDRoUKu+BgQEmNXV1Z6222+/3fTz82vV//nz55sjR4486/HFOhrxiM+M\nHDmy1WUqf//Wf45DhgwhKCioVduBAwd45JFH2LFjB5WVlbS0tNDQ0MDnn3/u9esWFRVhGAaXXXaZ\np61bt24kJibS1NR0xv0++OADhg4dSq9evbx+rfXr1/PMM89w4MABjh07RnNzMydOnODIkSNERUVx\n5513cv311/P+++8zYcIEJk+ezJVXXolhGERGRnpu7E+YMIGxY8cyffp0Bg4c+L2v2bdvX8LDwz3L\nvXv3pqWlhSNHjtC7d+9Ttp8zZw5XXnklAwcO5IorruCKK67gqquu+t77LHv37iU6OpoLL7zQ0xYY\nGMiIESPYu3cvcPJ9vvTSS7HZ/u+K/rff82+79NJLT2l77rnnWL16NZ9//jkNDQ00NTW1OtY3fXU4\nHJ7lnj170qdPn1b979mzJ5WVlWfsi1hP93jEZwIDA4mJifH8nH/++a3WBwcHn7LPlClTOHToEOnp\n6ezYsYPCwkLCw8M91/4NwwDA/M5D1xsbG9unE99j+/bt3HDDDYwfP57s7Gw+/PBDVq1aBeCpd8qU\nKXzxxRcsXLiQhoYGbrrpJpxOJ83NzQC89NJLFBQUMHHiRDZv3syQIUM8l+nO5LuB8c170tLSctrt\nExISOHjwIE8++ST+/v7cfffdJCQkUF9f/5P6/+3XPpvvnuvMzEzuueceZs6cyX//93/z0UcfsWjR\nolb3eIBTJpwYhnHatjP1XXxDwSM/G19++SXFxcU89NBDTJo0icGDBxMQEEBVVZVnGz8/P8LDwzl8\n+LCn7fjx4+zbt8+zPHjwYEzT9NzHAPj666/54IMPvvf1ExIS2LNnD+Xl5V7V+95779GzZ08WL17M\npZdeSmxsLGVlZadsFx4ezk033cQLL7zA22+/TW5uLsXFxZ71w4YN47777mPjxo3ccsstvPDCC169\n/g8REhLC9OnTWblyJf/7v//Lnj172LZtG3AyyL4Jwm8MGTKEL7/8kk8//dTTdvz4cQoKChg6dChw\n8n1+//33W/2j7+1nnPLy8khMTCQ5OZmEhAQGDhzIwYMHf2o35Ryh4JGfjYiICBwOBy+88ALFxcXk\n5+czc+bMU262O51Oz4ho9+7dzJ49u9UltEGDBjFlyhTuuOMOtm7dyt69e5kzZw5fffXV977+zJkz\n6d27N1dffTWbNm3i4MGD5OTksG7dutNuf+GFF1JRUcFf/vIXSktLeemll3j++edbbfPggw+SnZ1N\ncXExxcXFvPbaa4SEhNC3b18+/fRTHnzwQbZv387nn39Ofn4+27dvZ/DgwT/yHTy9J554gtdee42i\noiJKS0t58cUX8ff391zSu+CCCygqKqKoqIiqqiq+/vprJk2aREJCAjfeeCP5+fns3r2bm2++maam\nJubNmwfAnXfeSVlZGXfeeSf79u1j06ZNnokBZxsJXXjhhRQWFvK3v/2NkpISli9fzltvvdWm/Rbf\nUfDIz4afnx/r1q1j3759DB8+nFtvvZX77rvvlA9CLl++nEGDBnHFFVcwdepUJk6cSHx8fKttXn75\nZYYMGcIvf/lLxo8fzwUXXMC0adO+9/Xtdjt5eXkMGjSIGTNmcNFFF3H33Xdz4sSJ025/zTXX8MAD\nD/Cf//mfDBs2jDfffJMnn3yy1TZdu3Zl0aJFxMfHM2LECIqKiti4cSN2ux273c6+ffuYMWMGsbGx\nXH/99YwZM4ZnnnnmR7x7ZxYSEsJTTz3FyJEjufjii3nnnXfYsGEDMTExANx2223Ex8czatQoIiMj\nWbduHYZh8NZbbxETE8Mvf/lLLr30Uqqrq/nnP//puefSr18/3nrrLfLy8rj44ou59957efTRRwE8\n0+bPZP78+dx4443MmjWLhIQEPvzwQ/7whz+0ab/FdwzzuxfDRUTaSW5uLhMnTqSoqIiLLrrI1+WI\njyh4RKTdpKenEx8fT69evdi7dy/JyclER0fz3nvv+bo08SFNpxaRdnPw4EH+9Kc/UVlZSa9evZg0\naRJPPPGEr8sSH9OIR0RELKXJBSIiYikFj4iIWErBIyIiltLkgjP49iff5aeJiIho9XQBkXOJ/j7b\nzumeBXg6GvGIiIilFDwiImIpBY+IiFhKwSMiIpZS8IiIiKUUPCIiYikFj4iIWErBIyIiltIHSH/G\nmm/7/i8uO1d86esCvOSX8bavSxDpFDTiERERSyl4RETEUgoeERGxlIJHREQspeARERFLKXhERMRS\nCh4REbGUgkdERCyl4BEREUspeERExFIKHhERsZSCR0RELKXgERERSyl4RETEUgoeERGxlIJHREQs\npeARERFLKXhERMRSCh4REbGUgkdERCyl4BEREUv5W/EiVVVVrFq1iqNHj2IYBk6nkylTprB27Vo2\nbdpE9+7dAbjxxhu55JJLANiwYQO5ubnYbDaSkpKIi4sDoLS0lFWrVuF2u4mPjycpKQnDMGhsbCQt\nLY3S0lJCQkJITk4mKioKgC1btpCVlQXA9OnTGTdunBXdFhGR07AkePz8/Lj55pvp378/x48fZ+HC\nhQwfPhyAqVOnMm3atFbbl5WVkZ+fz/Lly6mpqeHRRx/lmWeewWazkZGRwbx58xg4cCB/+tOfKCws\nJD4+ntzcXIKDg1m5ciXbt29nzZo1LFiwgPr6etavX09KSgoACxcuJDExEbvdbkXXRUTkOyy51BYW\nFkb//v0BCAwMpE+fPrhcrjNuX1BQwOjRowkICCAqKoqePXtSUlJCTU0Nx48fJzY2FsMwGDNmDAUF\nBQDs3LnTM5IZNWoUe/bswTRNCgsLGT58OHa7HbvdzvDhwyksLGz3PouIyOlZMuL5tsrKSg4ePEhM\nTAz79u1j48aN5OXl0b9/f2655Rbsdjsul4uBAwd69nE4HLhcLvz8/AgPD/e0h4eHewLM5XJ51vn5\n+REUFERdXV2r9m8f67tycnLIyckBICUlhYiIiHbpf1v60tcFdDA/h3Mubc/f31/n3mKWBs+JEydY\ntmwZs2fPJigoiEmTJnHdddcB8MYbb/DKK68wf/58K0vycDqdOJ1Oz3JVVZVP6hDf0TnvnCIiInTu\n20jv3r292s6yWW1NTU0sW7aMyy+/nJEjRwIQGhqKzWbDZrMxceJEDhw4AJwclVRXV3v2dblcOByO\nU9qrq6txOByn7NPc3ExDQwMhISFnPJaIiPiGJcFjmibPPfccffr04aqrrvK019TUeH5///336du3\nLwCJiYnk5+fT2NhIZWUl5eXlxMTEEBYWRmBgIMXFxZimSV5eHomJiQAkJCSwZcsWAHbs2MGQIUMw\nDIO4uDh27dpFfX099fX17Nq1yzNDTkRErGfJpbZPP/2UvLw8+vXrx/333w+cnDq9fft2PvvsMwzD\nIDIykttvvx2Avn37ctlll3Hvvfdis9m49dZbsdlOZuTcuXNJT0/H7XYTFxdHfHw8ABMmTCAtLY27\n774bu91OcnIyAHa7nWuvvZYHH3wQgOuuu04z2kREfMgwTdP0dRHnosOHD/u6hLNqvm3a2TcSr/ll\nvO3rEsQHdI+n7Zxz93hERERAwSMiIhZT8IiIiKUUPCIiYikFj4iIWErBIyIillLwiIiIpRQ8IiJi\nKQWPiIhYSsEjIiKWUvCIiIilFDwiImIpBY+IiFhKwSMiIpZS8IiIiKUUPCIiYikFj4iIWErBIyIi\nllLwiIiIpRQ8IiJiKQWPiIhYSsEjIiKWUvCIiIilFDwiImIpBY+IiFhKwSMiIpZS8IiIiKX8rXiR\nqqoqVq1axdGjRzEMA6fTyZQpU6ivr2fFihUcOXKEyMhIFixYgN1uB2DDhg3k5uZis9lISkoiLi4O\ngNLSUlatWoXb7SY+Pp6kpCQMw6CxsZG0tDRKS0sJCQkhOTmZqKgoALZs2UJWVhYA06dPZ9y4cVZ0\nW0RETsOSEY+fnx8333wzK1as4PHHH+d//ud/KCsrIzs7m2HDhpGamsqwYcPIzs4GoKysjPz8fJYv\nX86iRYtYvXo1LS0tAGRkZDBv3jxSU1OpqKigsLAQgNzcXIKDg1m5ciVTp05lzZo1ANTX17N+/XqW\nLFnCkiVLWL9+PfX19VZ0W0RETsOS4AkLC6N///4ABAYG0qdPH1wuFwUFBYwdOxaAsWPHUlBQAEBB\nQQGjR48mICCAqKgoevbsSUlJCTU1NRw/fpzY2FgMw2DMmDGefXbu3OkZyYwaNYo9e/ZgmiaFhYUM\nHz4cu92O3W5n+PDhnrASERHrWX6Pp7KykoMHDxITE0NtbS1hYWEAhIaGUltbC4DL5SI8PNyzj8Ph\nwOVyndIeHh6Oy+U6ZR8/Pz+CgoKoq6s747FERMQ3LLnH840TJ06wbNkyZs+eTVBQUKt1hmFgGIaV\n5bSSk5NDTk4OACkpKURERPisFm996esCOpifwzmXtufv769zbzHLgqepqYlly5Zx+eWXM3LkSAB6\n9OhBTU0NYWFh1NTU0L17d+DkqKS6utqzr8vlwuFwnNJeXV2Nw+FotU94eDjNzc00NDQQEhKCw+Gg\nqKio1bEGDx58Sn1OpxOn0+lZrqqqats3QM55OuedU0REhM59G+ndu7dX21lyqc00TZ577jn69OnD\nVVdd5WlPTExk69atAGzdupURI0Z42vPz82lsbKSyspLy8nJiYmIICwsjMDCQ4uJiTNMkLy+PxMRE\nABISEtiyZQsAO3bsYMiQIRiGQVxcHLt27aK+vp76+np27drlmSEnIiLWM0zTNNv7Rfbt28cf/vAH\n+vXr57mcduONNzJw4EBWrFhBVVXVKdOps7Ky2Lx5MzabjdmzZxMfHw/AgQMHSE9Px+12ExcXx5w5\nczAMA7fbTVpaGgcPHsRut5OcnEx0dDRwcsbbhg0bgJPTqcePH3/Wmg8fPtweb0Wbar5tmq9L6FD8\nMt72dQniAxrxtB1vRzyWBM/PkYKn81HwdE4KnrZzTl1qExER+YaCR0RELKXgERERS3kdPO+++y7H\njh1rz1pERKQT8PpzPHv27CEzM5MhQ4YwZswYRowYQUBAQHvWJiIiHZDXwfPAAw9QV1fH9u3b+fvf\n/05GRgYjR45kzJgxp/1ApoiIyOn8oCcXhISEMHnyZCZPnsznn39OWloamzdvJiIigokTJzJlyhS6\ndevWXrWKiEgH8IMfmbN79262bdtGQUEBAwYM4K677iIiIoJ3332XJUuWsHjx4vaoU0REOgivg+eV\nV14hPz+foKAgxowZw7JlyzzPSQMYOHAgSUlJ7VKkiIh0HF4HT2NjI7/73e+IiYk5/YH8/UlJSWmz\nwkREpGPyOnj+/d//nS5durRqq6+vx+12e0Y+ffr0advqRESkw/H6czxLly495QvUXC4XTz31VJsX\nJSIiHZfXwXP48GH69evXqq1fv34cOnSozYsSEZGOy+vg6d69OxUVFa3aKioqCAkJafOiRESk4/L6\nHs/48eNZtmwZv/71r4mOjqaiooI33niDCRMmtGd9IiLSwXgdPNdccw3+/v789a9/9XzF9IQJE1p9\no6iIiMjZeB08NpuNadOmMW2avnxMRER+vB/05ILDhw/z2WefceLEiVbtutwmIiLe8jp4srKyePPN\nNznvvPPo2rVrq3UKHhER8ZbXwfPNs9jOO++89qxHREQ6OK+nU3fp0kVPJhARkZ/M6+C54YYbePHF\nF6mpqaGlpaXVj4iIiLe8vtSWnp4OwKZNm05Z98Ybb7RdRSIi0qF5HTxpaWntWYeIiHQSXgdPZGQk\nAC0tLdTW1hIWFtZuRYmISMfldfB89dVX/PnPf2bHjh2eJxjs3LmTkpISfv3rX7dnjSIi0oF4Pbkg\nIyODoKAg0tPT8fc/mVexsbHk5+e3W3EiItLxeD3i2b17N88//7wndODkE6tra2vPum96ejoffvgh\nPXr0YNmyZQCsXbuWTZs20b17dwBuvPFGLrnkEgA2bNhAbm4uNpuNpKQk4uLiACgtLWXVqlW43W7i\n4+NJSkrCMAwaGxtJS0ujtLSUkJAQkpOTiYqKAmDLli1kZWUBMH36dMaNG+dtl0VEpB14PeIJCgqi\nrq6uVVtVVZVX93rGjRvHQw89dEr71KlTWbp0KUuXLvWETllZGfn5+SxfvpxFixaxevVqz5TtjIwM\n5s2bR2pqKhUVFRQWFgKQm5tLcHAwK1euZOrUqaxZswY4+Q2p69evZ8mSJSxZsoT169dTX1/vbZdF\nRKQdeB08EydOZNmyZezZswfTNCkuLmbVqlVcccUVZ9138ODB2O12r16noKCA0aNHExAQQFRUFD17\n9qSkpISamhqOHz9ObGwshmEwZswYCgoKANi5c6dnJDNq1ChPjYWFhQwfPhy73Y7dbmf48OGesBIR\nEd/w+lLbr371K7p06cLq1atpbm7m2Wefxel0MmXKlB/94hs3biQvL4/+/ftzyy23YLfbcblcDBw4\n0LONw+HA5XLh5+dHeHi4pz08PNzzVdwul8uzzs/PzzM6+3b7t48lIiK+43XwGIbBlClTflLQfNuk\nSZO47rrrgJMfQH3llVeYP39+mxz7x8jJySEnJweAlJQUIiIifFaLt770dQEdzM/hnEvb8/f317m3\nmNfBs2fPnjOuGzp06A9+4dDQUM/vEydO5IknngBOjkqqq6s961wuFw6H45T26upqHA5Hq33Cw8Np\nbm6moaGBkJAQHA4HRUVFrY41ePDg09bjdDpxOp2e5aqqqh/cJ/l50znvnCIiInTu20jv3r292s7r\n4Hn22WdbLR87doympibCw8N/1FMNampqPBMT3n//ffr27QtAYmIiqampXHXVVdTU1FBeXk5MTAw2\nm43AwECKi4sZOHAgeXl5TJ48GYCEhAS2bNlCbGwsO3bsYMiQIRiGQVxcHJmZmZ4JBbt27eKmm276\nwbWKiEjbMUzTNH/Mji0tLbz55psEBgae9euvn376aYqKiqirq6NHjx7MmDGDvXv38tlnn2EYBpGR\nkdx+++2eIMrKymLz5s3YbDZmz55NfHw8AAcOHCA9PR23201cXBxz5szBMAzcbjdpaWkcPHgQu91O\ncnIy0dHRwMkZbxs2bABOTqceP368V/07fPjwj3lbLNV8m74Nti35Zbzt6xLEBzTiaTvejnh+dPAA\nNDc385vf/IaMjIwfe4hzloKn81HwdE4KnrbjbfB4PZ36dD7++GNstp90CBER6WS8vsdzxx13tFp2\nu9243W7mzp3b5kWJiEjH5XXw3H333a2Wu3btSq9evQgKCmrzokREpOPyOnjONA1ZRETkh/A6eFau\nXIlhGGfd7q677vpJBYmISMfm9cyA4OBgCgoKaGlpweFw0NLSQkFBAUFBQURHR3t+REREvo/XI57y\n8nIWLlzIRRdd5Gnbt28fb775JnPmzGmX4kREpOPxesTzzRMDvi0mJobi4uI2L0pERDour4Pnggsu\nIDMzE7fbDZycTv36669z/vnnt1dtIiLSAXl9qW3+/PmkpqYya9Ys7HY79fX1DBgwgN/+9rftWZ+I\niHQwXgdPVFQUjz32GFVVVZ4HfOpR4iIi8kP9oOfd1NXVUVRURFFREREREbhcrlZfVSAiInI2XgdP\nUVERycnJbNu2jTfffBOAioqKDvmAUBERaT9eB89f/vIXkpOTWbRoEX5+fsDJWW0HDhxot+JERKTj\n8Tp4jhw5wrBhw1q1+fv709zc3OZFiYhIx+V18PziF7+gsLCwVdvu3bvp169fmxclIiIdl9ez2m6+\n+WaeeOIJ4uPjcbvdvPDCC3zwwQfcf//97VmfiIh0MF4HT2xsLEuXLmXbtm1069aNiIgIlixZQnh4\neHvWJyIiHYxXwdPS0sLixYtZtGgRv/rVr9q7JhER6cC8usdjs9morKzENM32rkdERDo4rycXXHfd\ndWRkZHDkyBFaWlpa/YiIiHjL63s8zz//PAB5eXmnrHvjjTfariIREenQzho8R48eJTQ0lLS0NCvq\nERGRDu6sl9ruueceACIjI4mMjOTll1/2/P7Nj4iIiLfOGjzfnVCwd+/editGREQ6vrMGj2EYVtQh\nIiKdxFnv8TQ3N7Nnzx7PcktLS6tlgKFDh7Z9ZSIi0iGdNXh69OjBs88+61m22+2tlg3D0MQDERHx\n2lmDZ9WqVT/5RdLT0/nwww/p0aMHy5YtA6C+vp4VK1Zw5MgRIiMjWbBgAXa7HYANGzaQm5uLzWYj\nKSmJuLg4AEpLS1m1ahVut5v4+HiSkpIwDIPGxkbS0tIoLS0lJCSE5ORkoqKiANiyZQtZWVkATJ8+\nnXHjxv3k/oiIyI/3g76B9McaN24cDz30UKu27Oxshg0bRmpqKsOGDSM7OxuAsrIy8vPzWb58OYsW\nLWL16tWeD6lmZGQwb948UlNTqaio8DwtOzc3l+DgYFauXMnUqVNZs2YNcDLc1q9fz5IlS1iyZAnr\n16+nvr7eii6LiMgZWBI8gwcP9oxmvlFQUMDYsWMBGDt2LAUFBZ720aNHExAQQFRUFD179qSkpISa\nmhqOHz9ObGwshmEwZswYzz47d+70jGRGjRrFnj17ME2TwsJChg8fjt1ux263M3z48FO+2kFERKxl\nSfCcTm1tLWFhYQCEhoZSW1sLgMvlavXEa4fDgcvlOqU9PDwcl8t1yj5+fn4EBQVRV1d3xmOJiIjv\neP3InPZkGIbPp23n5OSQk5MDQEpKChERET6txxtf+rqADubncM6l7fn7++vcW8xnwdOjRw9qamoI\nCwujpqaG7t27AydHJdXV1Z7tXC4XDofjlPbq6mocDkerfcLDw2lubqahoYGQkBAcDgdFRUWtjjV4\n8ODT1uN0OnE6nZ7lqqqqNu2vnPt0zjuniIgInfs20rt3b6+289mltsTERLZu3QrA1q1bGTFihKc9\nPz+fxsZGKisrKS8vJyYmhrCwMAIDAykuLsY0TfLy8khMTAQgISGBLVu2ALBjxw6GDBmCYRjExcWx\na9cu6uvrqa+vZ9euXZ4ZciIi4huGacGX7Dz99NMUFRVRV1dHjx49mDFjBiNGjGDFihVUVVWdMp06\nKyuLzZs3Y7PZmD17NvHx8QAcOHCA9PR03G43cXFxzJkzB8MwcLvdpKWlcfDgQex2O8nJyURHRwMn\nZ7xt2LClJ+7XAAAJx0lEQVQBODmdevz48V7VfPjw4XZ4J9pW823TfF1Ch+KX8bavSxAf0Iin7Xg7\n4rEkeH6OFDydj4Knc1LwtJ1z/lKbiIh0TgoeERGxlIJHREQspeARERFLKXhERMRSCh4REbGUgkdE\nRCyl4BEREUspeERExFIKHhERsZSCR0RELKXgERERSyl4RETEUgoeERGxlIJHREQspeARERFLKXhE\nRMRSCh4REbGUgkdERCyl4BEREUspeERExFIKHhERsZSCR0RELKXgERERSyl4RETEUgoeERGxlIJH\nREQs5e/rAu688066deuGzWbDz8+PlJQU6uvrWbFiBUeOHCEyMpIFCxZgt9sB2LBhA7m5udhsNpKS\nkoiLiwOgtLSUVatW4Xa7iY+PJykpCcMwaGxsJC0tjdLSUkJCQkhOTiYqKsqXXRYR6dTOiRHPI488\nwtKlS0lJSQEgOzubYcOGkZqayrBhw8jOzgagrKyM/Px8li9fzqJFi1i9ejUtLS0AZGRkMG/ePFJT\nU6moqKCwsBCA3NxcgoODWblyJVOnTmXNmjW+6aSIiADnSPB8V0FBAWPHjgVg7NixFBQUeNpHjx5N\nQEAAUVFR9OzZk5KSEmpqajh+/DixsbEYhsGYMWM8++zcuZNx48YBMGrUKPbs2YNpmj7pl4iInAOX\n2gAeffRRbDYbV1xxBU6nk9raWsLCwgAIDQ2ltrYWAJfLxcCBAz37ORwOXC4Xfn5+hIeHe9rDw8Nx\nuVyefb5Z5+fnR1BQEHV1dXTv3t2q7omIyLf4PHgeffRRHA4HtbW1PPbYY/Tu3bvVesMwMAyj3evI\nyckhJycHgJSUFCIiItr9NX+qL31dQAfzczjn0vb8/f117i3m8+BxOBwA9OjRgxEjRlBSUkKPHj2o\nqakhLCyMmpoaz+jE4XBQXV3t2dflcuFwOE5pr66u9hz3m3Xh4eE0NzfT0NBASEjIKXU4nU6cTqdn\nuaqqql36K+cunfPOKSIiQue+jXx34HAmPr3Hc+LECY4fP+75/eOPP6Zfv34kJiaydetWALZu3cqI\nESMASExMJD8/n8bGRiorKykvLycmJoawsDACAwMpLi7GNE3y8vJITEwEICEhgS1btgCwY8cOhgwZ\nYskISkRETs+nI57a2lqeeuopAJqbm/m3f/s34uLiGDBgACtWrCA3N9cznRqgb9++XHbZZdx7773Y\nbDZuvfVWbLaT2Tl37lzS09Nxu93ExcURHx8PwIQJE0hLS+Puu+/GbreTnJzsm86KiAgAhqkpXqd1\n+PBhX5dwVs23TfN1CR2KX8bbvi5BfECX2trOz+JSm4iIdD4KHhERsZSCR0RELKXgERERSyl4RETE\nUgoeERGxlIJHREQspeARERFLKXhERMRSCh4REbGUgkdERCyl4BEREUspeERExFIKHhERsZSCR0RE\nLKXgERERSyl4RETEUgoeERGxlIJHREQspeARERFLKXhERMRSCh4REbGUgkdERCyl4BEREUspeERE\nxFIKHhERsZSCR0RELKXgERERS/n7ugCrFBYW8tJLL9HS0sLEiRO55pprfF2SiEin1ClGPC0tLaxe\nvZqHHnqIFStWsH37dsrKynxdlohIp9QpgqekpISePXsSHR2Nv78/o0ePpqCgwNdliYh0Sp3iUpvL\n5SI8PNyzHB4ezv79+1ttk5OTQ05ODgApKSn07t3b0hp/lL/v9HUFIh3Cz+K/9w6kU4x4vOF0OklJ\nSSElJcXXpXQ4Cxcu9HUJImekv0/rdYrgcTgcVFdXe5arq6txOBw+rEhEpPPqFMEzYMAAysvLqays\npKmpifz8fBITE31dlohIp9Qp7vH4+fkxZ84cHn/8cVpaWhg/fjx9+/b1dVmdhtPp9HUJImekv0/r\nGaZpmr4uQkREOo9OcalNRETOHQoeERGxlIJHREQs1SkmF4i1Dh06REFBAS6XCzg5nT0xMZFf/OIX\nPq5MRM4FGvFIm8rOzubpp58GICYmhpiYGACeeeYZsrOzfVmayPfavHmzr0voNDTikTa1efNmli1b\nhr9/6z+tq666invvvVdPBZdz1tq1axk/fryvy+gUFDzSpgzDoKamhsjIyFbtNTU1GIbho6pETvrd\n73532nbTNKmtrbW4ms5LwSNtavbs2SxevJhevXp5HsxaVVVFRUUFt956q4+rk86utraWRYsWERwc\n3KrdNE0efvhhH1XV+Sh4pE3FxcXxzDPPUFJS0mpyQUxMDDabbimKb11yySWcOHGC888//5R1gwcP\ntr6gTkpPLhAREUvpf0FFRMRSCh4REbGUgkfkHLN27VpSU1N9XYZIu9HkAhEfee+993jnnXc4dOgQ\ngYGBnH/++UyfPt3XZYm0OwWPiA+88847ZGdnc9ttt3HxxRfj7+/Prl272LlzJ126dPF1eSLtSsEj\nYrGGhgbeeOMN5s+fz8iRIz3tCQkJJCQksHbt2lbbL1++nE8++QS3283555/P3LlzPV9k+OGHH/LX\nv/6V6upqAgMDmTp1KtOmTePYsWOkp6ezb98+DMOgb9++/PGPf9SUdjknKHhELFZcXExjYyOXXnqp\nV9vHxcVxxx134O/vz5o1a0hNTWXp0qUAPPfccyxYsICLLrqI+vp6KisrgZMjKofDwZ///GcA9u/f\nrydHyDlD//sjYrG6ujpCQkLw8/PzavsJEyYQGBhIQEAA119/PZ9//jkNDQ3Aya91Lysro6GhAbvd\nTv/+/T3tR48epaqqCn9/fy666CIFj5wzNOIRsVhISAh1dXU0NzefNXxaWlrIzMxkx44dHDt2zBMe\nx44dIygoiPvuu4+srCxee+01+vXrx8yZM4mNjWXatGmsW7eOxx57DACn06kHtMo5Q8EjYrHY2FgC\nAgIoKChg1KhR37vte++9x86dO3n44YeJjIykoaGBpKQkz/qYmBgeeOABmpqa2LhxIytWrODZZ58l\nMDCQW265hVtuuYUvvviCxYsXM2DAAIYNG9be3RM5K11qE7FYUFAQM2bMYPXq1bz//vt8/fXXNDU1\n8dFHH/Hqq6+22vb48eP4+/tjt9v5+uuvyczM9Kxrampi27ZtNDQ04O/vT1BQkGdE9MEHH1BRUYFp\nmgQFBWGz2XSpTc4ZGvGI+MDVV19NaGgoWVlZrFy5km7dutG/f3+mT5/Orl27PNuNHTuWXbt28Zvf\n/Aa73c4NN9zAP/7xD8/6vLw8XnzxRVpaWujduze//e1vASgvL+fFF1/k2LFjBAcHM2nSJIYOHWp5\nP0VORw8JFRERS+lSm4iIWErBIyIillLwiIiIpRQ8IiJiKQWPiIhYSsEjIiKWUvCIiIilFDwiImIp\nBY+IiFjq/wEs5BITJe0CZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc82de1ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for all data\n",
    "count_classes = pd.value_counts(dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset on train_and_validation dataset and test dataset\n",
    "train_and_validation, test = train_test_split(dataset, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Convert test data to numpyarray and split them.\n",
    "test = test.values\n",
    "x_test = test[:,:-1]\n",
    "y_test = test[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create balanced, under sample train and validation dataset \n",
    "fraud_indices = np.array(train_and_validation[train_and_validation.Class == 1].index)\n",
    "normal_indices = np.array(train_and_validation[train_and_validation.Class == 0].index)\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indices, NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "under_sample_dataset = dataset.iloc[under_sample_indices,:]\n",
    "\n",
    "# Shuffle train and validation dataset\n",
    "under_sample_dataset = under_sample_dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgphYWIiJj6P0+koQ8tk9iMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8680e4128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    400\n",
       "1    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for training and validation dataset\n",
    "count_classes = pd.value_counts(under_sample_dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert training and validation dataset to numpy array\n",
    "under_sample_dataset = under_sample_dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pot loss\n",
    "def show_loss(history):   \n",
    "    x_axis = range(0, EPOCHS)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, history.history['loss'], label='train_loss')\n",
    "    ax.plot(x_axis, history.history['val_loss'], label='val_loss')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Log loss')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.title('loss vs epoch number')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ROC(TPR_array, FPR_array):   \n",
    "    plt.title('ROC')\n",
    "    plt.plot(FPR_array, TPR_array, 'b')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 632 samples, validate on 159 samples\n",
      "Epoch 1/1000\n",
      "632/632 [==============================] - 0s - loss: 5.9079 - acc: 0.5854 - precision: 0.5436 - recall: 0.9793 - f1_score: 0.6955 - val_loss: 5.8821 - val_acc: 0.5409 - val_precision: 0.5229 - val_recall: 0.9617 - val_f1_score: 0.6764\n",
      "Epoch 2/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8709 - acc: 0.6076 - precision: 0.5590 - recall: 0.9805 - f1_score: 0.7086 - val_loss: 5.8460 - val_acc: 0.5660 - val_precision: 0.5365 - val_recall: 0.9617 - val_f1_score: 0.6879\n",
      "Epoch 3/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8352 - acc: 0.6234 - precision: 0.5644 - recall: 0.9795 - f1_score: 0.7097 - val_loss: 5.8111 - val_acc: 0.5849 - val_precision: 0.5481 - val_recall: 0.9617 - val_f1_score: 0.6976\n",
      "Epoch 4/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8004 - acc: 0.6487 - precision: 0.5842 - recall: 0.9842 - f1_score: 0.7305 - val_loss: 5.7771 - val_acc: 0.5975 - val_precision: 0.5564 - val_recall: 0.9617 - val_f1_score: 0.7043\n",
      "Epoch 5/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7665 - acc: 0.6709 - precision: 0.5996 - recall: 0.9841 - f1_score: 0.7433 - val_loss: 5.7437 - val_acc: 0.6289 - val_precision: 0.5779 - val_recall: 0.9617 - val_f1_score: 0.7214\n",
      "Epoch 6/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7331 - acc: 0.6915 - precision: 0.6188 - recall: 0.9793 - f1_score: 0.7558 - val_loss: 5.7108 - val_acc: 0.6415 - val_precision: 0.5861 - val_recall: 0.9617 - val_f1_score: 0.7277\n",
      "Epoch 7/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7002 - acc: 0.7136 - precision: 0.6377 - recall: 0.9769 - f1_score: 0.7674 - val_loss: 5.6785 - val_acc: 0.6667 - val_precision: 0.6051 - val_recall: 0.9617 - val_f1_score: 0.7416\n",
      "Epoch 8/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6678 - acc: 0.7468 - precision: 0.6648 - recall: 0.9739 - f1_score: 0.7834 - val_loss: 5.6465 - val_acc: 0.6855 - val_precision: 0.6197 - val_recall: 0.9617 - val_f1_score: 0.7526\n",
      "Epoch 9/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6358 - acc: 0.7595 - precision: 0.6796 - recall: 0.9639 - f1_score: 0.7950 - val_loss: 5.6149 - val_acc: 0.6981 - val_precision: 0.6300 - val_recall: 0.9617 - val_f1_score: 0.7602\n",
      "Epoch 10/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6041 - acc: 0.7848 - precision: 0.7084 - recall: 0.9601 - f1_score: 0.8136 - val_loss: 5.5837 - val_acc: 0.7044 - val_precision: 0.6379 - val_recall: 0.9496 - val_f1_score: 0.7615\n",
      "Epoch 11/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5728 - acc: 0.7943 - precision: 0.7197 - recall: 0.9580 - f1_score: 0.8187 - val_loss: 5.5528 - val_acc: 0.7358 - val_precision: 0.6670 - val_recall: 0.9353 - val_f1_score: 0.7777\n",
      "Epoch 12/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5417 - acc: 0.8196 - precision: 0.7514 - recall: 0.9550 - f1_score: 0.8384 - val_loss: 5.5223 - val_acc: 0.7547 - val_precision: 0.6865 - val_recall: 0.9353 - val_f1_score: 0.7901\n",
      "Epoch 13/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5111 - acc: 0.8418 - precision: 0.7776 - recall: 0.9499 - f1_score: 0.8529 - val_loss: 5.4920 - val_acc: 0.7673 - val_precision: 0.7004 - val_recall: 0.9353 - val_f1_score: 0.7987\n",
      "Epoch 14/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4807 - acc: 0.8544 - precision: 0.7976 - recall: 0.9506 - f1_score: 0.8638 - val_loss: 5.4620 - val_acc: 0.7925 - val_precision: 0.7262 - val_recall: 0.9353 - val_f1_score: 0.8165\n",
      "Epoch 15/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4505 - acc: 0.8592 - precision: 0.8024 - recall: 0.9441 - f1_score: 0.8669 - val_loss: 5.4322 - val_acc: 0.8050 - val_precision: 0.7471 - val_recall: 0.9232 - val_f1_score: 0.8237\n",
      "Epoch 16/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4207 - acc: 0.8671 - precision: 0.8109 - recall: 0.9465 - f1_score: 0.8715 - val_loss: 5.4028 - val_acc: 0.8176 - val_precision: 0.7607 - val_recall: 0.9232 - val_f1_score: 0.8320\n",
      "Epoch 17/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3911 - acc: 0.8813 - precision: 0.8340 - recall: 0.9456 - f1_score: 0.8852 - val_loss: 5.3736 - val_acc: 0.8302 - val_precision: 0.7781 - val_recall: 0.9232 - val_f1_score: 0.8416\n",
      "Epoch 18/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3618 - acc: 0.8940 - precision: 0.8576 - recall: 0.9398 - f1_score: 0.8952 - val_loss: 5.3447 - val_acc: 0.8365 - val_precision: 0.7876 - val_recall: 0.9232 - val_f1_score: 0.8468\n",
      "Epoch 19/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3328 - acc: 0.9082 - precision: 0.8800 - recall: 0.9403 - f1_score: 0.9060 - val_loss: 5.3160 - val_acc: 0.8491 - val_precision: 0.8023 - val_recall: 0.9232 - val_f1_score: 0.8566\n",
      "Epoch 20/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3039 - acc: 0.9130 - precision: 0.8902 - recall: 0.9413 - f1_score: 0.9125 - val_loss: 5.2875 - val_acc: 0.8616 - val_precision: 0.8205 - val_recall: 0.9232 - val_f1_score: 0.8671\n",
      "Epoch 21/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2753 - acc: 0.9177 - precision: 0.8977 - recall: 0.9402 - f1_score: 0.9162 - val_loss: 5.2593 - val_acc: 0.8805 - val_precision: 0.8483 - val_recall: 0.9232 - val_f1_score: 0.8823\n",
      "Epoch 22/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2470 - acc: 0.9272 - precision: 0.9173 - recall: 0.9352 - f1_score: 0.9254 - val_loss: 5.2313 - val_acc: 0.8805 - val_precision: 0.8483 - val_recall: 0.9232 - val_f1_score: 0.8823\n",
      "Epoch 23/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2188 - acc: 0.9320 - precision: 0.9270 - recall: 0.9322 - f1_score: 0.9276 - val_loss: 5.2035 - val_acc: 0.8931 - val_precision: 0.8678 - val_recall: 0.9232 - val_f1_score: 0.8938\n",
      "Epoch 24/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1909 - acc: 0.9351 - precision: 0.9312 - recall: 0.9368 - f1_score: 0.9327 - val_loss: 5.1759 - val_acc: 0.8868 - val_precision: 0.8674 - val_recall: 0.9119 - val_f1_score: 0.8881\n",
      "Epoch 25/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1632 - acc: 0.9383 - precision: 0.9343 - recall: 0.9341 - f1_score: 0.9325 - val_loss: 5.1486 - val_acc: 0.8994 - val_precision: 0.8901 - val_recall: 0.9119 - val_f1_score: 0.8988\n",
      "Epoch 26/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1357 - acc: 0.9430 - precision: 0.9501 - recall: 0.9379 - f1_score: 0.9431 - val_loss: 5.1215 - val_acc: 0.9182 - val_precision: 0.9237 - val_recall: 0.9119 - val_f1_score: 0.9166\n",
      "Epoch 27/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1085 - acc: 0.9462 - precision: 0.9530 - recall: 0.9353 - f1_score: 0.9428 - val_loss: 5.0945 - val_acc: 0.9182 - val_precision: 0.9363 - val_recall: 0.9007 - val_f1_score: 0.9173\n",
      "Epoch 28/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0814 - acc: 0.9478 - precision: 0.9567 - recall: 0.9341 - f1_score: 0.9445 - val_loss: 5.0678 - val_acc: 0.9182 - val_precision: 0.9480 - val_recall: 0.8895 - val_f1_score: 0.9167\n",
      "Epoch 29/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0545 - acc: 0.9478 - precision: 0.9587 - recall: 0.9322 - f1_score: 0.9444 - val_loss: 5.0412 - val_acc: 0.9119 - val_precision: 0.9480 - val_recall: 0.8783 - val_f1_score: 0.9103\n",
      "Epoch 30/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0278 - acc: 0.9525 - precision: 0.9686 - recall: 0.9328 - f1_score: 0.9497 - val_loss: 5.0148 - val_acc: 0.9119 - val_precision: 0.9480 - val_recall: 0.8783 - val_f1_score: 0.9103\n",
      "Epoch 31/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0013 - acc: 0.9509 - precision: 0.9729 - recall: 0.9273 - f1_score: 0.9485 - val_loss: 4.9887 - val_acc: 0.9119 - val_precision: 0.9480 - val_recall: 0.8783 - val_f1_score: 0.9103\n",
      "Epoch 32/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9750 - acc: 0.9509 - precision: 0.9681 - recall: 0.9291 - f1_score: 0.9475 - val_loss: 4.9627 - val_acc: 0.9119 - val_precision: 0.9480 - val_recall: 0.8783 - val_f1_score: 0.9103\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.9489 - acc: 0.9525 - precision: 0.9741 - recall: 0.9301 - f1_score: 0.9508 - val_loss: 4.9369 - val_acc: 0.9119 - val_precision: 0.9480 - val_recall: 0.8783 - val_f1_score: 0.9103\n",
      "Epoch 34/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9230 - acc: 0.9525 - precision: 0.9729 - recall: 0.9274 - f1_score: 0.9489 - val_loss: 4.9113 - val_acc: 0.9182 - val_precision: 0.9595 - val_recall: 0.8783 - val_f1_score: 0.9157\n",
      "Epoch 35/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8973 - acc: 0.9525 - precision: 0.9742 - recall: 0.9280 - f1_score: 0.9501 - val_loss: 4.8858 - val_acc: 0.9182 - val_precision: 0.9595 - val_recall: 0.8783 - val_f1_score: 0.9157\n",
      "Epoch 36/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8717 - acc: 0.9541 - precision: 0.9767 - recall: 0.9318 - f1_score: 0.9529 - val_loss: 4.8606 - val_acc: 0.9182 - val_precision: 0.9595 - val_recall: 0.8783 - val_f1_score: 0.9157\n",
      "Epoch 37/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8463 - acc: 0.9509 - precision: 0.9750 - recall: 0.9244 - f1_score: 0.9480 - val_loss: 4.8354 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8783 - val_f1_score: 0.9283\n",
      "Epoch 38/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8211 - acc: 0.9509 - precision: 0.9760 - recall: 0.9260 - f1_score: 0.9498 - val_loss: 4.8106 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8783 - val_f1_score: 0.9283\n",
      "Epoch 39/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7960 - acc: 0.9509 - precision: 0.9801 - recall: 0.9203 - f1_score: 0.9487 - val_loss: 4.7858 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8783 - val_f1_score: 0.9283\n",
      "Epoch 40/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7712 - acc: 0.9494 - precision: 0.9775 - recall: 0.9168 - f1_score: 0.9453 - val_loss: 4.7612 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8783 - val_f1_score: 0.9283\n",
      "Epoch 41/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7464 - acc: 0.9494 - precision: 0.9794 - recall: 0.9169 - f1_score: 0.9466 - val_loss: 4.7367 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 42/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7219 - acc: 0.9494 - precision: 0.9809 - recall: 0.9183 - f1_score: 0.9465 - val_loss: 4.7125 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 43/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6975 - acc: 0.9494 - precision: 0.9789 - recall: 0.9165 - f1_score: 0.9458 - val_loss: 4.6884 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 44/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6733 - acc: 0.9478 - precision: 0.9818 - recall: 0.9110 - f1_score: 0.9438 - val_loss: 4.6644 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 45/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6492 - acc: 0.9478 - precision: 0.9804 - recall: 0.9139 - f1_score: 0.9451 - val_loss: 4.6406 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 46/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6252 - acc: 0.9430 - precision: 0.9792 - recall: 0.9019 - f1_score: 0.9369 - val_loss: 4.6169 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 47/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6015 - acc: 0.9415 - precision: 0.9796 - recall: 0.9016 - f1_score: 0.9382 - val_loss: 4.5934 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 48/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5779 - acc: 0.9430 - precision: 0.9821 - recall: 0.9020 - f1_score: 0.9386 - val_loss: 4.5701 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 49/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5544 - acc: 0.9430 - precision: 0.9832 - recall: 0.9029 - f1_score: 0.9399 - val_loss: 4.5468 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 50/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5311 - acc: 0.9430 - precision: 0.9818 - recall: 0.8966 - f1_score: 0.9356 - val_loss: 4.5238 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 51/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5079 - acc: 0.9430 - precision: 0.9811 - recall: 0.8999 - f1_score: 0.9376 - val_loss: 4.5009 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 52/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4849 - acc: 0.9415 - precision: 0.9823 - recall: 0.8974 - f1_score: 0.9371 - val_loss: 4.4781 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 53/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4620 - acc: 0.9415 - precision: 0.9818 - recall: 0.8964 - f1_score: 0.9361 - val_loss: 4.4555 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 54/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4393 - acc: 0.9430 - precision: 0.9848 - recall: 0.9046 - f1_score: 0.9414 - val_loss: 4.4330 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 55/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4167 - acc: 0.9415 - precision: 0.9823 - recall: 0.8916 - f1_score: 0.9329 - val_loss: 4.4107 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 56/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3942 - acc: 0.9415 - precision: 0.9824 - recall: 0.8993 - f1_score: 0.9377 - val_loss: 4.3884 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 57/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3719 - acc: 0.9415 - precision: 0.9822 - recall: 0.8949 - f1_score: 0.9351 - val_loss: 4.3664 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 58/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3497 - acc: 0.9415 - precision: 0.9823 - recall: 0.8993 - f1_score: 0.9377 - val_loss: 4.3444 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 59/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3277 - acc: 0.9415 - precision: 0.9815 - recall: 0.8979 - f1_score: 0.9369 - val_loss: 4.3226 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 60/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3058 - acc: 0.9415 - precision: 0.9841 - recall: 0.8943 - f1_score: 0.9353 - val_loss: 4.3009 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 61/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2840 - acc: 0.9415 - precision: 0.9822 - recall: 0.9007 - f1_score: 0.9384 - val_loss: 4.2794 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 62/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2624 - acc: 0.9430 - precision: 0.9830 - recall: 0.8981 - f1_score: 0.9377 - val_loss: 4.2580 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 63/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2409 - acc: 0.9415 - precision: 0.9836 - recall: 0.8975 - f1_score: 0.9372 - val_loss: 4.2367 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 64/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2195 - acc: 0.9415 - precision: 0.9807 - recall: 0.9005 - f1_score: 0.9367 - val_loss: 4.2155 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.1982 - acc: 0.9399 - precision: 0.9819 - recall: 0.8923 - f1_score: 0.9333 - val_loss: 4.1944 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 66/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1771 - acc: 0.9415 - precision: 0.9829 - recall: 0.8952 - f1_score: 0.9356 - val_loss: 4.1735 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 67/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1560 - acc: 0.9399 - precision: 0.9816 - recall: 0.8910 - f1_score: 0.9326 - val_loss: 4.1527 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 68/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1351 - acc: 0.9415 - precision: 0.9820 - recall: 0.8952 - f1_score: 0.9355 - val_loss: 4.1320 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 69/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1144 - acc: 0.9415 - precision: 0.9821 - recall: 0.9001 - f1_score: 0.9384 - val_loss: 4.1115 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 70/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0938 - acc: 0.9415 - precision: 0.9813 - recall: 0.8973 - f1_score: 0.9371 - val_loss: 4.0910 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 71/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0732 - acc: 0.9415 - precision: 0.9830 - recall: 0.8984 - f1_score: 0.9384 - val_loss: 4.0707 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 72/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0528 - acc: 0.9415 - precision: 0.9820 - recall: 0.8997 - f1_score: 0.9372 - val_loss: 4.0505 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 73/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0325 - acc: 0.9415 - precision: 0.9852 - recall: 0.8996 - f1_score: 0.9385 - val_loss: 4.0304 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 74/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0124 - acc: 0.9399 - precision: 0.9832 - recall: 0.8961 - f1_score: 0.9356 - val_loss: 4.0104 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 75/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9923 - acc: 0.9399 - precision: 0.9837 - recall: 0.8949 - f1_score: 0.9356 - val_loss: 3.9906 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 76/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9724 - acc: 0.9399 - precision: 0.9820 - recall: 0.8937 - f1_score: 0.9343 - val_loss: 3.9708 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 77/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9526 - acc: 0.9399 - precision: 0.9799 - recall: 0.8933 - f1_score: 0.9335 - val_loss: 3.9512 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 78/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9329 - acc: 0.9399 - precision: 0.9829 - recall: 0.8931 - f1_score: 0.9346 - val_loss: 3.9317 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 79/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9133 - acc: 0.9399 - precision: 0.9838 - recall: 0.8958 - f1_score: 0.9350 - val_loss: 3.9123 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 80/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8938 - acc: 0.9399 - precision: 0.9825 - recall: 0.8911 - f1_score: 0.9333 - val_loss: 3.8930 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 81/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8744 - acc: 0.9399 - precision: 0.9849 - recall: 0.8931 - f1_score: 0.9356 - val_loss: 3.8738 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 82/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8551 - acc: 0.9399 - precision: 0.9822 - recall: 0.8935 - f1_score: 0.9351 - val_loss: 3.8547 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 83/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8360 - acc: 0.9399 - precision: 0.9832 - recall: 0.8929 - f1_score: 0.9341 - val_loss: 3.8357 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 84/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8169 - acc: 0.9399 - precision: 0.9817 - recall: 0.8953 - f1_score: 0.9358 - val_loss: 3.8169 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 85/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7980 - acc: 0.9399 - precision: 0.9831 - recall: 0.8961 - f1_score: 0.9363 - val_loss: 3.7981 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 86/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7792 - acc: 0.9399 - precision: 0.9827 - recall: 0.8952 - f1_score: 0.9359 - val_loss: 3.7795 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 87/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7605 - acc: 0.9399 - precision: 0.9826 - recall: 0.8910 - f1_score: 0.9317 - val_loss: 3.7609 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 88/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7418 - acc: 0.9399 - precision: 0.9833 - recall: 0.8978 - f1_score: 0.9367 - val_loss: 3.7425 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 89/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7233 - acc: 0.9399 - precision: 0.9825 - recall: 0.8925 - f1_score: 0.9342 - val_loss: 3.7241 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 90/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7049 - acc: 0.9399 - precision: 0.9820 - recall: 0.8939 - f1_score: 0.9344 - val_loss: 3.7059 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 91/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6866 - acc: 0.9399 - precision: 0.9805 - recall: 0.8903 - f1_score: 0.9309 - val_loss: 3.6877 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 92/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6684 - acc: 0.9399 - precision: 0.9843 - recall: 0.8912 - f1_score: 0.9338 - val_loss: 3.6697 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 93/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6503 - acc: 0.9399 - precision: 0.9821 - recall: 0.8912 - f1_score: 0.9329 - val_loss: 3.6518 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 94/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6323 - acc: 0.9399 - precision: 0.9815 - recall: 0.8934 - f1_score: 0.9341 - val_loss: 3.6339 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 95/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6144 - acc: 0.9399 - precision: 0.9824 - recall: 0.8935 - f1_score: 0.9356 - val_loss: 3.6162 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 96/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5966 - acc: 0.9399 - precision: 0.9815 - recall: 0.8983 - f1_score: 0.9368 - val_loss: 3.5985 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.5789 - acc: 0.9399 - precision: 0.9833 - recall: 0.8966 - f1_score: 0.9369 - val_loss: 3.5810 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 98/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5613 - acc: 0.9399 - precision: 0.9823 - recall: 0.8943 - f1_score: 0.9349 - val_loss: 3.5635 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 99/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5438 - acc: 0.9399 - precision: 0.9830 - recall: 0.8923 - f1_score: 0.9347 - val_loss: 3.5462 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 100/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5264 - acc: 0.9399 - precision: 0.9839 - recall: 0.8912 - f1_score: 0.9333 - val_loss: 3.5289 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 101/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5091 - acc: 0.9399 - precision: 0.9837 - recall: 0.8928 - f1_score: 0.9353 - val_loss: 3.5118 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 102/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4919 - acc: 0.9399 - precision: 0.9829 - recall: 0.8938 - f1_score: 0.9350 - val_loss: 3.4947 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 103/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4747 - acc: 0.9399 - precision: 0.9812 - recall: 0.8920 - f1_score: 0.9337 - val_loss: 3.4777 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 104/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4577 - acc: 0.9399 - precision: 0.9777 - recall: 0.8878 - f1_score: 0.9297 - val_loss: 3.4608 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 105/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4408 - acc: 0.9399 - precision: 0.9833 - recall: 0.8912 - f1_score: 0.9338 - val_loss: 3.4440 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 106/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4239 - acc: 0.9399 - precision: 0.9836 - recall: 0.8953 - f1_score: 0.9367 - val_loss: 3.4273 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 107/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4072 - acc: 0.9399 - precision: 0.9817 - recall: 0.8955 - f1_score: 0.9356 - val_loss: 3.4107 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 108/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3905 - acc: 0.9399 - precision: 0.9814 - recall: 0.8900 - f1_score: 0.9332 - val_loss: 3.3942 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 109/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3739 - acc: 0.9399 - precision: 0.9820 - recall: 0.8953 - f1_score: 0.9355 - val_loss: 3.3778 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 110/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3575 - acc: 0.9399 - precision: 0.9826 - recall: 0.8945 - f1_score: 0.9356 - val_loss: 3.3614 - val_acc: 0.9245 - val_precision: 0.9863 - val_recall: 0.8640 - val_f1_score: 0.9207\n",
      "Epoch 111/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3411 - acc: 0.9399 - precision: 0.9807 - recall: 0.8913 - f1_score: 0.9332 - val_loss: 3.3452 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 112/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3248 - acc: 0.9399 - precision: 0.9830 - recall: 0.8955 - f1_score: 0.9363 - val_loss: 3.3290 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 113/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3086 - acc: 0.9415 - precision: 0.9858 - recall: 0.8938 - f1_score: 0.9364 - val_loss: 3.3129 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 114/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2924 - acc: 0.9415 - precision: 0.9872 - recall: 0.8947 - f1_score: 0.9378 - val_loss: 3.2970 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 115/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2764 - acc: 0.9415 - precision: 0.9861 - recall: 0.8935 - f1_score: 0.9359 - val_loss: 3.2811 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 116/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2605 - acc: 0.9415 - precision: 0.9856 - recall: 0.8935 - f1_score: 0.9361 - val_loss: 3.2652 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 117/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2446 - acc: 0.9415 - precision: 0.9869 - recall: 0.8971 - f1_score: 0.9379 - val_loss: 3.2495 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 118/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2288 - acc: 0.9415 - precision: 0.9857 - recall: 0.8948 - f1_score: 0.9371 - val_loss: 3.2339 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 119/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2131 - acc: 0.9415 - precision: 0.9861 - recall: 0.8971 - f1_score: 0.9383 - val_loss: 3.2183 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 120/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1975 - acc: 0.9415 - precision: 0.9854 - recall: 0.8972 - f1_score: 0.9378 - val_loss: 3.2028 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 121/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1820 - acc: 0.9415 - precision: 0.9853 - recall: 0.8963 - f1_score: 0.9374 - val_loss: 3.1874 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 122/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1666 - acc: 0.9415 - precision: 0.9849 - recall: 0.8937 - f1_score: 0.9365 - val_loss: 3.1721 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 123/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1512 - acc: 0.9415 - precision: 0.9855 - recall: 0.8936 - f1_score: 0.9363 - val_loss: 3.1569 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 124/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1360 - acc: 0.9415 - precision: 0.9877 - recall: 0.8973 - f1_score: 0.9389 - val_loss: 3.1417 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 125/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1208 - acc: 0.9415 - precision: 0.9846 - recall: 0.8923 - f1_score: 0.9353 - val_loss: 3.1267 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 126/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1057 - acc: 0.9415 - precision: 0.9853 - recall: 0.8942 - f1_score: 0.9368 - val_loss: 3.1117 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 127/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0906 - acc: 0.9415 - precision: 0.9845 - recall: 0.8934 - f1_score: 0.9362 - val_loss: 3.0968 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 128/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0757 - acc: 0.9415 - precision: 0.9859 - recall: 0.8966 - f1_score: 0.9379 - val_loss: 3.0820 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.0608 - acc: 0.9415 - precision: 0.9862 - recall: 0.8930 - f1_score: 0.9359 - val_loss: 3.0672 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 130/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0461 - acc: 0.9415 - precision: 0.9888 - recall: 0.8924 - f1_score: 0.9367 - val_loss: 3.0526 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 131/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0314 - acc: 0.9415 - precision: 0.9841 - recall: 0.8972 - f1_score: 0.9371 - val_loss: 3.0380 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 132/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0167 - acc: 0.9415 - precision: 0.9863 - recall: 0.8944 - f1_score: 0.9372 - val_loss: 3.0235 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 133/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0022 - acc: 0.9415 - precision: 0.9871 - recall: 0.8915 - f1_score: 0.9362 - val_loss: 3.0090 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 134/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9877 - acc: 0.9415 - precision: 0.9873 - recall: 0.8914 - f1_score: 0.9355 - val_loss: 2.9947 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 135/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9733 - acc: 0.9415 - precision: 0.9863 - recall: 0.8949 - f1_score: 0.9371 - val_loss: 2.9804 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 136/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9590 - acc: 0.9415 - precision: 0.9847 - recall: 0.8886 - f1_score: 0.9333 - val_loss: 2.9662 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 137/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9448 - acc: 0.9415 - precision: 0.9871 - recall: 0.8931 - f1_score: 0.9357 - val_loss: 2.9520 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 138/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9306 - acc: 0.9415 - precision: 0.9858 - recall: 0.8952 - f1_score: 0.9372 - val_loss: 2.9380 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 139/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9165 - acc: 0.9415 - precision: 0.9847 - recall: 0.8904 - f1_score: 0.9338 - val_loss: 2.9240 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 140/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9025 - acc: 0.9415 - precision: 0.9868 - recall: 0.8951 - f1_score: 0.9363 - val_loss: 2.9101 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 141/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8886 - acc: 0.9415 - precision: 0.9828 - recall: 0.8899 - f1_score: 0.9328 - val_loss: 2.8963 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 142/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8747 - acc: 0.9415 - precision: 0.9873 - recall: 0.8925 - f1_score: 0.9359 - val_loss: 2.8825 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 143/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8609 - acc: 0.9415 - precision: 0.9857 - recall: 0.8917 - f1_score: 0.9347 - val_loss: 2.8688 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 144/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8472 - acc: 0.9415 - precision: 0.9868 - recall: 0.8950 - f1_score: 0.9367 - val_loss: 2.8552 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 145/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8336 - acc: 0.9415 - precision: 0.9879 - recall: 0.8935 - f1_score: 0.9373 - val_loss: 2.8417 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 146/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8200 - acc: 0.9415 - precision: 0.9865 - recall: 0.8925 - f1_score: 0.9353 - val_loss: 2.8282 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 147/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8065 - acc: 0.9415 - precision: 0.9855 - recall: 0.8930 - f1_score: 0.9368 - val_loss: 2.8148 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 148/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7931 - acc: 0.9415 - precision: 0.9856 - recall: 0.8897 - f1_score: 0.9335 - val_loss: 2.8015 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 149/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7798 - acc: 0.9415 - precision: 0.9845 - recall: 0.8929 - f1_score: 0.9360 - val_loss: 2.7883 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 150/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7665 - acc: 0.9415 - precision: 0.9863 - recall: 0.8919 - f1_score: 0.9356 - val_loss: 2.7751 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 151/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7533 - acc: 0.9415 - precision: 0.9856 - recall: 0.8969 - f1_score: 0.9377 - val_loss: 2.7620 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 152/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7401 - acc: 0.9415 - precision: 0.9849 - recall: 0.8925 - f1_score: 0.9348 - val_loss: 2.7489 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 153/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7271 - acc: 0.9415 - precision: 0.9866 - recall: 0.8950 - f1_score: 0.9376 - val_loss: 2.7359 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 154/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7141 - acc: 0.9415 - precision: 0.9862 - recall: 0.8968 - f1_score: 0.9383 - val_loss: 2.7230 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 155/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7011 - acc: 0.9415 - precision: 0.9866 - recall: 0.8923 - f1_score: 0.9360 - val_loss: 2.7102 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 156/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6883 - acc: 0.9415 - precision: 0.9878 - recall: 0.8878 - f1_score: 0.9333 - val_loss: 2.6974 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 157/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6755 - acc: 0.9415 - precision: 0.9855 - recall: 0.8956 - f1_score: 0.9373 - val_loss: 2.6847 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 158/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6627 - acc: 0.9415 - precision: 0.9838 - recall: 0.8926 - f1_score: 0.9353 - val_loss: 2.6721 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 159/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6501 - acc: 0.9415 - precision: 0.9872 - recall: 0.8945 - f1_score: 0.9370 - val_loss: 2.6595 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 160/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6375 - acc: 0.9415 - precision: 0.9863 - recall: 0.8973 - f1_score: 0.9388 - val_loss: 2.6470 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.6250 - acc: 0.9415 - precision: 0.9858 - recall: 0.8911 - f1_score: 0.9350 - val_loss: 2.6346 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 162/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6125 - acc: 0.9415 - precision: 0.9860 - recall: 0.8962 - f1_score: 0.9376 - val_loss: 2.6222 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 163/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6001 - acc: 0.9415 - precision: 0.9865 - recall: 0.8944 - f1_score: 0.9376 - val_loss: 2.6099 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 164/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5878 - acc: 0.9415 - precision: 0.9844 - recall: 0.8926 - f1_score: 0.9348 - val_loss: 2.5977 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 165/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5755 - acc: 0.9415 - precision: 0.9859 - recall: 0.8921 - f1_score: 0.9356 - val_loss: 2.5855 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 166/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5633 - acc: 0.9415 - precision: 0.9871 - recall: 0.8941 - f1_score: 0.9371 - val_loss: 2.5734 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 167/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5512 - acc: 0.9415 - precision: 0.9868 - recall: 0.8923 - f1_score: 0.9362 - val_loss: 2.5613 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 168/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5391 - acc: 0.9399 - precision: 0.9863 - recall: 0.8893 - f1_score: 0.9340 - val_loss: 2.5494 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 169/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5271 - acc: 0.9399 - precision: 0.9855 - recall: 0.8936 - f1_score: 0.9358 - val_loss: 2.5374 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 170/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5152 - acc: 0.9383 - precision: 0.9855 - recall: 0.8859 - f1_score: 0.9321 - val_loss: 2.5256 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 171/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5032 - acc: 0.9383 - precision: 0.9859 - recall: 0.8881 - f1_score: 0.9338 - val_loss: 2.5138 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 172/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4915 - acc: 0.9383 - precision: 0.9851 - recall: 0.8918 - f1_score: 0.9351 - val_loss: 2.5020 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 173/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4797 - acc: 0.9383 - precision: 0.9863 - recall: 0.8882 - f1_score: 0.9337 - val_loss: 2.4904 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 174/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4680 - acc: 0.9383 - precision: 0.9861 - recall: 0.8881 - f1_score: 0.9342 - val_loss: 2.4788 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 175/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4564 - acc: 0.9383 - precision: 0.9866 - recall: 0.8894 - f1_score: 0.9345 - val_loss: 2.4672 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 176/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4448 - acc: 0.9383 - precision: 0.9867 - recall: 0.8881 - f1_score: 0.9339 - val_loss: 2.4557 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 177/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4333 - acc: 0.9383 - precision: 0.9843 - recall: 0.8873 - f1_score: 0.9326 - val_loss: 2.4443 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 178/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4219 - acc: 0.9383 - precision: 0.9868 - recall: 0.8849 - f1_score: 0.9311 - val_loss: 2.4329 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 179/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4105 - acc: 0.9383 - precision: 0.9848 - recall: 0.8831 - f1_score: 0.9300 - val_loss: 2.4216 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 180/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3991 - acc: 0.9383 - precision: 0.9869 - recall: 0.8885 - f1_score: 0.9329 - val_loss: 2.4103 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 181/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3879 - acc: 0.9383 - precision: 0.9875 - recall: 0.8902 - f1_score: 0.9358 - val_loss: 2.3991 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 182/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3767 - acc: 0.9383 - precision: 0.9874 - recall: 0.8837 - f1_score: 0.9311 - val_loss: 2.3880 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 183/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3655 - acc: 0.9383 - precision: 0.9866 - recall: 0.8776 - f1_score: 0.9263 - val_loss: 2.3769 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 184/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3544 - acc: 0.9383 - precision: 0.9860 - recall: 0.8916 - f1_score: 0.9349 - val_loss: 2.3659 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 185/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3434 - acc: 0.9383 - precision: 0.9867 - recall: 0.8872 - f1_score: 0.9335 - val_loss: 2.3550 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 186/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3324 - acc: 0.9383 - precision: 0.9850 - recall: 0.8863 - f1_score: 0.9324 - val_loss: 2.3441 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 187/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3215 - acc: 0.9383 - precision: 0.9866 - recall: 0.8865 - f1_score: 0.9327 - val_loss: 2.3332 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 188/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3106 - acc: 0.9383 - precision: 0.9843 - recall: 0.8877 - f1_score: 0.9332 - val_loss: 2.3224 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 189/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2998 - acc: 0.9383 - precision: 0.9866 - recall: 0.8906 - f1_score: 0.9351 - val_loss: 2.3117 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 190/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2891 - acc: 0.9383 - precision: 0.9846 - recall: 0.8904 - f1_score: 0.9336 - val_loss: 2.3010 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 191/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2784 - acc: 0.9383 - precision: 0.9848 - recall: 0.8888 - f1_score: 0.9333 - val_loss: 2.2904 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 192/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2677 - acc: 0.9383 - precision: 0.9847 - recall: 0.8864 - f1_score: 0.9322 - val_loss: 2.2798 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.2572 - acc: 0.9383 - precision: 0.9865 - recall: 0.8885 - f1_score: 0.9342 - val_loss: 2.2693 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 194/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2466 - acc: 0.9383 - precision: 0.9861 - recall: 0.8919 - f1_score: 0.9341 - val_loss: 2.2588 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 195/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2362 - acc: 0.9383 - precision: 0.9878 - recall: 0.8881 - f1_score: 0.9330 - val_loss: 2.2484 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 196/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2258 - acc: 0.9383 - precision: 0.9865 - recall: 0.8854 - f1_score: 0.9304 - val_loss: 2.2381 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 197/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2154 - acc: 0.9383 - precision: 0.9854 - recall: 0.8915 - f1_score: 0.9350 - val_loss: 2.2278 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 198/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2051 - acc: 0.9383 - precision: 0.9859 - recall: 0.8860 - f1_score: 0.9297 - val_loss: 2.2176 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 199/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1948 - acc: 0.9383 - precision: 0.9856 - recall: 0.8862 - f1_score: 0.9321 - val_loss: 2.2074 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 200/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1846 - acc: 0.9383 - precision: 0.9841 - recall: 0.8879 - f1_score: 0.9321 - val_loss: 2.1972 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 201/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1745 - acc: 0.9383 - precision: 0.9871 - recall: 0.8859 - f1_score: 0.9327 - val_loss: 2.1871 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 202/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1644 - acc: 0.9383 - precision: 0.9862 - recall: 0.8870 - f1_score: 0.9333 - val_loss: 2.1771 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 203/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1544 - acc: 0.9383 - precision: 0.9868 - recall: 0.8851 - f1_score: 0.9320 - val_loss: 2.1672 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 204/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1444 - acc: 0.9383 - precision: 0.9851 - recall: 0.8848 - f1_score: 0.9314 - val_loss: 2.1572 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 205/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1344 - acc: 0.9383 - precision: 0.9854 - recall: 0.8883 - f1_score: 0.9326 - val_loss: 2.1474 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 206/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1246 - acc: 0.9383 - precision: 0.9846 - recall: 0.8879 - f1_score: 0.9323 - val_loss: 2.1375 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 207/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1147 - acc: 0.9383 - precision: 0.9861 - recall: 0.8876 - f1_score: 0.9330 - val_loss: 2.1278 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 208/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1049 - acc: 0.9383 - precision: 0.9849 - recall: 0.8873 - f1_score: 0.9322 - val_loss: 2.1180 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 209/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0952 - acc: 0.9383 - precision: 0.9869 - recall: 0.8877 - f1_score: 0.9335 - val_loss: 2.1084 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 210/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0855 - acc: 0.9383 - precision: 0.9859 - recall: 0.8880 - f1_score: 0.9335 - val_loss: 2.0988 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 211/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0759 - acc: 0.9383 - precision: 0.9845 - recall: 0.8854 - f1_score: 0.9313 - val_loss: 2.0892 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 212/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0663 - acc: 0.9383 - precision: 0.9855 - recall: 0.8858 - f1_score: 0.9318 - val_loss: 2.0797 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 213/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0568 - acc: 0.9383 - precision: 0.9855 - recall: 0.8869 - f1_score: 0.9330 - val_loss: 2.0702 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 214/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0473 - acc: 0.9383 - precision: 0.9844 - recall: 0.8842 - f1_score: 0.9299 - val_loss: 2.0608 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 215/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0379 - acc: 0.9383 - precision: 0.9855 - recall: 0.8900 - f1_score: 0.9340 - val_loss: 2.0514 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 216/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0285 - acc: 0.9383 - precision: 0.9850 - recall: 0.8838 - f1_score: 0.9308 - val_loss: 2.0421 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 217/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0192 - acc: 0.9383 - precision: 0.9865 - recall: 0.8868 - f1_score: 0.9328 - val_loss: 2.0328 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 218/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0099 - acc: 0.9383 - precision: 0.9866 - recall: 0.8863 - f1_score: 0.9330 - val_loss: 2.0236 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 219/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0006 - acc: 0.9383 - precision: 0.9835 - recall: 0.8864 - f1_score: 0.9308 - val_loss: 2.0144 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 220/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9915 - acc: 0.9383 - precision: 0.9861 - recall: 0.8891 - f1_score: 0.9336 - val_loss: 2.0053 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 221/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9824 - acc: 0.9383 - precision: 0.9862 - recall: 0.8850 - f1_score: 0.9317 - val_loss: 1.9962 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 222/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9733 - acc: 0.9383 - precision: 0.9854 - recall: 0.8867 - f1_score: 0.9325 - val_loss: 1.9872 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 223/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9642 - acc: 0.9383 - precision: 0.9870 - recall: 0.8857 - f1_score: 0.9324 - val_loss: 1.9782 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 224/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9552 - acc: 0.9383 - precision: 0.9857 - recall: 0.8888 - f1_score: 0.9329 - val_loss: 1.9692 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.9463 - acc: 0.9383 - precision: 0.9860 - recall: 0.8879 - f1_score: 0.9327 - val_loss: 1.9604 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 226/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9374 - acc: 0.9383 - precision: 0.9849 - recall: 0.8882 - f1_score: 0.9331 - val_loss: 1.9515 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 227/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9285 - acc: 0.9383 - precision: 0.9856 - recall: 0.8873 - f1_score: 0.9319 - val_loss: 1.9427 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 228/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9197 - acc: 0.9383 - precision: 0.9856 - recall: 0.8912 - f1_score: 0.9340 - val_loss: 1.9339 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 229/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9110 - acc: 0.9383 - precision: 0.9849 - recall: 0.8869 - f1_score: 0.9322 - val_loss: 1.9252 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 230/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9022 - acc: 0.9383 - precision: 0.9859 - recall: 0.8890 - f1_score: 0.9338 - val_loss: 1.9166 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 231/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8936 - acc: 0.9383 - precision: 0.9855 - recall: 0.8884 - f1_score: 0.9337 - val_loss: 1.9080 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 232/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8849 - acc: 0.9383 - precision: 0.9865 - recall: 0.8877 - f1_score: 0.9339 - val_loss: 1.8994 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 233/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8764 - acc: 0.9383 - precision: 0.9851 - recall: 0.8870 - f1_score: 0.9327 - val_loss: 1.8908 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 234/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8678 - acc: 0.9383 - precision: 0.9860 - recall: 0.8912 - f1_score: 0.9350 - val_loss: 1.8824 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 235/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8593 - acc: 0.9383 - precision: 0.9861 - recall: 0.8876 - f1_score: 0.9330 - val_loss: 1.8739 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 236/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8509 - acc: 0.9383 - precision: 0.9874 - recall: 0.8864 - f1_score: 0.9313 - val_loss: 1.8655 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 237/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8425 - acc: 0.9383 - precision: 0.9835 - recall: 0.8849 - f1_score: 0.9311 - val_loss: 1.8572 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 238/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8341 - acc: 0.9383 - precision: 0.9860 - recall: 0.8874 - f1_score: 0.9325 - val_loss: 1.8488 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 239/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8258 - acc: 0.9399 - precision: 0.9890 - recall: 0.8877 - f1_score: 0.9349 - val_loss: 1.8406 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 240/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8175 - acc: 0.9399 - precision: 0.9890 - recall: 0.8869 - f1_score: 0.9340 - val_loss: 1.8323 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 241/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8093 - acc: 0.9399 - precision: 0.9906 - recall: 0.8880 - f1_score: 0.9342 - val_loss: 1.8242 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 242/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8011 - acc: 0.9399 - precision: 0.9894 - recall: 0.8846 - f1_score: 0.9327 - val_loss: 1.8160 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 243/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7929 - acc: 0.9399 - precision: 0.9885 - recall: 0.8937 - f1_score: 0.9363 - val_loss: 1.8079 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 244/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7848 - acc: 0.9399 - precision: 0.9890 - recall: 0.8859 - f1_score: 0.9340 - val_loss: 1.7999 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 245/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7768 - acc: 0.9399 - precision: 0.9888 - recall: 0.8823 - f1_score: 0.9315 - val_loss: 1.7918 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 246/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7688 - acc: 0.9399 - precision: 0.9902 - recall: 0.8875 - f1_score: 0.9348 - val_loss: 1.7839 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 247/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7608 - acc: 0.9399 - precision: 0.9905 - recall: 0.8871 - f1_score: 0.9338 - val_loss: 1.7759 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 248/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7528 - acc: 0.9399 - precision: 0.9911 - recall: 0.8854 - f1_score: 0.9331 - val_loss: 1.7680 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 249/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7449 - acc: 0.9399 - precision: 0.9879 - recall: 0.8876 - f1_score: 0.9335 - val_loss: 1.7602 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 250/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7371 - acc: 0.9399 - precision: 0.9871 - recall: 0.8877 - f1_score: 0.9342 - val_loss: 1.7524 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 251/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7293 - acc: 0.9399 - precision: 0.9889 - recall: 0.8880 - f1_score: 0.9343 - val_loss: 1.7446 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 252/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7215 - acc: 0.9399 - precision: 0.9897 - recall: 0.8870 - f1_score: 0.9346 - val_loss: 1.7369 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 253/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7137 - acc: 0.9399 - precision: 0.9894 - recall: 0.8838 - f1_score: 0.9321 - val_loss: 1.7292 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 254/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7061 - acc: 0.9399 - precision: 0.9905 - recall: 0.8896 - f1_score: 0.9360 - val_loss: 1.7215 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 255/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6984 - acc: 0.9399 - precision: 0.9898 - recall: 0.8879 - f1_score: 0.9351 - val_loss: 1.7139 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 256/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6908 - acc: 0.9399 - precision: 0.9888 - recall: 0.8921 - f1_score: 0.9372 - val_loss: 1.7063 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.6832 - acc: 0.9399 - precision: 0.9897 - recall: 0.8864 - f1_score: 0.9343 - val_loss: 1.6988 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 258/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6757 - acc: 0.9399 - precision: 0.9894 - recall: 0.8859 - f1_score: 0.9342 - val_loss: 1.6913 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 259/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6682 - acc: 0.9399 - precision: 0.9891 - recall: 0.8875 - f1_score: 0.9349 - val_loss: 1.6839 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 260/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6607 - acc: 0.9399 - precision: 0.9901 - recall: 0.8896 - f1_score: 0.9353 - val_loss: 1.6764 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 261/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6533 - acc: 0.9399 - precision: 0.9887 - recall: 0.8883 - f1_score: 0.9342 - val_loss: 1.6691 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 262/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6459 - acc: 0.9399 - precision: 0.9889 - recall: 0.8890 - f1_score: 0.9349 - val_loss: 1.6617 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 263/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6386 - acc: 0.9399 - precision: 0.9892 - recall: 0.8895 - f1_score: 0.9358 - val_loss: 1.6544 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 264/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6313 - acc: 0.9399 - precision: 0.9893 - recall: 0.8900 - f1_score: 0.9357 - val_loss: 1.6471 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 265/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6240 - acc: 0.9399 - precision: 0.9901 - recall: 0.8866 - f1_score: 0.9348 - val_loss: 1.6399 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 266/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6168 - acc: 0.9399 - precision: 0.9872 - recall: 0.8888 - f1_score: 0.9338 - val_loss: 1.6327 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 267/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6096 - acc: 0.9399 - precision: 0.9882 - recall: 0.8856 - f1_score: 0.9325 - val_loss: 1.6256 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 268/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6024 - acc: 0.9399 - precision: 0.9875 - recall: 0.8912 - f1_score: 0.9354 - val_loss: 1.6185 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 269/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5953 - acc: 0.9399 - precision: 0.9872 - recall: 0.8837 - f1_score: 0.9311 - val_loss: 1.6114 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 270/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5882 - acc: 0.9399 - precision: 0.9906 - recall: 0.8872 - f1_score: 0.9354 - val_loss: 1.6043 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 271/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5812 - acc: 0.9399 - precision: 0.9899 - recall: 0.8877 - f1_score: 0.9356 - val_loss: 1.5973 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 272/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5742 - acc: 0.9399 - precision: 0.9897 - recall: 0.8862 - f1_score: 0.9338 - val_loss: 1.5904 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 273/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5672 - acc: 0.9399 - precision: 0.9897 - recall: 0.8834 - f1_score: 0.9323 - val_loss: 1.5834 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 274/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5603 - acc: 0.9399 - precision: 0.9901 - recall: 0.8891 - f1_score: 0.9360 - val_loss: 1.5765 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 275/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5534 - acc: 0.9399 - precision: 0.9902 - recall: 0.8854 - f1_score: 0.9330 - val_loss: 1.5697 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 276/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5465 - acc: 0.9399 - precision: 0.9893 - recall: 0.8875 - f1_score: 0.9343 - val_loss: 1.5628 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 277/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5397 - acc: 0.9399 - precision: 0.9873 - recall: 0.8874 - f1_score: 0.9339 - val_loss: 1.5560 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 278/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5329 - acc: 0.9399 - precision: 0.9904 - recall: 0.8883 - f1_score: 0.9351 - val_loss: 1.5493 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 279/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5261 - acc: 0.9399 - precision: 0.9895 - recall: 0.8929 - f1_score: 0.9373 - val_loss: 1.5426 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 280/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5194 - acc: 0.9399 - precision: 0.9892 - recall: 0.8887 - f1_score: 0.9353 - val_loss: 1.5359 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 281/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5127 - acc: 0.9399 - precision: 0.9906 - recall: 0.8898 - f1_score: 0.9366 - val_loss: 1.5292 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 282/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5060 - acc: 0.9399 - precision: 0.9888 - recall: 0.8908 - f1_score: 0.9358 - val_loss: 1.5226 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 283/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4994 - acc: 0.9399 - precision: 0.9883 - recall: 0.8897 - f1_score: 0.9351 - val_loss: 1.5160 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 284/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4928 - acc: 0.9399 - precision: 0.9898 - recall: 0.8918 - f1_score: 0.9364 - val_loss: 1.5095 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 285/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4863 - acc: 0.9399 - precision: 0.9882 - recall: 0.8863 - f1_score: 0.9331 - val_loss: 1.5029 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 286/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4797 - acc: 0.9399 - precision: 0.9878 - recall: 0.8865 - f1_score: 0.9323 - val_loss: 1.4964 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 287/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4733 - acc: 0.9399 - precision: 0.9900 - recall: 0.8873 - f1_score: 0.9335 - val_loss: 1.4900 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 288/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4668 - acc: 0.9399 - precision: 0.9893 - recall: 0.8855 - f1_score: 0.9339 - val_loss: 1.4836 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.4604 - acc: 0.9415 - precision: 0.9909 - recall: 0.8937 - f1_score: 0.9384 - val_loss: 1.4772 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 290/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4540 - acc: 0.9415 - precision: 0.9905 - recall: 0.8908 - f1_score: 0.9374 - val_loss: 1.4708 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 291/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4477 - acc: 0.9415 - precision: 0.9890 - recall: 0.8901 - f1_score: 0.9358 - val_loss: 1.4645 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 292/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4413 - acc: 0.9415 - precision: 0.9895 - recall: 0.8921 - f1_score: 0.9374 - val_loss: 1.4582 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 293/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4351 - acc: 0.9415 - precision: 0.9893 - recall: 0.8899 - f1_score: 0.9358 - val_loss: 1.4520 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 294/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4288 - acc: 0.9415 - precision: 0.9905 - recall: 0.8901 - f1_score: 0.9357 - val_loss: 1.4458 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 295/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4226 - acc: 0.9430 - precision: 0.9899 - recall: 0.8962 - f1_score: 0.9402 - val_loss: 1.4396 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 296/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4164 - acc: 0.9430 - precision: 0.9896 - recall: 0.8930 - f1_score: 0.9374 - val_loss: 1.4334 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 297/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4102 - acc: 0.9430 - precision: 0.9901 - recall: 0.8950 - f1_score: 0.9393 - val_loss: 1.4273 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 298/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4041 - acc: 0.9430 - precision: 0.9893 - recall: 0.8974 - f1_score: 0.9399 - val_loss: 1.4212 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 299/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3980 - acc: 0.9430 - precision: 0.9902 - recall: 0.8929 - f1_score: 0.9378 - val_loss: 1.4152 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 300/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3919 - acc: 0.9430 - precision: 0.9898 - recall: 0.8897 - f1_score: 0.9350 - val_loss: 1.4091 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 301/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3859 - acc: 0.9430 - precision: 0.9903 - recall: 0.8946 - f1_score: 0.9390 - val_loss: 1.4031 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 302/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3799 - acc: 0.9430 - precision: 0.9892 - recall: 0.8954 - f1_score: 0.9394 - val_loss: 1.3972 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 303/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3739 - acc: 0.9430 - precision: 0.9876 - recall: 0.8941 - f1_score: 0.9378 - val_loss: 1.3912 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 304/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3680 - acc: 0.9430 - precision: 0.9899 - recall: 0.8930 - f1_score: 0.9376 - val_loss: 1.3853 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 305/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3621 - acc: 0.9430 - precision: 0.9909 - recall: 0.8922 - f1_score: 0.9381 - val_loss: 1.3794 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 306/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3562 - acc: 0.9430 - precision: 0.9904 - recall: 0.8954 - f1_score: 0.9397 - val_loss: 1.3736 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 307/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3504 - acc: 0.9430 - precision: 0.9889 - recall: 0.8958 - f1_score: 0.9389 - val_loss: 1.3678 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 308/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3445 - acc: 0.9430 - precision: 0.9896 - recall: 0.8942 - f1_score: 0.9372 - val_loss: 1.3620 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 309/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3388 - acc: 0.9430 - precision: 0.9890 - recall: 0.8957 - f1_score: 0.9385 - val_loss: 1.3562 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 310/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3330 - acc: 0.9430 - precision: 0.9901 - recall: 0.8935 - f1_score: 0.9387 - val_loss: 1.3505 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 311/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3273 - acc: 0.9430 - precision: 0.9877 - recall: 0.8897 - f1_score: 0.9353 - val_loss: 1.3448 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 312/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3216 - acc: 0.9430 - precision: 0.9912 - recall: 0.8942 - f1_score: 0.9391 - val_loss: 1.3391 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 313/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3159 - acc: 0.9430 - precision: 0.9897 - recall: 0.8938 - f1_score: 0.9379 - val_loss: 1.3335 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 314/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3103 - acc: 0.9430 - precision: 0.9895 - recall: 0.8921 - f1_score: 0.9376 - val_loss: 1.3279 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 315/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3046 - acc: 0.9430 - precision: 0.9901 - recall: 0.8951 - f1_score: 0.9395 - val_loss: 1.3223 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 316/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2991 - acc: 0.9430 - precision: 0.9880 - recall: 0.8967 - f1_score: 0.9396 - val_loss: 1.3167 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 317/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2935 - acc: 0.9430 - precision: 0.9901 - recall: 0.8935 - f1_score: 0.9382 - val_loss: 1.3112 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 318/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2880 - acc: 0.9430 - precision: 0.9903 - recall: 0.8930 - f1_score: 0.9381 - val_loss: 1.3057 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 319/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2825 - acc: 0.9430 - precision: 0.9901 - recall: 0.8956 - f1_score: 0.9392 - val_loss: 1.3002 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 320/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2770 - acc: 0.9430 - precision: 0.9885 - recall: 0.8935 - f1_score: 0.9378 - val_loss: 1.2948 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.2716 - acc: 0.9430 - precision: 0.9900 - recall: 0.8908 - f1_score: 0.9361 - val_loss: 1.2894 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 322/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2662 - acc: 0.9430 - precision: 0.9900 - recall: 0.8932 - f1_score: 0.9383 - val_loss: 1.2840 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 323/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2608 - acc: 0.9430 - precision: 0.9896 - recall: 0.9012 - f1_score: 0.9421 - val_loss: 1.2787 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 324/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2554 - acc: 0.9430 - precision: 0.9902 - recall: 0.8964 - f1_score: 0.9398 - val_loss: 1.2733 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 325/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2501 - acc: 0.9430 - precision: 0.9892 - recall: 0.8953 - f1_score: 0.9387 - val_loss: 1.2680 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 326/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2448 - acc: 0.9430 - precision: 0.9894 - recall: 0.8909 - f1_score: 0.9363 - val_loss: 1.2627 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 327/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2395 - acc: 0.9430 - precision: 0.9895 - recall: 0.8961 - f1_score: 0.9398 - val_loss: 1.2575 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 328/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2342 - acc: 0.9430 - precision: 0.9908 - recall: 0.8951 - f1_score: 0.9399 - val_loss: 1.2523 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 329/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2290 - acc: 0.9430 - precision: 0.9890 - recall: 0.8938 - f1_score: 0.9382 - val_loss: 1.2471 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 330/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2238 - acc: 0.9430 - precision: 0.9912 - recall: 0.8942 - f1_score: 0.9394 - val_loss: 1.2419 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 331/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2187 - acc: 0.9430 - precision: 0.9900 - recall: 0.8897 - f1_score: 0.9354 - val_loss: 1.2368 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 332/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2135 - acc: 0.9430 - precision: 0.9898 - recall: 0.8925 - f1_score: 0.9378 - val_loss: 1.2317 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 333/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2084 - acc: 0.9430 - precision: 0.9902 - recall: 0.8929 - f1_score: 0.9378 - val_loss: 1.2266 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 334/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2033 - acc: 0.9430 - precision: 0.9904 - recall: 0.8962 - f1_score: 0.9396 - val_loss: 1.2215 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 335/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1983 - acc: 0.9430 - precision: 0.9868 - recall: 0.9010 - f1_score: 0.9406 - val_loss: 1.2165 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 336/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1932 - acc: 0.9430 - precision: 0.9885 - recall: 0.8937 - f1_score: 0.9376 - val_loss: 1.2115 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 337/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1882 - acc: 0.9430 - precision: 0.9883 - recall: 0.8954 - f1_score: 0.9389 - val_loss: 1.2065 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 338/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1832 - acc: 0.9430 - precision: 0.9888 - recall: 0.8924 - f1_score: 0.9373 - val_loss: 1.2015 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 339/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1782 - acc: 0.9430 - precision: 0.9896 - recall: 0.8906 - f1_score: 0.9366 - val_loss: 1.1966 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 340/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1733 - acc: 0.9430 - precision: 0.9887 - recall: 0.8985 - f1_score: 0.9402 - val_loss: 1.1917 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 341/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1684 - acc: 0.9430 - precision: 0.9907 - recall: 0.8958 - f1_score: 0.9397 - val_loss: 1.1868 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 342/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1635 - acc: 0.9430 - precision: 0.9909 - recall: 0.8918 - f1_score: 0.9375 - val_loss: 1.1819 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 343/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1587 - acc: 0.9430 - precision: 0.9906 - recall: 0.8966 - f1_score: 0.9404 - val_loss: 1.1771 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 344/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1538 - acc: 0.9430 - precision: 0.9880 - recall: 0.8861 - f1_score: 0.9326 - val_loss: 1.1723 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 345/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1490 - acc: 0.9430 - precision: 0.9911 - recall: 0.8916 - f1_score: 0.9364 - val_loss: 1.1675 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 346/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1442 - acc: 0.9430 - precision: 0.9896 - recall: 0.8979 - f1_score: 0.9388 - val_loss: 1.1628 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 347/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1395 - acc: 0.9430 - precision: 0.9875 - recall: 0.9015 - f1_score: 0.9410 - val_loss: 1.1580 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 348/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1347 - acc: 0.9430 - precision: 0.9912 - recall: 0.8913 - f1_score: 0.9356 - val_loss: 1.1533 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 349/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1300 - acc: 0.9430 - precision: 0.9895 - recall: 0.8932 - f1_score: 0.9378 - val_loss: 1.1486 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 350/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1253 - acc: 0.9430 - precision: 0.9900 - recall: 0.8949 - f1_score: 0.9388 - val_loss: 1.1440 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 351/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1206 - acc: 0.9430 - precision: 0.9898 - recall: 0.8885 - f1_score: 0.9348 - val_loss: 1.1393 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 352/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1160 - acc: 0.9430 - precision: 0.9899 - recall: 0.8951 - f1_score: 0.9392 - val_loss: 1.1347 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.1114 - acc: 0.9430 - precision: 0.9894 - recall: 0.8909 - f1_score: 0.9363 - val_loss: 1.1301 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 354/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1068 - acc: 0.9430 - precision: 0.9897 - recall: 0.8942 - f1_score: 0.9386 - val_loss: 1.1255 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 355/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1022 - acc: 0.9430 - precision: 0.9899 - recall: 0.8950 - f1_score: 0.9388 - val_loss: 1.1210 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 356/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0977 - acc: 0.9430 - precision: 0.9885 - recall: 0.8967 - f1_score: 0.9394 - val_loss: 1.1165 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 357/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0931 - acc: 0.9430 - precision: 0.9882 - recall: 0.8931 - f1_score: 0.9375 - val_loss: 1.1120 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 358/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0886 - acc: 0.9430 - precision: 0.9895 - recall: 0.8933 - f1_score: 0.9382 - val_loss: 1.1075 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 359/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0842 - acc: 0.9430 - precision: 0.9897 - recall: 0.8897 - f1_score: 0.9352 - val_loss: 1.1030 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 360/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0797 - acc: 0.9430 - precision: 0.9891 - recall: 0.8917 - f1_score: 0.9354 - val_loss: 1.0986 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 361/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0753 - acc: 0.9430 - precision: 0.9891 - recall: 0.8939 - f1_score: 0.9384 - val_loss: 1.0942 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 362/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0709 - acc: 0.9430 - precision: 0.9883 - recall: 0.8941 - f1_score: 0.9376 - val_loss: 1.0898 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 363/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0665 - acc: 0.9430 - precision: 0.9895 - recall: 0.8963 - f1_score: 0.9389 - val_loss: 1.0854 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 364/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0621 - acc: 0.9430 - precision: 0.9898 - recall: 0.8900 - f1_score: 0.9351 - val_loss: 1.0811 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 365/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0578 - acc: 0.9446 - precision: 0.9896 - recall: 0.8949 - f1_score: 0.9386 - val_loss: 1.0768 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 366/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0534 - acc: 0.9446 - precision: 0.9892 - recall: 0.8996 - f1_score: 0.9415 - val_loss: 1.0725 - val_acc: 0.9371 - val_precision: 1.0000 - val_recall: 0.8752 - val_f1_score: 0.9329\n",
      "Epoch 367/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0491 - acc: 0.9446 - precision: 0.9891 - recall: 0.8962 - f1_score: 0.9397 - val_loss: 1.0682 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 368/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0449 - acc: 0.9446 - precision: 0.9899 - recall: 0.8943 - f1_score: 0.9388 - val_loss: 1.0640 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 369/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0406 - acc: 0.9446 - precision: 0.9892 - recall: 0.8952 - f1_score: 0.9387 - val_loss: 1.0597 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 370/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0364 - acc: 0.9446 - precision: 0.9906 - recall: 0.8976 - f1_score: 0.9408 - val_loss: 1.0555 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 371/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0322 - acc: 0.9446 - precision: 0.9905 - recall: 0.8982 - f1_score: 0.9401 - val_loss: 1.0513 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 372/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0280 - acc: 0.9446 - precision: 0.9906 - recall: 0.8945 - f1_score: 0.9391 - val_loss: 1.0472 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 373/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0238 - acc: 0.9446 - precision: 0.9909 - recall: 0.8942 - f1_score: 0.9375 - val_loss: 1.0430 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 374/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0197 - acc: 0.9446 - precision: 0.9901 - recall: 0.8998 - f1_score: 0.9416 - val_loss: 1.0389 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 375/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0155 - acc: 0.9446 - precision: 0.9885 - recall: 0.8943 - f1_score: 0.9383 - val_loss: 1.0348 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 376/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0114 - acc: 0.9446 - precision: 0.9894 - recall: 0.8959 - f1_score: 0.9392 - val_loss: 1.0307 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 377/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0073 - acc: 0.9446 - precision: 0.9891 - recall: 0.8985 - f1_score: 0.9409 - val_loss: 1.0266 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 378/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0033 - acc: 0.9446 - precision: 0.9903 - recall: 0.8975 - f1_score: 0.9397 - val_loss: 1.0226 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 379/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9992 - acc: 0.9446 - precision: 0.9893 - recall: 0.8998 - f1_score: 0.9416 - val_loss: 1.0186 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 380/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9952 - acc: 0.9446 - precision: 0.9909 - recall: 0.8960 - f1_score: 0.9402 - val_loss: 1.0146 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 381/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9912 - acc: 0.9446 - precision: 0.9880 - recall: 0.8978 - f1_score: 0.9397 - val_loss: 1.0106 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 382/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9872 - acc: 0.9446 - precision: 0.9895 - recall: 0.8966 - f1_score: 0.9400 - val_loss: 1.0066 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 383/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9833 - acc: 0.9446 - precision: 0.9881 - recall: 0.8954 - f1_score: 0.9381 - val_loss: 1.0027 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 384/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9793 - acc: 0.9446 - precision: 0.9890 - recall: 0.8935 - f1_score: 0.9377 - val_loss: 0.9988 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.9754 - acc: 0.9446 - precision: 0.9892 - recall: 0.8986 - f1_score: 0.9410 - val_loss: 0.9949 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 386/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9715 - acc: 0.9446 - precision: 0.9900 - recall: 0.8967 - f1_score: 0.9397 - val_loss: 0.9910 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 387/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9676 - acc: 0.9446 - precision: 0.9892 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 0.9871 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 388/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9637 - acc: 0.9446 - precision: 0.9891 - recall: 0.8962 - f1_score: 0.9393 - val_loss: 0.9833 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 389/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9599 - acc: 0.9446 - precision: 0.9900 - recall: 0.8986 - f1_score: 0.9407 - val_loss: 0.9795 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 390/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9561 - acc: 0.9446 - precision: 0.9910 - recall: 0.8940 - f1_score: 0.9386 - val_loss: 0.9757 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 391/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9523 - acc: 0.9446 - precision: 0.9895 - recall: 0.8996 - f1_score: 0.9406 - val_loss: 0.9719 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 392/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9485 - acc: 0.9446 - precision: 0.9899 - recall: 0.8972 - f1_score: 0.9399 - val_loss: 0.9681 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 393/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9447 - acc: 0.9446 - precision: 0.9873 - recall: 0.8958 - f1_score: 0.9384 - val_loss: 0.9644 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 394/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9410 - acc: 0.9446 - precision: 0.9888 - recall: 0.8974 - f1_score: 0.9393 - val_loss: 0.9606 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 395/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9372 - acc: 0.9446 - precision: 0.9898 - recall: 0.8968 - f1_score: 0.9401 - val_loss: 0.9569 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 396/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9335 - acc: 0.9446 - precision: 0.9875 - recall: 0.9015 - f1_score: 0.9411 - val_loss: 0.9532 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 397/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9298 - acc: 0.9446 - precision: 0.9896 - recall: 0.8993 - f1_score: 0.9417 - val_loss: 0.9496 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 398/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9262 - acc: 0.9446 - precision: 0.9893 - recall: 0.8963 - f1_score: 0.9389 - val_loss: 0.9459 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 399/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9225 - acc: 0.9446 - precision: 0.9905 - recall: 0.8984 - f1_score: 0.9409 - val_loss: 0.9423 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 400/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9189 - acc: 0.9446 - precision: 0.9878 - recall: 0.8953 - f1_score: 0.9382 - val_loss: 0.9387 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 401/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9153 - acc: 0.9446 - precision: 0.9899 - recall: 0.8950 - f1_score: 0.9386 - val_loss: 0.9351 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 402/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9117 - acc: 0.9446 - precision: 0.9902 - recall: 0.8986 - f1_score: 0.9403 - val_loss: 0.9315 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 403/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9081 - acc: 0.9446 - precision: 0.9900 - recall: 0.8952 - f1_score: 0.9397 - val_loss: 0.9279 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 404/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9045 - acc: 0.9446 - precision: 0.9891 - recall: 0.8947 - f1_score: 0.9389 - val_loss: 0.9244 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 405/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9010 - acc: 0.9446 - precision: 0.9893 - recall: 0.8970 - f1_score: 0.9402 - val_loss: 0.9209 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 406/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8975 - acc: 0.9446 - precision: 0.9897 - recall: 0.8976 - f1_score: 0.9404 - val_loss: 0.9174 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 407/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8939 - acc: 0.9446 - precision: 0.9904 - recall: 0.8931 - f1_score: 0.9383 - val_loss: 0.9139 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 408/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8905 - acc: 0.9446 - precision: 0.9892 - recall: 0.9006 - f1_score: 0.9411 - val_loss: 0.9104 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 409/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8870 - acc: 0.9446 - precision: 0.9889 - recall: 0.8934 - f1_score: 0.9378 - val_loss: 0.9070 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 410/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8835 - acc: 0.9446 - precision: 0.9901 - recall: 0.8958 - f1_score: 0.9388 - val_loss: 0.9035 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 411/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8801 - acc: 0.9446 - precision: 0.9882 - recall: 0.8954 - f1_score: 0.9385 - val_loss: 0.9001 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 412/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8767 - acc: 0.9446 - precision: 0.9897 - recall: 0.8922 - f1_score: 0.9371 - val_loss: 0.8967 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 413/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8733 - acc: 0.9446 - precision: 0.9888 - recall: 0.8995 - f1_score: 0.9407 - val_loss: 0.8933 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 414/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8699 - acc: 0.9446 - precision: 0.9889 - recall: 0.8990 - f1_score: 0.9407 - val_loss: 0.8900 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 415/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8665 - acc: 0.9462 - precision: 0.9886 - recall: 0.8975 - f1_score: 0.9403 - val_loss: 0.8866 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 416/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8632 - acc: 0.9446 - precision: 0.9891 - recall: 0.9049 - f1_score: 0.9439 - val_loss: 0.8833 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 417/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.8598 - acc: 0.9446 - precision: 0.9898 - recall: 0.8990 - f1_score: 0.9414 - val_loss: 0.8800 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 418/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8565 - acc: 0.9462 - precision: 0.9890 - recall: 0.9014 - f1_score: 0.9424 - val_loss: 0.8767 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 419/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8532 - acc: 0.9462 - precision: 0.9898 - recall: 0.8999 - f1_score: 0.9419 - val_loss: 0.8734 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 420/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8499 - acc: 0.9462 - precision: 0.9887 - recall: 0.8996 - f1_score: 0.9410 - val_loss: 0.8701 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 421/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8467 - acc: 0.9462 - precision: 0.9910 - recall: 0.8998 - f1_score: 0.9413 - val_loss: 0.8669 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 422/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8434 - acc: 0.9462 - precision: 0.9894 - recall: 0.9006 - f1_score: 0.9421 - val_loss: 0.8636 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 423/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8402 - acc: 0.9462 - precision: 0.9905 - recall: 0.8994 - f1_score: 0.9417 - val_loss: 0.8604 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 424/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8370 - acc: 0.9462 - precision: 0.9891 - recall: 0.9004 - f1_score: 0.9420 - val_loss: 0.8572 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 425/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8338 - acc: 0.9462 - precision: 0.9893 - recall: 0.8989 - f1_score: 0.9411 - val_loss: 0.8540 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 426/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8306 - acc: 0.9462 - precision: 0.9883 - recall: 0.8991 - f1_score: 0.9408 - val_loss: 0.8509 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 427/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8274 - acc: 0.9462 - precision: 0.9895 - recall: 0.9004 - f1_score: 0.9416 - val_loss: 0.8477 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 428/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8243 - acc: 0.9462 - precision: 0.9912 - recall: 0.9017 - f1_score: 0.9429 - val_loss: 0.8446 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 429/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8211 - acc: 0.9462 - precision: 0.9908 - recall: 0.9031 - f1_score: 0.9435 - val_loss: 0.8415 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 430/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8180 - acc: 0.9462 - precision: 0.9902 - recall: 0.9050 - f1_score: 0.9447 - val_loss: 0.8384 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 431/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8149 - acc: 0.9462 - precision: 0.9897 - recall: 0.9005 - f1_score: 0.9413 - val_loss: 0.8353 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 432/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8118 - acc: 0.9462 - precision: 0.9898 - recall: 0.9026 - f1_score: 0.9435 - val_loss: 0.8322 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 433/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8087 - acc: 0.9462 - precision: 0.9885 - recall: 0.9033 - f1_score: 0.9430 - val_loss: 0.8291 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 434/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8057 - acc: 0.9462 - precision: 0.9892 - recall: 0.9005 - f1_score: 0.9419 - val_loss: 0.8261 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 435/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8026 - acc: 0.9462 - precision: 0.9910 - recall: 0.9016 - f1_score: 0.9423 - val_loss: 0.8231 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 436/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7996 - acc: 0.9462 - precision: 0.9901 - recall: 0.9018 - f1_score: 0.9428 - val_loss: 0.8201 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 437/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7966 - acc: 0.9462 - precision: 0.9899 - recall: 0.9046 - f1_score: 0.9435 - val_loss: 0.8171 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 438/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7936 - acc: 0.9462 - precision: 0.9890 - recall: 0.8996 - f1_score: 0.9415 - val_loss: 0.8141 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 439/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7906 - acc: 0.9462 - precision: 0.9884 - recall: 0.9054 - f1_score: 0.9437 - val_loss: 0.8111 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 440/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7877 - acc: 0.9462 - precision: 0.9883 - recall: 0.8974 - f1_score: 0.9394 - val_loss: 0.8082 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 441/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7847 - acc: 0.9462 - precision: 0.9897 - recall: 0.9014 - f1_score: 0.9432 - val_loss: 0.8052 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 442/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7818 - acc: 0.9462 - precision: 0.9906 - recall: 0.9009 - f1_score: 0.9424 - val_loss: 0.8023 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 443/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7788 - acc: 0.9462 - precision: 0.9887 - recall: 0.9012 - f1_score: 0.9423 - val_loss: 0.7994 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 444/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7759 - acc: 0.9462 - precision: 0.9904 - recall: 0.9018 - f1_score: 0.9421 - val_loss: 0.7965 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 445/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7730 - acc: 0.9462 - precision: 0.9887 - recall: 0.9011 - f1_score: 0.9418 - val_loss: 0.7937 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 446/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7702 - acc: 0.9462 - precision: 0.9889 - recall: 0.8986 - f1_score: 0.9404 - val_loss: 0.7908 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 447/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7673 - acc: 0.9462 - precision: 0.9897 - recall: 0.9022 - f1_score: 0.9432 - val_loss: 0.7879 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 448/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7644 - acc: 0.9462 - precision: 0.9896 - recall: 0.8996 - f1_score: 0.9413 - val_loss: 0.7851 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.7616 - acc: 0.9462 - precision: 0.9883 - recall: 0.8986 - f1_score: 0.9406 - val_loss: 0.7823 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 450/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7588 - acc: 0.9462 - precision: 0.9887 - recall: 0.9027 - f1_score: 0.9431 - val_loss: 0.7795 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 451/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7560 - acc: 0.9462 - precision: 0.9886 - recall: 0.9004 - f1_score: 0.9407 - val_loss: 0.7767 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 452/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7532 - acc: 0.9462 - precision: 0.9896 - recall: 0.9003 - f1_score: 0.9422 - val_loss: 0.7739 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 453/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7504 - acc: 0.9462 - precision: 0.9890 - recall: 0.9012 - f1_score: 0.9423 - val_loss: 0.7712 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 454/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7476 - acc: 0.9462 - precision: 0.9895 - recall: 0.8990 - f1_score: 0.9410 - val_loss: 0.7684 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 455/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7449 - acc: 0.9462 - precision: 0.9885 - recall: 0.9041 - f1_score: 0.9425 - val_loss: 0.7657 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 456/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7422 - acc: 0.9462 - precision: 0.9895 - recall: 0.9038 - f1_score: 0.9437 - val_loss: 0.7630 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 457/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7394 - acc: 0.9462 - precision: 0.9881 - recall: 0.9003 - f1_score: 0.9415 - val_loss: 0.7603 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 458/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7367 - acc: 0.9462 - precision: 0.9896 - recall: 0.8997 - f1_score: 0.9409 - val_loss: 0.7576 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 459/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7340 - acc: 0.9462 - precision: 0.9902 - recall: 0.8973 - f1_score: 0.9406 - val_loss: 0.7549 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 460/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7313 - acc: 0.9462 - precision: 0.9875 - recall: 0.9000 - f1_score: 0.9409 - val_loss: 0.7522 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 461/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7287 - acc: 0.9462 - precision: 0.9902 - recall: 0.8995 - f1_score: 0.9416 - val_loss: 0.7496 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 462/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7260 - acc: 0.9462 - precision: 0.9894 - recall: 0.8977 - f1_score: 0.9402 - val_loss: 0.7469 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 463/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7234 - acc: 0.9462 - precision: 0.9899 - recall: 0.9023 - f1_score: 0.9426 - val_loss: 0.7443 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 464/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7207 - acc: 0.9462 - precision: 0.9895 - recall: 0.9011 - f1_score: 0.9424 - val_loss: 0.7417 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 465/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7181 - acc: 0.9462 - precision: 0.9905 - recall: 0.8989 - f1_score: 0.9414 - val_loss: 0.7391 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 466/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7155 - acc: 0.9462 - precision: 0.9908 - recall: 0.9023 - f1_score: 0.9437 - val_loss: 0.7365 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 467/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7129 - acc: 0.9462 - precision: 0.9895 - recall: 0.9006 - f1_score: 0.9422 - val_loss: 0.7339 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 468/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7104 - acc: 0.9462 - precision: 0.9901 - recall: 0.9006 - f1_score: 0.9418 - val_loss: 0.7314 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 469/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7078 - acc: 0.9462 - precision: 0.9871 - recall: 0.9071 - f1_score: 0.9432 - val_loss: 0.7288 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 470/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7052 - acc: 0.9462 - precision: 0.9900 - recall: 0.9006 - f1_score: 0.9423 - val_loss: 0.7263 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 471/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7027 - acc: 0.9462 - precision: 0.9909 - recall: 0.9001 - f1_score: 0.9420 - val_loss: 0.7238 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 472/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7002 - acc: 0.9462 - precision: 0.9901 - recall: 0.9009 - f1_score: 0.9429 - val_loss: 0.7212 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 473/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6977 - acc: 0.9462 - precision: 0.9887 - recall: 0.9016 - f1_score: 0.9422 - val_loss: 0.7187 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 474/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6952 - acc: 0.9462 - precision: 0.9891 - recall: 0.9004 - f1_score: 0.9417 - val_loss: 0.7163 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 475/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6927 - acc: 0.9462 - precision: 0.9897 - recall: 0.9017 - f1_score: 0.9421 - val_loss: 0.7138 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 476/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6902 - acc: 0.9462 - precision: 0.9900 - recall: 0.8979 - f1_score: 0.9401 - val_loss: 0.7113 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 477/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6877 - acc: 0.9462 - precision: 0.9894 - recall: 0.8982 - f1_score: 0.9410 - val_loss: 0.7089 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 478/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6853 - acc: 0.9462 - precision: 0.9901 - recall: 0.9004 - f1_score: 0.9419 - val_loss: 0.7064 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 479/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6829 - acc: 0.9462 - precision: 0.9901 - recall: 0.8961 - f1_score: 0.9398 - val_loss: 0.7040 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 480/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6804 - acc: 0.9462 - precision: 0.9889 - recall: 0.9026 - f1_score: 0.9429 - val_loss: 0.7016 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6780 - acc: 0.9462 - precision: 0.9898 - recall: 0.8992 - f1_score: 0.9409 - val_loss: 0.6992 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 482/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6756 - acc: 0.9462 - precision: 0.9908 - recall: 0.8974 - f1_score: 0.9406 - val_loss: 0.6968 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 483/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6732 - acc: 0.9462 - precision: 0.9894 - recall: 0.8991 - f1_score: 0.9409 - val_loss: 0.6945 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 484/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6708 - acc: 0.9462 - precision: 0.9903 - recall: 0.8996 - f1_score: 0.9415 - val_loss: 0.6921 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 485/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6685 - acc: 0.9462 - precision: 0.9883 - recall: 0.8981 - f1_score: 0.9391 - val_loss: 0.6897 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 486/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6661 - acc: 0.9462 - precision: 0.9897 - recall: 0.9003 - f1_score: 0.9418 - val_loss: 0.6874 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 487/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6638 - acc: 0.9462 - precision: 0.9896 - recall: 0.9022 - f1_score: 0.9429 - val_loss: 0.6851 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 488/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6614 - acc: 0.9462 - precision: 0.9902 - recall: 0.8990 - f1_score: 0.9421 - val_loss: 0.6828 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 489/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6591 - acc: 0.9462 - precision: 0.9890 - recall: 0.9017 - f1_score: 0.9426 - val_loss: 0.6805 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 490/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6568 - acc: 0.9462 - precision: 0.9904 - recall: 0.8998 - f1_score: 0.9421 - val_loss: 0.6782 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 491/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6545 - acc: 0.9462 - precision: 0.9898 - recall: 0.9020 - f1_score: 0.9428 - val_loss: 0.6759 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 492/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6522 - acc: 0.9462 - precision: 0.9901 - recall: 0.9015 - f1_score: 0.9412 - val_loss: 0.6736 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 493/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6500 - acc: 0.9462 - precision: 0.9897 - recall: 0.9005 - f1_score: 0.9418 - val_loss: 0.6713 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 494/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6477 - acc: 0.9462 - precision: 0.9893 - recall: 0.9001 - f1_score: 0.9416 - val_loss: 0.6691 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 495/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6455 - acc: 0.9462 - precision: 0.9898 - recall: 0.9024 - f1_score: 0.9429 - val_loss: 0.6669 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 496/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6432 - acc: 0.9462 - precision: 0.9901 - recall: 0.9015 - f1_score: 0.9433 - val_loss: 0.6646 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 497/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6410 - acc: 0.9462 - precision: 0.9868 - recall: 0.8936 - f1_score: 0.9372 - val_loss: 0.6624 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 498/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6388 - acc: 0.9462 - precision: 0.9899 - recall: 0.8967 - f1_score: 0.9401 - val_loss: 0.6602 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 499/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6366 - acc: 0.9462 - precision: 0.9892 - recall: 0.8948 - f1_score: 0.9378 - val_loss: 0.6580 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 500/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6344 - acc: 0.9462 - precision: 0.9899 - recall: 0.8982 - f1_score: 0.9408 - val_loss: 0.6559 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 501/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6322 - acc: 0.9462 - precision: 0.9907 - recall: 0.8985 - f1_score: 0.9402 - val_loss: 0.6537 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 502/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6300 - acc: 0.9462 - precision: 0.9889 - recall: 0.9038 - f1_score: 0.9435 - val_loss: 0.6515 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 503/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6278 - acc: 0.9462 - precision: 0.9885 - recall: 0.8999 - f1_score: 0.9416 - val_loss: 0.6494 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 504/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6257 - acc: 0.9462 - precision: 0.9884 - recall: 0.9036 - f1_score: 0.9433 - val_loss: 0.6472 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 505/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6235 - acc: 0.9462 - precision: 0.9897 - recall: 0.8978 - f1_score: 0.9393 - val_loss: 0.6451 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 506/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6214 - acc: 0.9462 - precision: 0.9894 - recall: 0.9023 - f1_score: 0.9422 - val_loss: 0.6430 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 507/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6193 - acc: 0.9462 - precision: 0.9887 - recall: 0.8996 - f1_score: 0.9417 - val_loss: 0.6409 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 508/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6172 - acc: 0.9462 - precision: 0.9899 - recall: 0.9056 - f1_score: 0.9444 - val_loss: 0.6388 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 509/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6151 - acc: 0.9462 - precision: 0.9887 - recall: 0.8977 - f1_score: 0.9396 - val_loss: 0.6367 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 510/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6130 - acc: 0.9462 - precision: 0.9896 - recall: 0.9015 - f1_score: 0.9426 - val_loss: 0.6346 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 511/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6109 - acc: 0.9462 - precision: 0.9887 - recall: 0.9008 - f1_score: 0.9417 - val_loss: 0.6326 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 512/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6089 - acc: 0.9462 - precision: 0.9886 - recall: 0.9032 - f1_score: 0.9431 - val_loss: 0.6305 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6068 - acc: 0.9462 - precision: 0.9902 - recall: 0.9011 - f1_score: 0.9422 - val_loss: 0.6285 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 514/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6047 - acc: 0.9462 - precision: 0.9888 - recall: 0.9023 - f1_score: 0.9426 - val_loss: 0.6265 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 515/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6027 - acc: 0.9462 - precision: 0.9898 - recall: 0.9009 - f1_score: 0.9424 - val_loss: 0.6244 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 516/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6007 - acc: 0.9462 - precision: 0.9871 - recall: 0.8962 - f1_score: 0.9384 - val_loss: 0.6224 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 517/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5987 - acc: 0.9462 - precision: 0.9897 - recall: 0.8954 - f1_score: 0.9387 - val_loss: 0.6204 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 518/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5967 - acc: 0.9462 - precision: 0.9909 - recall: 0.9028 - f1_score: 0.9434 - val_loss: 0.6184 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 519/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5947 - acc: 0.9462 - precision: 0.9894 - recall: 0.9000 - f1_score: 0.9407 - val_loss: 0.6164 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 520/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5927 - acc: 0.9462 - precision: 0.9897 - recall: 0.9008 - f1_score: 0.9424 - val_loss: 0.6145 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 521/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5907 - acc: 0.9462 - precision: 0.9890 - recall: 0.8980 - f1_score: 0.9400 - val_loss: 0.6125 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 522/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5887 - acc: 0.9462 - precision: 0.9885 - recall: 0.9007 - f1_score: 0.9409 - val_loss: 0.6106 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 523/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5868 - acc: 0.9462 - precision: 0.9893 - recall: 0.8998 - f1_score: 0.9418 - val_loss: 0.6086 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 524/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5848 - acc: 0.9462 - precision: 0.9895 - recall: 0.9024 - f1_score: 0.9427 - val_loss: 0.6067 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 525/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5829 - acc: 0.9462 - precision: 0.9899 - recall: 0.9044 - f1_score: 0.9438 - val_loss: 0.6048 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 526/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5810 - acc: 0.9462 - precision: 0.9890 - recall: 0.9030 - f1_score: 0.9426 - val_loss: 0.6028 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 527/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5790 - acc: 0.9462 - precision: 0.9878 - recall: 0.9021 - f1_score: 0.9417 - val_loss: 0.6009 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 528/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5771 - acc: 0.9462 - precision: 0.9905 - recall: 0.8981 - f1_score: 0.9409 - val_loss: 0.5990 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 529/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5752 - acc: 0.9462 - precision: 0.9893 - recall: 0.8930 - f1_score: 0.9365 - val_loss: 0.5972 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 530/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5733 - acc: 0.9462 - precision: 0.9902 - recall: 0.8964 - f1_score: 0.9398 - val_loss: 0.5953 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 531/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5715 - acc: 0.9462 - precision: 0.9898 - recall: 0.9027 - f1_score: 0.9433 - val_loss: 0.5934 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 532/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5696 - acc: 0.9462 - precision: 0.9893 - recall: 0.8988 - f1_score: 0.9411 - val_loss: 0.5916 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 533/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5677 - acc: 0.9462 - precision: 0.9898 - recall: 0.9038 - f1_score: 0.9439 - val_loss: 0.5897 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 534/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5659 - acc: 0.9462 - precision: 0.9884 - recall: 0.8978 - f1_score: 0.9400 - val_loss: 0.5879 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 535/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5640 - acc: 0.9462 - precision: 0.9905 - recall: 0.8985 - f1_score: 0.9403 - val_loss: 0.5860 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 536/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5622 - acc: 0.9462 - precision: 0.9902 - recall: 0.8966 - f1_score: 0.9378 - val_loss: 0.5842 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 537/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5604 - acc: 0.9462 - precision: 0.9888 - recall: 0.9001 - f1_score: 0.9416 - val_loss: 0.5824 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 538/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5585 - acc: 0.9462 - precision: 0.9895 - recall: 0.8995 - f1_score: 0.9411 - val_loss: 0.5806 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 539/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5567 - acc: 0.9462 - precision: 0.9901 - recall: 0.9009 - f1_score: 0.9425 - val_loss: 0.5788 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 540/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5549 - acc: 0.9462 - precision: 0.9899 - recall: 0.9002 - f1_score: 0.9425 - val_loss: 0.5770 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 541/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5531 - acc: 0.9462 - precision: 0.9895 - recall: 0.9002 - f1_score: 0.9419 - val_loss: 0.5752 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 542/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5514 - acc: 0.9462 - precision: 0.9885 - recall: 0.8988 - f1_score: 0.9408 - val_loss: 0.5735 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 543/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5496 - acc: 0.9462 - precision: 0.9877 - recall: 0.8946 - f1_score: 0.9373 - val_loss: 0.5717 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 544/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5478 - acc: 0.9462 - precision: 0.9894 - recall: 0.8978 - f1_score: 0.9403 - val_loss: 0.5699 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.5461 - acc: 0.9462 - precision: 0.9897 - recall: 0.8993 - f1_score: 0.9415 - val_loss: 0.5682 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 546/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5443 - acc: 0.9462 - precision: 0.9907 - recall: 0.8999 - f1_score: 0.9416 - val_loss: 0.5665 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 547/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5426 - acc: 0.9462 - precision: 0.9880 - recall: 0.8992 - f1_score: 0.9406 - val_loss: 0.5647 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 548/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5409 - acc: 0.9462 - precision: 0.9899 - recall: 0.9008 - f1_score: 0.9428 - val_loss: 0.5630 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 549/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5391 - acc: 0.9462 - precision: 0.9889 - recall: 0.9032 - f1_score: 0.9431 - val_loss: 0.5613 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 550/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5374 - acc: 0.9462 - precision: 0.9896 - recall: 0.9023 - f1_score: 0.9434 - val_loss: 0.5596 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 551/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5357 - acc: 0.9462 - precision: 0.9890 - recall: 0.8985 - f1_score: 0.9402 - val_loss: 0.5579 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 552/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5340 - acc: 0.9462 - precision: 0.9905 - recall: 0.8992 - f1_score: 0.9415 - val_loss: 0.5563 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 553/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5323 - acc: 0.9462 - precision: 0.9898 - recall: 0.8985 - f1_score: 0.9410 - val_loss: 0.5546 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 554/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5307 - acc: 0.9462 - precision: 0.9893 - recall: 0.9015 - f1_score: 0.9420 - val_loss: 0.5529 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 555/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5290 - acc: 0.9462 - precision: 0.9895 - recall: 0.9028 - f1_score: 0.9426 - val_loss: 0.5513 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 556/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5273 - acc: 0.9462 - precision: 0.9902 - recall: 0.9001 - f1_score: 0.9422 - val_loss: 0.5496 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 557/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5257 - acc: 0.9462 - precision: 0.9892 - recall: 0.8938 - f1_score: 0.9379 - val_loss: 0.5480 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 558/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5240 - acc: 0.9462 - precision: 0.9890 - recall: 0.9005 - f1_score: 0.9421 - val_loss: 0.5463 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 559/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5224 - acc: 0.9462 - precision: 0.9882 - recall: 0.9018 - f1_score: 0.9421 - val_loss: 0.5447 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 560/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5207 - acc: 0.9462 - precision: 0.9895 - recall: 0.8980 - f1_score: 0.9404 - val_loss: 0.5431 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 561/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5191 - acc: 0.9462 - precision: 0.9900 - recall: 0.9041 - f1_score: 0.9439 - val_loss: 0.5415 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 562/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5175 - acc: 0.9462 - precision: 0.9890 - recall: 0.9010 - f1_score: 0.9418 - val_loss: 0.5399 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 563/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5159 - acc: 0.9462 - precision: 0.9893 - recall: 0.9042 - f1_score: 0.9435 - val_loss: 0.5383 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 564/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5143 - acc: 0.9462 - precision: 0.9883 - recall: 0.9005 - f1_score: 0.9415 - val_loss: 0.5367 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 565/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5127 - acc: 0.9462 - precision: 0.9888 - recall: 0.9040 - f1_score: 0.9433 - val_loss: 0.5352 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 566/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5111 - acc: 0.9462 - precision: 0.9886 - recall: 0.9003 - f1_score: 0.9421 - val_loss: 0.5336 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 567/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5096 - acc: 0.9462 - precision: 0.9895 - recall: 0.9017 - f1_score: 0.9430 - val_loss: 0.5320 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 568/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5080 - acc: 0.9462 - precision: 0.9898 - recall: 0.8974 - f1_score: 0.9403 - val_loss: 0.5305 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 569/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5064 - acc: 0.9462 - precision: 0.9896 - recall: 0.9024 - f1_score: 0.9423 - val_loss: 0.5289 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 570/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5049 - acc: 0.9462 - precision: 0.9907 - recall: 0.9014 - f1_score: 0.9419 - val_loss: 0.5274 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 571/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5033 - acc: 0.9462 - precision: 0.9899 - recall: 0.8982 - f1_score: 0.9409 - val_loss: 0.5259 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 572/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5018 - acc: 0.9462 - precision: 0.9895 - recall: 0.8985 - f1_score: 0.9405 - val_loss: 0.5243 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 573/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5003 - acc: 0.9462 - precision: 0.9903 - recall: 0.8986 - f1_score: 0.9415 - val_loss: 0.5228 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 574/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4987 - acc: 0.9462 - precision: 0.9895 - recall: 0.9021 - f1_score: 0.9426 - val_loss: 0.5213 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 575/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4972 - acc: 0.9462 - precision: 0.9872 - recall: 0.8942 - f1_score: 0.9369 - val_loss: 0.5198 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 576/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4957 - acc: 0.9462 - precision: 0.9883 - recall: 0.8935 - f1_score: 0.9364 - val_loss: 0.5183 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4942 - acc: 0.9462 - precision: 0.9895 - recall: 0.8975 - f1_score: 0.9394 - val_loss: 0.5168 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 578/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4927 - acc: 0.9462 - precision: 0.9894 - recall: 0.8968 - f1_score: 0.9396 - val_loss: 0.5153 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 579/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4912 - acc: 0.9462 - precision: 0.9890 - recall: 0.8980 - f1_score: 0.9402 - val_loss: 0.5139 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 580/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4898 - acc: 0.9462 - precision: 0.9926 - recall: 0.8960 - f1_score: 0.9407 - val_loss: 0.5124 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 581/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4883 - acc: 0.9462 - precision: 0.9878 - recall: 0.9009 - f1_score: 0.9412 - val_loss: 0.5110 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 582/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4868 - acc: 0.9462 - precision: 0.9886 - recall: 0.9003 - f1_score: 0.9400 - val_loss: 0.5095 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 583/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4854 - acc: 0.9462 - precision: 0.9897 - recall: 0.9014 - f1_score: 0.9424 - val_loss: 0.5081 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 584/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4839 - acc: 0.9462 - precision: 0.9892 - recall: 0.8987 - f1_score: 0.9400 - val_loss: 0.5066 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 585/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4825 - acc: 0.9462 - precision: 0.9895 - recall: 0.9003 - f1_score: 0.9415 - val_loss: 0.5052 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 586/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4811 - acc: 0.9462 - precision: 0.9890 - recall: 0.9041 - f1_score: 0.9439 - val_loss: 0.5038 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 587/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4796 - acc: 0.9462 - precision: 0.9878 - recall: 0.8991 - f1_score: 0.9402 - val_loss: 0.5024 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 588/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4782 - acc: 0.9462 - precision: 0.9898 - recall: 0.9008 - f1_score: 0.9411 - val_loss: 0.5010 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 589/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4768 - acc: 0.9462 - precision: 0.9881 - recall: 0.8982 - f1_score: 0.9407 - val_loss: 0.4996 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 590/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4754 - acc: 0.9462 - precision: 0.9894 - recall: 0.9049 - f1_score: 0.9444 - val_loss: 0.4982 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 591/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4740 - acc: 0.9462 - precision: 0.9892 - recall: 0.9048 - f1_score: 0.9439 - val_loss: 0.4968 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 592/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4726 - acc: 0.9462 - precision: 0.9889 - recall: 0.9005 - f1_score: 0.9416 - val_loss: 0.4954 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 593/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4712 - acc: 0.9462 - precision: 0.9848 - recall: 0.9037 - f1_score: 0.9404 - val_loss: 0.4940 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 594/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4698 - acc: 0.9462 - precision: 0.9900 - recall: 0.9004 - f1_score: 0.9416 - val_loss: 0.4927 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 595/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4684 - acc: 0.9462 - precision: 0.9902 - recall: 0.9010 - f1_score: 0.9427 - val_loss: 0.4913 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 596/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4671 - acc: 0.9462 - precision: 0.9840 - recall: 0.8920 - f1_score: 0.9342 - val_loss: 0.4900 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 597/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4657 - acc: 0.9462 - precision: 0.9896 - recall: 0.9021 - f1_score: 0.9425 - val_loss: 0.4886 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 598/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4644 - acc: 0.9462 - precision: 0.9904 - recall: 0.9009 - f1_score: 0.9421 - val_loss: 0.4873 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 599/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4630 - acc: 0.9462 - precision: 0.9882 - recall: 0.9022 - f1_score: 0.9423 - val_loss: 0.4860 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 600/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4617 - acc: 0.9462 - precision: 0.9895 - recall: 0.9018 - f1_score: 0.9430 - val_loss: 0.4846 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 601/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4603 - acc: 0.9462 - precision: 0.9901 - recall: 0.9058 - f1_score: 0.9446 - val_loss: 0.4833 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 602/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4590 - acc: 0.9462 - precision: 0.9875 - recall: 0.8964 - f1_score: 0.9389 - val_loss: 0.4820 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 603/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4577 - acc: 0.9462 - precision: 0.9884 - recall: 0.9028 - f1_score: 0.9419 - val_loss: 0.4807 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 604/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4564 - acc: 0.9462 - precision: 0.9882 - recall: 0.9007 - f1_score: 0.9411 - val_loss: 0.4794 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 605/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4551 - acc: 0.9462 - precision: 0.9882 - recall: 0.8976 - f1_score: 0.9391 - val_loss: 0.4781 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 606/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4538 - acc: 0.9462 - precision: 0.9902 - recall: 0.9042 - f1_score: 0.9435 - val_loss: 0.4768 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 607/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4525 - acc: 0.9462 - precision: 0.9901 - recall: 0.9003 - f1_score: 0.9410 - val_loss: 0.4755 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 608/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4512 - acc: 0.9462 - precision: 0.9905 - recall: 0.8978 - f1_score: 0.9400 - val_loss: 0.4742 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4499 - acc: 0.9462 - precision: 0.9883 - recall: 0.9008 - f1_score: 0.9419 - val_loss: 0.4730 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 610/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4486 - acc: 0.9462 - precision: 0.9886 - recall: 0.9034 - f1_score: 0.9415 - val_loss: 0.4717 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 611/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4473 - acc: 0.9462 - precision: 0.9901 - recall: 0.9039 - f1_score: 0.9446 - val_loss: 0.4704 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 612/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4461 - acc: 0.9462 - precision: 0.9902 - recall: 0.9003 - f1_score: 0.9425 - val_loss: 0.4692 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 613/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4448 - acc: 0.9462 - precision: 0.9912 - recall: 0.8996 - f1_score: 0.9422 - val_loss: 0.4680 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 614/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4436 - acc: 0.9462 - precision: 0.9905 - recall: 0.8979 - f1_score: 0.9410 - val_loss: 0.4667 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 615/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4423 - acc: 0.9462 - precision: 0.9896 - recall: 0.8995 - f1_score: 0.9411 - val_loss: 0.4655 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 616/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4411 - acc: 0.9462 - precision: 0.9898 - recall: 0.9027 - f1_score: 0.9418 - val_loss: 0.4642 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 617/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4398 - acc: 0.9462 - precision: 0.9892 - recall: 0.8972 - f1_score: 0.9396 - val_loss: 0.4630 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 618/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4386 - acc: 0.9462 - precision: 0.9907 - recall: 0.9026 - f1_score: 0.9433 - val_loss: 0.4618 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 619/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4374 - acc: 0.9462 - precision: 0.9904 - recall: 0.9023 - f1_score: 0.9432 - val_loss: 0.4606 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 620/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4362 - acc: 0.9462 - precision: 0.9899 - recall: 0.9023 - f1_score: 0.9429 - val_loss: 0.4594 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 621/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4350 - acc: 0.9462 - precision: 0.9898 - recall: 0.9028 - f1_score: 0.9428 - val_loss: 0.4582 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 622/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4338 - acc: 0.9462 - precision: 0.9875 - recall: 0.8995 - f1_score: 0.9406 - val_loss: 0.4570 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 623/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4326 - acc: 0.9462 - precision: 0.9897 - recall: 0.8996 - f1_score: 0.9412 - val_loss: 0.4558 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 624/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4314 - acc: 0.9462 - precision: 0.9891 - recall: 0.9039 - f1_score: 0.9437 - val_loss: 0.4546 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 625/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4302 - acc: 0.9462 - precision: 0.9906 - recall: 0.9024 - f1_score: 0.9423 - val_loss: 0.4535 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 626/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4290 - acc: 0.9462 - precision: 0.9907 - recall: 0.9007 - f1_score: 0.9421 - val_loss: 0.4523 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 627/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4278 - acc: 0.9446 - precision: 0.9851 - recall: 0.8987 - f1_score: 0.9391 - val_loss: 0.4511 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 628/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4267 - acc: 0.9462 - precision: 0.9882 - recall: 0.9023 - f1_score: 0.9419 - val_loss: 0.4500 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 629/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4255 - acc: 0.9462 - precision: 0.9898 - recall: 0.8996 - f1_score: 0.9420 - val_loss: 0.4488 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 630/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4243 - acc: 0.9462 - precision: 0.9895 - recall: 0.9003 - f1_score: 0.9415 - val_loss: 0.4477 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 631/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4232 - acc: 0.9446 - precision: 0.9858 - recall: 0.9015 - f1_score: 0.9412 - val_loss: 0.4465 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 632/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4220 - acc: 0.9446 - precision: 0.9872 - recall: 0.9034 - f1_score: 0.9417 - val_loss: 0.4454 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 633/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4209 - acc: 0.9446 - precision: 0.9865 - recall: 0.8991 - f1_score: 0.9395 - val_loss: 0.4443 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 634/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4197 - acc: 0.9462 - precision: 0.9889 - recall: 0.9030 - f1_score: 0.9429 - val_loss: 0.4432 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 635/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4186 - acc: 0.9446 - precision: 0.9881 - recall: 0.8986 - f1_score: 0.9396 - val_loss: 0.4420 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 636/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4175 - acc: 0.9446 - precision: 0.9868 - recall: 0.9009 - f1_score: 0.9407 - val_loss: 0.4409 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 637/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4164 - acc: 0.9446 - precision: 0.9850 - recall: 0.9024 - f1_score: 0.9405 - val_loss: 0.4398 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 638/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4152 - acc: 0.9446 - precision: 0.9864 - recall: 0.9026 - f1_score: 0.9416 - val_loss: 0.4387 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 639/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4141 - acc: 0.9462 - precision: 0.9909 - recall: 0.9048 - f1_score: 0.9448 - val_loss: 0.4376 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 640/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4130 - acc: 0.9446 - precision: 0.9862 - recall: 0.8982 - f1_score: 0.9395 - val_loss: 0.4365 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4119 - acc: 0.9446 - precision: 0.9860 - recall: 0.9017 - f1_score: 0.9407 - val_loss: 0.4354 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 642/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4108 - acc: 0.9462 - precision: 0.9888 - recall: 0.9022 - f1_score: 0.9423 - val_loss: 0.4343 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 643/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4097 - acc: 0.9446 - precision: 0.9861 - recall: 0.9022 - f1_score: 0.9411 - val_loss: 0.4333 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 644/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4087 - acc: 0.9446 - precision: 0.9840 - recall: 0.9022 - f1_score: 0.9397 - val_loss: 0.4322 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 645/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4076 - acc: 0.9446 - precision: 0.9863 - recall: 0.8998 - f1_score: 0.9398 - val_loss: 0.4311 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 646/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4065 - acc: 0.9446 - precision: 0.9866 - recall: 0.9041 - f1_score: 0.9423 - val_loss: 0.4301 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 647/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4054 - acc: 0.9446 - precision: 0.9863 - recall: 0.8981 - f1_score: 0.9373 - val_loss: 0.4290 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 648/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4044 - acc: 0.9446 - precision: 0.9867 - recall: 0.8996 - f1_score: 0.9402 - val_loss: 0.4280 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 649/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4033 - acc: 0.9446 - precision: 0.9870 - recall: 0.8976 - f1_score: 0.9384 - val_loss: 0.4269 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 650/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4023 - acc: 0.9446 - precision: 0.9853 - recall: 0.9032 - f1_score: 0.9411 - val_loss: 0.4259 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 651/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4012 - acc: 0.9446 - precision: 0.9871 - recall: 0.8973 - f1_score: 0.9383 - val_loss: 0.4248 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 652/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4002 - acc: 0.9446 - precision: 0.9875 - recall: 0.9056 - f1_score: 0.9440 - val_loss: 0.4238 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 653/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3991 - acc: 0.9446 - precision: 0.9859 - recall: 0.9018 - f1_score: 0.9413 - val_loss: 0.4228 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 654/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3981 - acc: 0.9446 - precision: 0.9851 - recall: 0.9022 - f1_score: 0.9410 - val_loss: 0.4217 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 655/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3971 - acc: 0.9446 - precision: 0.9867 - recall: 0.9027 - f1_score: 0.9421 - val_loss: 0.4207 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 656/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3960 - acc: 0.9446 - precision: 0.9853 - recall: 0.8987 - f1_score: 0.9394 - val_loss: 0.4197 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 657/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3950 - acc: 0.9446 - precision: 0.9856 - recall: 0.8980 - f1_score: 0.9386 - val_loss: 0.4187 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 658/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3940 - acc: 0.9446 - precision: 0.9844 - recall: 0.9007 - f1_score: 0.9394 - val_loss: 0.4177 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 659/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3930 - acc: 0.9446 - precision: 0.9861 - recall: 0.8973 - f1_score: 0.9384 - val_loss: 0.4167 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 660/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3920 - acc: 0.9446 - precision: 0.9870 - recall: 0.9022 - f1_score: 0.9410 - val_loss: 0.4157 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 661/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3910 - acc: 0.9446 - precision: 0.9857 - recall: 0.8998 - f1_score: 0.9399 - val_loss: 0.4147 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 662/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3900 - acc: 0.9446 - precision: 0.9863 - recall: 0.9033 - f1_score: 0.9422 - val_loss: 0.4138 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 663/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3890 - acc: 0.9446 - precision: 0.9831 - recall: 0.9001 - f1_score: 0.9387 - val_loss: 0.4128 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 664/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3880 - acc: 0.9446 - precision: 0.9855 - recall: 0.8993 - f1_score: 0.9396 - val_loss: 0.4118 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 665/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3870 - acc: 0.9446 - precision: 0.9835 - recall: 0.8977 - f1_score: 0.9382 - val_loss: 0.4108 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 666/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3861 - acc: 0.9446 - precision: 0.9860 - recall: 0.8998 - f1_score: 0.9400 - val_loss: 0.4099 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 667/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3851 - acc: 0.9446 - precision: 0.9830 - recall: 0.8975 - f1_score: 0.9378 - val_loss: 0.4089 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 668/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3841 - acc: 0.9446 - precision: 0.9869 - recall: 0.9003 - f1_score: 0.9407 - val_loss: 0.4080 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 669/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3832 - acc: 0.9446 - precision: 0.9857 - recall: 0.8987 - f1_score: 0.9398 - val_loss: 0.4070 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 670/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3822 - acc: 0.9446 - precision: 0.9856 - recall: 0.8982 - f1_score: 0.9384 - val_loss: 0.4061 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 671/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3813 - acc: 0.9446 - precision: 0.9844 - recall: 0.9011 - f1_score: 0.9404 - val_loss: 0.4051 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 672/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3803 - acc: 0.9446 - precision: 0.9861 - recall: 0.9000 - f1_score: 0.9400 - val_loss: 0.4042 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3794 - acc: 0.9446 - precision: 0.9873 - recall: 0.9022 - f1_score: 0.9421 - val_loss: 0.4033 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 674/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3784 - acc: 0.9446 - precision: 0.9862 - recall: 0.9007 - f1_score: 0.9406 - val_loss: 0.4023 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 675/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3775 - acc: 0.9446 - precision: 0.9871 - recall: 0.9028 - f1_score: 0.9413 - val_loss: 0.4014 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 676/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3766 - acc: 0.9446 - precision: 0.9854 - recall: 0.9008 - f1_score: 0.9400 - val_loss: 0.4005 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 677/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3756 - acc: 0.9446 - precision: 0.9857 - recall: 0.9009 - f1_score: 0.9407 - val_loss: 0.3996 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 678/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3747 - acc: 0.9446 - precision: 0.9854 - recall: 0.8982 - f1_score: 0.9391 - val_loss: 0.3987 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 679/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3738 - acc: 0.9446 - precision: 0.9876 - recall: 0.8997 - f1_score: 0.9401 - val_loss: 0.3978 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 680/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3729 - acc: 0.9446 - precision: 0.9867 - recall: 0.9001 - f1_score: 0.9397 - val_loss: 0.3969 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 681/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3720 - acc: 0.9446 - precision: 0.9846 - recall: 0.8994 - f1_score: 0.9382 - val_loss: 0.3960 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 682/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3711 - acc: 0.9446 - precision: 0.9861 - recall: 0.9007 - f1_score: 0.9407 - val_loss: 0.3951 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 683/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3702 - acc: 0.9446 - precision: 0.9860 - recall: 0.8971 - f1_score: 0.9385 - val_loss: 0.3942 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 684/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3693 - acc: 0.9446 - precision: 0.9874 - recall: 0.9019 - f1_score: 0.9418 - val_loss: 0.3933 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 685/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3684 - acc: 0.9446 - precision: 0.9859 - recall: 0.9017 - f1_score: 0.9411 - val_loss: 0.3924 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 686/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3675 - acc: 0.9446 - precision: 0.9882 - recall: 0.8972 - f1_score: 0.9391 - val_loss: 0.3915 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 687/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3666 - acc: 0.9446 - precision: 0.9852 - recall: 0.9014 - f1_score: 0.9405 - val_loss: 0.3907 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 688/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3657 - acc: 0.9446 - precision: 0.9859 - recall: 0.9016 - f1_score: 0.9408 - val_loss: 0.3898 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 689/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3648 - acc: 0.9446 - precision: 0.9854 - recall: 0.9018 - f1_score: 0.9410 - val_loss: 0.3889 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 690/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3640 - acc: 0.9446 - precision: 0.9864 - recall: 0.9001 - f1_score: 0.9400 - val_loss: 0.3881 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 691/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3631 - acc: 0.9446 - precision: 0.9861 - recall: 0.9056 - f1_score: 0.9427 - val_loss: 0.3872 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 692/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3622 - acc: 0.9446 - precision: 0.9853 - recall: 0.8987 - f1_score: 0.9393 - val_loss: 0.3864 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 693/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3614 - acc: 0.9446 - precision: 0.9841 - recall: 0.8983 - f1_score: 0.9380 - val_loss: 0.3855 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 694/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3605 - acc: 0.9446 - precision: 0.9866 - recall: 0.9021 - f1_score: 0.9417 - val_loss: 0.3847 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 695/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3597 - acc: 0.9446 - precision: 0.9855 - recall: 0.8985 - f1_score: 0.9393 - val_loss: 0.3839 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 696/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3588 - acc: 0.9446 - precision: 0.9861 - recall: 0.8978 - f1_score: 0.9381 - val_loss: 0.3830 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 697/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3580 - acc: 0.9446 - precision: 0.9856 - recall: 0.9008 - f1_score: 0.9405 - val_loss: 0.3822 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 698/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3572 - acc: 0.9446 - precision: 0.9879 - recall: 0.8989 - f1_score: 0.9399 - val_loss: 0.3814 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 699/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3563 - acc: 0.9446 - precision: 0.9862 - recall: 0.9005 - f1_score: 0.9408 - val_loss: 0.3805 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 700/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3555 - acc: 0.9446 - precision: 0.9863 - recall: 0.9032 - f1_score: 0.9418 - val_loss: 0.3797 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 701/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3547 - acc: 0.9446 - precision: 0.9880 - recall: 0.8997 - f1_score: 0.9407 - val_loss: 0.3789 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 702/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3538 - acc: 0.9446 - precision: 0.9865 - recall: 0.9033 - f1_score: 0.9418 - val_loss: 0.3781 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 703/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3530 - acc: 0.9446 - precision: 0.9866 - recall: 0.9015 - f1_score: 0.9403 - val_loss: 0.3773 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 704/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3522 - acc: 0.9446 - precision: 0.9853 - recall: 0.8975 - f1_score: 0.9380 - val_loss: 0.3765 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3514 - acc: 0.9446 - precision: 0.9866 - recall: 0.9007 - f1_score: 0.9404 - val_loss: 0.3757 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 706/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3506 - acc: 0.9446 - precision: 0.9829 - recall: 0.9020 - f1_score: 0.9387 - val_loss: 0.3749 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 707/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3498 - acc: 0.9446 - precision: 0.9858 - recall: 0.9005 - f1_score: 0.9403 - val_loss: 0.3741 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 708/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3490 - acc: 0.9446 - precision: 0.9864 - recall: 0.9057 - f1_score: 0.9429 - val_loss: 0.3733 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 709/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3482 - acc: 0.9446 - precision: 0.9834 - recall: 0.8961 - f1_score: 0.9367 - val_loss: 0.3725 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 710/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3474 - acc: 0.9446 - precision: 0.9868 - recall: 0.8999 - f1_score: 0.9405 - val_loss: 0.3718 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 711/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3466 - acc: 0.9446 - precision: 0.9851 - recall: 0.8990 - f1_score: 0.9392 - val_loss: 0.3710 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 712/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3458 - acc: 0.9446 - precision: 0.9862 - recall: 0.9006 - f1_score: 0.9391 - val_loss: 0.3702 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 713/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3450 - acc: 0.9446 - precision: 0.9873 - recall: 0.8991 - f1_score: 0.9395 - val_loss: 0.3694 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 714/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3442 - acc: 0.9446 - precision: 0.9864 - recall: 0.9034 - f1_score: 0.9419 - val_loss: 0.3687 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 715/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3435 - acc: 0.9446 - precision: 0.9864 - recall: 0.9020 - f1_score: 0.9410 - val_loss: 0.3679 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 716/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3427 - acc: 0.9446 - precision: 0.9872 - recall: 0.9033 - f1_score: 0.9424 - val_loss: 0.3672 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 717/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3419 - acc: 0.9446 - precision: 0.9868 - recall: 0.9013 - f1_score: 0.9403 - val_loss: 0.3664 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 718/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3412 - acc: 0.9446 - precision: 0.9837 - recall: 0.8991 - f1_score: 0.9383 - val_loss: 0.3657 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 719/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3404 - acc: 0.9446 - precision: 0.9871 - recall: 0.8988 - f1_score: 0.9392 - val_loss: 0.3649 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 720/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3397 - acc: 0.9446 - precision: 0.9864 - recall: 0.9024 - f1_score: 0.9413 - val_loss: 0.3642 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 721/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3389 - acc: 0.9446 - precision: 0.9869 - recall: 0.9023 - f1_score: 0.9417 - val_loss: 0.3634 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 722/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3382 - acc: 0.9446 - precision: 0.9853 - recall: 0.8993 - f1_score: 0.9393 - val_loss: 0.3627 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 723/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3374 - acc: 0.9446 - precision: 0.9857 - recall: 0.9031 - f1_score: 0.9418 - val_loss: 0.3619 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 724/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3367 - acc: 0.9446 - precision: 0.9843 - recall: 0.8961 - f1_score: 0.9375 - val_loss: 0.3612 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 725/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3359 - acc: 0.9446 - precision: 0.9862 - recall: 0.9002 - f1_score: 0.9403 - val_loss: 0.3605 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 726/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3352 - acc: 0.9446 - precision: 0.9856 - recall: 0.9038 - f1_score: 0.9412 - val_loss: 0.3598 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 727/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3345 - acc: 0.9446 - precision: 0.9864 - recall: 0.9019 - f1_score: 0.9413 - val_loss: 0.3590 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 728/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3337 - acc: 0.9446 - precision: 0.9854 - recall: 0.8977 - f1_score: 0.9382 - val_loss: 0.3583 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 729/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3330 - acc: 0.9446 - precision: 0.9861 - recall: 0.9006 - f1_score: 0.9411 - val_loss: 0.3576 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 730/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3323 - acc: 0.9446 - precision: 0.9877 - recall: 0.8974 - f1_score: 0.9376 - val_loss: 0.3569 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 731/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3316 - acc: 0.9446 - precision: 0.9871 - recall: 0.9005 - f1_score: 0.9411 - val_loss: 0.3562 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 732/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3308 - acc: 0.9446 - precision: 0.9848 - recall: 0.9021 - f1_score: 0.9401 - val_loss: 0.3555 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 733/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3301 - acc: 0.9446 - precision: 0.9871 - recall: 0.9009 - f1_score: 0.9404 - val_loss: 0.3548 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 734/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3294 - acc: 0.9446 - precision: 0.9862 - recall: 0.9005 - f1_score: 0.9406 - val_loss: 0.3541 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 735/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3287 - acc: 0.9446 - precision: 0.9858 - recall: 0.9034 - f1_score: 0.9418 - val_loss: 0.3534 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 736/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3280 - acc: 0.9446 - precision: 0.9873 - recall: 0.8985 - f1_score: 0.9387 - val_loss: 0.3527 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3273 - acc: 0.9446 - precision: 0.9860 - recall: 0.9034 - f1_score: 0.9414 - val_loss: 0.3520 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 738/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3266 - acc: 0.9446 - precision: 0.9860 - recall: 0.9039 - f1_score: 0.9419 - val_loss: 0.3514 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 739/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3259 - acc: 0.9446 - precision: 0.9862 - recall: 0.9027 - f1_score: 0.9416 - val_loss: 0.3507 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 740/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3252 - acc: 0.9446 - precision: 0.9864 - recall: 0.8996 - f1_score: 0.9399 - val_loss: 0.3500 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 741/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3246 - acc: 0.9446 - precision: 0.9854 - recall: 0.8983 - f1_score: 0.9392 - val_loss: 0.3493 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 742/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3239 - acc: 0.9446 - precision: 0.9874 - recall: 0.8995 - f1_score: 0.9396 - val_loss: 0.3486 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 743/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3232 - acc: 0.9446 - precision: 0.9852 - recall: 0.8982 - f1_score: 0.9385 - val_loss: 0.3480 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 744/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3225 - acc: 0.9446 - precision: 0.9867 - recall: 0.9011 - f1_score: 0.9411 - val_loss: 0.3473 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 745/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3218 - acc: 0.9446 - precision: 0.9868 - recall: 0.9013 - f1_score: 0.9415 - val_loss: 0.3467 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 746/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3212 - acc: 0.9446 - precision: 0.9868 - recall: 0.8991 - f1_score: 0.9395 - val_loss: 0.3460 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 747/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3205 - acc: 0.9446 - precision: 0.9851 - recall: 0.8994 - f1_score: 0.9398 - val_loss: 0.3453 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 748/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3198 - acc: 0.9446 - precision: 0.9845 - recall: 0.9023 - f1_score: 0.9405 - val_loss: 0.3447 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 749/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3192 - acc: 0.9446 - precision: 0.9868 - recall: 0.9013 - f1_score: 0.9408 - val_loss: 0.3441 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 750/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3185 - acc: 0.9446 - precision: 0.9862 - recall: 0.8956 - f1_score: 0.9379 - val_loss: 0.3434 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 751/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3179 - acc: 0.9446 - precision: 0.9861 - recall: 0.8991 - f1_score: 0.9390 - val_loss: 0.3428 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 752/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3172 - acc: 0.9446 - precision: 0.9848 - recall: 0.8998 - f1_score: 0.9394 - val_loss: 0.3421 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 753/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3166 - acc: 0.9446 - precision: 0.9864 - recall: 0.8990 - f1_score: 0.9396 - val_loss: 0.3415 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 754/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3159 - acc: 0.9446 - precision: 0.9841 - recall: 0.9013 - f1_score: 0.9404 - val_loss: 0.3409 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 755/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3153 - acc: 0.9446 - precision: 0.9851 - recall: 0.9003 - f1_score: 0.9386 - val_loss: 0.3402 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 756/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3146 - acc: 0.9446 - precision: 0.9863 - recall: 0.9017 - f1_score: 0.9415 - val_loss: 0.3396 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 757/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3140 - acc: 0.9446 - precision: 0.9834 - recall: 0.8998 - f1_score: 0.9384 - val_loss: 0.3390 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 758/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3134 - acc: 0.9446 - precision: 0.9861 - recall: 0.9020 - f1_score: 0.9417 - val_loss: 0.3384 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 759/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3127 - acc: 0.9446 - precision: 0.9851 - recall: 0.9055 - f1_score: 0.9409 - val_loss: 0.3377 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 760/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3121 - acc: 0.9446 - precision: 0.9831 - recall: 0.8978 - f1_score: 0.9381 - val_loss: 0.3371 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 761/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3115 - acc: 0.9446 - precision: 0.9875 - recall: 0.9009 - f1_score: 0.9412 - val_loss: 0.3365 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 762/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3109 - acc: 0.9446 - precision: 0.9871 - recall: 0.9020 - f1_score: 0.9412 - val_loss: 0.3359 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 763/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3102 - acc: 0.9446 - precision: 0.9863 - recall: 0.9008 - f1_score: 0.9411 - val_loss: 0.3353 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 764/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3096 - acc: 0.9446 - precision: 0.9864 - recall: 0.9010 - f1_score: 0.9407 - val_loss: 0.3347 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 765/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3090 - acc: 0.9446 - precision: 0.9859 - recall: 0.9016 - f1_score: 0.9407 - val_loss: 0.3341 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 766/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3084 - acc: 0.9446 - precision: 0.9873 - recall: 0.8962 - f1_score: 0.9381 - val_loss: 0.3335 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 767/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3078 - acc: 0.9446 - precision: 0.9860 - recall: 0.8976 - f1_score: 0.9389 - val_loss: 0.3329 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 768/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3072 - acc: 0.9446 - precision: 0.9873 - recall: 0.8986 - f1_score: 0.9399 - val_loss: 0.3323 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3066 - acc: 0.9446 - precision: 0.9843 - recall: 0.8990 - f1_score: 0.9389 - val_loss: 0.3317 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 770/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3060 - acc: 0.9446 - precision: 0.9869 - recall: 0.9017 - f1_score: 0.9410 - val_loss: 0.3311 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 771/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3054 - acc: 0.9446 - precision: 0.9853 - recall: 0.9009 - f1_score: 0.9401 - val_loss: 0.3305 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 772/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3048 - acc: 0.9446 - precision: 0.9849 - recall: 0.9035 - f1_score: 0.9404 - val_loss: 0.3299 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 773/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3042 - acc: 0.9446 - precision: 0.9862 - recall: 0.8988 - f1_score: 0.9399 - val_loss: 0.3294 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 774/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3036 - acc: 0.9446 - precision: 0.9844 - recall: 0.8990 - f1_score: 0.9383 - val_loss: 0.3288 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 775/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3030 - acc: 0.9446 - precision: 0.9874 - recall: 0.9035 - f1_score: 0.9426 - val_loss: 0.3282 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 776/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3024 - acc: 0.9446 - precision: 0.9848 - recall: 0.9012 - f1_score: 0.9398 - val_loss: 0.3277 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 777/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3019 - acc: 0.9446 - precision: 0.9869 - recall: 0.9055 - f1_score: 0.9436 - val_loss: 0.3271 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 778/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3013 - acc: 0.9446 - precision: 0.9862 - recall: 0.9042 - f1_score: 0.9419 - val_loss: 0.3265 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 779/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3007 - acc: 0.9446 - precision: 0.9859 - recall: 0.9031 - f1_score: 0.9412 - val_loss: 0.3260 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 780/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3001 - acc: 0.9446 - precision: 0.9867 - recall: 0.9015 - f1_score: 0.9404 - val_loss: 0.3254 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 781/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2996 - acc: 0.9446 - precision: 0.9864 - recall: 0.8985 - f1_score: 0.9395 - val_loss: 0.3248 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 782/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2990 - acc: 0.9446 - precision: 0.9850 - recall: 0.9007 - f1_score: 0.9382 - val_loss: 0.3243 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 783/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2984 - acc: 0.9446 - precision: 0.9843 - recall: 0.8992 - f1_score: 0.9389 - val_loss: 0.3237 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 784/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2979 - acc: 0.9446 - precision: 0.9857 - recall: 0.9013 - f1_score: 0.9399 - val_loss: 0.3232 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 785/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2973 - acc: 0.9446 - precision: 0.9859 - recall: 0.9049 - f1_score: 0.9423 - val_loss: 0.3227 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 786/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2967 - acc: 0.9446 - precision: 0.9852 - recall: 0.8956 - f1_score: 0.9365 - val_loss: 0.3221 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 787/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2962 - acc: 0.9446 - precision: 0.9867 - recall: 0.8983 - f1_score: 0.9396 - val_loss: 0.3216 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 788/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2956 - acc: 0.9446 - precision: 0.9854 - recall: 0.8946 - f1_score: 0.9372 - val_loss: 0.3210 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 789/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2951 - acc: 0.9446 - precision: 0.9869 - recall: 0.9032 - f1_score: 0.9419 - val_loss: 0.3205 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 790/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2945 - acc: 0.9446 - precision: 0.9839 - recall: 0.9003 - f1_score: 0.9390 - val_loss: 0.3199 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 791/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2940 - acc: 0.9446 - precision: 0.9849 - recall: 0.9028 - f1_score: 0.9411 - val_loss: 0.3194 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 792/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2934 - acc: 0.9446 - precision: 0.9859 - recall: 0.9033 - f1_score: 0.9417 - val_loss: 0.3189 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 793/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2929 - acc: 0.9446 - precision: 0.9860 - recall: 0.8994 - f1_score: 0.9392 - val_loss: 0.3184 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 794/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2924 - acc: 0.9446 - precision: 0.9848 - recall: 0.9000 - f1_score: 0.9390 - val_loss: 0.3178 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 795/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2918 - acc: 0.9446 - precision: 0.9859 - recall: 0.9038 - f1_score: 0.9417 - val_loss: 0.3173 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 796/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2913 - acc: 0.9446 - precision: 0.9882 - recall: 0.8986 - f1_score: 0.9407 - val_loss: 0.3168 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 797/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2908 - acc: 0.9446 - precision: 0.9853 - recall: 0.9009 - f1_score: 0.9403 - val_loss: 0.3163 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 798/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2902 - acc: 0.9446 - precision: 0.9865 - recall: 0.8990 - f1_score: 0.9393 - val_loss: 0.3157 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 799/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2897 - acc: 0.9446 - precision: 0.9840 - recall: 0.9012 - f1_score: 0.9402 - val_loss: 0.3152 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 800/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2892 - acc: 0.9446 - precision: 0.9861 - recall: 0.8988 - f1_score: 0.9394 - val_loss: 0.3147 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2887 - acc: 0.9446 - precision: 0.9859 - recall: 0.9018 - f1_score: 0.9411 - val_loss: 0.3142 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 802/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2881 - acc: 0.9446 - precision: 0.9875 - recall: 0.9006 - f1_score: 0.9414 - val_loss: 0.3137 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 803/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2876 - acc: 0.9446 - precision: 0.9857 - recall: 0.9017 - f1_score: 0.9401 - val_loss: 0.3132 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 804/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2871 - acc: 0.9446 - precision: 0.9865 - recall: 0.8999 - f1_score: 0.9401 - val_loss: 0.3127 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 805/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2866 - acc: 0.9446 - precision: 0.9845 - recall: 0.8990 - f1_score: 0.9388 - val_loss: 0.3122 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 806/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2861 - acc: 0.9446 - precision: 0.9858 - recall: 0.8998 - f1_score: 0.9390 - val_loss: 0.3117 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 807/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2856 - acc: 0.9446 - precision: 0.9883 - recall: 0.8970 - f1_score: 0.9390 - val_loss: 0.3112 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 808/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2851 - acc: 0.9446 - precision: 0.9871 - recall: 0.8988 - f1_score: 0.9404 - val_loss: 0.3107 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 809/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2846 - acc: 0.9446 - precision: 0.9861 - recall: 0.9030 - f1_score: 0.9419 - val_loss: 0.3102 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 810/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2841 - acc: 0.9446 - precision: 0.9853 - recall: 0.8994 - f1_score: 0.9393 - val_loss: 0.3097 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 811/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2836 - acc: 0.9446 - precision: 0.9851 - recall: 0.8987 - f1_score: 0.9387 - val_loss: 0.3092 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 812/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2831 - acc: 0.9446 - precision: 0.9865 - recall: 0.8999 - f1_score: 0.9402 - val_loss: 0.3088 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 813/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2826 - acc: 0.9446 - precision: 0.9874 - recall: 0.9008 - f1_score: 0.9413 - val_loss: 0.3083 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 814/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2821 - acc: 0.9446 - precision: 0.9866 - recall: 0.8993 - f1_score: 0.9395 - val_loss: 0.3078 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 815/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2816 - acc: 0.9446 - precision: 0.9846 - recall: 0.8995 - f1_score: 0.9392 - val_loss: 0.3073 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 816/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2811 - acc: 0.9446 - precision: 0.9858 - recall: 0.9026 - f1_score: 0.9415 - val_loss: 0.3069 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 817/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2806 - acc: 0.9446 - precision: 0.9876 - recall: 0.9051 - f1_score: 0.9433 - val_loss: 0.3064 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 818/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2801 - acc: 0.9446 - precision: 0.9860 - recall: 0.9033 - f1_score: 0.9422 - val_loss: 0.3059 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 819/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2797 - acc: 0.9446 - precision: 0.9845 - recall: 0.9000 - f1_score: 0.9400 - val_loss: 0.3055 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 820/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2792 - acc: 0.9446 - precision: 0.9836 - recall: 0.8992 - f1_score: 0.9385 - val_loss: 0.3050 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 821/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2787 - acc: 0.9446 - precision: 0.9866 - recall: 0.8987 - f1_score: 0.9401 - val_loss: 0.3045 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 822/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2782 - acc: 0.9446 - precision: 0.9840 - recall: 0.8968 - f1_score: 0.9371 - val_loss: 0.3041 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 823/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2778 - acc: 0.9446 - precision: 0.9850 - recall: 0.9005 - f1_score: 0.9398 - val_loss: 0.3036 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 824/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2773 - acc: 0.9446 - precision: 0.9863 - recall: 0.9009 - f1_score: 0.9402 - val_loss: 0.3031 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 825/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2768 - acc: 0.9446 - precision: 0.9840 - recall: 0.8967 - f1_score: 0.9375 - val_loss: 0.3027 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 826/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2764 - acc: 0.9446 - precision: 0.9872 - recall: 0.8950 - f1_score: 0.9371 - val_loss: 0.3022 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 827/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2759 - acc: 0.9446 - precision: 0.9885 - recall: 0.8983 - f1_score: 0.9394 - val_loss: 0.3018 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 828/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2754 - acc: 0.9446 - precision: 0.9852 - recall: 0.8974 - f1_score: 0.9376 - val_loss: 0.3013 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 829/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2750 - acc: 0.9446 - precision: 0.9848 - recall: 0.8995 - f1_score: 0.9394 - val_loss: 0.3009 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 830/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2745 - acc: 0.9446 - precision: 0.9870 - recall: 0.9008 - f1_score: 0.9412 - val_loss: 0.3004 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 831/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2741 - acc: 0.9446 - precision: 0.9859 - recall: 0.9009 - f1_score: 0.9404 - val_loss: 0.3000 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 832/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2736 - acc: 0.9446 - precision: 0.9867 - recall: 0.9041 - f1_score: 0.9416 - val_loss: 0.2996 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 833/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2731 - acc: 0.9446 - precision: 0.9852 - recall: 0.9008 - f1_score: 0.9400 - val_loss: 0.2991 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 834/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2727 - acc: 0.9446 - precision: 0.9865 - recall: 0.9036 - f1_score: 0.9415 - val_loss: 0.2987 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 835/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2722 - acc: 0.9446 - precision: 0.9868 - recall: 0.8987 - f1_score: 0.9388 - val_loss: 0.2983 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 836/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2718 - acc: 0.9446 - precision: 0.9872 - recall: 0.9009 - f1_score: 0.9408 - val_loss: 0.2978 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 837/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2714 - acc: 0.9446 - precision: 0.9855 - recall: 0.8972 - f1_score: 0.9386 - val_loss: 0.2974 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 838/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2709 - acc: 0.9446 - precision: 0.9876 - recall: 0.9032 - f1_score: 0.9428 - val_loss: 0.2970 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 839/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2705 - acc: 0.9446 - precision: 0.9851 - recall: 0.8996 - f1_score: 0.9398 - val_loss: 0.2965 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 840/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2700 - acc: 0.9446 - precision: 0.9854 - recall: 0.9026 - f1_score: 0.9415 - val_loss: 0.2961 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 841/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2696 - acc: 0.9446 - precision: 0.9852 - recall: 0.8999 - f1_score: 0.9393 - val_loss: 0.2957 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 842/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2692 - acc: 0.9446 - precision: 0.9856 - recall: 0.8999 - f1_score: 0.9396 - val_loss: 0.2953 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 843/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2687 - acc: 0.9446 - precision: 0.9869 - recall: 0.9010 - f1_score: 0.9413 - val_loss: 0.2948 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 844/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2683 - acc: 0.9446 - precision: 0.9859 - recall: 0.9002 - f1_score: 0.9403 - val_loss: 0.2944 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 845/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2679 - acc: 0.9446 - precision: 0.9874 - recall: 0.8999 - f1_score: 0.9408 - val_loss: 0.2940 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 846/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2674 - acc: 0.9446 - precision: 0.9864 - recall: 0.8972 - f1_score: 0.9385 - val_loss: 0.2936 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 847/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2670 - acc: 0.9446 - precision: 0.9874 - recall: 0.8974 - f1_score: 0.9389 - val_loss: 0.2932 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 848/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2666 - acc: 0.9446 - precision: 0.9864 - recall: 0.8949 - f1_score: 0.9370 - val_loss: 0.2928 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 849/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2662 - acc: 0.9446 - precision: 0.9858 - recall: 0.8991 - f1_score: 0.9395 - val_loss: 0.2924 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 850/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2658 - acc: 0.9446 - precision: 0.9854 - recall: 0.9010 - f1_score: 0.9404 - val_loss: 0.2920 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 851/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2653 - acc: 0.9446 - precision: 0.9876 - recall: 0.8994 - f1_score: 0.9401 - val_loss: 0.2916 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 852/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2649 - acc: 0.9446 - precision: 0.9871 - recall: 0.8999 - f1_score: 0.9407 - val_loss: 0.2912 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 853/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2645 - acc: 0.9446 - precision: 0.9872 - recall: 0.8994 - f1_score: 0.9396 - val_loss: 0.2908 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 854/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2641 - acc: 0.9446 - precision: 0.9856 - recall: 0.9015 - f1_score: 0.9415 - val_loss: 0.2904 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 855/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2637 - acc: 0.9446 - precision: 0.9872 - recall: 0.9015 - f1_score: 0.9419 - val_loss: 0.2900 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 856/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2633 - acc: 0.9446 - precision: 0.9859 - recall: 0.8978 - f1_score: 0.9382 - val_loss: 0.2896 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 857/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2629 - acc: 0.9446 - precision: 0.9866 - recall: 0.8959 - f1_score: 0.9377 - val_loss: 0.2892 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 858/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2625 - acc: 0.9446 - precision: 0.9879 - recall: 0.9004 - f1_score: 0.9406 - val_loss: 0.2888 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 859/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2621 - acc: 0.9446 - precision: 0.9859 - recall: 0.9019 - f1_score: 0.9411 - val_loss: 0.2884 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 860/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2617 - acc: 0.9446 - precision: 0.9865 - recall: 0.8982 - f1_score: 0.9388 - val_loss: 0.2880 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 861/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2613 - acc: 0.9446 - precision: 0.9865 - recall: 0.9032 - f1_score: 0.9422 - val_loss: 0.2876 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 862/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2609 - acc: 0.9446 - precision: 0.9862 - recall: 0.9014 - f1_score: 0.9409 - val_loss: 0.2873 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 863/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2605 - acc: 0.9446 - precision: 0.9840 - recall: 0.8999 - f1_score: 0.9395 - val_loss: 0.2869 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 864/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2601 - acc: 0.9446 - precision: 0.9867 - recall: 0.9014 - f1_score: 0.9417 - val_loss: 0.2865 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2597 - acc: 0.9446 - precision: 0.9863 - recall: 0.9013 - f1_score: 0.9412 - val_loss: 0.2861 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 866/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2593 - acc: 0.9446 - precision: 0.9864 - recall: 0.9015 - f1_score: 0.9404 - val_loss: 0.2857 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 867/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2589 - acc: 0.9446 - precision: 0.9856 - recall: 0.9016 - f1_score: 0.9409 - val_loss: 0.2854 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 868/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2585 - acc: 0.9446 - precision: 0.9868 - recall: 0.8984 - f1_score: 0.9392 - val_loss: 0.2850 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 869/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2581 - acc: 0.9446 - precision: 0.9863 - recall: 0.9012 - f1_score: 0.9410 - val_loss: 0.2846 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 870/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2578 - acc: 0.9446 - precision: 0.9827 - recall: 0.9005 - f1_score: 0.9387 - val_loss: 0.2842 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 871/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2574 - acc: 0.9446 - precision: 0.9851 - recall: 0.9014 - f1_score: 0.9407 - val_loss: 0.2839 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 872/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2570 - acc: 0.9446 - precision: 0.9863 - recall: 0.8981 - f1_score: 0.9382 - val_loss: 0.2835 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 873/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2566 - acc: 0.9446 - precision: 0.9860 - recall: 0.8988 - f1_score: 0.9387 - val_loss: 0.2832 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 874/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2562 - acc: 0.9446 - precision: 0.9873 - recall: 0.8962 - f1_score: 0.9379 - val_loss: 0.2828 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 875/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2559 - acc: 0.9446 - precision: 0.9876 - recall: 0.8975 - f1_score: 0.9384 - val_loss: 0.2824 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 876/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2555 - acc: 0.9446 - precision: 0.9858 - recall: 0.9017 - f1_score: 0.9399 - val_loss: 0.2821 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 877/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2551 - acc: 0.9446 - precision: 0.9853 - recall: 0.9020 - f1_score: 0.9406 - val_loss: 0.2817 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 878/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2547 - acc: 0.9446 - precision: 0.9844 - recall: 0.8977 - f1_score: 0.9386 - val_loss: 0.2814 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 879/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2544 - acc: 0.9446 - precision: 0.9844 - recall: 0.8990 - f1_score: 0.9394 - val_loss: 0.2810 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 880/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2540 - acc: 0.9446 - precision: 0.9860 - recall: 0.8987 - f1_score: 0.9391 - val_loss: 0.2807 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 881/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2537 - acc: 0.9446 - precision: 0.9845 - recall: 0.8988 - f1_score: 0.9384 - val_loss: 0.2803 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 882/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2533 - acc: 0.9446 - precision: 0.9866 - recall: 0.8978 - f1_score: 0.9383 - val_loss: 0.2799 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 883/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2529 - acc: 0.9446 - precision: 0.9864 - recall: 0.9034 - f1_score: 0.9419 - val_loss: 0.2796 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 884/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2526 - acc: 0.9446 - precision: 0.9862 - recall: 0.9002 - f1_score: 0.9407 - val_loss: 0.2793 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 885/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2522 - acc: 0.9446 - precision: 0.9850 - recall: 0.8985 - f1_score: 0.9391 - val_loss: 0.2789 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 886/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2518 - acc: 0.9446 - precision: 0.9870 - recall: 0.9012 - f1_score: 0.9405 - val_loss: 0.2786 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 887/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2515 - acc: 0.9446 - precision: 0.9872 - recall: 0.8956 - f1_score: 0.9386 - val_loss: 0.2782 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 888/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2511 - acc: 0.9446 - precision: 0.9865 - recall: 0.9034 - f1_score: 0.9422 - val_loss: 0.2779 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 889/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2508 - acc: 0.9446 - precision: 0.9861 - recall: 0.9029 - f1_score: 0.9415 - val_loss: 0.2775 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 890/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2504 - acc: 0.9446 - precision: 0.9862 - recall: 0.8996 - f1_score: 0.9405 - val_loss: 0.2772 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 891/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2501 - acc: 0.9446 - precision: 0.9854 - recall: 0.8983 - f1_score: 0.9383 - val_loss: 0.2769 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 892/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2497 - acc: 0.9446 - precision: 0.9867 - recall: 0.9004 - f1_score: 0.9398 - val_loss: 0.2766 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 893/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2494 - acc: 0.9446 - precision: 0.9853 - recall: 0.9004 - f1_score: 0.9398 - val_loss: 0.2762 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 894/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2490 - acc: 0.9446 - precision: 0.9866 - recall: 0.9014 - f1_score: 0.9408 - val_loss: 0.2759 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 895/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2487 - acc: 0.9446 - precision: 0.9860 - recall: 0.8998 - f1_score: 0.9397 - val_loss: 0.2756 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 896/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2484 - acc: 0.9446 - precision: 0.9854 - recall: 0.8998 - f1_score: 0.9400 - val_loss: 0.2752 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2480 - acc: 0.9446 - precision: 0.9880 - recall: 0.8983 - f1_score: 0.9401 - val_loss: 0.2749 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 898/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2477 - acc: 0.9446 - precision: 0.9856 - recall: 0.9004 - f1_score: 0.9403 - val_loss: 0.2746 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 899/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2473 - acc: 0.9446 - precision: 0.9856 - recall: 0.8981 - f1_score: 0.9378 - val_loss: 0.2742 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 900/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2470 - acc: 0.9446 - precision: 0.9865 - recall: 0.8985 - f1_score: 0.9397 - val_loss: 0.2739 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 901/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2467 - acc: 0.9446 - precision: 0.9862 - recall: 0.8981 - f1_score: 0.9389 - val_loss: 0.2736 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 902/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2463 - acc: 0.9446 - precision: 0.9856 - recall: 0.9031 - f1_score: 0.9400 - val_loss: 0.2733 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 903/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2460 - acc: 0.9446 - precision: 0.9854 - recall: 0.9016 - f1_score: 0.9401 - val_loss: 0.2730 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 904/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2457 - acc: 0.9446 - precision: 0.9843 - recall: 0.9027 - f1_score: 0.9406 - val_loss: 0.2727 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 905/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2453 - acc: 0.9446 - precision: 0.9840 - recall: 0.9023 - f1_score: 0.9400 - val_loss: 0.2723 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 906/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2450 - acc: 0.9446 - precision: 0.9866 - recall: 0.9003 - f1_score: 0.9409 - val_loss: 0.2720 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 907/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2447 - acc: 0.9446 - precision: 0.9862 - recall: 0.9008 - f1_score: 0.9408 - val_loss: 0.2717 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 908/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2444 - acc: 0.9446 - precision: 0.9851 - recall: 0.9028 - f1_score: 0.9410 - val_loss: 0.2714 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 909/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2440 - acc: 0.9446 - precision: 0.9858 - recall: 0.8992 - f1_score: 0.9396 - val_loss: 0.2711 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 910/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2437 - acc: 0.9446 - precision: 0.9855 - recall: 0.8994 - f1_score: 0.9396 - val_loss: 0.2708 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 911/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2434 - acc: 0.9446 - precision: 0.9863 - recall: 0.8992 - f1_score: 0.9398 - val_loss: 0.2705 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 912/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2431 - acc: 0.9446 - precision: 0.9851 - recall: 0.8993 - f1_score: 0.9397 - val_loss: 0.2702 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 913/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2428 - acc: 0.9446 - precision: 0.9867 - recall: 0.9041 - f1_score: 0.9415 - val_loss: 0.2699 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 914/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2425 - acc: 0.9446 - precision: 0.9867 - recall: 0.8995 - f1_score: 0.9398 - val_loss: 0.2696 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 915/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2421 - acc: 0.9446 - precision: 0.9865 - recall: 0.8997 - f1_score: 0.9396 - val_loss: 0.2693 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 916/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2418 - acc: 0.9446 - precision: 0.9868 - recall: 0.9007 - f1_score: 0.9409 - val_loss: 0.2690 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 917/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2415 - acc: 0.9446 - precision: 0.9865 - recall: 0.8997 - f1_score: 0.9407 - val_loss: 0.2687 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 918/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2412 - acc: 0.9446 - precision: 0.9854 - recall: 0.9018 - f1_score: 0.9413 - val_loss: 0.2684 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 919/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2409 - acc: 0.9446 - precision: 0.9877 - recall: 0.8989 - f1_score: 0.9407 - val_loss: 0.2681 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 920/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2406 - acc: 0.9446 - precision: 0.9845 - recall: 0.9029 - f1_score: 0.9408 - val_loss: 0.2678 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 921/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2403 - acc: 0.9446 - precision: 0.9869 - recall: 0.9044 - f1_score: 0.9420 - val_loss: 0.2675 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 922/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2400 - acc: 0.9446 - precision: 0.9848 - recall: 0.8970 - f1_score: 0.9379 - val_loss: 0.2672 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 923/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2397 - acc: 0.9446 - precision: 0.9860 - recall: 0.9018 - f1_score: 0.9406 - val_loss: 0.2669 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 924/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2394 - acc: 0.9446 - precision: 0.9864 - recall: 0.9002 - f1_score: 0.9397 - val_loss: 0.2666 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 925/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2391 - acc: 0.9446 - precision: 0.9860 - recall: 0.8972 - f1_score: 0.9387 - val_loss: 0.2663 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 926/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2388 - acc: 0.9446 - precision: 0.9873 - recall: 0.8997 - f1_score: 0.9402 - val_loss: 0.2661 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 927/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2385 - acc: 0.9446 - precision: 0.9850 - recall: 0.9022 - f1_score: 0.9411 - val_loss: 0.2658 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 928/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2382 - acc: 0.9446 - precision: 0.9885 - recall: 0.8981 - f1_score: 0.9391 - val_loss: 0.2655 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2379 - acc: 0.9446 - precision: 0.9860 - recall: 0.9034 - f1_score: 0.9420 - val_loss: 0.2652 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 930/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2376 - acc: 0.9446 - precision: 0.9864 - recall: 0.9034 - f1_score: 0.9422 - val_loss: 0.2649 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 931/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2373 - acc: 0.9446 - precision: 0.9848 - recall: 0.9024 - f1_score: 0.9402 - val_loss: 0.2646 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 932/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2370 - acc: 0.9446 - precision: 0.9864 - recall: 0.9013 - f1_score: 0.9411 - val_loss: 0.2644 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 933/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2367 - acc: 0.9446 - precision: 0.9867 - recall: 0.9006 - f1_score: 0.9407 - val_loss: 0.2641 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 934/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2364 - acc: 0.9446 - precision: 0.9874 - recall: 0.8991 - f1_score: 0.9403 - val_loss: 0.2638 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 935/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2361 - acc: 0.9446 - precision: 0.9867 - recall: 0.8991 - f1_score: 0.9401 - val_loss: 0.2635 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 936/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2358 - acc: 0.9446 - precision: 0.9857 - recall: 0.8977 - f1_score: 0.9384 - val_loss: 0.2632 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 937/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2355 - acc: 0.9446 - precision: 0.9861 - recall: 0.9027 - f1_score: 0.9413 - val_loss: 0.2630 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 938/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2352 - acc: 0.9446 - precision: 0.9865 - recall: 0.8982 - f1_score: 0.9387 - val_loss: 0.2627 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 939/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2350 - acc: 0.9446 - precision: 0.9849 - recall: 0.8994 - f1_score: 0.9394 - val_loss: 0.2624 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 940/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2347 - acc: 0.9446 - precision: 0.9867 - recall: 0.9004 - f1_score: 0.9404 - val_loss: 0.2622 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 941/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2344 - acc: 0.9446 - precision: 0.9872 - recall: 0.9005 - f1_score: 0.9414 - val_loss: 0.2619 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 942/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2341 - acc: 0.9446 - precision: 0.9849 - recall: 0.9033 - f1_score: 0.9416 - val_loss: 0.2616 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 943/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2338 - acc: 0.9446 - precision: 0.9872 - recall: 0.8975 - f1_score: 0.9390 - val_loss: 0.2614 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 944/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2335 - acc: 0.9446 - precision: 0.9863 - recall: 0.8978 - f1_score: 0.9387 - val_loss: 0.2611 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 945/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2333 - acc: 0.9446 - precision: 0.9862 - recall: 0.8984 - f1_score: 0.9388 - val_loss: 0.2608 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 946/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2330 - acc: 0.9446 - precision: 0.9870 - recall: 0.9003 - f1_score: 0.9403 - val_loss: 0.2606 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 947/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2327 - acc: 0.9446 - precision: 0.9863 - recall: 0.8991 - f1_score: 0.9397 - val_loss: 0.2603 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 948/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2325 - acc: 0.9446 - precision: 0.9865 - recall: 0.9000 - f1_score: 0.9408 - val_loss: 0.2601 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 949/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2322 - acc: 0.9446 - precision: 0.9862 - recall: 0.9027 - f1_score: 0.9412 - val_loss: 0.2598 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 950/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2319 - acc: 0.9446 - precision: 0.9874 - recall: 0.9035 - f1_score: 0.9426 - val_loss: 0.2596 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 951/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2316 - acc: 0.9446 - precision: 0.9843 - recall: 0.9006 - f1_score: 0.9401 - val_loss: 0.2593 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 952/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2314 - acc: 0.9446 - precision: 0.9848 - recall: 0.9051 - f1_score: 0.9421 - val_loss: 0.2591 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 953/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2311 - acc: 0.9446 - precision: 0.9866 - recall: 0.9011 - f1_score: 0.9406 - val_loss: 0.2588 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 954/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2308 - acc: 0.9446 - precision: 0.9855 - recall: 0.9000 - f1_score: 0.9395 - val_loss: 0.2586 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 955/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2306 - acc: 0.9446 - precision: 0.9875 - recall: 0.9006 - f1_score: 0.9409 - val_loss: 0.2583 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 956/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2303 - acc: 0.9446 - precision: 0.9879 - recall: 0.9032 - f1_score: 0.9425 - val_loss: 0.2581 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 957/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2300 - acc: 0.9446 - precision: 0.9859 - recall: 0.8975 - f1_score: 0.9383 - val_loss: 0.2578 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 958/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2298 - acc: 0.9446 - precision: 0.9856 - recall: 0.9037 - f1_score: 0.9422 - val_loss: 0.2576 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 959/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2295 - acc: 0.9446 - precision: 0.9866 - recall: 0.9009 - f1_score: 0.9411 - val_loss: 0.2573 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 960/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2293 - acc: 0.9446 - precision: 0.9859 - recall: 0.9018 - f1_score: 0.9412 - val_loss: 0.2571 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2290 - acc: 0.9446 - precision: 0.9865 - recall: 0.8969 - f1_score: 0.9385 - val_loss: 0.2568 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 962/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2288 - acc: 0.9446 - precision: 0.9867 - recall: 0.8964 - f1_score: 0.9374 - val_loss: 0.2566 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 963/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2285 - acc: 0.9446 - precision: 0.9858 - recall: 0.9030 - f1_score: 0.9402 - val_loss: 0.2563 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 964/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2282 - acc: 0.9446 - precision: 0.9850 - recall: 0.9065 - f1_score: 0.9428 - val_loss: 0.2561 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 965/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2280 - acc: 0.9446 - precision: 0.9856 - recall: 0.8991 - f1_score: 0.9394 - val_loss: 0.2559 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 966/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2277 - acc: 0.9446 - precision: 0.9862 - recall: 0.9043 - f1_score: 0.9423 - val_loss: 0.2556 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 967/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2275 - acc: 0.9446 - precision: 0.9859 - recall: 0.9040 - f1_score: 0.9417 - val_loss: 0.2554 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 968/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2272 - acc: 0.9446 - precision: 0.9874 - recall: 0.8924 - f1_score: 0.9358 - val_loss: 0.2551 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 969/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2270 - acc: 0.9446 - precision: 0.9865 - recall: 0.8987 - f1_score: 0.9391 - val_loss: 0.2549 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 970/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2267 - acc: 0.9446 - precision: 0.9875 - recall: 0.8988 - f1_score: 0.9395 - val_loss: 0.2547 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 971/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2265 - acc: 0.9446 - precision: 0.9846 - recall: 0.9009 - f1_score: 0.9392 - val_loss: 0.2544 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 972/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2262 - acc: 0.9446 - precision: 0.9841 - recall: 0.8989 - f1_score: 0.9389 - val_loss: 0.2542 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 973/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2260 - acc: 0.9446 - precision: 0.9868 - recall: 0.8978 - f1_score: 0.9391 - val_loss: 0.2540 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 974/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2258 - acc: 0.9446 - precision: 0.9858 - recall: 0.9037 - f1_score: 0.9417 - val_loss: 0.2537 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 975/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2255 - acc: 0.9446 - precision: 0.9828 - recall: 0.9032 - f1_score: 0.9402 - val_loss: 0.2535 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 976/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2253 - acc: 0.9446 - precision: 0.9868 - recall: 0.8998 - f1_score: 0.9399 - val_loss: 0.2533 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 977/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2250 - acc: 0.9446 - precision: 0.9868 - recall: 0.9025 - f1_score: 0.9420 - val_loss: 0.2530 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 978/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2248 - acc: 0.9446 - precision: 0.9859 - recall: 0.9002 - f1_score: 0.9394 - val_loss: 0.2528 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 979/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2245 - acc: 0.9446 - precision: 0.9846 - recall: 0.8995 - f1_score: 0.9396 - val_loss: 0.2526 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 980/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2243 - acc: 0.9462 - precision: 0.9859 - recall: 0.9070 - f1_score: 0.9439 - val_loss: 0.2523 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 981/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2241 - acc: 0.9462 - precision: 0.9866 - recall: 0.8991 - f1_score: 0.9397 - val_loss: 0.2521 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 982/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2238 - acc: 0.9462 - precision: 0.9856 - recall: 0.9004 - f1_score: 0.9405 - val_loss: 0.2519 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 983/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2236 - acc: 0.9462 - precision: 0.9829 - recall: 0.9004 - f1_score: 0.9380 - val_loss: 0.2517 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 984/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2234 - acc: 0.9462 - precision: 0.9853 - recall: 0.9029 - f1_score: 0.9418 - val_loss: 0.2514 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 985/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2231 - acc: 0.9462 - precision: 0.9859 - recall: 0.9014 - f1_score: 0.9407 - val_loss: 0.2512 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 986/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2229 - acc: 0.9462 - precision: 0.9873 - recall: 0.9086 - f1_score: 0.9456 - val_loss: 0.2510 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 987/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2227 - acc: 0.9462 - precision: 0.9868 - recall: 0.8991 - f1_score: 0.9392 - val_loss: 0.2508 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 988/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2224 - acc: 0.9462 - precision: 0.9842 - recall: 0.9027 - f1_score: 0.9413 - val_loss: 0.2506 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 989/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2222 - acc: 0.9462 - precision: 0.9868 - recall: 0.8972 - f1_score: 0.9389 - val_loss: 0.2503 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 990/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2220 - acc: 0.9462 - precision: 0.9861 - recall: 0.9063 - f1_score: 0.9437 - val_loss: 0.2501 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 991/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2217 - acc: 0.9462 - precision: 0.9864 - recall: 0.9037 - f1_score: 0.9417 - val_loss: 0.2499 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 992/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2215 - acc: 0.9462 - precision: 0.9872 - recall: 0.9033 - f1_score: 0.9427 - val_loss: 0.2497 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2213 - acc: 0.9462 - precision: 0.9852 - recall: 0.9021 - f1_score: 0.9409 - val_loss: 0.2495 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 994/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2211 - acc: 0.9462 - precision: 0.9844 - recall: 0.9035 - f1_score: 0.9417 - val_loss: 0.2493 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 995/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2208 - acc: 0.9462 - precision: 0.9849 - recall: 0.9031 - f1_score: 0.9412 - val_loss: 0.2491 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 996/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2206 - acc: 0.9462 - precision: 0.9861 - recall: 0.9028 - f1_score: 0.9414 - val_loss: 0.2489 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 997/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2204 - acc: 0.9462 - precision: 0.9867 - recall: 0.9042 - f1_score: 0.9431 - val_loss: 0.2487 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 998/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2202 - acc: 0.9462 - precision: 0.9879 - recall: 0.9043 - f1_score: 0.9434 - val_loss: 0.2485 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 999/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2200 - acc: 0.9462 - precision: 0.9852 - recall: 0.9033 - f1_score: 0.9404 - val_loss: 0.2483 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      "Epoch 1000/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2197 - acc: 0.9462 - precision: 0.9849 - recall: 0.8963 - f1_score: 0.9374 - val_loss: 0.2481 - val_acc: 0.9308 - val_precision: 0.9863 - val_recall: 0.8752 - val_f1_score: 0.9271\n",
      " 50/159 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9338 - acc: 0.5766 - precision: 0.5378 - recall: 0.9910 - f1_score: 0.6953 - val_loss: 5.9219 - val_acc: 0.5380 - val_precision: 0.5212 - val_recall: 0.9756 - val_f1_score: 0.6780\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8849 - acc: 0.5782 - precision: 0.5386 - recall: 0.9939 - f1_score: 0.6967 - val_loss: 5.8802 - val_acc: 0.5570 - val_precision: 0.5321 - val_recall: 0.9756 - val_f1_score: 0.6871\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8446 - acc: 0.5814 - precision: 0.5413 - recall: 0.9942 - f1_score: 0.6993 - val_loss: 5.8425 - val_acc: 0.5696 - val_precision: 0.5383 - val_recall: 0.9756 - val_f1_score: 0.6929\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8075 - acc: 0.5893 - precision: 0.5458 - recall: 0.9905 - f1_score: 0.7022 - val_loss: 5.8069 - val_acc: 0.5823 - val_precision: 0.5458 - val_recall: 0.9756 - val_f1_score: 0.6993\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7719 - acc: 0.6051 - precision: 0.5567 - recall: 0.9877 - f1_score: 0.7099 - val_loss: 5.7725 - val_acc: 0.5759 - val_precision: 0.5424 - val_recall: 0.9630 - val_f1_score: 0.6933\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7375 - acc: 0.6193 - precision: 0.5646 - recall: 0.9870 - f1_score: 0.7168 - val_loss: 5.7389 - val_acc: 0.5886 - val_precision: 0.5498 - val_recall: 0.9461 - val_f1_score: 0.6953\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7039 - acc: 0.6335 - precision: 0.5732 - recall: 0.9878 - f1_score: 0.7224 - val_loss: 5.7061 - val_acc: 0.6013 - val_precision: 0.5583 - val_recall: 0.9461 - val_f1_score: 0.7018\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6708 - acc: 0.6509 - precision: 0.5885 - recall: 0.9829 - f1_score: 0.7338 - val_loss: 5.6737 - val_acc: 0.6266 - val_precision: 0.5751 - val_recall: 0.9461 - val_f1_score: 0.7147\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6382 - acc: 0.6840 - precision: 0.6128 - recall: 0.9804 - f1_score: 0.7527 - val_loss: 5.6419 - val_acc: 0.6329 - val_precision: 0.5795 - val_recall: 0.9461 - val_f1_score: 0.7183\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6061 - acc: 0.6919 - precision: 0.6184 - recall: 0.9758 - f1_score: 0.7534 - val_loss: 5.6104 - val_acc: 0.6392 - val_precision: 0.5841 - val_recall: 0.9461 - val_f1_score: 0.7219\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5743 - acc: 0.7030 - precision: 0.6258 - recall: 0.9707 - f1_score: 0.7588 - val_loss: 5.5793 - val_acc: 0.6519 - val_precision: 0.5940 - val_recall: 0.9461 - val_f1_score: 0.7293\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5429 - acc: 0.7330 - precision: 0.6529 - recall: 0.9716 - f1_score: 0.7788 - val_loss: 5.5486 - val_acc: 0.7089 - val_precision: 0.6434 - val_recall: 0.9461 - val_f1_score: 0.7638\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5118 - acc: 0.7551 - precision: 0.6758 - recall: 0.9702 - f1_score: 0.7936 - val_loss: 5.5181 - val_acc: 0.7152 - val_precision: 0.6480 - val_recall: 0.9461 - val_f1_score: 0.7673\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4811 - acc: 0.7694 - precision: 0.6926 - recall: 0.9654 - f1_score: 0.8053 - val_loss: 5.4880 - val_acc: 0.7152 - val_precision: 0.6480 - val_recall: 0.9461 - val_f1_score: 0.7673\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4506 - acc: 0.7899 - precision: 0.7133 - recall: 0.9612 - f1_score: 0.8170 - val_loss: 5.4582 - val_acc: 0.7532 - val_precision: 0.6856 - val_recall: 0.9334 - val_f1_score: 0.7888\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4205 - acc: 0.8088 - precision: 0.7338 - recall: 0.9634 - f1_score: 0.8299 - val_loss: 5.4286 - val_acc: 0.7595 - val_precision: 0.6915 - val_recall: 0.9334 - val_f1_score: 0.7927\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3907 - acc: 0.8246 - precision: 0.7543 - recall: 0.9572 - f1_score: 0.8414 - val_loss: 5.3993 - val_acc: 0.7722 - val_precision: 0.7095 - val_recall: 0.9217 - val_f1_score: 0.7994\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3611 - acc: 0.8373 - precision: 0.7718 - recall: 0.9546 - f1_score: 0.8502 - val_loss: 5.3703 - val_acc: 0.7848 - val_precision: 0.7219 - val_recall: 0.9217 - val_f1_score: 0.8081\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3318 - acc: 0.8499 - precision: 0.7877 - recall: 0.9449 - f1_score: 0.8569 - val_loss: 5.3415 - val_acc: 0.7848 - val_precision: 0.7260 - val_recall: 0.9085 - val_f1_score: 0.8062\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3027 - acc: 0.8689 - precision: 0.8191 - recall: 0.9385 - f1_score: 0.8721 - val_loss: 5.3129 - val_acc: 0.8038 - val_precision: 0.7483 - val_recall: 0.9085 - val_f1_score: 0.8199\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2739 - acc: 0.8752 - precision: 0.8299 - recall: 0.9358 - f1_score: 0.8778 - val_loss: 5.2846 - val_acc: 0.8101 - val_precision: 0.7562 - val_recall: 0.9085 - val_f1_score: 0.8248\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2453 - acc: 0.8878 - precision: 0.8525 - recall: 0.9307 - f1_score: 0.8890 - val_loss: 5.2565 - val_acc: 0.8165 - val_precision: 0.7645 - val_recall: 0.9085 - val_f1_score: 0.8299\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2170 - acc: 0.8926 - precision: 0.8623 - recall: 0.9320 - f1_score: 0.8941 - val_loss: 5.2286 - val_acc: 0.8165 - val_precision: 0.7783 - val_recall: 0.8959 - val_f1_score: 0.8296\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1889 - acc: 0.8942 - precision: 0.8641 - recall: 0.9327 - f1_score: 0.8958 - val_loss: 5.2010 - val_acc: 0.8354 - val_precision: 0.8046 - val_recall: 0.8959 - val_f1_score: 0.8449\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.1610 - acc: 0.8973 - precision: 0.8736 - recall: 0.9327 - f1_score: 0.8994 - val_loss: 5.1735 - val_acc: 0.8544 - val_precision: 0.8301 - val_recall: 0.8959 - val_f1_score: 0.8591\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1333 - acc: 0.9005 - precision: 0.8773 - recall: 0.9300 - f1_score: 0.9010 - val_loss: 5.1463 - val_acc: 0.8544 - val_precision: 0.8386 - val_recall: 0.8841 - val_f1_score: 0.8585\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1058 - acc: 0.9021 - precision: 0.8870 - recall: 0.9266 - f1_score: 0.9042 - val_loss: 5.1193 - val_acc: 0.8671 - val_precision: 0.8580 - val_recall: 0.8841 - val_f1_score: 0.8685\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0786 - acc: 0.9052 - precision: 0.8883 - recall: 0.9257 - f1_score: 0.9041 - val_loss: 5.0925 - val_acc: 0.8671 - val_precision: 0.8681 - val_recall: 0.8710 - val_f1_score: 0.8675\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0516 - acc: 0.9068 - precision: 0.8919 - recall: 0.9281 - f1_score: 0.9065 - val_loss: 5.0658 - val_acc: 0.8734 - val_precision: 0.8776 - val_recall: 0.8710 - val_f1_score: 0.8725\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0247 - acc: 0.9131 - precision: 0.9009 - recall: 0.9235 - f1_score: 0.9105 - val_loss: 5.0394 - val_acc: 0.8734 - val_precision: 0.8875 - val_recall: 0.8592 - val_f1_score: 0.8711\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9981 - acc: 0.9179 - precision: 0.9137 - recall: 0.9201 - f1_score: 0.9145 - val_loss: 5.0132 - val_acc: 0.8797 - val_precision: 0.8977 - val_recall: 0.8592 - val_f1_score: 0.8764\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9716 - acc: 0.9194 - precision: 0.9235 - recall: 0.9186 - f1_score: 0.9201 - val_loss: 4.9871 - val_acc: 0.8797 - val_precision: 0.8977 - val_recall: 0.8592 - val_f1_score: 0.8764\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9454 - acc: 0.9226 - precision: 0.9238 - recall: 0.9168 - f1_score: 0.9185 - val_loss: 4.9612 - val_acc: 0.8861 - val_precision: 0.9103 - val_recall: 0.8592 - val_f1_score: 0.8825\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9193 - acc: 0.9210 - precision: 0.9238 - recall: 0.9112 - f1_score: 0.9166 - val_loss: 4.9355 - val_acc: 0.8861 - val_precision: 0.9103 - val_recall: 0.8592 - val_f1_score: 0.8825\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8935 - acc: 0.9258 - precision: 0.9331 - recall: 0.9168 - f1_score: 0.9235 - val_loss: 4.9100 - val_acc: 0.8987 - val_precision: 0.9351 - val_recall: 0.8592 - val_f1_score: 0.8944\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8678 - acc: 0.9289 - precision: 0.9432 - recall: 0.9145 - f1_score: 0.9272 - val_loss: 4.8847 - val_acc: 0.8987 - val_precision: 0.9461 - val_recall: 0.8475 - val_f1_score: 0.8931\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8423 - acc: 0.9321 - precision: 0.9471 - recall: 0.9136 - f1_score: 0.9295 - val_loss: 4.8596 - val_acc: 0.8987 - val_precision: 0.9461 - val_recall: 0.8475 - val_f1_score: 0.8931\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8169 - acc: 0.9321 - precision: 0.9505 - recall: 0.9070 - f1_score: 0.9273 - val_loss: 4.8346 - val_acc: 0.8987 - val_precision: 0.9461 - val_recall: 0.8475 - val_f1_score: 0.8931\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7918 - acc: 0.9352 - precision: 0.9586 - recall: 0.9123 - f1_score: 0.9324 - val_loss: 4.8098 - val_acc: 0.8987 - val_precision: 0.9461 - val_recall: 0.8475 - val_f1_score: 0.8931\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7667 - acc: 0.9368 - precision: 0.9595 - recall: 0.9076 - f1_score: 0.9319 - val_loss: 4.7851 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7419 - acc: 0.9400 - precision: 0.9649 - recall: 0.9082 - f1_score: 0.9344 - val_loss: 4.7606 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7173 - acc: 0.9368 - precision: 0.9636 - recall: 0.9053 - f1_score: 0.9326 - val_loss: 4.7363 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6928 - acc: 0.9352 - precision: 0.9681 - recall: 0.9012 - f1_score: 0.9322 - val_loss: 4.7121 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6684 - acc: 0.9336 - precision: 0.9662 - recall: 0.8956 - f1_score: 0.9285 - val_loss: 4.6881 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6443 - acc: 0.9336 - precision: 0.9689 - recall: 0.8949 - f1_score: 0.9290 - val_loss: 4.6643 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6203 - acc: 0.9336 - precision: 0.9696 - recall: 0.8977 - f1_score: 0.9315 - val_loss: 4.6405 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5964 - acc: 0.9336 - precision: 0.9683 - recall: 0.8940 - f1_score: 0.9279 - val_loss: 4.6170 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5727 - acc: 0.9336 - precision: 0.9683 - recall: 0.8959 - f1_score: 0.9284 - val_loss: 4.5936 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5492 - acc: 0.9336 - precision: 0.9697 - recall: 0.8973 - f1_score: 0.9302 - val_loss: 4.5704 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5258 - acc: 0.9321 - precision: 0.9683 - recall: 0.8982 - f1_score: 0.9297 - val_loss: 4.5473 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5026 - acc: 0.9321 - precision: 0.9667 - recall: 0.8849 - f1_score: 0.9224 - val_loss: 4.5243 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4795 - acc: 0.9321 - precision: 0.9700 - recall: 0.8908 - f1_score: 0.9276 - val_loss: 4.5015 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4566 - acc: 0.9352 - precision: 0.9761 - recall: 0.8912 - f1_score: 0.9306 - val_loss: 4.4789 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4337 - acc: 0.9352 - precision: 0.9749 - recall: 0.8917 - f1_score: 0.9302 - val_loss: 4.4563 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4111 - acc: 0.9352 - precision: 0.9780 - recall: 0.8895 - f1_score: 0.9309 - val_loss: 4.4339 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3886 - acc: 0.9368 - precision: 0.9766 - recall: 0.8899 - f1_score: 0.9306 - val_loss: 4.4117 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.3662 - acc: 0.9368 - precision: 0.9798 - recall: 0.8917 - f1_score: 0.9324 - val_loss: 4.3896 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3439 - acc: 0.9368 - precision: 0.9801 - recall: 0.8908 - f1_score: 0.9323 - val_loss: 4.3676 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3218 - acc: 0.9368 - precision: 0.9803 - recall: 0.8932 - f1_score: 0.9340 - val_loss: 4.3458 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2998 - acc: 0.9368 - precision: 0.9792 - recall: 0.8912 - f1_score: 0.9324 - val_loss: 4.3240 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2780 - acc: 0.9368 - precision: 0.9760 - recall: 0.8840 - f1_score: 0.9252 - val_loss: 4.3024 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2563 - acc: 0.9384 - precision: 0.9829 - recall: 0.8908 - f1_score: 0.9334 - val_loss: 4.2810 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2347 - acc: 0.9384 - precision: 0.9825 - recall: 0.8919 - f1_score: 0.9337 - val_loss: 4.2596 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2133 - acc: 0.9368 - precision: 0.9829 - recall: 0.8835 - f1_score: 0.9293 - val_loss: 4.2384 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1919 - acc: 0.9368 - precision: 0.9820 - recall: 0.8875 - f1_score: 0.9318 - val_loss: 4.2173 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1707 - acc: 0.9368 - precision: 0.9818 - recall: 0.8901 - f1_score: 0.9317 - val_loss: 4.1964 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1497 - acc: 0.9368 - precision: 0.9817 - recall: 0.8864 - f1_score: 0.9296 - val_loss: 4.1756 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1287 - acc: 0.9368 - precision: 0.9826 - recall: 0.8865 - f1_score: 0.9311 - val_loss: 4.1549 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1079 - acc: 0.9368 - precision: 0.9824 - recall: 0.8851 - f1_score: 0.9289 - val_loss: 4.1343 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0872 - acc: 0.9368 - precision: 0.9838 - recall: 0.8880 - f1_score: 0.9324 - val_loss: 4.1138 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0666 - acc: 0.9384 - precision: 0.9845 - recall: 0.8916 - f1_score: 0.9341 - val_loss: 4.0935 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0462 - acc: 0.9384 - precision: 0.9827 - recall: 0.8871 - f1_score: 0.9313 - val_loss: 4.0732 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0259 - acc: 0.9384 - precision: 0.9824 - recall: 0.8931 - f1_score: 0.9340 - val_loss: 4.0531 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0056 - acc: 0.9384 - precision: 0.9835 - recall: 0.8924 - f1_score: 0.9351 - val_loss: 4.0331 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9856 - acc: 0.9400 - precision: 0.9807 - recall: 0.8845 - f1_score: 0.9284 - val_loss: 4.0133 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9656 - acc: 0.9400 - precision: 0.9852 - recall: 0.8884 - f1_score: 0.9330 - val_loss: 3.9935 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9457 - acc: 0.9400 - precision: 0.9859 - recall: 0.8914 - f1_score: 0.9360 - val_loss: 3.9738 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9259 - acc: 0.9400 - precision: 0.9850 - recall: 0.8904 - f1_score: 0.9340 - val_loss: 3.9543 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9063 - acc: 0.9400 - precision: 0.9855 - recall: 0.8938 - f1_score: 0.9360 - val_loss: 3.9349 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8868 - acc: 0.9400 - precision: 0.9865 - recall: 0.8916 - f1_score: 0.9359 - val_loss: 3.9155 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8674 - acc: 0.9400 - precision: 0.9869 - recall: 0.8902 - f1_score: 0.9338 - val_loss: 3.8964 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8481 - acc: 0.9400 - precision: 0.9854 - recall: 0.8908 - f1_score: 0.9349 - val_loss: 3.8772 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8289 - acc: 0.9400 - precision: 0.9869 - recall: 0.8914 - f1_score: 0.9357 - val_loss: 3.8583 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8098 - acc: 0.9400 - precision: 0.9847 - recall: 0.8919 - f1_score: 0.9350 - val_loss: 3.8394 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7908 - acc: 0.9400 - precision: 0.9851 - recall: 0.8933 - f1_score: 0.9358 - val_loss: 3.8206 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7720 - acc: 0.9400 - precision: 0.9870 - recall: 0.8938 - f1_score: 0.9367 - val_loss: 3.8019 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7532 - acc: 0.9400 - precision: 0.9877 - recall: 0.8959 - f1_score: 0.9386 - val_loss: 3.7834 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7346 - acc: 0.9400 - precision: 0.9863 - recall: 0.8923 - f1_score: 0.9355 - val_loss: 3.7649 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.7160 - acc: 0.9400 - precision: 0.9857 - recall: 0.8905 - f1_score: 0.9347 - val_loss: 3.7466 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6976 - acc: 0.9400 - precision: 0.9850 - recall: 0.8917 - f1_score: 0.9354 - val_loss: 3.7283 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6792 - acc: 0.9400 - precision: 0.9857 - recall: 0.8914 - f1_score: 0.9347 - val_loss: 3.7102 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6610 - acc: 0.9400 - precision: 0.9863 - recall: 0.8883 - f1_score: 0.9341 - val_loss: 3.6921 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6429 - acc: 0.9400 - precision: 0.9832 - recall: 0.8936 - f1_score: 0.9349 - val_loss: 3.6742 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6248 - acc: 0.9400 - precision: 0.9858 - recall: 0.8910 - f1_score: 0.9350 - val_loss: 3.6563 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6069 - acc: 0.9400 - precision: 0.9876 - recall: 0.8874 - f1_score: 0.9340 - val_loss: 3.6385 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5891 - acc: 0.9400 - precision: 0.9859 - recall: 0.8893 - f1_score: 0.9339 - val_loss: 3.6209 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5713 - acc: 0.9400 - precision: 0.9861 - recall: 0.8919 - f1_score: 0.9357 - val_loss: 3.6033 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5537 - acc: 0.9400 - precision: 0.9837 - recall: 0.8906 - f1_score: 0.9339 - val_loss: 3.5859 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5362 - acc: 0.9400 - precision: 0.9857 - recall: 0.8932 - f1_score: 0.9357 - val_loss: 3.5685 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5187 - acc: 0.9400 - precision: 0.9853 - recall: 0.8918 - f1_score: 0.9344 - val_loss: 3.5513 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5014 - acc: 0.9400 - precision: 0.9860 - recall: 0.8898 - f1_score: 0.9344 - val_loss: 3.5341 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4841 - acc: 0.9400 - precision: 0.9851 - recall: 0.8957 - f1_score: 0.9366 - val_loss: 3.5170 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4670 - acc: 0.9400 - precision: 0.9850 - recall: 0.8888 - f1_score: 0.9332 - val_loss: 3.5001 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4499 - acc: 0.9400 - precision: 0.9857 - recall: 0.8931 - f1_score: 0.9362 - val_loss: 3.4832 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4330 - acc: 0.9400 - precision: 0.9853 - recall: 0.8874 - f1_score: 0.9328 - val_loss: 3.4664 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4161 - acc: 0.9400 - precision: 0.9826 - recall: 0.8884 - f1_score: 0.9323 - val_loss: 3.4497 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3993 - acc: 0.9400 - precision: 0.9861 - recall: 0.8942 - f1_score: 0.9371 - val_loss: 3.4331 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3827 - acc: 0.9400 - precision: 0.9844 - recall: 0.8900 - f1_score: 0.9338 - val_loss: 3.4166 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3661 - acc: 0.9400 - precision: 0.9858 - recall: 0.8930 - f1_score: 0.9357 - val_loss: 3.4001 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3496 - acc: 0.9400 - precision: 0.9834 - recall: 0.8886 - f1_score: 0.9323 - val_loss: 3.3838 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3331 - acc: 0.9400 - precision: 0.9845 - recall: 0.8928 - f1_score: 0.9356 - val_loss: 3.3676 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3168 - acc: 0.9400 - precision: 0.9864 - recall: 0.8904 - f1_score: 0.9349 - val_loss: 3.3514 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3006 - acc: 0.9400 - precision: 0.9859 - recall: 0.8885 - f1_score: 0.9339 - val_loss: 3.3353 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2844 - acc: 0.9400 - precision: 0.9850 - recall: 0.8885 - f1_score: 0.9332 - val_loss: 3.3193 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2684 - acc: 0.9400 - precision: 0.9864 - recall: 0.8939 - f1_score: 0.9361 - val_loss: 3.3034 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2524 - acc: 0.9400 - precision: 0.9843 - recall: 0.8913 - f1_score: 0.9344 - val_loss: 3.2876 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2366 - acc: 0.9400 - precision: 0.9874 - recall: 0.8917 - f1_score: 0.9360 - val_loss: 3.2719 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2207 - acc: 0.9400 - precision: 0.9825 - recall: 0.8847 - f1_score: 0.9293 - val_loss: 3.2562 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2050 - acc: 0.9415 - precision: 0.9868 - recall: 0.8946 - f1_score: 0.9368 - val_loss: 3.2407 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1894 - acc: 0.9415 - precision: 0.9856 - recall: 0.8968 - f1_score: 0.9374 - val_loss: 3.2252 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.1738 - acc: 0.9415 - precision: 0.9843 - recall: 0.8962 - f1_score: 0.9375 - val_loss: 3.2098 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1584 - acc: 0.9415 - precision: 0.9862 - recall: 0.8923 - f1_score: 0.9362 - val_loss: 3.1945 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1430 - acc: 0.9415 - precision: 0.9853 - recall: 0.8957 - f1_score: 0.9375 - val_loss: 3.1793 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1278 - acc: 0.9415 - precision: 0.9858 - recall: 0.8971 - f1_score: 0.9389 - val_loss: 3.1642 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1125 - acc: 0.9415 - precision: 0.9863 - recall: 0.8983 - f1_score: 0.9391 - val_loss: 3.1491 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0974 - acc: 0.9415 - precision: 0.9856 - recall: 0.8957 - f1_score: 0.9375 - val_loss: 3.1341 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0824 - acc: 0.9415 - precision: 0.9873 - recall: 0.8968 - f1_score: 0.9391 - val_loss: 3.1192 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0674 - acc: 0.9415 - precision: 0.9856 - recall: 0.9009 - f1_score: 0.9403 - val_loss: 3.1044 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0525 - acc: 0.9415 - precision: 0.9868 - recall: 0.8951 - f1_score: 0.9365 - val_loss: 3.0897 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0377 - acc: 0.9415 - precision: 0.9866 - recall: 0.8920 - f1_score: 0.9351 - val_loss: 3.0750 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0230 - acc: 0.9415 - precision: 0.9858 - recall: 0.8957 - f1_score: 0.9378 - val_loss: 3.0604 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0084 - acc: 0.9415 - precision: 0.9856 - recall: 0.8916 - f1_score: 0.9352 - val_loss: 3.0459 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9938 - acc: 0.9415 - precision: 0.9847 - recall: 0.8899 - f1_score: 0.9339 - val_loss: 3.0315 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9793 - acc: 0.9400 - precision: 0.9864 - recall: 0.8928 - f1_score: 0.9362 - val_loss: 3.0172 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9649 - acc: 0.9400 - precision: 0.9870 - recall: 0.8892 - f1_score: 0.9352 - val_loss: 3.0029 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9506 - acc: 0.9400 - precision: 0.9856 - recall: 0.8953 - f1_score: 0.9375 - val_loss: 2.9887 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9364 - acc: 0.9400 - precision: 0.9873 - recall: 0.8899 - f1_score: 0.9355 - val_loss: 2.9746 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9222 - acc: 0.9400 - precision: 0.9838 - recall: 0.8877 - f1_score: 0.9327 - val_loss: 2.9605 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9081 - acc: 0.9400 - precision: 0.9854 - recall: 0.8915 - f1_score: 0.9348 - val_loss: 2.9466 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8941 - acc: 0.9400 - precision: 0.9843 - recall: 0.8920 - f1_score: 0.9348 - val_loss: 2.9327 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8801 - acc: 0.9400 - precision: 0.9826 - recall: 0.8934 - f1_score: 0.9341 - val_loss: 2.9189 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8662 - acc: 0.9400 - precision: 0.9855 - recall: 0.8905 - f1_score: 0.9352 - val_loss: 2.9051 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8524 - acc: 0.9400 - precision: 0.9865 - recall: 0.8902 - f1_score: 0.9341 - val_loss: 2.8914 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8387 - acc: 0.9400 - precision: 0.9862 - recall: 0.8931 - f1_score: 0.9366 - val_loss: 2.8778 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8251 - acc: 0.9400 - precision: 0.9863 - recall: 0.8923 - f1_score: 0.9357 - val_loss: 2.8643 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8115 - acc: 0.9400 - precision: 0.9848 - recall: 0.8932 - f1_score: 0.9350 - val_loss: 2.8509 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7980 - acc: 0.9400 - precision: 0.9871 - recall: 0.8940 - f1_score: 0.9364 - val_loss: 2.8375 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7845 - acc: 0.9400 - precision: 0.9863 - recall: 0.8901 - f1_score: 0.9350 - val_loss: 2.8242 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7712 - acc: 0.9400 - precision: 0.9864 - recall: 0.8887 - f1_score: 0.9331 - val_loss: 2.8109 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7579 - acc: 0.9415 - precision: 0.9893 - recall: 0.8890 - f1_score: 0.9352 - val_loss: 2.7978 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.7508 - acc: 0.9200 - precision: 1.0000 - recall: 0.8519 - f1_score: 0.920 - 0s - loss: 2.7447 - acc: 0.9400 - precision: 0.9864 - recall: 0.8912 - f1_score: 0.9354 - val_loss: 2.7847 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7315 - acc: 0.9400 - precision: 0.9855 - recall: 0.8920 - f1_score: 0.9362 - val_loss: 2.7716 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.7184 - acc: 0.9415 - precision: 0.9895 - recall: 0.8908 - f1_score: 0.9370 - val_loss: 2.7587 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7054 - acc: 0.9415 - precision: 0.9906 - recall: 0.8993 - f1_score: 0.9419 - val_loss: 2.7458 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6925 - acc: 0.9415 - precision: 0.9900 - recall: 0.8908 - f1_score: 0.9366 - val_loss: 2.7330 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6796 - acc: 0.9415 - precision: 0.9908 - recall: 0.8886 - f1_score: 0.9362 - val_loss: 2.7202 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6668 - acc: 0.9415 - precision: 0.9894 - recall: 0.8900 - f1_score: 0.9358 - val_loss: 2.7075 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6541 - acc: 0.9400 - precision: 0.9869 - recall: 0.8947 - f1_score: 0.9371 - val_loss: 2.6949 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6414 - acc: 0.9415 - precision: 0.9903 - recall: 0.8881 - f1_score: 0.9350 - val_loss: 2.6823 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6288 - acc: 0.9415 - precision: 0.9892 - recall: 0.8933 - f1_score: 0.9384 - val_loss: 2.6699 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6162 - acc: 0.9415 - precision: 0.9909 - recall: 0.8909 - f1_score: 0.9362 - val_loss: 2.6574 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6038 - acc: 0.9415 - precision: 0.9896 - recall: 0.8935 - f1_score: 0.9366 - val_loss: 2.6451 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5914 - acc: 0.9431 - precision: 0.9911 - recall: 0.8889 - f1_score: 0.9363 - val_loss: 2.6328 - val_acc: 0.9051 - val_precision: 0.9587 - val_recall: 0.8475 - val_f1_score: 0.8986\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5790 - acc: 0.9400 - precision: 0.9862 - recall: 0.8913 - f1_score: 0.9358 - val_loss: 2.6206 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5668 - acc: 0.9431 - precision: 0.9930 - recall: 0.8889 - f1_score: 0.9370 - val_loss: 2.6084 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5546 - acc: 0.9415 - precision: 0.9876 - recall: 0.8917 - f1_score: 0.9341 - val_loss: 2.5963 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5424 - acc: 0.9431 - precision: 0.9913 - recall: 0.8900 - f1_score: 0.9370 - val_loss: 2.5843 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5303 - acc: 0.9431 - precision: 0.9930 - recall: 0.8929 - f1_score: 0.9385 - val_loss: 2.5723 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5183 - acc: 0.9431 - precision: 0.9938 - recall: 0.8917 - f1_score: 0.9382 - val_loss: 2.5604 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5064 - acc: 0.9415 - precision: 0.9904 - recall: 0.8931 - f1_score: 0.9386 - val_loss: 2.5485 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4945 - acc: 0.9431 - precision: 0.9930 - recall: 0.8898 - f1_score: 0.9380 - val_loss: 2.5368 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4827 - acc: 0.9431 - precision: 0.9919 - recall: 0.8918 - f1_score: 0.9386 - val_loss: 2.5250 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4709 - acc: 0.9415 - precision: 0.9892 - recall: 0.8924 - f1_score: 0.9375 - val_loss: 2.5134 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4592 - acc: 0.9431 - precision: 0.9933 - recall: 0.8929 - f1_score: 0.9394 - val_loss: 2.5018 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4475 - acc: 0.9431 - precision: 0.9913 - recall: 0.8907 - f1_score: 0.9370 - val_loss: 2.4902 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4360 - acc: 0.9431 - precision: 0.9914 - recall: 0.8923 - f1_score: 0.9379 - val_loss: 2.4788 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4245 - acc: 0.9415 - precision: 0.9902 - recall: 0.8914 - f1_score: 0.9367 - val_loss: 2.4674 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4130 - acc: 0.9431 - precision: 0.9937 - recall: 0.8908 - f1_score: 0.9383 - val_loss: 2.4560 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4016 - acc: 0.9431 - precision: 0.9934 - recall: 0.8853 - f1_score: 0.9339 - val_loss: 2.4447 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3903 - acc: 0.9431 - precision: 0.9923 - recall: 0.8949 - f1_score: 0.9389 - val_loss: 2.4335 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3790 - acc: 0.9431 - precision: 0.9934 - recall: 0.8933 - f1_score: 0.9402 - val_loss: 2.4223 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3678 - acc: 0.9431 - precision: 0.9931 - recall: 0.8910 - f1_score: 0.9365 - val_loss: 2.4112 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3566 - acc: 0.9415 - precision: 0.9898 - recall: 0.8906 - f1_score: 0.9366 - val_loss: 2.4001 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3455 - acc: 0.9431 - precision: 0.9929 - recall: 0.8904 - f1_score: 0.9378 - val_loss: 2.3891 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.3345 - acc: 0.9431 - precision: 0.9921 - recall: 0.8898 - f1_score: 0.9376 - val_loss: 2.3782 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3235 - acc: 0.9431 - precision: 0.9931 - recall: 0.8914 - f1_score: 0.9375 - val_loss: 2.3673 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3126 - acc: 0.9431 - precision: 0.9921 - recall: 0.8937 - f1_score: 0.9397 - val_loss: 2.3564 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3017 - acc: 0.9431 - precision: 0.9936 - recall: 0.8922 - f1_score: 0.9387 - val_loss: 2.3457 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2909 - acc: 0.9431 - precision: 0.9911 - recall: 0.8883 - f1_score: 0.9352 - val_loss: 2.3350 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2801 - acc: 0.9431 - precision: 0.9921 - recall: 0.8868 - f1_score: 0.9354 - val_loss: 2.3243 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2694 - acc: 0.9431 - precision: 0.9908 - recall: 0.8920 - f1_score: 0.9381 - val_loss: 2.3137 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2588 - acc: 0.9431 - precision: 0.9917 - recall: 0.8911 - f1_score: 0.9381 - val_loss: 2.3031 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2482 - acc: 0.9431 - precision: 0.9935 - recall: 0.8916 - f1_score: 0.9386 - val_loss: 2.2927 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2377 - acc: 0.9431 - precision: 0.9921 - recall: 0.8918 - f1_score: 0.9389 - val_loss: 2.2822 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2272 - acc: 0.9431 - precision: 0.9916 - recall: 0.8909 - f1_score: 0.9376 - val_loss: 2.2718 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2168 - acc: 0.9447 - precision: 0.9929 - recall: 0.8983 - f1_score: 0.9421 - val_loss: 2.2615 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2064 - acc: 0.9447 - precision: 0.9930 - recall: 0.8929 - f1_score: 0.9386 - val_loss: 2.2512 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1961 - acc: 0.9447 - precision: 0.9929 - recall: 0.8953 - f1_score: 0.9389 - val_loss: 2.2410 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1858 - acc: 0.9447 - precision: 0.9923 - recall: 0.8934 - f1_score: 0.9391 - val_loss: 2.2308 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1756 - acc: 0.9447 - precision: 0.9929 - recall: 0.8933 - f1_score: 0.9384 - val_loss: 2.2207 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1655 - acc: 0.9447 - precision: 0.9943 - recall: 0.8944 - f1_score: 0.9403 - val_loss: 2.2107 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1554 - acc: 0.9447 - precision: 0.9935 - recall: 0.8959 - f1_score: 0.9417 - val_loss: 2.2007 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1453 - acc: 0.9447 - precision: 0.9914 - recall: 0.8899 - f1_score: 0.9366 - val_loss: 2.1907 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1354 - acc: 0.9447 - precision: 0.9921 - recall: 0.8936 - f1_score: 0.9392 - val_loss: 2.1808 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1254 - acc: 0.9447 - precision: 0.9934 - recall: 0.8944 - f1_score: 0.9400 - val_loss: 2.1709 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1155 - acc: 0.9447 - precision: 0.9936 - recall: 0.8939 - f1_score: 0.9402 - val_loss: 2.1611 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1057 - acc: 0.9447 - precision: 0.9921 - recall: 0.8976 - f1_score: 0.9414 - val_loss: 2.1514 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0959 - acc: 0.9447 - precision: 0.9912 - recall: 0.8943 - f1_score: 0.9388 - val_loss: 2.1417 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0862 - acc: 0.9447 - precision: 0.9920 - recall: 0.8938 - f1_score: 0.9393 - val_loss: 2.1320 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0765 - acc: 0.9447 - precision: 0.9918 - recall: 0.8936 - f1_score: 0.9394 - val_loss: 2.1224 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0669 - acc: 0.9447 - precision: 0.9925 - recall: 0.8950 - f1_score: 0.9400 - val_loss: 2.1129 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0573 - acc: 0.9447 - precision: 0.9928 - recall: 0.8958 - f1_score: 0.9395 - val_loss: 2.1034 - val_acc: 0.9114 - val_precision: 0.9719 - val_recall: 0.8475 - val_f1_score: 0.9045\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0477 - acc: 0.9447 - precision: 0.9931 - recall: 0.8934 - f1_score: 0.9397 - val_loss: 2.0940 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0383 - acc: 0.9447 - precision: 0.9937 - recall: 0.8948 - f1_score: 0.9409 - val_loss: 2.0845 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0288 - acc: 0.9447 - precision: 0.9934 - recall: 0.8910 - f1_score: 0.9384 - val_loss: 2.0752 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0195 - acc: 0.9463 - precision: 0.9933 - recall: 0.9012 - f1_score: 0.9440 - val_loss: 2.0659 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.0101 - acc: 0.9463 - precision: 0.9919 - recall: 0.8948 - f1_score: 0.9395 - val_loss: 2.0566 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0008 - acc: 0.9463 - precision: 0.9939 - recall: 0.8933 - f1_score: 0.9392 - val_loss: 2.0474 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9916 - acc: 0.9463 - precision: 0.9929 - recall: 0.8992 - f1_score: 0.9425 - val_loss: 2.0383 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9824 - acc: 0.9463 - precision: 0.9933 - recall: 0.8978 - f1_score: 0.9421 - val_loss: 2.0292 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9733 - acc: 0.9463 - precision: 0.9926 - recall: 0.8951 - f1_score: 0.9398 - val_loss: 2.0201 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9642 - acc: 0.9463 - precision: 0.9925 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 2.0111 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9551 - acc: 0.9463 - precision: 0.9934 - recall: 0.8981 - f1_score: 0.9421 - val_loss: 2.0021 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9461 - acc: 0.9463 - precision: 0.9930 - recall: 0.8975 - f1_score: 0.9422 - val_loss: 1.9932 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9372 - acc: 0.9463 - precision: 0.9925 - recall: 0.8974 - f1_score: 0.9416 - val_loss: 1.9843 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9283 - acc: 0.9463 - precision: 0.9923 - recall: 0.9021 - f1_score: 0.9434 - val_loss: 1.9755 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9194 - acc: 0.9463 - precision: 0.9934 - recall: 0.8996 - f1_score: 0.9429 - val_loss: 1.9667 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9106 - acc: 0.9463 - precision: 0.9929 - recall: 0.8968 - f1_score: 0.9418 - val_loss: 1.9580 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9018 - acc: 0.9463 - precision: 0.9926 - recall: 0.8945 - f1_score: 0.9402 - val_loss: 1.9493 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8931 - acc: 0.9463 - precision: 0.9927 - recall: 0.8981 - f1_score: 0.9420 - val_loss: 1.9406 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8844 - acc: 0.9463 - precision: 0.9926 - recall: 0.8950 - f1_score: 0.9400 - val_loss: 1.9320 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8758 - acc: 0.9463 - precision: 0.9939 - recall: 0.8962 - f1_score: 0.9405 - val_loss: 1.9235 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8672 - acc: 0.9463 - precision: 0.9919 - recall: 0.8956 - f1_score: 0.9408 - val_loss: 1.9150 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8587 - acc: 0.9463 - precision: 0.9937 - recall: 0.8994 - f1_score: 0.9427 - val_loss: 1.9065 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8502 - acc: 0.9463 - precision: 0.9942 - recall: 0.8947 - f1_score: 0.9392 - val_loss: 1.8981 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8417 - acc: 0.9463 - precision: 0.9933 - recall: 0.8977 - f1_score: 0.9415 - val_loss: 1.8897 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8333 - acc: 0.9463 - precision: 0.9938 - recall: 0.8980 - f1_score: 0.9428 - val_loss: 1.8814 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8250 - acc: 0.9463 - precision: 0.9931 - recall: 0.9007 - f1_score: 0.9439 - val_loss: 1.8731 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8167 - acc: 0.9463 - precision: 0.9937 - recall: 0.9028 - f1_score: 0.9450 - val_loss: 1.8648 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8084 - acc: 0.9463 - precision: 0.9931 - recall: 0.8978 - f1_score: 0.9424 - val_loss: 1.8566 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8001 - acc: 0.9463 - precision: 0.9929 - recall: 0.9027 - f1_score: 0.9444 - val_loss: 1.8484 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7920 - acc: 0.9463 - precision: 0.9930 - recall: 0.8980 - f1_score: 0.9423 - val_loss: 1.8403 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7838 - acc: 0.9463 - precision: 0.9913 - recall: 0.8960 - f1_score: 0.9404 - val_loss: 1.8322 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7757 - acc: 0.9463 - precision: 0.9936 - recall: 0.8967 - f1_score: 0.9409 - val_loss: 1.8242 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7676 - acc: 0.9463 - precision: 0.9930 - recall: 0.8966 - f1_score: 0.9414 - val_loss: 1.8162 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7596 - acc: 0.9463 - precision: 0.9927 - recall: 0.8968 - f1_score: 0.9409 - val_loss: 1.8082 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7516 - acc: 0.9463 - precision: 0.9929 - recall: 0.8981 - f1_score: 0.9420 - val_loss: 1.8003 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7437 - acc: 0.9463 - precision: 0.9939 - recall: 0.8972 - f1_score: 0.9420 - val_loss: 1.7925 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.7358 - acc: 0.9463 - precision: 0.9930 - recall: 0.9012 - f1_score: 0.9431 - val_loss: 1.7846 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7279 - acc: 0.9463 - precision: 0.9934 - recall: 0.8992 - f1_score: 0.9425 - val_loss: 1.7768 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7201 - acc: 0.9463 - precision: 0.9928 - recall: 0.8979 - f1_score: 0.9424 - val_loss: 1.7691 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7123 - acc: 0.9463 - precision: 0.9929 - recall: 0.8988 - f1_score: 0.9426 - val_loss: 1.7614 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7046 - acc: 0.9463 - precision: 0.9937 - recall: 0.8971 - f1_score: 0.9414 - val_loss: 1.7537 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6969 - acc: 0.9463 - precision: 0.9935 - recall: 0.8943 - f1_score: 0.9396 - val_loss: 1.7461 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6892 - acc: 0.9463 - precision: 0.9936 - recall: 0.8993 - f1_score: 0.9427 - val_loss: 1.7385 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6816 - acc: 0.9463 - precision: 0.9926 - recall: 0.9015 - f1_score: 0.9438 - val_loss: 1.7309 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6741 - acc: 0.9463 - precision: 0.9934 - recall: 0.8972 - f1_score: 0.9422 - val_loss: 1.7234 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6665 - acc: 0.9463 - precision: 0.9926 - recall: 0.8978 - f1_score: 0.9414 - val_loss: 1.7159 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6590 - acc: 0.9463 - precision: 0.9932 - recall: 0.8960 - f1_score: 0.9408 - val_loss: 1.7085 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6516 - acc: 0.9463 - precision: 0.9928 - recall: 0.8976 - f1_score: 0.9422 - val_loss: 1.7011 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6441 - acc: 0.9463 - precision: 0.9939 - recall: 0.8952 - f1_score: 0.9404 - val_loss: 1.6937 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6367 - acc: 0.9463 - precision: 0.9941 - recall: 0.8984 - f1_score: 0.9427 - val_loss: 1.6864 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6294 - acc: 0.9463 - precision: 0.9926 - recall: 0.8965 - f1_score: 0.9415 - val_loss: 1.6791 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6221 - acc: 0.9463 - precision: 0.9931 - recall: 0.8982 - f1_score: 0.9414 - val_loss: 1.6719 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6148 - acc: 0.9463 - precision: 0.9915 - recall: 0.8939 - f1_score: 0.9380 - val_loss: 1.6647 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6076 - acc: 0.9463 - precision: 0.9939 - recall: 0.8953 - f1_score: 0.9390 - val_loss: 1.6575 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6004 - acc: 0.9463 - precision: 0.9934 - recall: 0.8906 - f1_score: 0.9380 - val_loss: 1.6504 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5932 - acc: 0.9463 - precision: 0.9922 - recall: 0.9038 - f1_score: 0.9450 - val_loss: 1.6433 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5861 - acc: 0.9463 - precision: 0.9937 - recall: 0.8956 - f1_score: 0.9410 - val_loss: 1.6362 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5790 - acc: 0.9463 - precision: 0.9935 - recall: 0.8951 - f1_score: 0.9402 - val_loss: 1.6292 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5720 - acc: 0.9463 - precision: 0.9919 - recall: 0.8971 - f1_score: 0.9413 - val_loss: 1.6222 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5650 - acc: 0.9463 - precision: 0.9935 - recall: 0.9009 - f1_score: 0.9433 - val_loss: 1.6153 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5580 - acc: 0.9463 - precision: 0.9926 - recall: 0.8965 - f1_score: 0.9406 - val_loss: 1.6083 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5511 - acc: 0.9463 - precision: 0.9931 - recall: 0.8972 - f1_score: 0.9421 - val_loss: 1.6015 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5442 - acc: 0.9463 - precision: 0.9941 - recall: 0.8971 - f1_score: 0.9420 - val_loss: 1.5946 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5373 - acc: 0.9463 - precision: 0.9940 - recall: 0.8974 - f1_score: 0.9426 - val_loss: 1.5878 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5305 - acc: 0.9463 - precision: 0.9923 - recall: 0.8987 - f1_score: 0.9423 - val_loss: 1.5810 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5237 - acc: 0.9463 - precision: 0.9939 - recall: 0.8966 - f1_score: 0.9410 - val_loss: 1.5743 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5169 - acc: 0.9463 - precision: 0.9944 - recall: 0.9008 - f1_score: 0.9442 - val_loss: 1.5676 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5102 - acc: 0.9463 - precision: 0.9926 - recall: 0.8986 - f1_score: 0.9422 - val_loss: 1.5609 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.5035 - acc: 0.9463 - precision: 0.9939 - recall: 0.8962 - f1_score: 0.9414 - val_loss: 1.5543 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4968 - acc: 0.9463 - precision: 0.9921 - recall: 0.8941 - f1_score: 0.9400 - val_loss: 1.5477 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4902 - acc: 0.9463 - precision: 0.9922 - recall: 0.8997 - f1_score: 0.9421 - val_loss: 1.5411 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4836 - acc: 0.9463 - precision: 0.9930 - recall: 0.8967 - f1_score: 0.9415 - val_loss: 1.5346 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4771 - acc: 0.9463 - precision: 0.9917 - recall: 0.8982 - f1_score: 0.9414 - val_loss: 1.5281 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4706 - acc: 0.9463 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9406 - val_loss: 1.5216 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4641 - acc: 0.9463 - precision: 0.9951 - recall: 0.8967 - f1_score: 0.9421 - val_loss: 1.5152 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4576 - acc: 0.9463 - precision: 0.9929 - recall: 0.9021 - f1_score: 0.9437 - val_loss: 1.5088 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4512 - acc: 0.9463 - precision: 0.9930 - recall: 0.8995 - f1_score: 0.9432 - val_loss: 1.5024 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4448 - acc: 0.9463 - precision: 0.9933 - recall: 0.8985 - f1_score: 0.9425 - val_loss: 1.4961 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4385 - acc: 0.9463 - precision: 0.9934 - recall: 0.9036 - f1_score: 0.9455 - val_loss: 1.4898 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4321 - acc: 0.9463 - precision: 0.9923 - recall: 0.8979 - f1_score: 0.9400 - val_loss: 1.4835 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4258 - acc: 0.9463 - precision: 0.9924 - recall: 0.9006 - f1_score: 0.9434 - val_loss: 1.4773 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4196 - acc: 0.9463 - precision: 0.9937 - recall: 0.8990 - f1_score: 0.9436 - val_loss: 1.4711 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4134 - acc: 0.9463 - precision: 0.9918 - recall: 0.8989 - f1_score: 0.9421 - val_loss: 1.4649 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4072 - acc: 0.9463 - precision: 0.9944 - recall: 0.8946 - f1_score: 0.9402 - val_loss: 1.4588 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4010 - acc: 0.9463 - precision: 0.9931 - recall: 0.8936 - f1_score: 0.9390 - val_loss: 1.4527 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3949 - acc: 0.9463 - precision: 0.9943 - recall: 0.8947 - f1_score: 0.9412 - val_loss: 1.4466 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3888 - acc: 0.9463 - precision: 0.9931 - recall: 0.8971 - f1_score: 0.9418 - val_loss: 1.4405 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3827 - acc: 0.9463 - precision: 0.9937 - recall: 0.8961 - f1_score: 0.9419 - val_loss: 1.4345 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3767 - acc: 0.9463 - precision: 0.9935 - recall: 0.8993 - f1_score: 0.9432 - val_loss: 1.4285 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3707 - acc: 0.9463 - precision: 0.9920 - recall: 0.8957 - f1_score: 0.9406 - val_loss: 1.4226 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3647 - acc: 0.9463 - precision: 0.9931 - recall: 0.8971 - f1_score: 0.9422 - val_loss: 1.4167 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3588 - acc: 0.9463 - precision: 0.9924 - recall: 0.8954 - f1_score: 0.9400 - val_loss: 1.4108 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3529 - acc: 0.9463 - precision: 0.9927 - recall: 0.8972 - f1_score: 0.9407 - val_loss: 1.4049 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3470 - acc: 0.9463 - precision: 0.9928 - recall: 0.8979 - f1_score: 0.9423 - val_loss: 1.3991 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3411 - acc: 0.9463 - precision: 0.9928 - recall: 0.8981 - f1_score: 0.9423 - val_loss: 1.3933 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3353 - acc: 0.9463 - precision: 0.9935 - recall: 0.8984 - f1_score: 0.9427 - val_loss: 1.3875 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3295 - acc: 0.9463 - precision: 0.9931 - recall: 0.9014 - f1_score: 0.9439 - val_loss: 1.3818 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3238 - acc: 0.9463 - precision: 0.9928 - recall: 0.8916 - f1_score: 0.9383 - val_loss: 1.3761 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3180 - acc: 0.9463 - precision: 0.9926 - recall: 0.8991 - f1_score: 0.9428 - val_loss: 1.3704 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3123 - acc: 0.9463 - precision: 0.9929 - recall: 0.8985 - f1_score: 0.9425 - val_loss: 1.3647 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3067 - acc: 0.9463 - precision: 0.9922 - recall: 0.8952 - f1_score: 0.9398 - val_loss: 1.3591 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3010 - acc: 0.9463 - precision: 0.9928 - recall: 0.8957 - f1_score: 0.9411 - val_loss: 1.3535 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2954 - acc: 0.9463 - precision: 0.9910 - recall: 0.8966 - f1_score: 0.9404 - val_loss: 1.3479 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2898 - acc: 0.9463 - precision: 0.9944 - recall: 0.8987 - f1_score: 0.9425 - val_loss: 1.3424 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2843 - acc: 0.9463 - precision: 0.9929 - recall: 0.8983 - f1_score: 0.9428 - val_loss: 1.3369 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2787 - acc: 0.9463 - precision: 0.9926 - recall: 0.9020 - f1_score: 0.9441 - val_loss: 1.3314 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2732 - acc: 0.9463 - precision: 0.9919 - recall: 0.8960 - f1_score: 0.9406 - val_loss: 1.3260 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2678 - acc: 0.9463 - precision: 0.9924 - recall: 0.9004 - f1_score: 0.9431 - val_loss: 1.3205 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2623 - acc: 0.9479 - precision: 0.9941 - recall: 0.9003 - f1_score: 0.9437 - val_loss: 1.3151 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2569 - acc: 0.9479 - precision: 0.9925 - recall: 0.8982 - f1_score: 0.9412 - val_loss: 1.3098 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2515 - acc: 0.9479 - precision: 0.9930 - recall: 0.9007 - f1_score: 0.9434 - val_loss: 1.3044 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2462 - acc: 0.9479 - precision: 0.9939 - recall: 0.8999 - f1_score: 0.9436 - val_loss: 1.2991 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2408 - acc: 0.9479 - precision: 0.9922 - recall: 0.9019 - f1_score: 0.9438 - val_loss: 1.2938 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2355 - acc: 0.9479 - precision: 0.9919 - recall: 0.8985 - f1_score: 0.9411 - val_loss: 1.2886 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2302 - acc: 0.9479 - precision: 0.9923 - recall: 0.9012 - f1_score: 0.9427 - val_loss: 1.2833 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2250 - acc: 0.9479 - precision: 0.9925 - recall: 0.9020 - f1_score: 0.9441 - val_loss: 1.2781 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2198 - acc: 0.9479 - precision: 0.9927 - recall: 0.9029 - f1_score: 0.9446 - val_loss: 1.2729 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2146 - acc: 0.9479 - precision: 0.9935 - recall: 0.9008 - f1_score: 0.9440 - val_loss: 1.2678 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2094 - acc: 0.9479 - precision: 0.9929 - recall: 0.9001 - f1_score: 0.9437 - val_loss: 1.2627 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2043 - acc: 0.9479 - precision: 0.9938 - recall: 0.9002 - f1_score: 0.9436 - val_loss: 1.2576 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1991 - acc: 0.9479 - precision: 0.9928 - recall: 0.9032 - f1_score: 0.9450 - val_loss: 1.2525 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1941 - acc: 0.9479 - precision: 0.9934 - recall: 0.9015 - f1_score: 0.9444 - val_loss: 1.2474 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1890 - acc: 0.9479 - precision: 0.9930 - recall: 0.8999 - f1_score: 0.9432 - val_loss: 1.2424 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1839 - acc: 0.9479 - precision: 0.9937 - recall: 0.9004 - f1_score: 0.9439 - val_loss: 1.2374 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1789 - acc: 0.9479 - precision: 0.9937 - recall: 0.9000 - f1_score: 0.9433 - val_loss: 1.2324 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1739 - acc: 0.9479 - precision: 0.9934 - recall: 0.8992 - f1_score: 0.9432 - val_loss: 1.2275 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1690 - acc: 0.9479 - precision: 0.9919 - recall: 0.9044 - f1_score: 0.9455 - val_loss: 1.2226 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1640 - acc: 0.9479 - precision: 0.9933 - recall: 0.8995 - f1_score: 0.9434 - val_loss: 1.2177 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1591 - acc: 0.9479 - precision: 0.9942 - recall: 0.9018 - f1_score: 0.9453 - val_loss: 1.2128 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1542 - acc: 0.9479 - precision: 0.9916 - recall: 0.8987 - f1_score: 0.9418 - val_loss: 1.2080 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1494 - acc: 0.9479 - precision: 0.9945 - recall: 0.9014 - f1_score: 0.9448 - val_loss: 1.2031 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1445 - acc: 0.9479 - precision: 0.9911 - recall: 0.9015 - f1_score: 0.9437 - val_loss: 1.1984 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 345/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1397 - acc: 0.9479 - precision: 0.9935 - recall: 0.9022 - f1_score: 0.9443 - val_loss: 1.1936 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1350 - acc: 0.9479 - precision: 0.9928 - recall: 0.8992 - f1_score: 0.9419 - val_loss: 1.1888 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1302 - acc: 0.9479 - precision: 0.9937 - recall: 0.9019 - f1_score: 0.9443 - val_loss: 1.1841 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1255 - acc: 0.9479 - precision: 0.9909 - recall: 0.8954 - f1_score: 0.9397 - val_loss: 1.1794 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1207 - acc: 0.9479 - precision: 0.9930 - recall: 0.8967 - f1_score: 0.9405 - val_loss: 1.1747 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1160 - acc: 0.9479 - precision: 0.9934 - recall: 0.8979 - f1_score: 0.9415 - val_loss: 1.1701 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1114 - acc: 0.9479 - precision: 0.9923 - recall: 0.8999 - f1_score: 0.9431 - val_loss: 1.1655 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1067 - acc: 0.9479 - precision: 0.9933 - recall: 0.8993 - f1_score: 0.9430 - val_loss: 1.1609 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1021 - acc: 0.9479 - precision: 0.9917 - recall: 0.8968 - f1_score: 0.9409 - val_loss: 1.1563 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0975 - acc: 0.9479 - precision: 0.9934 - recall: 0.8993 - f1_score: 0.9429 - val_loss: 1.1517 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0930 - acc: 0.9479 - precision: 0.9931 - recall: 0.9022 - f1_score: 0.9448 - val_loss: 1.1472 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0884 - acc: 0.9479 - precision: 0.9929 - recall: 0.9024 - f1_score: 0.9447 - val_loss: 1.1427 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0839 - acc: 0.9479 - precision: 0.9906 - recall: 0.9040 - f1_score: 0.9445 - val_loss: 1.1382 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0794 - acc: 0.9479 - precision: 0.9925 - recall: 0.9039 - f1_score: 0.9453 - val_loss: 1.1338 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0749 - acc: 0.9479 - precision: 0.9931 - recall: 0.9014 - f1_score: 0.9439 - val_loss: 1.1293 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0704 - acc: 0.9479 - precision: 0.9933 - recall: 0.8981 - f1_score: 0.9419 - val_loss: 1.1249 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0660 - acc: 0.9479 - precision: 0.9933 - recall: 0.9012 - f1_score: 0.9440 - val_loss: 1.1205 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0616 - acc: 0.9479 - precision: 0.9933 - recall: 0.8994 - f1_score: 0.9431 - val_loss: 1.1161 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0572 - acc: 0.9479 - precision: 0.9916 - recall: 0.8993 - f1_score: 0.9422 - val_loss: 1.1118 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0528 - acc: 0.9479 - precision: 0.9927 - recall: 0.8966 - f1_score: 0.9409 - val_loss: 1.1075 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0485 - acc: 0.9479 - precision: 0.9935 - recall: 0.8993 - f1_score: 0.9430 - val_loss: 1.1031 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0442 - acc: 0.9479 - precision: 0.9916 - recall: 0.9022 - f1_score: 0.9434 - val_loss: 1.0989 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0399 - acc: 0.9479 - precision: 0.9911 - recall: 0.8988 - f1_score: 0.9415 - val_loss: 1.0946 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0356 - acc: 0.9479 - precision: 0.9923 - recall: 0.9020 - f1_score: 0.9441 - val_loss: 1.0904 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0313 - acc: 0.9479 - precision: 0.9915 - recall: 0.8978 - f1_score: 0.9414 - val_loss: 1.0861 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0271 - acc: 0.9479 - precision: 0.9923 - recall: 0.9049 - f1_score: 0.9448 - val_loss: 1.0819 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0229 - acc: 0.9479 - precision: 0.9939 - recall: 0.8994 - f1_score: 0.9416 - val_loss: 1.0778 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0187 - acc: 0.9479 - precision: 0.9925 - recall: 0.8993 - f1_score: 0.9424 - val_loss: 1.0736 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0145 - acc: 0.9479 - precision: 0.9931 - recall: 0.9022 - f1_score: 0.9442 - val_loss: 1.0695 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0104 - acc: 0.9479 - precision: 0.9926 - recall: 0.9032 - f1_score: 0.9442 - val_loss: 1.0654 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0063 - acc: 0.9479 - precision: 0.9936 - recall: 0.9039 - f1_score: 0.9452 - val_loss: 1.0613 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0022 - acc: 0.9479 - precision: 0.9924 - recall: 0.9038 - f1_score: 0.9449 - val_loss: 1.0572 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9981 - acc: 0.9479 - precision: 0.9924 - recall: 0.9027 - f1_score: 0.9447 - val_loss: 1.0532 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9940 - acc: 0.9479 - precision: 0.9931 - recall: 0.9043 - f1_score: 0.9459 - val_loss: 1.0491 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9900 - acc: 0.9479 - precision: 0.9923 - recall: 0.9021 - f1_score: 0.9445 - val_loss: 1.0451 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9859 - acc: 0.9479 - precision: 0.9929 - recall: 0.8966 - f1_score: 0.9414 - val_loss: 1.0411 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9819 - acc: 0.9479 - precision: 0.9921 - recall: 0.9036 - f1_score: 0.9451 - val_loss: 1.0372 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9780 - acc: 0.9479 - precision: 0.9936 - recall: 0.9029 - f1_score: 0.9453 - val_loss: 1.0332 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9740 - acc: 0.9479 - precision: 0.9937 - recall: 0.9014 - f1_score: 0.9441 - val_loss: 1.0293 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9700 - acc: 0.9479 - precision: 0.9935 - recall: 0.8984 - f1_score: 0.9427 - val_loss: 1.0254 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9661 - acc: 0.9479 - precision: 0.9939 - recall: 0.9016 - f1_score: 0.9446 - val_loss: 1.0215 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9622 - acc: 0.9479 - precision: 0.9937 - recall: 0.9007 - f1_score: 0.9440 - val_loss: 1.0176 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9583 - acc: 0.9479 - precision: 0.9938 - recall: 0.9023 - f1_score: 0.9449 - val_loss: 1.0138 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9545 - acc: 0.9479 - precision: 0.9940 - recall: 0.9058 - f1_score: 0.9463 - val_loss: 1.0100 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9506 - acc: 0.9479 - precision: 0.9928 - recall: 0.8978 - f1_score: 0.9417 - val_loss: 1.0062 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9468 - acc: 0.9479 - precision: 0.9941 - recall: 0.9005 - f1_score: 0.9438 - val_loss: 1.0024 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9430 - acc: 0.9479 - precision: 0.9928 - recall: 0.8973 - f1_score: 0.9415 - val_loss: 0.9986 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9392 - acc: 0.9479 - precision: 0.9930 - recall: 0.9012 - f1_score: 0.9437 - val_loss: 0.9948 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9355 - acc: 0.9479 - precision: 0.9935 - recall: 0.9037 - f1_score: 0.9449 - val_loss: 0.9911 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9317 - acc: 0.9479 - precision: 0.9928 - recall: 0.9073 - f1_score: 0.9463 - val_loss: 0.9874 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9280 - acc: 0.9494 - precision: 0.9934 - recall: 0.9055 - f1_score: 0.9467 - val_loss: 0.9837 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9243 - acc: 0.9494 - precision: 0.9929 - recall: 0.9048 - f1_score: 0.9462 - val_loss: 0.9800 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9206 - acc: 0.9494 - precision: 0.9934 - recall: 0.9036 - f1_score: 0.9455 - val_loss: 0.9764 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9169 - acc: 0.9494 - precision: 0.9933 - recall: 0.9018 - f1_score: 0.9433 - val_loss: 0.9727 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9133 - acc: 0.9494 - precision: 0.9928 - recall: 0.8990 - f1_score: 0.9426 - val_loss: 0.9691 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9096 - acc: 0.9494 - precision: 0.9928 - recall: 0.9025 - f1_score: 0.9445 - val_loss: 0.9655 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9060 - acc: 0.9494 - precision: 0.9920 - recall: 0.9038 - f1_score: 0.9445 - val_loss: 0.9619 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9024 - acc: 0.9494 - precision: 0.9926 - recall: 0.9047 - f1_score: 0.9462 - val_loss: 0.9584 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8989 - acc: 0.9494 - precision: 0.9933 - recall: 0.9003 - f1_score: 0.9431 - val_loss: 0.9548 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8953 - acc: 0.9494 - precision: 0.9928 - recall: 0.9066 - f1_score: 0.9466 - val_loss: 0.9513 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8918 - acc: 0.9494 - precision: 0.9933 - recall: 0.9097 - f1_score: 0.9480 - val_loss: 0.9478 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8882 - acc: 0.9494 - precision: 0.9940 - recall: 0.9080 - f1_score: 0.9485 - val_loss: 0.9443 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8847 - acc: 0.9494 - precision: 0.9923 - recall: 0.9042 - f1_score: 0.9453 - val_loss: 0.9408 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8812 - acc: 0.9510 - precision: 0.9935 - recall: 0.9086 - f1_score: 0.9479 - val_loss: 0.9374 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8778 - acc: 0.9510 - precision: 0.9931 - recall: 0.9042 - f1_score: 0.9456 - val_loss: 0.9339 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8743 - acc: 0.9510 - precision: 0.9931 - recall: 0.9073 - f1_score: 0.9477 - val_loss: 0.9305 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8709 - acc: 0.9510 - precision: 0.9935 - recall: 0.9069 - f1_score: 0.9471 - val_loss: 0.9271 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8674 - acc: 0.9510 - precision: 0.9942 - recall: 0.9035 - f1_score: 0.9455 - val_loss: 0.9237 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.8844 - acc: 0.9200 - precision: 1.0000 - recall: 0.8571 - f1_score: 0.923 - 0s - loss: 0.8640 - acc: 0.9510 - precision: 0.9921 - recall: 0.9089 - f1_score: 0.9477 - val_loss: 0.9203 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8607 - acc: 0.9510 - precision: 0.9926 - recall: 0.9031 - f1_score: 0.9432 - val_loss: 0.9170 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8573 - acc: 0.9510 - precision: 0.9929 - recall: 0.9060 - f1_score: 0.9467 - val_loss: 0.9137 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8539 - acc: 0.9510 - precision: 0.9934 - recall: 0.9058 - f1_score: 0.9466 - val_loss: 0.9103 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8506 - acc: 0.9510 - precision: 0.9935 - recall: 0.9032 - f1_score: 0.9435 - val_loss: 0.9070 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.8402 - acc: 0.9564 - precision: 0.9957 - recall: 0.9187 - f1_score: 0.955 - 0s - loss: 0.8473 - acc: 0.9510 - precision: 0.9932 - recall: 0.9098 - f1_score: 0.9489 - val_loss: 0.9038 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8440 - acc: 0.9510 - precision: 0.9929 - recall: 0.9100 - f1_score: 0.9491 - val_loss: 0.9005 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8407 - acc: 0.9510 - precision: 0.9919 - recall: 0.9082 - f1_score: 0.9475 - val_loss: 0.8972 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8374 - acc: 0.9510 - precision: 0.9940 - recall: 0.9017 - f1_score: 0.9440 - val_loss: 0.8940 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8342 - acc: 0.9510 - precision: 0.9935 - recall: 0.9086 - f1_score: 0.9482 - val_loss: 0.8908 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8310 - acc: 0.9510 - precision: 0.9923 - recall: 0.9042 - f1_score: 0.9454 - val_loss: 0.8876 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8277 - acc: 0.9510 - precision: 0.9929 - recall: 0.9052 - f1_score: 0.9451 - val_loss: 0.8844 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8245 - acc: 0.9510 - precision: 0.9931 - recall: 0.9100 - f1_score: 0.9483 - val_loss: 0.8812 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8214 - acc: 0.9510 - precision: 0.9934 - recall: 0.9087 - f1_score: 0.9483 - val_loss: 0.8781 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8182 - acc: 0.9510 - precision: 0.9912 - recall: 0.9057 - f1_score: 0.9456 - val_loss: 0.8749 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8150 - acc: 0.9510 - precision: 0.9917 - recall: 0.9094 - f1_score: 0.9481 - val_loss: 0.8718 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8119 - acc: 0.9510 - precision: 0.9933 - recall: 0.9072 - f1_score: 0.9475 - val_loss: 0.8687 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8088 - acc: 0.9510 - precision: 0.9937 - recall: 0.9061 - f1_score: 0.9466 - val_loss: 0.8656 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8057 - acc: 0.9510 - precision: 0.9935 - recall: 0.9079 - f1_score: 0.9479 - val_loss: 0.8625 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8026 - acc: 0.9510 - precision: 0.9941 - recall: 0.9039 - f1_score: 0.9458 - val_loss: 0.8595 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7995 - acc: 0.9510 - precision: 0.9939 - recall: 0.9092 - f1_score: 0.9486 - val_loss: 0.8564 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7965 - acc: 0.9510 - precision: 0.9933 - recall: 0.9081 - f1_score: 0.9483 - val_loss: 0.8534 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7934 - acc: 0.9510 - precision: 0.9932 - recall: 0.9063 - f1_score: 0.9470 - val_loss: 0.8504 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7904 - acc: 0.9510 - precision: 0.9936 - recall: 0.9094 - f1_score: 0.9478 - val_loss: 0.8474 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7874 - acc: 0.9510 - precision: 0.9922 - recall: 0.9081 - f1_score: 0.9471 - val_loss: 0.8444 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7844 - acc: 0.9510 - precision: 0.9937 - recall: 0.9065 - f1_score: 0.9471 - val_loss: 0.8414 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7814 - acc: 0.9510 - precision: 0.9929 - recall: 0.9048 - f1_score: 0.9453 - val_loss: 0.8385 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7784 - acc: 0.9510 - precision: 0.9937 - recall: 0.9052 - f1_score: 0.9462 - val_loss: 0.8356 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7755 - acc: 0.9510 - precision: 0.9924 - recall: 0.9044 - f1_score: 0.9457 - val_loss: 0.8326 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7725 - acc: 0.9510 - precision: 0.9932 - recall: 0.9093 - f1_score: 0.9482 - val_loss: 0.8297 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7696 - acc: 0.9510 - precision: 0.9924 - recall: 0.9018 - f1_score: 0.9436 - val_loss: 0.8268 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7667 - acc: 0.9510 - precision: 0.9935 - recall: 0.9090 - f1_score: 0.9489 - val_loss: 0.8240 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7638 - acc: 0.9510 - precision: 0.9929 - recall: 0.9052 - f1_score: 0.9462 - val_loss: 0.8211 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7609 - acc: 0.9510 - precision: 0.9924 - recall: 0.9038 - f1_score: 0.9441 - val_loss: 0.8182 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7581 - acc: 0.9510 - precision: 0.9938 - recall: 0.9064 - f1_score: 0.9464 - val_loss: 0.8154 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7552 - acc: 0.9510 - precision: 0.9921 - recall: 0.9070 - f1_score: 0.9461 - val_loss: 0.8126 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7524 - acc: 0.9510 - precision: 0.9928 - recall: 0.9079 - f1_score: 0.9478 - val_loss: 0.8098 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7496 - acc: 0.9510 - precision: 0.9934 - recall: 0.9113 - f1_score: 0.9496 - val_loss: 0.8070 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7468 - acc: 0.9510 - precision: 0.9936 - recall: 0.9109 - f1_score: 0.9492 - val_loss: 0.8042 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7440 - acc: 0.9510 - precision: 0.9919 - recall: 0.9080 - f1_score: 0.9469 - val_loss: 0.8014 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7412 - acc: 0.9510 - precision: 0.9920 - recall: 0.9062 - f1_score: 0.9467 - val_loss: 0.7987 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7384 - acc: 0.9510 - precision: 0.9923 - recall: 0.9053 - f1_score: 0.9463 - val_loss: 0.7960 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7357 - acc: 0.9510 - precision: 0.9930 - recall: 0.9092 - f1_score: 0.9489 - val_loss: 0.7932 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7329 - acc: 0.9510 - precision: 0.9940 - recall: 0.9038 - f1_score: 0.9463 - val_loss: 0.7905 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7302 - acc: 0.9510 - precision: 0.9928 - recall: 0.9050 - f1_score: 0.9459 - val_loss: 0.7878 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7275 - acc: 0.9510 - precision: 0.9931 - recall: 0.9130 - f1_score: 0.9497 - val_loss: 0.7851 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7248 - acc: 0.9510 - precision: 0.9919 - recall: 0.9062 - f1_score: 0.9466 - val_loss: 0.7825 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7221 - acc: 0.9510 - precision: 0.9931 - recall: 0.9038 - f1_score: 0.9459 - val_loss: 0.7798 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7195 - acc: 0.9510 - precision: 0.9926 - recall: 0.9094 - f1_score: 0.9482 - val_loss: 0.7772 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7168 - acc: 0.9510 - precision: 0.9921 - recall: 0.9083 - f1_score: 0.9478 - val_loss: 0.7745 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7142 - acc: 0.9510 - precision: 0.9936 - recall: 0.9125 - f1_score: 0.9494 - val_loss: 0.7719 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7116 - acc: 0.9510 - precision: 0.9923 - recall: 0.9064 - f1_score: 0.9465 - val_loss: 0.7693 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7089 - acc: 0.9510 - precision: 0.9923 - recall: 0.9045 - f1_score: 0.9454 - val_loss: 0.7667 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7063 - acc: 0.9510 - precision: 0.9928 - recall: 0.9090 - f1_score: 0.9478 - val_loss: 0.7642 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7037 - acc: 0.9510 - precision: 0.9923 - recall: 0.9044 - f1_score: 0.9453 - val_loss: 0.7616 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7012 - acc: 0.9510 - precision: 0.9941 - recall: 0.9078 - f1_score: 0.9478 - val_loss: 0.7590 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6986 - acc: 0.9510 - precision: 0.9934 - recall: 0.9071 - f1_score: 0.9472 - val_loss: 0.7565 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6961 - acc: 0.9510 - precision: 0.9931 - recall: 0.9049 - f1_score: 0.9459 - val_loss: 0.7540 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6935 - acc: 0.9510 - precision: 0.9920 - recall: 0.9058 - f1_score: 0.9468 - val_loss: 0.7515 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6910 - acc: 0.9510 - precision: 0.9939 - recall: 0.9090 - f1_score: 0.9485 - val_loss: 0.7490 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6885 - acc: 0.9510 - precision: 0.9926 - recall: 0.9107 - f1_score: 0.9486 - val_loss: 0.7465 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6860 - acc: 0.9510 - precision: 0.9928 - recall: 0.9066 - f1_score: 0.9471 - val_loss: 0.7440 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6835 - acc: 0.9510 - precision: 0.9924 - recall: 0.9062 - f1_score: 0.9464 - val_loss: 0.7416 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6810 - acc: 0.9510 - precision: 0.9937 - recall: 0.9064 - f1_score: 0.9467 - val_loss: 0.7391 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6786 - acc: 0.9510 - precision: 0.9939 - recall: 0.9084 - f1_score: 0.9479 - val_loss: 0.7367 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6761 - acc: 0.9510 - precision: 0.9948 - recall: 0.9038 - f1_score: 0.9459 - val_loss: 0.7342 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6737 - acc: 0.9510 - precision: 0.9933 - recall: 0.9067 - f1_score: 0.9467 - val_loss: 0.7318 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6712 - acc: 0.9510 - precision: 0.9931 - recall: 0.9068 - f1_score: 0.9470 - val_loss: 0.7294 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6688 - acc: 0.9510 - precision: 0.9937 - recall: 0.9058 - f1_score: 0.9471 - val_loss: 0.7270 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6664 - acc: 0.9510 - precision: 0.9938 - recall: 0.9049 - f1_score: 0.9457 - val_loss: 0.7247 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6640 - acc: 0.9510 - precision: 0.9933 - recall: 0.9054 - f1_score: 0.9456 - val_loss: 0.7223 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6617 - acc: 0.9510 - precision: 0.9938 - recall: 0.9103 - f1_score: 0.9494 - val_loss: 0.7200 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6593 - acc: 0.9510 - precision: 0.9941 - recall: 0.9057 - f1_score: 0.9471 - val_loss: 0.7176 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6569 - acc: 0.9510 - precision: 0.9929 - recall: 0.9068 - f1_score: 0.9471 - val_loss: 0.7153 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6546 - acc: 0.9510 - precision: 0.9924 - recall: 0.9063 - f1_score: 0.9470 - val_loss: 0.7130 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6523 - acc: 0.9510 - precision: 0.9924 - recall: 0.9098 - f1_score: 0.9485 - val_loss: 0.7107 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6500 - acc: 0.9510 - precision: 0.9928 - recall: 0.9053 - f1_score: 0.9460 - val_loss: 0.7084 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6476 - acc: 0.9510 - precision: 0.9931 - recall: 0.9100 - f1_score: 0.9489 - val_loss: 0.7061 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6454 - acc: 0.9510 - precision: 0.9929 - recall: 0.9086 - f1_score: 0.9467 - val_loss: 0.7038 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6431 - acc: 0.9510 - precision: 0.9927 - recall: 0.9086 - f1_score: 0.9479 - val_loss: 0.7016 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6408 - acc: 0.9510 - precision: 0.9938 - recall: 0.9089 - f1_score: 0.9481 - val_loss: 0.6993 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6385 - acc: 0.9510 - precision: 0.9928 - recall: 0.9107 - f1_score: 0.9492 - val_loss: 0.6971 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6363 - acc: 0.9510 - precision: 0.9931 - recall: 0.9176 - f1_score: 0.9514 - val_loss: 0.6948 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6340 - acc: 0.9510 - precision: 0.9930 - recall: 0.9108 - f1_score: 0.9491 - val_loss: 0.6926 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6318 - acc: 0.9510 - precision: 0.9925 - recall: 0.9112 - f1_score: 0.9490 - val_loss: 0.6904 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6296 - acc: 0.9510 - precision: 0.9932 - recall: 0.9067 - f1_score: 0.9472 - val_loss: 0.6882 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6274 - acc: 0.9510 - precision: 0.9930 - recall: 0.9044 - f1_score: 0.9459 - val_loss: 0.6860 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6252 - acc: 0.9510 - precision: 0.9929 - recall: 0.9059 - f1_score: 0.9465 - val_loss: 0.6839 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6230 - acc: 0.9510 - precision: 0.9937 - recall: 0.9064 - f1_score: 0.9467 - val_loss: 0.6817 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6208 - acc: 0.9510 - precision: 0.9936 - recall: 0.9055 - f1_score: 0.9456 - val_loss: 0.6796 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6187 - acc: 0.9510 - precision: 0.9937 - recall: 0.9079 - f1_score: 0.9479 - val_loss: 0.6774 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6165 - acc: 0.9510 - precision: 0.9926 - recall: 0.9115 - f1_score: 0.9492 - val_loss: 0.6753 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6144 - acc: 0.9510 - precision: 0.9937 - recall: 0.9074 - f1_score: 0.9476 - val_loss: 0.6732 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6123 - acc: 0.9510 - precision: 0.9930 - recall: 0.9046 - f1_score: 0.9452 - val_loss: 0.6711 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6101 - acc: 0.9510 - precision: 0.9926 - recall: 0.9096 - f1_score: 0.9483 - val_loss: 0.6690 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6080 - acc: 0.9510 - precision: 0.9926 - recall: 0.9056 - f1_score: 0.9458 - val_loss: 0.6669 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6059 - acc: 0.9510 - precision: 0.9931 - recall: 0.9098 - f1_score: 0.9489 - val_loss: 0.6648 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6039 - acc: 0.9510 - precision: 0.9917 - recall: 0.9054 - f1_score: 0.9463 - val_loss: 0.6628 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6018 - acc: 0.9510 - precision: 0.9937 - recall: 0.9088 - f1_score: 0.9488 - val_loss: 0.6607 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5997 - acc: 0.9510 - precision: 0.9921 - recall: 0.9034 - f1_score: 0.9447 - val_loss: 0.6587 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5976 - acc: 0.9510 - precision: 0.9934 - recall: 0.9077 - f1_score: 0.9473 - val_loss: 0.6566 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5956 - acc: 0.9510 - precision: 0.9930 - recall: 0.9055 - f1_score: 0.9459 - val_loss: 0.6546 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5936 - acc: 0.9510 - precision: 0.9931 - recall: 0.9070 - f1_score: 0.9471 - val_loss: 0.6526 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5915 - acc: 0.9510 - precision: 0.9935 - recall: 0.9066 - f1_score: 0.9474 - val_loss: 0.6506 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5895 - acc: 0.9510 - precision: 0.9919 - recall: 0.9111 - f1_score: 0.9481 - val_loss: 0.6486 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5875 - acc: 0.9510 - precision: 0.9926 - recall: 0.9065 - f1_score: 0.9464 - val_loss: 0.6466 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5855 - acc: 0.9510 - precision: 0.9933 - recall: 0.9067 - f1_score: 0.9477 - val_loss: 0.6447 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5835 - acc: 0.9510 - precision: 0.9935 - recall: 0.9087 - f1_score: 0.9479 - val_loss: 0.6427 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5816 - acc: 0.9510 - precision: 0.9941 - recall: 0.9088 - f1_score: 0.9481 - val_loss: 0.6407 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5796 - acc: 0.9510 - precision: 0.9928 - recall: 0.9085 - f1_score: 0.9483 - val_loss: 0.6388 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5776 - acc: 0.9510 - precision: 0.9935 - recall: 0.9053 - f1_score: 0.9462 - val_loss: 0.6369 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5757 - acc: 0.9510 - precision: 0.9934 - recall: 0.9094 - f1_score: 0.9483 - val_loss: 0.6349 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5737 - acc: 0.9510 - precision: 0.9922 - recall: 0.9089 - f1_score: 0.9479 - val_loss: 0.6330 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5718 - acc: 0.9526 - precision: 0.9925 - recall: 0.9076 - f1_score: 0.9468 - val_loss: 0.6311 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5699 - acc: 0.9526 - precision: 0.9931 - recall: 0.9058 - f1_score: 0.9456 - val_loss: 0.6292 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5680 - acc: 0.9526 - precision: 0.9907 - recall: 0.9132 - f1_score: 0.9492 - val_loss: 0.6273 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5661 - acc: 0.9526 - precision: 0.9931 - recall: 0.9123 - f1_score: 0.9495 - val_loss: 0.6255 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5642 - acc: 0.9526 - precision: 0.9941 - recall: 0.9126 - f1_score: 0.9506 - val_loss: 0.6236 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5623 - acc: 0.9526 - precision: 0.9917 - recall: 0.9060 - f1_score: 0.9462 - val_loss: 0.6217 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5605 - acc: 0.9526 - precision: 0.9941 - recall: 0.9119 - f1_score: 0.9493 - val_loss: 0.6199 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5586 - acc: 0.9526 - precision: 0.9934 - recall: 0.9102 - f1_score: 0.9490 - val_loss: 0.6181 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5567 - acc: 0.9526 - precision: 0.9932 - recall: 0.9107 - f1_score: 0.9494 - val_loss: 0.6162 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5549 - acc: 0.9526 - precision: 0.9936 - recall: 0.9121 - f1_score: 0.9495 - val_loss: 0.6144 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5531 - acc: 0.9526 - precision: 0.9927 - recall: 0.9108 - f1_score: 0.9492 - val_loss: 0.6126 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5512 - acc: 0.9526 - precision: 0.9927 - recall: 0.9068 - f1_score: 0.9470 - val_loss: 0.6108 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5494 - acc: 0.9526 - precision: 0.9924 - recall: 0.9101 - f1_score: 0.9485 - val_loss: 0.6090 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5476 - acc: 0.9526 - precision: 0.9924 - recall: 0.9108 - f1_score: 0.9492 - val_loss: 0.6072 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5458 - acc: 0.9526 - precision: 0.9925 - recall: 0.9116 - f1_score: 0.9494 - val_loss: 0.6054 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5440 - acc: 0.9526 - precision: 0.9923 - recall: 0.9125 - f1_score: 0.9492 - val_loss: 0.6037 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5422 - acc: 0.9526 - precision: 0.9938 - recall: 0.9110 - f1_score: 0.9491 - val_loss: 0.6019 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5405 - acc: 0.9526 - precision: 0.9940 - recall: 0.9120 - f1_score: 0.9499 - val_loss: 0.6001 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5387 - acc: 0.9526 - precision: 0.9940 - recall: 0.9096 - f1_score: 0.9494 - val_loss: 0.5984 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5370 - acc: 0.9526 - precision: 0.9895 - recall: 0.9075 - f1_score: 0.9460 - val_loss: 0.5967 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5352 - acc: 0.9526 - precision: 0.9930 - recall: 0.9133 - f1_score: 0.9488 - val_loss: 0.5949 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5335 - acc: 0.9526 - precision: 0.9919 - recall: 0.9127 - f1_score: 0.9499 - val_loss: 0.5932 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5317 - acc: 0.9526 - precision: 0.9928 - recall: 0.9097 - f1_score: 0.9490 - val_loss: 0.5915 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5300 - acc: 0.9526 - precision: 0.9928 - recall: 0.9100 - f1_score: 0.9487 - val_loss: 0.5898 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5283 - acc: 0.9526 - precision: 0.9935 - recall: 0.9137 - f1_score: 0.9505 - val_loss: 0.5881 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5266 - acc: 0.9526 - precision: 0.9917 - recall: 0.9117 - f1_score: 0.9494 - val_loss: 0.5864 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5249 - acc: 0.9526 - precision: 0.9918 - recall: 0.9106 - f1_score: 0.9480 - val_loss: 0.5848 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5232 - acc: 0.9526 - precision: 0.9921 - recall: 0.9112 - f1_score: 0.9492 - val_loss: 0.5831 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5215 - acc: 0.9526 - precision: 0.9940 - recall: 0.9104 - f1_score: 0.9492 - val_loss: 0.5814 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5199 - acc: 0.9526 - precision: 0.9925 - recall: 0.9114 - f1_score: 0.9486 - val_loss: 0.5798 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5182 - acc: 0.9526 - precision: 0.9937 - recall: 0.9140 - f1_score: 0.9512 - val_loss: 0.5782 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5166 - acc: 0.9526 - precision: 0.9918 - recall: 0.9044 - f1_score: 0.9439 - val_loss: 0.5765 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5149 - acc: 0.9526 - precision: 0.9928 - recall: 0.9113 - f1_score: 0.9494 - val_loss: 0.5749 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5133 - acc: 0.9526 - precision: 0.9928 - recall: 0.9103 - f1_score: 0.9494 - val_loss: 0.5733 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5117 - acc: 0.9526 - precision: 0.9923 - recall: 0.9102 - f1_score: 0.9479 - val_loss: 0.5717 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5100 - acc: 0.9526 - precision: 0.9920 - recall: 0.9082 - f1_score: 0.9475 - val_loss: 0.5701 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5084 - acc: 0.9526 - precision: 0.9938 - recall: 0.9108 - f1_score: 0.9493 - val_loss: 0.5685 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5068 - acc: 0.9526 - precision: 0.9936 - recall: 0.9098 - f1_score: 0.9491 - val_loss: 0.5669 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5052 - acc: 0.9526 - precision: 0.9919 - recall: 0.9115 - f1_score: 0.9480 - val_loss: 0.5653 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5036 - acc: 0.9526 - precision: 0.9944 - recall: 0.9131 - f1_score: 0.9509 - val_loss: 0.5638 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5020 - acc: 0.9526 - precision: 0.9934 - recall: 0.9097 - f1_score: 0.9473 - val_loss: 0.5622 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5005 - acc: 0.9526 - precision: 0.9926 - recall: 0.9100 - f1_score: 0.9481 - val_loss: 0.5607 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 568/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4989 - acc: 0.9526 - precision: 0.9924 - recall: 0.9093 - f1_score: 0.9480 - val_loss: 0.5591 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4973 - acc: 0.9526 - precision: 0.9933 - recall: 0.9107 - f1_score: 0.9492 - val_loss: 0.5576 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4958 - acc: 0.9526 - precision: 0.9926 - recall: 0.9071 - f1_score: 0.9462 - val_loss: 0.5560 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4943 - acc: 0.9526 - precision: 0.9935 - recall: 0.9127 - f1_score: 0.9507 - val_loss: 0.5545 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4927 - acc: 0.9526 - precision: 0.9938 - recall: 0.9136 - f1_score: 0.9508 - val_loss: 0.5530 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4912 - acc: 0.9526 - precision: 0.9926 - recall: 0.9071 - f1_score: 0.9468 - val_loss: 0.5515 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4897 - acc: 0.9526 - precision: 0.9939 - recall: 0.9123 - f1_score: 0.9502 - val_loss: 0.5500 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4882 - acc: 0.9526 - precision: 0.9940 - recall: 0.9100 - f1_score: 0.9487 - val_loss: 0.5485 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4866 - acc: 0.9526 - precision: 0.9919 - recall: 0.9068 - f1_score: 0.9459 - val_loss: 0.5470 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4851 - acc: 0.9526 - precision: 0.9923 - recall: 0.9113 - f1_score: 0.9495 - val_loss: 0.5455 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4837 - acc: 0.9526 - precision: 0.9932 - recall: 0.9134 - f1_score: 0.9508 - val_loss: 0.5441 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4822 - acc: 0.9526 - precision: 0.9946 - recall: 0.9087 - f1_score: 0.9482 - val_loss: 0.5426 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4807 - acc: 0.9526 - precision: 0.9934 - recall: 0.9113 - f1_score: 0.9496 - val_loss: 0.5411 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4792 - acc: 0.9526 - precision: 0.9928 - recall: 0.9088 - f1_score: 0.9483 - val_loss: 0.5397 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4778 - acc: 0.9526 - precision: 0.9939 - recall: 0.9079 - f1_score: 0.9477 - val_loss: 0.5382 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4763 - acc: 0.9526 - precision: 0.9947 - recall: 0.9079 - f1_score: 0.9478 - val_loss: 0.5368 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4749 - acc: 0.9526 - precision: 0.9931 - recall: 0.9057 - f1_score: 0.9460 - val_loss: 0.5354 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4734 - acc: 0.9526 - precision: 0.9934 - recall: 0.9058 - f1_score: 0.9464 - val_loss: 0.5340 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4720 - acc: 0.9526 - precision: 0.9926 - recall: 0.9119 - f1_score: 0.9495 - val_loss: 0.5325 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4705 - acc: 0.9526 - precision: 0.9924 - recall: 0.9067 - f1_score: 0.9466 - val_loss: 0.5311 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4691 - acc: 0.9526 - precision: 0.9916 - recall: 0.9090 - f1_score: 0.9479 - val_loss: 0.5297 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4677 - acc: 0.9526 - precision: 0.9930 - recall: 0.9116 - f1_score: 0.9499 - val_loss: 0.5283 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4663 - acc: 0.9526 - precision: 0.9930 - recall: 0.9100 - f1_score: 0.9487 - val_loss: 0.5270 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4649 - acc: 0.9526 - precision: 0.9938 - recall: 0.9122 - f1_score: 0.9504 - val_loss: 0.5256 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4635 - acc: 0.9526 - precision: 0.9943 - recall: 0.9058 - f1_score: 0.9463 - val_loss: 0.5242 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4621 - acc: 0.9526 - precision: 0.9941 - recall: 0.9082 - f1_score: 0.9476 - val_loss: 0.5228 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4608 - acc: 0.9526 - precision: 0.9923 - recall: 0.9112 - f1_score: 0.9488 - val_loss: 0.5215 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4594 - acc: 0.9526 - precision: 0.9925 - recall: 0.9119 - f1_score: 0.9493 - val_loss: 0.5201 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4580 - acc: 0.9526 - precision: 0.9941 - recall: 0.9100 - f1_score: 0.9494 - val_loss: 0.5188 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4567 - acc: 0.9526 - precision: 0.9930 - recall: 0.9126 - f1_score: 0.9505 - val_loss: 0.5174 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4553 - acc: 0.9526 - precision: 0.9925 - recall: 0.9071 - f1_score: 0.9468 - val_loss: 0.5161 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4540 - acc: 0.9526 - precision: 0.9911 - recall: 0.9099 - f1_score: 0.9481 - val_loss: 0.5148 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4526 - acc: 0.9526 - precision: 0.9934 - recall: 0.9109 - f1_score: 0.9497 - val_loss: 0.5134 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4513 - acc: 0.9526 - precision: 0.9938 - recall: 0.9122 - f1_score: 0.9508 - val_loss: 0.5121 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4500 - acc: 0.9526 - precision: 0.9924 - recall: 0.9127 - f1_score: 0.9499 - val_loss: 0.5108 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4486 - acc: 0.9526 - precision: 0.9932 - recall: 0.9095 - f1_score: 0.9487 - val_loss: 0.5095 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4473 - acc: 0.9526 - precision: 0.9926 - recall: 0.9127 - f1_score: 0.9502 - val_loss: 0.5082 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4460 - acc: 0.9526 - precision: 0.9946 - recall: 0.9107 - f1_score: 0.9501 - val_loss: 0.5069 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4447 - acc: 0.9526 - precision: 0.9944 - recall: 0.9090 - f1_score: 0.9487 - val_loss: 0.5057 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4434 - acc: 0.9526 - precision: 0.9923 - recall: 0.9100 - f1_score: 0.9490 - val_loss: 0.5044 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4421 - acc: 0.9526 - precision: 0.9938 - recall: 0.9144 - f1_score: 0.9519 - val_loss: 0.5031 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4408 - acc: 0.9526 - precision: 0.9931 - recall: 0.9093 - f1_score: 0.9485 - val_loss: 0.5018 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4396 - acc: 0.9526 - precision: 0.9940 - recall: 0.9069 - f1_score: 0.9477 - val_loss: 0.5006 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4383 - acc: 0.9526 - precision: 0.9926 - recall: 0.9118 - f1_score: 0.9492 - val_loss: 0.4993 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4370 - acc: 0.9526 - precision: 0.9923 - recall: 0.9099 - f1_score: 0.9481 - val_loss: 0.4981 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4358 - acc: 0.9526 - precision: 0.9941 - recall: 0.9096 - f1_score: 0.9496 - val_loss: 0.4968 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4345 - acc: 0.9526 - precision: 0.9932 - recall: 0.9101 - f1_score: 0.9485 - val_loss: 0.4956 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4333 - acc: 0.9526 - precision: 0.9934 - recall: 0.9100 - f1_score: 0.9491 - val_loss: 0.4944 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4320 - acc: 0.9526 - precision: 0.9931 - recall: 0.9103 - f1_score: 0.9486 - val_loss: 0.4932 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4308 - acc: 0.9526 - precision: 0.9939 - recall: 0.9104 - f1_score: 0.9491 - val_loss: 0.4920 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4296 - acc: 0.9526 - precision: 0.9919 - recall: 0.9101 - f1_score: 0.9485 - val_loss: 0.4907 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4284 - acc: 0.9526 - precision: 0.9941 - recall: 0.9099 - f1_score: 0.9490 - val_loss: 0.4895 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4271 - acc: 0.9526 - precision: 0.9930 - recall: 0.9103 - f1_score: 0.9489 - val_loss: 0.4883 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4259 - acc: 0.9526 - precision: 0.9909 - recall: 0.9067 - f1_score: 0.9463 - val_loss: 0.4872 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4247 - acc: 0.9526 - precision: 0.9926 - recall: 0.9091 - f1_score: 0.9481 - val_loss: 0.4860 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4235 - acc: 0.9526 - precision: 0.9914 - recall: 0.9036 - f1_score: 0.9442 - val_loss: 0.4848 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4223 - acc: 0.9526 - precision: 0.9925 - recall: 0.9099 - f1_score: 0.9484 - val_loss: 0.4836 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4212 - acc: 0.9526 - precision: 0.9941 - recall: 0.9117 - f1_score: 0.9505 - val_loss: 0.4825 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4200 - acc: 0.9526 - precision: 0.9942 - recall: 0.9102 - f1_score: 0.9496 - val_loss: 0.4813 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4188 - acc: 0.9526 - precision: 0.9917 - recall: 0.9075 - f1_score: 0.9463 - val_loss: 0.4801 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4176 - acc: 0.9526 - precision: 0.9931 - recall: 0.9119 - f1_score: 0.9500 - val_loss: 0.4790 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4165 - acc: 0.9526 - precision: 0.9928 - recall: 0.9104 - f1_score: 0.9488 - val_loss: 0.4778 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4153 - acc: 0.9526 - precision: 0.9912 - recall: 0.9098 - f1_score: 0.9482 - val_loss: 0.4767 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4142 - acc: 0.9526 - precision: 0.9931 - recall: 0.9058 - f1_score: 0.9464 - val_loss: 0.4756 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 632/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4130 - acc: 0.9526 - precision: 0.9926 - recall: 0.9090 - f1_score: 0.9474 - val_loss: 0.4744 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4119 - acc: 0.9526 - precision: 0.9926 - recall: 0.9155 - f1_score: 0.9516 - val_loss: 0.4733 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4107 - acc: 0.9526 - precision: 0.9937 - recall: 0.9076 - f1_score: 0.9475 - val_loss: 0.4722 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4096 - acc: 0.9526 - precision: 0.9921 - recall: 0.9110 - f1_score: 0.9491 - val_loss: 0.4711 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4085 - acc: 0.9526 - precision: 0.9932 - recall: 0.9094 - f1_score: 0.9486 - val_loss: 0.4700 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4074 - acc: 0.9526 - precision: 0.9941 - recall: 0.9097 - f1_score: 0.9496 - val_loss: 0.4689 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4062 - acc: 0.9526 - precision: 0.9932 - recall: 0.9120 - f1_score: 0.9495 - val_loss: 0.4678 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4051 - acc: 0.9526 - precision: 0.9921 - recall: 0.9082 - f1_score: 0.9465 - val_loss: 0.4667 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4040 - acc: 0.9526 - precision: 0.9929 - recall: 0.9098 - f1_score: 0.9491 - val_loss: 0.4656 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4029 - acc: 0.9526 - precision: 0.9933 - recall: 0.9101 - f1_score: 0.9492 - val_loss: 0.4645 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4018 - acc: 0.9526 - precision: 0.9940 - recall: 0.9113 - f1_score: 0.9503 - val_loss: 0.4635 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4008 - acc: 0.9526 - precision: 0.9928 - recall: 0.9101 - f1_score: 0.9488 - val_loss: 0.4624 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3997 - acc: 0.9526 - precision: 0.9921 - recall: 0.9100 - f1_score: 0.9481 - val_loss: 0.4613 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3986 - acc: 0.9526 - precision: 0.9932 - recall: 0.9112 - f1_score: 0.9494 - val_loss: 0.4603 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3975 - acc: 0.9526 - precision: 0.9921 - recall: 0.9061 - f1_score: 0.9464 - val_loss: 0.4592 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3965 - acc: 0.9526 - precision: 0.9925 - recall: 0.9138 - f1_score: 0.9508 - val_loss: 0.4582 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3954 - acc: 0.9526 - precision: 0.9915 - recall: 0.9125 - f1_score: 0.9497 - val_loss: 0.4571 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3943 - acc: 0.9526 - precision: 0.9939 - recall: 0.9107 - f1_score: 0.9501 - val_loss: 0.4561 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3933 - acc: 0.9526 - precision: 0.9933 - recall: 0.9126 - f1_score: 0.9506 - val_loss: 0.4550 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3922 - acc: 0.9526 - precision: 0.9924 - recall: 0.9121 - f1_score: 0.9501 - val_loss: 0.4540 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3912 - acc: 0.9526 - precision: 0.9932 - recall: 0.9147 - f1_score: 0.9515 - val_loss: 0.4530 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3902 - acc: 0.9526 - precision: 0.9936 - recall: 0.9095 - f1_score: 0.9485 - val_loss: 0.4520 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3891 - acc: 0.9526 - precision: 0.9923 - recall: 0.9082 - f1_score: 0.9470 - val_loss: 0.4510 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9526 - precision: 0.9937 - recall: 0.9087 - f1_score: 0.9480 - val_loss: 0.4500 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3871 - acc: 0.9526 - precision: 0.9937 - recall: 0.9156 - f1_score: 0.9523 - val_loss: 0.4490 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3861 - acc: 0.9526 - precision: 0.9933 - recall: 0.9095 - f1_score: 0.9486 - val_loss: 0.4480 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3850 - acc: 0.9526 - precision: 0.9942 - recall: 0.9106 - f1_score: 0.9493 - val_loss: 0.4470 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3840 - acc: 0.9526 - precision: 0.9931 - recall: 0.9110 - f1_score: 0.9492 - val_loss: 0.4460 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3830 - acc: 0.9526 - precision: 0.9926 - recall: 0.9112 - f1_score: 0.9494 - val_loss: 0.4450 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3820 - acc: 0.9526 - precision: 0.9931 - recall: 0.9084 - f1_score: 0.9479 - val_loss: 0.4440 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3810 - acc: 0.9526 - precision: 0.9934 - recall: 0.9122 - f1_score: 0.9503 - val_loss: 0.4430 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3801 - acc: 0.9526 - precision: 0.9940 - recall: 0.9120 - f1_score: 0.9502 - val_loss: 0.4421 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3791 - acc: 0.9526 - precision: 0.9928 - recall: 0.9125 - f1_score: 0.9496 - val_loss: 0.4411 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3781 - acc: 0.9526 - precision: 0.9928 - recall: 0.9107 - f1_score: 0.9492 - val_loss: 0.4401 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3771 - acc: 0.9526 - precision: 0.9923 - recall: 0.9096 - f1_score: 0.9483 - val_loss: 0.4392 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3762 - acc: 0.9526 - precision: 0.9933 - recall: 0.9107 - f1_score: 0.9489 - val_loss: 0.4382 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3752 - acc: 0.9526 - precision: 0.9928 - recall: 0.9126 - f1_score: 0.9496 - val_loss: 0.4373 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3742 - acc: 0.9526 - precision: 0.9926 - recall: 0.9059 - f1_score: 0.9444 - val_loss: 0.4363 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3733 - acc: 0.9526 - precision: 0.9930 - recall: 0.9091 - f1_score: 0.9473 - val_loss: 0.4354 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3723 - acc: 0.9526 - precision: 0.9930 - recall: 0.9126 - f1_score: 0.9500 - val_loss: 0.4345 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3714 - acc: 0.9526 - precision: 0.9933 - recall: 0.9170 - f1_score: 0.9515 - val_loss: 0.4335 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3704 - acc: 0.9526 - precision: 0.9923 - recall: 0.9087 - f1_score: 0.9475 - val_loss: 0.4326 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3695 - acc: 0.9526 - precision: 0.9937 - recall: 0.9149 - f1_score: 0.9513 - val_loss: 0.4317 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3686 - acc: 0.9526 - precision: 0.9938 - recall: 0.9104 - f1_score: 0.9491 - val_loss: 0.4308 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3676 - acc: 0.9526 - precision: 0.9937 - recall: 0.9096 - f1_score: 0.9492 - val_loss: 0.4299 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3667 - acc: 0.9526 - precision: 0.9932 - recall: 0.9136 - f1_score: 0.9502 - val_loss: 0.4290 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3658 - acc: 0.9526 - precision: 0.9926 - recall: 0.9053 - f1_score: 0.9451 - val_loss: 0.4281 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3649 - acc: 0.9526 - precision: 0.9933 - recall: 0.9126 - f1_score: 0.9503 - val_loss: 0.4272 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3640 - acc: 0.9526 - precision: 0.9929 - recall: 0.9088 - f1_score: 0.9482 - val_loss: 0.4263 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3631 - acc: 0.9526 - precision: 0.9935 - recall: 0.9100 - f1_score: 0.9491 - val_loss: 0.4254 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3622 - acc: 0.9526 - precision: 0.9912 - recall: 0.9104 - f1_score: 0.9473 - val_loss: 0.4245 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3613 - acc: 0.9526 - precision: 0.9921 - recall: 0.9118 - f1_score: 0.9494 - val_loss: 0.4236 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3604 - acc: 0.9526 - precision: 0.9931 - recall: 0.9142 - f1_score: 0.9513 - val_loss: 0.4227 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3595 - acc: 0.9526 - precision: 0.9933 - recall: 0.9105 - f1_score: 0.9492 - val_loss: 0.4219 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3586 - acc: 0.9526 - precision: 0.9938 - recall: 0.9115 - f1_score: 0.9503 - val_loss: 0.4210 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3577 - acc: 0.9526 - precision: 0.9910 - recall: 0.9088 - f1_score: 0.9477 - val_loss: 0.4201 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3568 - acc: 0.9526 - precision: 0.9935 - recall: 0.9119 - f1_score: 0.9496 - val_loss: 0.4193 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3560 - acc: 0.9526 - precision: 0.9931 - recall: 0.9105 - f1_score: 0.9495 - val_loss: 0.4184 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3551 - acc: 0.9526 - precision: 0.9938 - recall: 0.9120 - f1_score: 0.9499 - val_loss: 0.4176 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3542 - acc: 0.9526 - precision: 0.9933 - recall: 0.9126 - f1_score: 0.9500 - val_loss: 0.4167 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3534 - acc: 0.9526 - precision: 0.9931 - recall: 0.9106 - f1_score: 0.9494 - val_loss: 0.4159 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3525 - acc: 0.9526 - precision: 0.9925 - recall: 0.9086 - f1_score: 0.9485 - val_loss: 0.4151 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3517 - acc: 0.9526 - precision: 0.9934 - recall: 0.9125 - f1_score: 0.9500 - val_loss: 0.4142 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3508 - acc: 0.9526 - precision: 0.9937 - recall: 0.9116 - f1_score: 0.9497 - val_loss: 0.4134 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 696/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3500 - acc: 0.9526 - precision: 0.9935 - recall: 0.9162 - f1_score: 0.9522 - val_loss: 0.4126 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3491 - acc: 0.9526 - precision: 0.9919 - recall: 0.9051 - f1_score: 0.9457 - val_loss: 0.4117 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3483 - acc: 0.9526 - precision: 0.9912 - recall: 0.9120 - f1_score: 0.9490 - val_loss: 0.4109 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3475 - acc: 0.9526 - precision: 0.9919 - recall: 0.9086 - f1_score: 0.9479 - val_loss: 0.4101 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3466 - acc: 0.9526 - precision: 0.9923 - recall: 0.9112 - f1_score: 0.9493 - val_loss: 0.4093 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3458 - acc: 0.9526 - precision: 0.9943 - recall: 0.9079 - f1_score: 0.9483 - val_loss: 0.4085 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3450 - acc: 0.9526 - precision: 0.9938 - recall: 0.9134 - f1_score: 0.9503 - val_loss: 0.4077 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3442 - acc: 0.9526 - precision: 0.9925 - recall: 0.9117 - f1_score: 0.9498 - val_loss: 0.4069 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3434 - acc: 0.9526 - precision: 0.9931 - recall: 0.9095 - f1_score: 0.9484 - val_loss: 0.4061 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3425 - acc: 0.9526 - precision: 0.9928 - recall: 0.9095 - f1_score: 0.9486 - val_loss: 0.4053 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3417 - acc: 0.9526 - precision: 0.9934 - recall: 0.9177 - f1_score: 0.9532 - val_loss: 0.4045 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3409 - acc: 0.9526 - precision: 0.9933 - recall: 0.9097 - f1_score: 0.9490 - val_loss: 0.4037 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3401 - acc: 0.9526 - precision: 0.9935 - recall: 0.9097 - f1_score: 0.9492 - val_loss: 0.4029 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3394 - acc: 0.9526 - precision: 0.9927 - recall: 0.9127 - f1_score: 0.9504 - val_loss: 0.4022 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3386 - acc: 0.9526 - precision: 0.9932 - recall: 0.9118 - f1_score: 0.9503 - val_loss: 0.4014 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3378 - acc: 0.9526 - precision: 0.9926 - recall: 0.9135 - f1_score: 0.9497 - val_loss: 0.4006 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3370 - acc: 0.9526 - precision: 0.9934 - recall: 0.9094 - f1_score: 0.9490 - val_loss: 0.3998 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3362 - acc: 0.9526 - precision: 0.9940 - recall: 0.9100 - f1_score: 0.9496 - val_loss: 0.3991 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3354 - acc: 0.9526 - precision: 0.9931 - recall: 0.9104 - f1_score: 0.9494 - val_loss: 0.3983 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3347 - acc: 0.9526 - precision: 0.9919 - recall: 0.9106 - f1_score: 0.9484 - val_loss: 0.3976 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3339 - acc: 0.9526 - precision: 0.9929 - recall: 0.9110 - f1_score: 0.9495 - val_loss: 0.3968 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3331 - acc: 0.9526 - precision: 0.9918 - recall: 0.9086 - f1_score: 0.9474 - val_loss: 0.3961 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3324 - acc: 0.9526 - precision: 0.9918 - recall: 0.9094 - f1_score: 0.9478 - val_loss: 0.3953 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3316 - acc: 0.9526 - precision: 0.9933 - recall: 0.9033 - f1_score: 0.9439 - val_loss: 0.3946 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3309 - acc: 0.9526 - precision: 0.9938 - recall: 0.9111 - f1_score: 0.9491 - val_loss: 0.3938 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3301 - acc: 0.9526 - precision: 0.9922 - recall: 0.9114 - f1_score: 0.9494 - val_loss: 0.3931 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3294 - acc: 0.9526 - precision: 0.9937 - recall: 0.9110 - f1_score: 0.9497 - val_loss: 0.3924 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3286 - acc: 0.9526 - precision: 0.9921 - recall: 0.9106 - f1_score: 0.9487 - val_loss: 0.3917 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3279 - acc: 0.9526 - precision: 0.9931 - recall: 0.9094 - f1_score: 0.9488 - val_loss: 0.3909 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3271 - acc: 0.9526 - precision: 0.9941 - recall: 0.9091 - f1_score: 0.9483 - val_loss: 0.3902 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3264 - acc: 0.9526 - precision: 0.9909 - recall: 0.9082 - f1_score: 0.9467 - val_loss: 0.3895 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3257 - acc: 0.9526 - precision: 0.9934 - recall: 0.9093 - f1_score: 0.9489 - val_loss: 0.3888 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3250 - acc: 0.9526 - precision: 0.9934 - recall: 0.9105 - f1_score: 0.9493 - val_loss: 0.3881 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3242 - acc: 0.9526 - precision: 0.9928 - recall: 0.9117 - f1_score: 0.9500 - val_loss: 0.3874 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3235 - acc: 0.9526 - precision: 0.9929 - recall: 0.9151 - f1_score: 0.9515 - val_loss: 0.3867 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3228 - acc: 0.9526 - precision: 0.9937 - recall: 0.9105 - f1_score: 0.9498 - val_loss: 0.3860 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3221 - acc: 0.9526 - precision: 0.9923 - recall: 0.9126 - f1_score: 0.9492 - val_loss: 0.3853 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3214 - acc: 0.9526 - precision: 0.9913 - recall: 0.9101 - f1_score: 0.9478 - val_loss: 0.3846 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3207 - acc: 0.9526 - precision: 0.9937 - recall: 0.9102 - f1_score: 0.9493 - val_loss: 0.3839 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3200 - acc: 0.9526 - precision: 0.9931 - recall: 0.9087 - f1_score: 0.9486 - val_loss: 0.3832 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3193 - acc: 0.9526 - precision: 0.9929 - recall: 0.9115 - f1_score: 0.9496 - val_loss: 0.3825 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3186 - acc: 0.9526 - precision: 0.9923 - recall: 0.9089 - f1_score: 0.9478 - val_loss: 0.3818 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3179 - acc: 0.9526 - precision: 0.9933 - recall: 0.9112 - f1_score: 0.9489 - val_loss: 0.3812 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9526 - precision: 0.9918 - recall: 0.9097 - f1_score: 0.9484 - val_loss: 0.3805 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3165 - acc: 0.9526 - precision: 0.9931 - recall: 0.9098 - f1_score: 0.9489 - val_loss: 0.3798 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3158 - acc: 0.9526 - precision: 0.9924 - recall: 0.9147 - f1_score: 0.9506 - val_loss: 0.3792 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3151 - acc: 0.9526 - precision: 0.9939 - recall: 0.9099 - f1_score: 0.9487 - val_loss: 0.3785 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3145 - acc: 0.9526 - precision: 0.9928 - recall: 0.9122 - f1_score: 0.9493 - val_loss: 0.3778 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3138 - acc: 0.9526 - precision: 0.9921 - recall: 0.9135 - f1_score: 0.9507 - val_loss: 0.3772 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3131 - acc: 0.9526 - precision: 0.9940 - recall: 0.9092 - f1_score: 0.9485 - val_loss: 0.3765 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3124 - acc: 0.9526 - precision: 0.9928 - recall: 0.9138 - f1_score: 0.9500 - val_loss: 0.3759 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3118 - acc: 0.9526 - precision: 0.9934 - recall: 0.9106 - f1_score: 0.9497 - val_loss: 0.3752 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3111 - acc: 0.9526 - precision: 0.9920 - recall: 0.9118 - f1_score: 0.9497 - val_loss: 0.3746 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3105 - acc: 0.9526 - precision: 0.9929 - recall: 0.9106 - f1_score: 0.9492 - val_loss: 0.3739 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3098 - acc: 0.9526 - precision: 0.9925 - recall: 0.9134 - f1_score: 0.9501 - val_loss: 0.3733 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3091 - acc: 0.9526 - precision: 0.9931 - recall: 0.9130 - f1_score: 0.9504 - val_loss: 0.3727 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3085 - acc: 0.9526 - precision: 0.9928 - recall: 0.9079 - f1_score: 0.9471 - val_loss: 0.3720 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3078 - acc: 0.9526 - precision: 0.9929 - recall: 0.9123 - f1_score: 0.9501 - val_loss: 0.3714 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3072 - acc: 0.9526 - precision: 0.9933 - recall: 0.9087 - f1_score: 0.9478 - val_loss: 0.3708 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3066 - acc: 0.9526 - precision: 0.9932 - recall: 0.9110 - f1_score: 0.9497 - val_loss: 0.3702 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3059 - acc: 0.9526 - precision: 0.9935 - recall: 0.9123 - f1_score: 0.9500 - val_loss: 0.3695 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3053 - acc: 0.9526 - precision: 0.9928 - recall: 0.9121 - f1_score: 0.9495 - val_loss: 0.3689 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3047 - acc: 0.9526 - precision: 0.9926 - recall: 0.9095 - f1_score: 0.9486 - val_loss: 0.3683 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3040 - acc: 0.9526 - precision: 0.9934 - recall: 0.9087 - f1_score: 0.9485 - val_loss: 0.3677 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 760/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3034 - acc: 0.9526 - precision: 0.9935 - recall: 0.9106 - f1_score: 0.9497 - val_loss: 0.3671 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3028 - acc: 0.9526 - precision: 0.9950 - recall: 0.9111 - f1_score: 0.9501 - val_loss: 0.3665 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3022 - acc: 0.9526 - precision: 0.9937 - recall: 0.9110 - f1_score: 0.9493 - val_loss: 0.3659 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3015 - acc: 0.9526 - precision: 0.9935 - recall: 0.9103 - f1_score: 0.9491 - val_loss: 0.3653 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3009 - acc: 0.9526 - precision: 0.9933 - recall: 0.9064 - f1_score: 0.9463 - val_loss: 0.3647 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3003 - acc: 0.9526 - precision: 0.9935 - recall: 0.9099 - f1_score: 0.9486 - val_loss: 0.3641 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2997 - acc: 0.9526 - precision: 0.9939 - recall: 0.9112 - f1_score: 0.9507 - val_loss: 0.3635 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2991 - acc: 0.9526 - precision: 0.9921 - recall: 0.9105 - f1_score: 0.9491 - val_loss: 0.3629 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2985 - acc: 0.9526 - precision: 0.9928 - recall: 0.9107 - f1_score: 0.9491 - val_loss: 0.3623 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2979 - acc: 0.9526 - precision: 0.9929 - recall: 0.9107 - f1_score: 0.9491 - val_loss: 0.3617 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2973 - acc: 0.9526 - precision: 0.9941 - recall: 0.9096 - f1_score: 0.9491 - val_loss: 0.3611 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2967 - acc: 0.9526 - precision: 0.9929 - recall: 0.9113 - f1_score: 0.9502 - val_loss: 0.3606 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2961 - acc: 0.9526 - precision: 0.9925 - recall: 0.9065 - f1_score: 0.9470 - val_loss: 0.3600 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2955 - acc: 0.9526 - precision: 0.9912 - recall: 0.9085 - f1_score: 0.9474 - val_loss: 0.3594 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2949 - acc: 0.9526 - precision: 0.9925 - recall: 0.9099 - f1_score: 0.9486 - val_loss: 0.3588 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2944 - acc: 0.9526 - precision: 0.9941 - recall: 0.9114 - f1_score: 0.9503 - val_loss: 0.3583 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2938 - acc: 0.9526 - precision: 0.9935 - recall: 0.9081 - f1_score: 0.9476 - val_loss: 0.3577 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2932 - acc: 0.9526 - precision: 0.9918 - recall: 0.9083 - f1_score: 0.9474 - val_loss: 0.3571 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2926 - acc: 0.9526 - precision: 0.9934 - recall: 0.9081 - f1_score: 0.9471 - val_loss: 0.3566 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2920 - acc: 0.9526 - precision: 0.9934 - recall: 0.9085 - f1_score: 0.9481 - val_loss: 0.3560 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2915 - acc: 0.9526 - precision: 0.9931 - recall: 0.9095 - f1_score: 0.9489 - val_loss: 0.3555 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2909 - acc: 0.9526 - precision: 0.9934 - recall: 0.9118 - f1_score: 0.9503 - val_loss: 0.3549 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2903 - acc: 0.9526 - precision: 0.9936 - recall: 0.9104 - f1_score: 0.9490 - val_loss: 0.3544 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2898 - acc: 0.9526 - precision: 0.9925 - recall: 0.9133 - f1_score: 0.9502 - val_loss: 0.3538 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2892 - acc: 0.9526 - precision: 0.9912 - recall: 0.9097 - f1_score: 0.9478 - val_loss: 0.3533 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2886 - acc: 0.9526 - precision: 0.9929 - recall: 0.9092 - f1_score: 0.9490 - val_loss: 0.3527 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2881 - acc: 0.9526 - precision: 0.9928 - recall: 0.9059 - f1_score: 0.9457 - val_loss: 0.3522 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2875 - acc: 0.9526 - precision: 0.9906 - recall: 0.9047 - f1_score: 0.9441 - val_loss: 0.3516 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2870 - acc: 0.9526 - precision: 0.9919 - recall: 0.9142 - f1_score: 0.9497 - val_loss: 0.3511 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2864 - acc: 0.9526 - precision: 0.9924 - recall: 0.9136 - f1_score: 0.9505 - val_loss: 0.3506 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2859 - acc: 0.9526 - precision: 0.9935 - recall: 0.9130 - f1_score: 0.9509 - val_loss: 0.3500 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2854 - acc: 0.9526 - precision: 0.9923 - recall: 0.9128 - f1_score: 0.9501 - val_loss: 0.3495 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 792/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9526 - precision: 0.9938 - recall: 0.9137 - f1_score: 0.9504 - val_loss: 0.3490 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9526 - precision: 0.9939 - recall: 0.9124 - f1_score: 0.9502 - val_loss: 0.3485 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2837 - acc: 0.9526 - precision: 0.9931 - recall: 0.9105 - f1_score: 0.9491 - val_loss: 0.3479 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2832 - acc: 0.9526 - precision: 0.9933 - recall: 0.9135 - f1_score: 0.9507 - val_loss: 0.3474 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2827 - acc: 0.9526 - precision: 0.9933 - recall: 0.9156 - f1_score: 0.9516 - val_loss: 0.3469 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2821 - acc: 0.9526 - precision: 0.9929 - recall: 0.9100 - f1_score: 0.9490 - val_loss: 0.3464 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2816 - acc: 0.9526 - precision: 0.9936 - recall: 0.9061 - f1_score: 0.9465 - val_loss: 0.3459 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2811 - acc: 0.9526 - precision: 0.9929 - recall: 0.9079 - f1_score: 0.9476 - val_loss: 0.3454 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2806 - acc: 0.9526 - precision: 0.9929 - recall: 0.9104 - f1_score: 0.9491 - val_loss: 0.3449 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2801 - acc: 0.9526 - precision: 0.9931 - recall: 0.9113 - f1_score: 0.9492 - val_loss: 0.3444 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2795 - acc: 0.9526 - precision: 0.9938 - recall: 0.9065 - f1_score: 0.9460 - val_loss: 0.3439 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2790 - acc: 0.9526 - precision: 0.9939 - recall: 0.9067 - f1_score: 0.9471 - val_loss: 0.3434 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9526 - precision: 0.9932 - recall: 0.9087 - f1_score: 0.9477 - val_loss: 0.3429 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2780 - acc: 0.9526 - precision: 0.9921 - recall: 0.9140 - f1_score: 0.9510 - val_loss: 0.3424 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2775 - acc: 0.9526 - precision: 0.9924 - recall: 0.9103 - f1_score: 0.9486 - val_loss: 0.3419 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2770 - acc: 0.9526 - precision: 0.9931 - recall: 0.9062 - f1_score: 0.9461 - val_loss: 0.3414 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2765 - acc: 0.9526 - precision: 0.9939 - recall: 0.9103 - f1_score: 0.9491 - val_loss: 0.3409 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9526 - precision: 0.9916 - recall: 0.9082 - f1_score: 0.9473 - val_loss: 0.3404 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2755 - acc: 0.9526 - precision: 0.9936 - recall: 0.9113 - f1_score: 0.9490 - val_loss: 0.3400 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2750 - acc: 0.9526 - precision: 0.9926 - recall: 0.9133 - f1_score: 0.9503 - val_loss: 0.3395 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2745 - acc: 0.9526 - precision: 0.9924 - recall: 0.9107 - f1_score: 0.9484 - val_loss: 0.3390 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9526 - precision: 0.9937 - recall: 0.9133 - f1_score: 0.9501 - val_loss: 0.3385 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2735 - acc: 0.9526 - precision: 0.9931 - recall: 0.9063 - f1_score: 0.9466 - val_loss: 0.3381 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2730 - acc: 0.9526 - precision: 0.9932 - recall: 0.9108 - f1_score: 0.9494 - val_loss: 0.3376 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2725 - acc: 0.9526 - precision: 0.9924 - recall: 0.9111 - f1_score: 0.9494 - val_loss: 0.3371 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2720 - acc: 0.9526 - precision: 0.9924 - recall: 0.9117 - f1_score: 0.9491 - val_loss: 0.3367 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2716 - acc: 0.9526 - precision: 0.9933 - recall: 0.9128 - f1_score: 0.9506 - val_loss: 0.3362 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2711 - acc: 0.9526 - precision: 0.9946 - recall: 0.9089 - f1_score: 0.9484 - val_loss: 0.3357 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2706 - acc: 0.9526 - precision: 0.9924 - recall: 0.9098 - f1_score: 0.9479 - val_loss: 0.3353 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9526 - precision: 0.9930 - recall: 0.9105 - f1_score: 0.9486 - val_loss: 0.3348 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9526 - precision: 0.9923 - recall: 0.9103 - f1_score: 0.9491 - val_loss: 0.3344 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2692 - acc: 0.9526 - precision: 0.9931 - recall: 0.9105 - f1_score: 0.9479 - val_loss: 0.3339 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2687 - acc: 0.9526 - precision: 0.9938 - recall: 0.9120 - f1_score: 0.9498 - val_loss: 0.3335 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2683 - acc: 0.9526 - precision: 0.9931 - recall: 0.9099 - f1_score: 0.9489 - val_loss: 0.3330 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2678 - acc: 0.9526 - precision: 0.9919 - recall: 0.9093 - f1_score: 0.9481 - val_loss: 0.3326 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2673 - acc: 0.9526 - precision: 0.9926 - recall: 0.9121 - f1_score: 0.9495 - val_loss: 0.3321 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2669 - acc: 0.9526 - precision: 0.9927 - recall: 0.9077 - f1_score: 0.9475 - val_loss: 0.3317 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2664 - acc: 0.9526 - precision: 0.9928 - recall: 0.9089 - f1_score: 0.9484 - val_loss: 0.3312 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2660 - acc: 0.9526 - precision: 0.9923 - recall: 0.9121 - f1_score: 0.9491 - val_loss: 0.3308 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2655 - acc: 0.9526 - precision: 0.9917 - recall: 0.9123 - f1_score: 0.9490 - val_loss: 0.3303 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2651 - acc: 0.9526 - precision: 0.9941 - recall: 0.9115 - f1_score: 0.9501 - val_loss: 0.3299 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2646 - acc: 0.9526 - precision: 0.9932 - recall: 0.9100 - f1_score: 0.9493 - val_loss: 0.3295 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2642 - acc: 0.9526 - precision: 0.9930 - recall: 0.9118 - f1_score: 0.9496 - val_loss: 0.3290 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2637 - acc: 0.9526 - precision: 0.9938 - recall: 0.9107 - f1_score: 0.9497 - val_loss: 0.3286 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2633 - acc: 0.9526 - precision: 0.9917 - recall: 0.9103 - f1_score: 0.9489 - val_loss: 0.3282 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2628 - acc: 0.9526 - precision: 0.9928 - recall: 0.9113 - f1_score: 0.9481 - val_loss: 0.3278 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2624 - acc: 0.9526 - precision: 0.9931 - recall: 0.9081 - f1_score: 0.9476 - val_loss: 0.3273 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2620 - acc: 0.9526 - precision: 0.9930 - recall: 0.9092 - f1_score: 0.9479 - val_loss: 0.3269 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2615 - acc: 0.9526 - precision: 0.9917 - recall: 0.9091 - f1_score: 0.9478 - val_loss: 0.3265 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2611 - acc: 0.9526 - precision: 0.9939 - recall: 0.9094 - f1_score: 0.9490 - val_loss: 0.3261 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2606 - acc: 0.9526 - precision: 0.9928 - recall: 0.9043 - f1_score: 0.9454 - val_loss: 0.3256 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9526 - precision: 0.9938 - recall: 0.9066 - f1_score: 0.9473 - val_loss: 0.3252 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9526 - precision: 0.9928 - recall: 0.9097 - f1_score: 0.9482 - val_loss: 0.3248 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2594 - acc: 0.9526 - precision: 0.9940 - recall: 0.9080 - f1_score: 0.9483 - val_loss: 0.3244 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2589 - acc: 0.9526 - precision: 0.9937 - recall: 0.9088 - f1_score: 0.9488 - val_loss: 0.3240 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9526 - precision: 0.9934 - recall: 0.9135 - f1_score: 0.9505 - val_loss: 0.3236 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9526 - precision: 0.9936 - recall: 0.9108 - f1_score: 0.9489 - val_loss: 0.3232 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2577 - acc: 0.9526 - precision: 0.9918 - recall: 0.9159 - f1_score: 0.9511 - val_loss: 0.3228 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2573 - acc: 0.9526 - precision: 0.9934 - recall: 0.9130 - f1_score: 0.9509 - val_loss: 0.3224 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2568 - acc: 0.9526 - precision: 0.9925 - recall: 0.9119 - f1_score: 0.9495 - val_loss: 0.3220 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2564 - acc: 0.9526 - precision: 0.9941 - recall: 0.9094 - f1_score: 0.9489 - val_loss: 0.3216 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2560 - acc: 0.9526 - precision: 0.9931 - recall: 0.9115 - f1_score: 0.9498 - val_loss: 0.3212 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2556 - acc: 0.9526 - precision: 0.9938 - recall: 0.9110 - f1_score: 0.9493 - val_loss: 0.3208 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2552 - acc: 0.9526 - precision: 0.9925 - recall: 0.9106 - f1_score: 0.9490 - val_loss: 0.3204 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 856/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2548 - acc: 0.9526 - precision: 0.9923 - recall: 0.9106 - f1_score: 0.9490 - val_loss: 0.3200 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2544 - acc: 0.9526 - precision: 0.9928 - recall: 0.9114 - f1_score: 0.9497 - val_loss: 0.3196 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2540 - acc: 0.9526 - precision: 0.9930 - recall: 0.9109 - f1_score: 0.9496 - val_loss: 0.3192 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2536 - acc: 0.9526 - precision: 0.9928 - recall: 0.9108 - f1_score: 0.9494 - val_loss: 0.3188 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2532 - acc: 0.9526 - precision: 0.9927 - recall: 0.9156 - f1_score: 0.9513 - val_loss: 0.3185 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2528 - acc: 0.9526 - precision: 0.9923 - recall: 0.9096 - f1_score: 0.9483 - val_loss: 0.3181 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2524 - acc: 0.9526 - precision: 0.9935 - recall: 0.9090 - f1_score: 0.9480 - val_loss: 0.3177 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2520 - acc: 0.9526 - precision: 0.9935 - recall: 0.9107 - f1_score: 0.9497 - val_loss: 0.3173 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2516 - acc: 0.9526 - precision: 0.9929 - recall: 0.9100 - f1_score: 0.9485 - val_loss: 0.3170 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2512 - acc: 0.9526 - precision: 0.9925 - recall: 0.9113 - f1_score: 0.9488 - val_loss: 0.3166 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2508 - acc: 0.9526 - precision: 0.9925 - recall: 0.9162 - f1_score: 0.9510 - val_loss: 0.3162 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2504 - acc: 0.9526 - precision: 0.9928 - recall: 0.9134 - f1_score: 0.9507 - val_loss: 0.3158 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2501 - acc: 0.9526 - precision: 0.9930 - recall: 0.9078 - f1_score: 0.9463 - val_loss: 0.3155 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2497 - acc: 0.9526 - precision: 0.9925 - recall: 0.9081 - f1_score: 0.9475 - val_loss: 0.3151 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9526 - precision: 0.9937 - recall: 0.9097 - f1_score: 0.9487 - val_loss: 0.3147 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9526 - precision: 0.9932 - recall: 0.9085 - f1_score: 0.9485 - val_loss: 0.3144 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2485 - acc: 0.9526 - precision: 0.9935 - recall: 0.9103 - f1_score: 0.9489 - val_loss: 0.3140 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2482 - acc: 0.9526 - precision: 0.9932 - recall: 0.9105 - f1_score: 0.9495 - val_loss: 0.3136 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9526 - precision: 0.9912 - recall: 0.9094 - f1_score: 0.9478 - val_loss: 0.3133 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2474 - acc: 0.9526 - precision: 0.9927 - recall: 0.9096 - f1_score: 0.9487 - val_loss: 0.3129 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9526 - precision: 0.9933 - recall: 0.9103 - f1_score: 0.9490 - val_loss: 0.3126 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9526 - precision: 0.9933 - recall: 0.9155 - f1_score: 0.9513 - val_loss: 0.3122 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2463 - acc: 0.9526 - precision: 0.9920 - recall: 0.9093 - f1_score: 0.9482 - val_loss: 0.3119 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9526 - precision: 0.9937 - recall: 0.9118 - f1_score: 0.9494 - val_loss: 0.3115 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9526 - precision: 0.9937 - recall: 0.9113 - f1_score: 0.9490 - val_loss: 0.3112 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2452 - acc: 0.9526 - precision: 0.9926 - recall: 0.9104 - f1_score: 0.9494 - val_loss: 0.3108 - val_acc: 0.9177 - val_precision: 0.9856 - val_recall: 0.8475 - val_f1_score: 0.9102\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9526 - precision: 0.9921 - recall: 0.9117 - f1_score: 0.9491 - val_loss: 0.3105 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2445 - acc: 0.9526 - precision: 0.9930 - recall: 0.9143 - f1_score: 0.9506 - val_loss: 0.3102 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2441 - acc: 0.9526 - precision: 0.9938 - recall: 0.9090 - f1_score: 0.9482 - val_loss: 0.3098 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2438 - acc: 0.9526 - precision: 0.9927 - recall: 0.9144 - f1_score: 0.9506 - val_loss: 0.3095 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2434 - acc: 0.9526 - precision: 0.9924 - recall: 0.9107 - f1_score: 0.9491 - val_loss: 0.3091 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2431 - acc: 0.9526 - precision: 0.9928 - recall: 0.9118 - f1_score: 0.9497 - val_loss: 0.3088 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2427 - acc: 0.9526 - precision: 0.9928 - recall: 0.9128 - f1_score: 0.9506 - val_loss: 0.3085 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2424 - acc: 0.9526 - precision: 0.9927 - recall: 0.9107 - f1_score: 0.9493 - val_loss: 0.3081 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2420 - acc: 0.9526 - precision: 0.9926 - recall: 0.9167 - f1_score: 0.9518 - val_loss: 0.3078 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2417 - acc: 0.9526 - precision: 0.9930 - recall: 0.9063 - f1_score: 0.9469 - val_loss: 0.3074 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2413 - acc: 0.9526 - precision: 0.9931 - recall: 0.9080 - f1_score: 0.9481 - val_loss: 0.3071 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2410 - acc: 0.9526 - precision: 0.9927 - recall: 0.9110 - f1_score: 0.9494 - val_loss: 0.3068 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9526 - precision: 0.9932 - recall: 0.9096 - f1_score: 0.9483 - val_loss: 0.3065 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2403 - acc: 0.9526 - precision: 0.9924 - recall: 0.9111 - f1_score: 0.9488 - val_loss: 0.3061 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9526 - precision: 0.9928 - recall: 0.9117 - f1_score: 0.9492 - val_loss: 0.3058 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2396 - acc: 0.9526 - precision: 0.9937 - recall: 0.9077 - f1_score: 0.9477 - val_loss: 0.3055 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2393 - acc: 0.9526 - precision: 0.9938 - recall: 0.9106 - f1_score: 0.9489 - val_loss: 0.3052 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9526 - precision: 0.9933 - recall: 0.9090 - f1_score: 0.9483 - val_loss: 0.3049 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9526 - precision: 0.9921 - recall: 0.9144 - f1_score: 0.9503 - val_loss: 0.3045 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2383 - acc: 0.9526 - precision: 0.9928 - recall: 0.9086 - f1_score: 0.9484 - val_loss: 0.3042 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2379 - acc: 0.9526 - precision: 0.9941 - recall: 0.9097 - f1_score: 0.9490 - val_loss: 0.3039 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2376 - acc: 0.9526 - precision: 0.9917 - recall: 0.9103 - f1_score: 0.9485 - val_loss: 0.3036 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2373 - acc: 0.9526 - precision: 0.9935 - recall: 0.9111 - f1_score: 0.9499 - val_loss: 0.3033 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9526 - precision: 0.9919 - recall: 0.9077 - f1_score: 0.9467 - val_loss: 0.3030 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2366 - acc: 0.9526 - precision: 0.9911 - recall: 0.9117 - f1_score: 0.9492 - val_loss: 0.3027 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2363 - acc: 0.9526 - precision: 0.9926 - recall: 0.9096 - f1_score: 0.9480 - val_loss: 0.3023 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9526 - precision: 0.9949 - recall: 0.9074 - f1_score: 0.9480 - val_loss: 0.3020 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2357 - acc: 0.9526 - precision: 0.9925 - recall: 0.9111 - f1_score: 0.9495 - val_loss: 0.3017 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9526 - precision: 0.9935 - recall: 0.9108 - f1_score: 0.9493 - val_loss: 0.3014 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9526 - precision: 0.9931 - recall: 0.9110 - f1_score: 0.9498 - val_loss: 0.3011 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2347 - acc: 0.9526 - precision: 0.9933 - recall: 0.9076 - f1_score: 0.9469 - val_loss: 0.3008 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9526 - precision: 0.9924 - recall: 0.9106 - f1_score: 0.9483 - val_loss: 0.3005 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9526 - precision: 0.9937 - recall: 0.9121 - f1_score: 0.9505 - val_loss: 0.3002 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2338 - acc: 0.9526 - precision: 0.9939 - recall: 0.9085 - f1_score: 0.9482 - val_loss: 0.2999 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2335 - acc: 0.9526 - precision: 0.9914 - recall: 0.9088 - f1_score: 0.9470 - val_loss: 0.2996 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9526 - precision: 0.9927 - recall: 0.9146 - f1_score: 0.9511 - val_loss: 0.2993 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2329 - acc: 0.9526 - precision: 0.9927 - recall: 0.9137 - f1_score: 0.9497 - val_loss: 0.2991 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9526 - precision: 0.9928 - recall: 0.9115 - f1_score: 0.9491 - val_loss: 0.2988 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 920/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9526 - precision: 0.9933 - recall: 0.9152 - f1_score: 0.9514 - val_loss: 0.2985 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9526 - precision: 0.9931 - recall: 0.9105 - f1_score: 0.9490 - val_loss: 0.2982 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2316 - acc: 0.9526 - precision: 0.9939 - recall: 0.9073 - f1_score: 0.9474 - val_loss: 0.2979 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2313 - acc: 0.9526 - precision: 0.9929 - recall: 0.9122 - f1_score: 0.9496 - val_loss: 0.2976 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9526 - precision: 0.9935 - recall: 0.9100 - f1_score: 0.9486 - val_loss: 0.2973 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9526 - precision: 0.9933 - recall: 0.9134 - f1_score: 0.9508 - val_loss: 0.2971 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2304 - acc: 0.9526 - precision: 0.9923 - recall: 0.9121 - f1_score: 0.9491 - val_loss: 0.2968 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2301 - acc: 0.9526 - precision: 0.9909 - recall: 0.9087 - f1_score: 0.9474 - val_loss: 0.2965 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2298 - acc: 0.9526 - precision: 0.9946 - recall: 0.9074 - f1_score: 0.9482 - val_loss: 0.2962 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2295 - acc: 0.9526 - precision: 0.9929 - recall: 0.9141 - f1_score: 0.9507 - val_loss: 0.2959 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2293 - acc: 0.9526 - precision: 0.9935 - recall: 0.9108 - f1_score: 0.9498 - val_loss: 0.2956 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2290 - acc: 0.9526 - precision: 0.9939 - recall: 0.9087 - f1_score: 0.9483 - val_loss: 0.2954 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2287 - acc: 0.9526 - precision: 0.9924 - recall: 0.9100 - f1_score: 0.9488 - val_loss: 0.2951 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2284 - acc: 0.9510 - precision: 0.9901 - recall: 0.9143 - f1_score: 0.9498 - val_loss: 0.2948 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2281 - acc: 0.9526 - precision: 0.9934 - recall: 0.9088 - f1_score: 0.9479 - val_loss: 0.2945 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2278 - acc: 0.9510 - precision: 0.9899 - recall: 0.9085 - f1_score: 0.9463 - val_loss: 0.2943 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2275 - acc: 0.9526 - precision: 0.9927 - recall: 0.9102 - f1_score: 0.9486 - val_loss: 0.2940 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2272 - acc: 0.9526 - precision: 0.9934 - recall: 0.9050 - f1_score: 0.9457 - val_loss: 0.2937 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2269 - acc: 0.9510 - precision: 0.9890 - recall: 0.9105 - f1_score: 0.9474 - val_loss: 0.2935 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2267 - acc: 0.9510 - precision: 0.9892 - recall: 0.9114 - f1_score: 0.9478 - val_loss: 0.2932 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2264 - acc: 0.9510 - precision: 0.9897 - recall: 0.9069 - f1_score: 0.9451 - val_loss: 0.2929 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2261 - acc: 0.9510 - precision: 0.9911 - recall: 0.9116 - f1_score: 0.9490 - val_loss: 0.2927 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2258 - acc: 0.9510 - precision: 0.9900 - recall: 0.9119 - f1_score: 0.9480 - val_loss: 0.2924 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2255 - acc: 0.9510 - precision: 0.9922 - recall: 0.9056 - f1_score: 0.9457 - val_loss: 0.2922 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2253 - acc: 0.9510 - precision: 0.9894 - recall: 0.9110 - f1_score: 0.9479 - val_loss: 0.2919 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2250 - acc: 0.9510 - precision: 0.9881 - recall: 0.9102 - f1_score: 0.9465 - val_loss: 0.2916 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2247 - acc: 0.9510 - precision: 0.9906 - recall: 0.9106 - f1_score: 0.9482 - val_loss: 0.2914 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2245 - acc: 0.9510 - precision: 0.9898 - recall: 0.9094 - f1_score: 0.9470 - val_loss: 0.2911 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2242 - acc: 0.9510 - precision: 0.9898 - recall: 0.9072 - f1_score: 0.9456 - val_loss: 0.2909 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2239 - acc: 0.9510 - precision: 0.9882 - recall: 0.9105 - f1_score: 0.9473 - val_loss: 0.2906 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2236 - acc: 0.9510 - precision: 0.9882 - recall: 0.9087 - f1_score: 0.9465 - val_loss: 0.2904 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2234 - acc: 0.9510 - precision: 0.9881 - recall: 0.9130 - f1_score: 0.9483 - val_loss: 0.2901 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2231 - acc: 0.9510 - precision: 0.9902 - recall: 0.9129 - f1_score: 0.9487 - val_loss: 0.2899 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2228 - acc: 0.9510 - precision: 0.9897 - recall: 0.9093 - f1_score: 0.9473 - val_loss: 0.2896 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2226 - acc: 0.9510 - precision: 0.9902 - recall: 0.9123 - f1_score: 0.9484 - val_loss: 0.2894 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2223 - acc: 0.9510 - precision: 0.9879 - recall: 0.9087 - f1_score: 0.9462 - val_loss: 0.2891 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2221 - acc: 0.9510 - precision: 0.9894 - recall: 0.9121 - f1_score: 0.9486 - val_loss: 0.2889 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2218 - acc: 0.9510 - precision: 0.9900 - recall: 0.9098 - f1_score: 0.9476 - val_loss: 0.2886 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2215 - acc: 0.9510 - precision: 0.9892 - recall: 0.9086 - f1_score: 0.9462 - val_loss: 0.2884 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2213 - acc: 0.9510 - precision: 0.9897 - recall: 0.9126 - f1_score: 0.9483 - val_loss: 0.2882 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2210 - acc: 0.9510 - precision: 0.9896 - recall: 0.9127 - f1_score: 0.9479 - val_loss: 0.2879 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2208 - acc: 0.9510 - precision: 0.9886 - recall: 0.9102 - f1_score: 0.9464 - val_loss: 0.2877 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2205 - acc: 0.9510 - precision: 0.9893 - recall: 0.9098 - f1_score: 0.9473 - val_loss: 0.2874 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2203 - acc: 0.9510 - precision: 0.9888 - recall: 0.9156 - f1_score: 0.9499 - val_loss: 0.2872 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2200 - acc: 0.9510 - precision: 0.9910 - recall: 0.9141 - f1_score: 0.9501 - val_loss: 0.2870 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2198 - acc: 0.9510 - precision: 0.9900 - recall: 0.9070 - f1_score: 0.9456 - val_loss: 0.2867 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2195 - acc: 0.9510 - precision: 0.9894 - recall: 0.9124 - f1_score: 0.9485 - val_loss: 0.2865 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2193 - acc: 0.9510 - precision: 0.9884 - recall: 0.9091 - f1_score: 0.9464 - val_loss: 0.2863 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2190 - acc: 0.9510 - precision: 0.9902 - recall: 0.9092 - f1_score: 0.9469 - val_loss: 0.2860 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2188 - acc: 0.9510 - precision: 0.9898 - recall: 0.9119 - f1_score: 0.9486 - val_loss: 0.2858 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2185 - acc: 0.9510 - precision: 0.9881 - recall: 0.9080 - f1_score: 0.9456 - val_loss: 0.2856 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2183 - acc: 0.9510 - precision: 0.9895 - recall: 0.9107 - f1_score: 0.9477 - val_loss: 0.2853 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2180 - acc: 0.9510 - precision: 0.9904 - recall: 0.9123 - f1_score: 0.9485 - val_loss: 0.2851 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2178 - acc: 0.9510 - precision: 0.9898 - recall: 0.9139 - f1_score: 0.9490 - val_loss: 0.2849 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2175 - acc: 0.9510 - precision: 0.9890 - recall: 0.9097 - f1_score: 0.9465 - val_loss: 0.2846 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2173 - acc: 0.9510 - precision: 0.9908 - recall: 0.9042 - f1_score: 0.9442 - val_loss: 0.2844 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2171 - acc: 0.9510 - precision: 0.9887 - recall: 0.9088 - f1_score: 0.9464 - val_loss: 0.2842 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2168 - acc: 0.9510 - precision: 0.9900 - recall: 0.9120 - f1_score: 0.9482 - val_loss: 0.2840 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2166 - acc: 0.9510 - precision: 0.9896 - recall: 0.9104 - f1_score: 0.9477 - val_loss: 0.2837 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2163 - acc: 0.9510 - precision: 0.9892 - recall: 0.9109 - f1_score: 0.9475 - val_loss: 0.2835 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2161 - acc: 0.9510 - precision: 0.9888 - recall: 0.9062 - f1_score: 0.9450 - val_loss: 0.2833 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2159 - acc: 0.9510 - precision: 0.9906 - recall: 0.9132 - f1_score: 0.9491 - val_loss: 0.2831 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2156 - acc: 0.9510 - precision: 0.9883 - recall: 0.9095 - f1_score: 0.9459 - val_loss: 0.2829 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2154 - acc: 0.9510 - precision: 0.9887 - recall: 0.9093 - f1_score: 0.9466 - val_loss: 0.2827 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 984/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2152 - acc: 0.9510 - precision: 0.9893 - recall: 0.9090 - f1_score: 0.9465 - val_loss: 0.2824 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2149 - acc: 0.9510 - precision: 0.9898 - recall: 0.9100 - f1_score: 0.9471 - val_loss: 0.2822 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2147 - acc: 0.9510 - precision: 0.9907 - recall: 0.9108 - f1_score: 0.9481 - val_loss: 0.2820 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2145 - acc: 0.9510 - precision: 0.9903 - recall: 0.9098 - f1_score: 0.9475 - val_loss: 0.2818 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2143 - acc: 0.9510 - precision: 0.9895 - recall: 0.9100 - f1_score: 0.9474 - val_loss: 0.2816 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2140 - acc: 0.9510 - precision: 0.9898 - recall: 0.9106 - f1_score: 0.9477 - val_loss: 0.2814 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2138 - acc: 0.9510 - precision: 0.9889 - recall: 0.9123 - f1_score: 0.9481 - val_loss: 0.2812 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2136 - acc: 0.9510 - precision: 0.9888 - recall: 0.9101 - f1_score: 0.9466 - val_loss: 0.2810 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2133 - acc: 0.9510 - precision: 0.9908 - recall: 0.9129 - f1_score: 0.9489 - val_loss: 0.2807 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2131 - acc: 0.9510 - precision: 0.9903 - recall: 0.9109 - f1_score: 0.9476 - val_loss: 0.2805 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2129 - acc: 0.9510 - precision: 0.9894 - recall: 0.9069 - f1_score: 0.9446 - val_loss: 0.2803 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2127 - acc: 0.9510 - precision: 0.9915 - recall: 0.9112 - f1_score: 0.9483 - val_loss: 0.2801 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2125 - acc: 0.9510 - precision: 0.9895 - recall: 0.9097 - f1_score: 0.9473 - val_loss: 0.2799 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2122 - acc: 0.9510 - precision: 0.9889 - recall: 0.9094 - f1_score: 0.9466 - val_loss: 0.2797 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2120 - acc: 0.9510 - precision: 0.9890 - recall: 0.9099 - f1_score: 0.9467 - val_loss: 0.2795 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2118 - acc: 0.9510 - precision: 0.9879 - recall: 0.9059 - f1_score: 0.9442 - val_loss: 0.2793 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2116 - acc: 0.9510 - precision: 0.9897 - recall: 0.9100 - f1_score: 0.9474 - val_loss: 0.2791 - val_acc: 0.9114 - val_precision: 0.9725 - val_recall: 0.8475 - val_f1_score: 0.9043\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9415 - acc: 0.5735 - precision: 0.5485 - recall: 0.9641 - f1_score: 0.6952 - val_loss: 5.9411 - val_acc: 0.5316 - val_precision: 0.4806 - val_recall: 1.0000 - val_f1_score: 0.6433\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8743 - acc: 0.5735 - precision: 0.5476 - recall: 0.9753 - f1_score: 0.6976 - val_loss: 5.8955 - val_acc: 0.5380 - val_precision: 0.4837 - val_recall: 1.0000 - val_f1_score: 0.6463\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8290 - acc: 0.5766 - precision: 0.5484 - recall: 0.9760 - f1_score: 0.6969 - val_loss: 5.8564 - val_acc: 0.5380 - val_precision: 0.4837 - val_recall: 1.0000 - val_f1_score: 0.6463\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7899 - acc: 0.5845 - precision: 0.5533 - recall: 0.9780 - f1_score: 0.7041 - val_loss: 5.8201 - val_acc: 0.5506 - val_precision: 0.4899 - val_recall: 1.0000 - val_f1_score: 0.6523\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7537 - acc: 0.5987 - precision: 0.5621 - recall: 0.9783 - f1_score: 0.7095 - val_loss: 5.7850 - val_acc: 0.5823 - val_precision: 0.5097 - val_recall: 1.0000 - val_f1_score: 0.6691\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7191 - acc: 0.6130 - precision: 0.5697 - recall: 0.9817 - f1_score: 0.7178 - val_loss: 5.7508 - val_acc: 0.6076 - val_precision: 0.5243 - val_recall: 1.0000 - val_f1_score: 0.6823\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6855 - acc: 0.6240 - precision: 0.5787 - recall: 0.9784 - f1_score: 0.7258 - val_loss: 5.7173 - val_acc: 0.6329 - val_precision: 0.5416 - val_recall: 1.0000 - val_f1_score: 0.6967\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6527 - acc: 0.6445 - precision: 0.5924 - recall: 0.9770 - f1_score: 0.7348 - val_loss: 5.6841 - val_acc: 0.6582 - val_precision: 0.5610 - val_recall: 1.0000 - val_f1_score: 0.7121\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6205 - acc: 0.6651 - precision: 0.6084 - recall: 0.9736 - f1_score: 0.7478 - val_loss: 5.6515 - val_acc: 0.6709 - val_precision: 0.5716 - val_recall: 1.0000 - val_f1_score: 0.7202\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5887 - acc: 0.6840 - precision: 0.6223 - recall: 0.9755 - f1_score: 0.7571 - val_loss: 5.6192 - val_acc: 0.6962 - val_precision: 0.5872 - val_recall: 1.0000 - val_f1_score: 0.7342\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5574 - acc: 0.7046 - precision: 0.6419 - recall: 0.9739 - f1_score: 0.7708 - val_loss: 5.5872 - val_acc: 0.7025 - val_precision: 0.5922 - val_recall: 1.0000 - val_f1_score: 0.7384\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5265 - acc: 0.7172 - precision: 0.6474 - recall: 0.9747 - f1_score: 0.7761 - val_loss: 5.5556 - val_acc: 0.7215 - val_precision: 0.6090 - val_recall: 1.0000 - val_f1_score: 0.7511\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4959 - acc: 0.7346 - precision: 0.6649 - recall: 0.9763 - f1_score: 0.7885 - val_loss: 5.5242 - val_acc: 0.7468 - val_precision: 0.6328 - val_recall: 1.0000 - val_f1_score: 0.7690\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4655 - acc: 0.7472 - precision: 0.6762 - recall: 0.9710 - f1_score: 0.7929 - val_loss: 5.4932 - val_acc: 0.7658 - val_precision: 0.6501 - val_recall: 1.0000 - val_f1_score: 0.7824\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4356 - acc: 0.7741 - precision: 0.7012 - recall: 0.9711 - f1_score: 0.8132 - val_loss: 5.4624 - val_acc: 0.7785 - val_precision: 0.6623 - val_recall: 1.0000 - val_f1_score: 0.7915\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.4059 - acc: 0.7883 - precision: 0.7158 - recall: 0.9733 - f1_score: 0.8230 - val_loss: 5.4319 - val_acc: 0.7911 - val_precision: 0.6767 - val_recall: 1.0000 - val_f1_score: 0.8014\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3764 - acc: 0.8199 - precision: 0.7478 - recall: 0.9738 - f1_score: 0.8422 - val_loss: 5.4017 - val_acc: 0.8038 - val_precision: 0.6921 - val_recall: 1.0000 - val_f1_score: 0.8117\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3473 - acc: 0.8262 - precision: 0.7585 - recall: 0.9606 - f1_score: 0.8432 - val_loss: 5.3717 - val_acc: 0.8291 - val_precision: 0.7177 - val_recall: 1.0000 - val_f1_score: 0.8300\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3183 - acc: 0.8420 - precision: 0.7833 - recall: 0.9654 - f1_score: 0.8636 - val_loss: 5.3420 - val_acc: 0.8481 - val_precision: 0.7446 - val_recall: 1.0000 - val_f1_score: 0.8472\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2897 - acc: 0.8499 - precision: 0.7896 - recall: 0.9660 - f1_score: 0.8660 - val_loss: 5.3125 - val_acc: 0.8544 - val_precision: 0.7546 - val_recall: 1.0000 - val_f1_score: 0.8536\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2612 - acc: 0.8657 - precision: 0.8185 - recall: 0.9511 - f1_score: 0.8785 - val_loss: 5.2832 - val_acc: 0.8608 - val_precision: 0.7617 - val_recall: 1.0000 - val_f1_score: 0.8586\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2330 - acc: 0.8768 - precision: 0.8368 - recall: 0.9497 - f1_score: 0.8883 - val_loss: 5.2542 - val_acc: 0.8797 - val_precision: 0.7778 - val_recall: 1.0000 - val_f1_score: 0.8723\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2050 - acc: 0.8878 - precision: 0.8497 - recall: 0.9456 - f1_score: 0.8926 - val_loss: 5.2254 - val_acc: 0.8987 - val_precision: 0.8146 - val_recall: 0.9833 - val_f1_score: 0.8872\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1773 - acc: 0.8973 - precision: 0.8617 - recall: 0.9486 - f1_score: 0.9012 - val_loss: 5.1968 - val_acc: 0.9051 - val_precision: 0.8234 - val_recall: 0.9833 - val_f1_score: 0.8928\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1497 - acc: 0.8973 - precision: 0.8649 - recall: 0.9455 - f1_score: 0.9024 - val_loss: 5.1686 - val_acc: 0.9114 - val_precision: 0.8328 - val_recall: 0.9833 - val_f1_score: 0.8987\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1224 - acc: 0.9021 - precision: 0.8741 - recall: 0.9382 - f1_score: 0.9040 - val_loss: 5.1405 - val_acc: 0.9177 - val_precision: 0.8441 - val_recall: 0.9833 - val_f1_score: 0.9047\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0953 - acc: 0.9084 - precision: 0.8858 - recall: 0.9402 - f1_score: 0.9113 - val_loss: 5.1126 - val_acc: 0.9241 - val_precision: 0.8543 - val_recall: 0.9833 - val_f1_score: 0.9108\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0683 - acc: 0.9100 - precision: 0.8933 - recall: 0.9360 - f1_score: 0.9121 - val_loss: 5.0849 - val_acc: 0.9177 - val_precision: 0.8522 - val_recall: 0.9683 - val_f1_score: 0.9032\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0416 - acc: 0.9147 - precision: 0.9012 - recall: 0.9311 - f1_score: 0.9147 - val_loss: 5.0574 - val_acc: 0.9304 - val_precision: 0.8760 - val_recall: 0.9683 - val_f1_score: 0.9165\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0150 - acc: 0.9179 - precision: 0.9176 - recall: 0.9320 - f1_score: 0.9232 - val_loss: 5.0302 - val_acc: 0.9304 - val_precision: 0.8760 - val_recall: 0.9683 - val_f1_score: 0.9165\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9887 - acc: 0.9194 - precision: 0.9129 - recall: 0.9273 - f1_score: 0.9187 - val_loss: 5.0031 - val_acc: 0.9367 - val_precision: 0.8885 - val_recall: 0.9683 - val_f1_score: 0.9232\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9625 - acc: 0.9210 - precision: 0.9207 - recall: 0.9333 - f1_score: 0.9250 - val_loss: 4.9763 - val_acc: 0.9304 - val_precision: 0.8863 - val_recall: 0.9516 - val_f1_score: 0.9143\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9365 - acc: 0.9258 - precision: 0.9245 - recall: 0.9276 - f1_score: 0.9253 - val_loss: 4.9497 - val_acc: 0.9367 - val_precision: 0.9004 - val_recall: 0.9516 - val_f1_score: 0.9215\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9107 - acc: 0.9273 - precision: 0.9299 - recall: 0.9284 - f1_score: 0.9280 - val_loss: 4.9232 - val_acc: 0.9367 - val_precision: 0.9004 - val_recall: 0.9516 - val_f1_score: 0.9215\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8851 - acc: 0.9321 - precision: 0.9399 - recall: 0.9277 - f1_score: 0.9327 - val_loss: 4.8970 - val_acc: 0.9367 - val_precision: 0.9004 - val_recall: 0.9516 - val_f1_score: 0.9215\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8597 - acc: 0.9336 - precision: 0.9424 - recall: 0.9282 - f1_score: 0.9338 - val_loss: 4.8709 - val_acc: 0.9367 - val_precision: 0.9004 - val_recall: 0.9516 - val_f1_score: 0.9215\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8344 - acc: 0.9336 - precision: 0.9453 - recall: 0.9270 - f1_score: 0.9352 - val_loss: 4.8451 - val_acc: 0.9430 - val_precision: 0.9141 - val_recall: 0.9516 - val_f1_score: 0.9285\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8094 - acc: 0.9321 - precision: 0.9450 - recall: 0.9182 - f1_score: 0.9305 - val_loss: 4.8195 - val_acc: 0.9430 - val_precision: 0.9141 - val_recall: 0.9516 - val_f1_score: 0.9285\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7845 - acc: 0.9336 - precision: 0.9473 - recall: 0.9207 - f1_score: 0.9323 - val_loss: 4.7939 - val_acc: 0.9494 - val_precision: 0.9299 - val_recall: 0.9516 - val_f1_score: 0.9362\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7597 - acc: 0.9368 - precision: 0.9546 - recall: 0.9206 - f1_score: 0.9352 - val_loss: 4.7687 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7351 - acc: 0.9368 - precision: 0.9507 - recall: 0.9172 - f1_score: 0.9322 - val_loss: 4.7435 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7107 - acc: 0.9352 - precision: 0.9566 - recall: 0.9157 - f1_score: 0.9350 - val_loss: 4.7186 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6864 - acc: 0.9352 - precision: 0.9599 - recall: 0.9148 - f1_score: 0.9346 - val_loss: 4.6939 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6623 - acc: 0.9336 - precision: 0.9563 - recall: 0.9117 - f1_score: 0.9317 - val_loss: 4.6692 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6384 - acc: 0.9336 - precision: 0.9572 - recall: 0.9104 - f1_score: 0.9327 - val_loss: 4.6447 - val_acc: 0.9430 - val_precision: 0.9288 - val_recall: 0.9350 - val_f1_score: 0.9267\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6145 - acc: 0.9321 - precision: 0.9614 - recall: 0.9081 - f1_score: 0.9329 - val_loss: 4.6204 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5909 - acc: 0.9336 - precision: 0.9628 - recall: 0.9076 - f1_score: 0.9333 - val_loss: 4.5963 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.5674 - acc: 0.9352 - precision: 0.9647 - recall: 0.9099 - f1_score: 0.9359 - val_loss: 4.5723 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5441 - acc: 0.9352 - precision: 0.9640 - recall: 0.9111 - f1_score: 0.9358 - val_loss: 4.5485 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5209 - acc: 0.9352 - precision: 0.9635 - recall: 0.9052 - f1_score: 0.9331 - val_loss: 4.5249 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4979 - acc: 0.9352 - precision: 0.9638 - recall: 0.9053 - f1_score: 0.9330 - val_loss: 4.5014 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4749 - acc: 0.9336 - precision: 0.9592 - recall: 0.9025 - f1_score: 0.9284 - val_loss: 4.4780 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4522 - acc: 0.9352 - precision: 0.9650 - recall: 0.9024 - f1_score: 0.9316 - val_loss: 4.4549 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4295 - acc: 0.9336 - precision: 0.9676 - recall: 0.9018 - f1_score: 0.9324 - val_loss: 4.4319 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4071 - acc: 0.9336 - precision: 0.9666 - recall: 0.9031 - f1_score: 0.9333 - val_loss: 4.4090 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3847 - acc: 0.9336 - precision: 0.9685 - recall: 0.8995 - f1_score: 0.9314 - val_loss: 4.3862 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3625 - acc: 0.9352 - precision: 0.9698 - recall: 0.9034 - f1_score: 0.9346 - val_loss: 4.3636 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3403 - acc: 0.9368 - precision: 0.9759 - recall: 0.9005 - f1_score: 0.9349 - val_loss: 4.3412 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3184 - acc: 0.9368 - precision: 0.9755 - recall: 0.9003 - f1_score: 0.9350 - val_loss: 4.3188 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2966 - acc: 0.9352 - precision: 0.9725 - recall: 0.8976 - f1_score: 0.9324 - val_loss: 4.2967 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2750 - acc: 0.9352 - precision: 0.9734 - recall: 0.8985 - f1_score: 0.9323 - val_loss: 4.2746 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2534 - acc: 0.9352 - precision: 0.9739 - recall: 0.8993 - f1_score: 0.9344 - val_loss: 4.2527 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2320 - acc: 0.9352 - precision: 0.9732 - recall: 0.8975 - f1_score: 0.9328 - val_loss: 4.2309 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2107 - acc: 0.9336 - precision: 0.9710 - recall: 0.8937 - f1_score: 0.9289 - val_loss: 4.2093 - val_acc: 0.9430 - val_precision: 0.9474 - val_recall: 0.9183 - val_f1_score: 0.9246\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1895 - acc: 0.9336 - precision: 0.9747 - recall: 0.8968 - f1_score: 0.9327 - val_loss: 4.1878 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1685 - acc: 0.9352 - precision: 0.9772 - recall: 0.8968 - f1_score: 0.9339 - val_loss: 4.1664 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1475 - acc: 0.9368 - precision: 0.9796 - recall: 0.8931 - f1_score: 0.9332 - val_loss: 4.1452 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1267 - acc: 0.9368 - precision: 0.9794 - recall: 0.8958 - f1_score: 0.9351 - val_loss: 4.1241 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1061 - acc: 0.9368 - precision: 0.9795 - recall: 0.8954 - f1_score: 0.9351 - val_loss: 4.1032 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0855 - acc: 0.9352 - precision: 0.9771 - recall: 0.8882 - f1_score: 0.9290 - val_loss: 4.0823 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0651 - acc: 0.9352 - precision: 0.9810 - recall: 0.8953 - f1_score: 0.9327 - val_loss: 4.0616 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0448 - acc: 0.9352 - precision: 0.9808 - recall: 0.8884 - f1_score: 0.9311 - val_loss: 4.0410 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0246 - acc: 0.9352 - precision: 0.9798 - recall: 0.8901 - f1_score: 0.9314 - val_loss: 4.0205 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0045 - acc: 0.9352 - precision: 0.9789 - recall: 0.8920 - f1_score: 0.9328 - val_loss: 4.0002 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9845 - acc: 0.9368 - precision: 0.9835 - recall: 0.8870 - f1_score: 0.9311 - val_loss: 3.9800 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9647 - acc: 0.9368 - precision: 0.9846 - recall: 0.8899 - f1_score: 0.9333 - val_loss: 3.9600 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9449 - acc: 0.9352 - precision: 0.9830 - recall: 0.8908 - f1_score: 0.9337 - val_loss: 3.9400 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9253 - acc: 0.9352 - precision: 0.9826 - recall: 0.8889 - f1_score: 0.9317 - val_loss: 3.9201 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9058 - acc: 0.9352 - precision: 0.9834 - recall: 0.8877 - f1_score: 0.9317 - val_loss: 3.9004 - val_acc: 0.9494 - val_precision: 0.9559 - val_recall: 0.9183 - val_f1_score: 0.9314\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.8864 - acc: 0.9352 - precision: 0.9817 - recall: 0.8887 - f1_score: 0.9325 - val_loss: 3.8807 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8671 - acc: 0.9352 - precision: 0.9810 - recall: 0.8911 - f1_score: 0.9331 - val_loss: 3.8612 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8479 - acc: 0.9352 - precision: 0.9812 - recall: 0.8842 - f1_score: 0.9292 - val_loss: 3.8418 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8289 - acc: 0.9352 - precision: 0.9823 - recall: 0.8912 - f1_score: 0.9329 - val_loss: 3.8226 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8099 - acc: 0.9352 - precision: 0.9827 - recall: 0.8880 - f1_score: 0.9320 - val_loss: 3.8034 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7911 - acc: 0.9352 - precision: 0.9850 - recall: 0.8887 - f1_score: 0.9327 - val_loss: 3.7844 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7723 - acc: 0.9352 - precision: 0.9827 - recall: 0.8903 - f1_score: 0.9320 - val_loss: 3.7654 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7537 - acc: 0.9352 - precision: 0.9836 - recall: 0.8901 - f1_score: 0.9329 - val_loss: 3.7466 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7351 - acc: 0.9352 - precision: 0.9821 - recall: 0.8850 - f1_score: 0.9302 - val_loss: 3.7279 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7167 - acc: 0.9336 - precision: 0.9820 - recall: 0.8886 - f1_score: 0.9314 - val_loss: 3.7093 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6984 - acc: 0.9336 - precision: 0.9848 - recall: 0.8854 - f1_score: 0.9310 - val_loss: 3.6907 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6801 - acc: 0.9336 - precision: 0.9828 - recall: 0.8836 - f1_score: 0.9290 - val_loss: 3.6724 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6620 - acc: 0.9336 - precision: 0.9816 - recall: 0.8863 - f1_score: 0.9306 - val_loss: 3.6541 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6440 - acc: 0.9336 - precision: 0.9836 - recall: 0.8849 - f1_score: 0.9304 - val_loss: 3.6359 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6261 - acc: 0.9336 - precision: 0.9829 - recall: 0.8882 - f1_score: 0.9309 - val_loss: 3.6178 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6083 - acc: 0.9336 - precision: 0.9833 - recall: 0.8889 - f1_score: 0.9321 - val_loss: 3.5998 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5905 - acc: 0.9336 - precision: 0.9819 - recall: 0.8840 - f1_score: 0.9292 - val_loss: 3.5820 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5729 - acc: 0.9336 - precision: 0.9837 - recall: 0.8826 - f1_score: 0.9298 - val_loss: 3.5642 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5554 - acc: 0.9336 - precision: 0.9803 - recall: 0.8832 - f1_score: 0.9285 - val_loss: 3.5465 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5380 - acc: 0.9336 - precision: 0.9834 - recall: 0.8857 - f1_score: 0.9314 - val_loss: 3.5290 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5206 - acc: 0.9336 - precision: 0.9805 - recall: 0.8812 - f1_score: 0.9271 - val_loss: 3.5115 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5034 - acc: 0.9336 - precision: 0.9814 - recall: 0.8872 - f1_score: 0.9310 - val_loss: 3.4941 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4862 - acc: 0.9336 - precision: 0.9838 - recall: 0.8850 - f1_score: 0.9309 - val_loss: 3.4768 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4692 - acc: 0.9336 - precision: 0.9842 - recall: 0.8861 - f1_score: 0.9310 - val_loss: 3.4596 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4522 - acc: 0.9336 - precision: 0.9812 - recall: 0.8835 - f1_score: 0.9285 - val_loss: 3.4425 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4353 - acc: 0.9336 - precision: 0.9836 - recall: 0.8829 - f1_score: 0.9296 - val_loss: 3.4255 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4186 - acc: 0.9336 - precision: 0.9830 - recall: 0.8911 - f1_score: 0.9331 - val_loss: 3.4086 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4019 - acc: 0.9336 - precision: 0.9830 - recall: 0.8882 - f1_score: 0.9316 - val_loss: 3.3918 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3853 - acc: 0.9336 - precision: 0.9847 - recall: 0.8800 - f1_score: 0.9281 - val_loss: 3.3751 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3688 - acc: 0.9336 - precision: 0.9819 - recall: 0.8855 - f1_score: 0.9302 - val_loss: 3.3584 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3524 - acc: 0.9336 - precision: 0.9840 - recall: 0.8880 - f1_score: 0.9320 - val_loss: 3.3419 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3360 - acc: 0.9336 - precision: 0.9815 - recall: 0.8854 - f1_score: 0.9305 - val_loss: 3.3255 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.3198 - acc: 0.9336 - precision: 0.9826 - recall: 0.8848 - f1_score: 0.9293 - val_loss: 3.3091 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3037 - acc: 0.9336 - precision: 0.9799 - recall: 0.8859 - f1_score: 0.9296 - val_loss: 3.2929 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2876 - acc: 0.9336 - precision: 0.9836 - recall: 0.8835 - f1_score: 0.9294 - val_loss: 3.2767 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2716 - acc: 0.9336 - precision: 0.9836 - recall: 0.8844 - f1_score: 0.9307 - val_loss: 3.2607 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2557 - acc: 0.9336 - precision: 0.9818 - recall: 0.8831 - f1_score: 0.9290 - val_loss: 3.2447 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2399 - acc: 0.9336 - precision: 0.9839 - recall: 0.8884 - f1_score: 0.9328 - val_loss: 3.2288 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2242 - acc: 0.9336 - precision: 0.9830 - recall: 0.8856 - f1_score: 0.9300 - val_loss: 3.2130 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2086 - acc: 0.9336 - precision: 0.9835 - recall: 0.8863 - f1_score: 0.9317 - val_loss: 3.1973 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1931 - acc: 0.9336 - precision: 0.9835 - recall: 0.8872 - f1_score: 0.9318 - val_loss: 3.1817 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1776 - acc: 0.9336 - precision: 0.9832 - recall: 0.8826 - f1_score: 0.9283 - val_loss: 3.1661 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1622 - acc: 0.9336 - precision: 0.9851 - recall: 0.8871 - f1_score: 0.9323 - val_loss: 3.1507 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1470 - acc: 0.9336 - precision: 0.9851 - recall: 0.8837 - f1_score: 0.9303 - val_loss: 3.1353 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1317 - acc: 0.9336 - precision: 0.9813 - recall: 0.8874 - f1_score: 0.9311 - val_loss: 3.1200 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1166 - acc: 0.9336 - precision: 0.9839 - recall: 0.8850 - f1_score: 0.9308 - val_loss: 3.1048 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1016 - acc: 0.9336 - precision: 0.9823 - recall: 0.8837 - f1_score: 0.9296 - val_loss: 3.0897 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0866 - acc: 0.9336 - precision: 0.9828 - recall: 0.8873 - f1_score: 0.9320 - val_loss: 3.0747 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0717 - acc: 0.9336 - precision: 0.9828 - recall: 0.8868 - f1_score: 0.9316 - val_loss: 3.0597 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0569 - acc: 0.9336 - precision: 0.9832 - recall: 0.8864 - f1_score: 0.9315 - val_loss: 3.0448 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0422 - acc: 0.9336 - precision: 0.9823 - recall: 0.8891 - f1_score: 0.9316 - val_loss: 3.0300 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0276 - acc: 0.9336 - precision: 0.9831 - recall: 0.8819 - f1_score: 0.9282 - val_loss: 3.0153 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0130 - acc: 0.9336 - precision: 0.9835 - recall: 0.8869 - f1_score: 0.9316 - val_loss: 3.0006 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9985 - acc: 0.9336 - precision: 0.9823 - recall: 0.8856 - f1_score: 0.9277 - val_loss: 2.9861 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9841 - acc: 0.9336 - precision: 0.9823 - recall: 0.8854 - f1_score: 0.9297 - val_loss: 2.9716 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9697 - acc: 0.9336 - precision: 0.9838 - recall: 0.8871 - f1_score: 0.9313 - val_loss: 2.9572 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9555 - acc: 0.9336 - precision: 0.9811 - recall: 0.8838 - f1_score: 0.9294 - val_loss: 2.9429 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9413 - acc: 0.9336 - precision: 0.9832 - recall: 0.8857 - f1_score: 0.9312 - val_loss: 2.9286 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9272 - acc: 0.9336 - precision: 0.9833 - recall: 0.8847 - f1_score: 0.9306 - val_loss: 2.9145 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9132 - acc: 0.9336 - precision: 0.9824 - recall: 0.8872 - f1_score: 0.9310 - val_loss: 2.9004 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8992 - acc: 0.9336 - precision: 0.9819 - recall: 0.8854 - f1_score: 0.9304 - val_loss: 2.8863 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8853 - acc: 0.9336 - precision: 0.9830 - recall: 0.8870 - f1_score: 0.9316 - val_loss: 2.8724 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8715 - acc: 0.9336 - precision: 0.9827 - recall: 0.8887 - f1_score: 0.9325 - val_loss: 2.8585 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8578 - acc: 0.9336 - precision: 0.9820 - recall: 0.8869 - f1_score: 0.9314 - val_loss: 2.8448 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.8441 - acc: 0.9336 - precision: 0.9818 - recall: 0.8858 - f1_score: 0.9305 - val_loss: 2.8310 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8305 - acc: 0.9336 - precision: 0.9845 - recall: 0.8878 - f1_score: 0.9327 - val_loss: 2.8174 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8170 - acc: 0.9336 - precision: 0.9824 - recall: 0.8854 - f1_score: 0.9305 - val_loss: 2.8038 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8036 - acc: 0.9336 - precision: 0.9842 - recall: 0.8869 - f1_score: 0.9320 - val_loss: 2.7904 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7902 - acc: 0.9336 - precision: 0.9834 - recall: 0.8870 - f1_score: 0.9315 - val_loss: 2.7769 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7769 - acc: 0.9336 - precision: 0.9827 - recall: 0.8857 - f1_score: 0.9300 - val_loss: 2.7636 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7636 - acc: 0.9336 - precision: 0.9844 - recall: 0.8859 - f1_score: 0.9315 - val_loss: 2.7503 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7505 - acc: 0.9336 - precision: 0.9818 - recall: 0.8874 - f1_score: 0.9311 - val_loss: 2.7371 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7374 - acc: 0.9336 - precision: 0.9826 - recall: 0.8871 - f1_score: 0.9298 - val_loss: 2.7240 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7244 - acc: 0.9336 - precision: 0.9832 - recall: 0.8866 - f1_score: 0.9312 - val_loss: 2.7109 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7114 - acc: 0.9336 - precision: 0.9835 - recall: 0.8862 - f1_score: 0.9314 - val_loss: 2.6979 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6985 - acc: 0.9336 - precision: 0.9845 - recall: 0.8848 - f1_score: 0.9315 - val_loss: 2.6850 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6857 - acc: 0.9336 - precision: 0.9814 - recall: 0.8820 - f1_score: 0.9276 - val_loss: 2.6721 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6730 - acc: 0.9336 - precision: 0.9842 - recall: 0.8856 - f1_score: 0.9308 - val_loss: 2.6593 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6603 - acc: 0.9336 - precision: 0.9838 - recall: 0.8849 - f1_score: 0.9305 - val_loss: 2.6466 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6477 - acc: 0.9336 - precision: 0.9815 - recall: 0.8893 - f1_score: 0.9314 - val_loss: 2.6340 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6351 - acc: 0.9336 - precision: 0.9830 - recall: 0.8882 - f1_score: 0.9324 - val_loss: 2.6214 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6226 - acc: 0.9336 - precision: 0.9829 - recall: 0.8888 - f1_score: 0.9322 - val_loss: 2.6089 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6102 - acc: 0.9336 - precision: 0.9832 - recall: 0.8878 - f1_score: 0.9321 - val_loss: 2.5964 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5979 - acc: 0.9336 - precision: 0.9843 - recall: 0.8884 - f1_score: 0.9319 - val_loss: 2.5840 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5856 - acc: 0.9336 - precision: 0.9829 - recall: 0.8871 - f1_score: 0.9318 - val_loss: 2.5717 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5734 - acc: 0.9336 - precision: 0.9823 - recall: 0.8869 - f1_score: 0.9319 - val_loss: 2.5595 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5612 - acc: 0.9336 - precision: 0.9832 - recall: 0.8847 - f1_score: 0.9305 - val_loss: 2.5473 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5491 - acc: 0.9336 - precision: 0.9824 - recall: 0.8880 - f1_score: 0.9318 - val_loss: 2.5352 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5371 - acc: 0.9336 - precision: 0.9829 - recall: 0.8868 - f1_score: 0.9311 - val_loss: 2.5231 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5251 - acc: 0.9336 - precision: 0.9831 - recall: 0.8855 - f1_score: 0.9314 - val_loss: 2.5111 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5132 - acc: 0.9336 - precision: 0.9823 - recall: 0.8849 - f1_score: 0.9300 - val_loss: 2.4992 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5014 - acc: 0.9336 - precision: 0.9850 - recall: 0.8905 - f1_score: 0.9334 - val_loss: 2.4873 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4896 - acc: 0.9336 - precision: 0.9806 - recall: 0.8828 - f1_score: 0.9280 - val_loss: 2.4755 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4779 - acc: 0.9336 - precision: 0.9827 - recall: 0.8848 - f1_score: 0.9298 - val_loss: 2.4638 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4663 - acc: 0.9336 - precision: 0.9817 - recall: 0.8887 - f1_score: 0.9317 - val_loss: 2.4521 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4547 - acc: 0.9336 - precision: 0.9810 - recall: 0.8831 - f1_score: 0.9284 - val_loss: 2.4405 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 176/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.4431 - acc: 0.9336 - precision: 0.9828 - recall: 0.8851 - f1_score: 0.9309 - val_loss: 2.4290 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4317 - acc: 0.9336 - precision: 0.9832 - recall: 0.8869 - f1_score: 0.9315 - val_loss: 2.4174 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4202 - acc: 0.9336 - precision: 0.9832 - recall: 0.8896 - f1_score: 0.9333 - val_loss: 2.4060 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4089 - acc: 0.9336 - precision: 0.9849 - recall: 0.8849 - f1_score: 0.9304 - val_loss: 2.3947 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3976 - acc: 0.9336 - precision: 0.9819 - recall: 0.8895 - f1_score: 0.9322 - val_loss: 2.3834 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3864 - acc: 0.9336 - precision: 0.9827 - recall: 0.8854 - f1_score: 0.9301 - val_loss: 2.3721 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3752 - acc: 0.9336 - precision: 0.9827 - recall: 0.8841 - f1_score: 0.9300 - val_loss: 2.3609 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3641 - acc: 0.9336 - precision: 0.9853 - recall: 0.8868 - f1_score: 0.9313 - val_loss: 2.3498 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3530 - acc: 0.9336 - precision: 0.9834 - recall: 0.8830 - f1_score: 0.9298 - val_loss: 2.3387 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3420 - acc: 0.9336 - precision: 0.9847 - recall: 0.8885 - f1_score: 0.9332 - val_loss: 2.3277 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3311 - acc: 0.9336 - precision: 0.9843 - recall: 0.8862 - f1_score: 0.9323 - val_loss: 2.3168 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3202 - acc: 0.9336 - precision: 0.9824 - recall: 0.8896 - f1_score: 0.9322 - val_loss: 2.3059 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3094 - acc: 0.9336 - precision: 0.9845 - recall: 0.8895 - f1_score: 0.9333 - val_loss: 2.2950 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2986 - acc: 0.9336 - precision: 0.9811 - recall: 0.8834 - f1_score: 0.9289 - val_loss: 2.2843 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2879 - acc: 0.9336 - precision: 0.9823 - recall: 0.8857 - f1_score: 0.9303 - val_loss: 2.2735 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2773 - acc: 0.9336 - precision: 0.9841 - recall: 0.8864 - f1_score: 0.9310 - val_loss: 2.2629 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2667 - acc: 0.9336 - precision: 0.9834 - recall: 0.8896 - f1_score: 0.9327 - val_loss: 2.2522 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2561 - acc: 0.9336 - precision: 0.9842 - recall: 0.8876 - f1_score: 0.9321 - val_loss: 2.2417 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2457 - acc: 0.9336 - precision: 0.9829 - recall: 0.8890 - f1_score: 0.9323 - val_loss: 2.2312 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2352 - acc: 0.9336 - precision: 0.9832 - recall: 0.8861 - f1_score: 0.9311 - val_loss: 2.2207 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2248 - acc: 0.9336 - precision: 0.9819 - recall: 0.8856 - f1_score: 0.9293 - val_loss: 2.2103 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2145 - acc: 0.9336 - precision: 0.9833 - recall: 0.8828 - f1_score: 0.9286 - val_loss: 2.2000 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2042 - acc: 0.9336 - precision: 0.9821 - recall: 0.8867 - f1_score: 0.9310 - val_loss: 2.1897 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1940 - acc: 0.9336 - precision: 0.9817 - recall: 0.8885 - f1_score: 0.9311 - val_loss: 2.1795 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1839 - acc: 0.9336 - precision: 0.9826 - recall: 0.8893 - f1_score: 0.9323 - val_loss: 2.1693 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1738 - acc: 0.9336 - precision: 0.9832 - recall: 0.8867 - f1_score: 0.9304 - val_loss: 2.1592 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1637 - acc: 0.9336 - precision: 0.9835 - recall: 0.8848 - f1_score: 0.9302 - val_loss: 2.1491 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1537 - acc: 0.9352 - precision: 0.9865 - recall: 0.8865 - f1_score: 0.9334 - val_loss: 2.1391 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1437 - acc: 0.9352 - precision: 0.9873 - recall: 0.8828 - f1_score: 0.9297 - val_loss: 2.1292 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1339 - acc: 0.9352 - precision: 0.9853 - recall: 0.8861 - f1_score: 0.9307 - val_loss: 2.1193 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1240 - acc: 0.9368 - precision: 0.9853 - recall: 0.8859 - f1_score: 0.9321 - val_loss: 2.1094 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1142 - acc: 0.9368 - precision: 0.9854 - recall: 0.8900 - f1_score: 0.9348 - val_loss: 2.0996 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 208/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.1045 - acc: 0.9368 - precision: 0.9872 - recall: 0.8914 - f1_score: 0.9362 - val_loss: 2.0898 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0948 - acc: 0.9368 - precision: 0.9873 - recall: 0.8898 - f1_score: 0.9350 - val_loss: 2.0802 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0851 - acc: 0.9368 - precision: 0.9868 - recall: 0.8865 - f1_score: 0.9330 - val_loss: 2.0705 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0755 - acc: 0.9368 - precision: 0.9857 - recall: 0.8910 - f1_score: 0.9352 - val_loss: 2.0609 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0660 - acc: 0.9384 - precision: 0.9899 - recall: 0.8874 - f1_score: 0.9345 - val_loss: 2.0513 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0565 - acc: 0.9368 - precision: 0.9863 - recall: 0.8927 - f1_score: 0.9363 - val_loss: 2.0418 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0470 - acc: 0.9384 - precision: 0.9894 - recall: 0.8882 - f1_score: 0.9358 - val_loss: 2.0324 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0376 - acc: 0.9384 - precision: 0.9878 - recall: 0.8896 - f1_score: 0.9348 - val_loss: 2.0230 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0283 - acc: 0.9400 - precision: 0.9933 - recall: 0.8944 - f1_score: 0.9405 - val_loss: 2.0136 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0190 - acc: 0.9400 - precision: 0.9935 - recall: 0.8892 - f1_score: 0.9373 - val_loss: 2.0043 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0098 - acc: 0.9400 - precision: 0.9931 - recall: 0.8894 - f1_score: 0.9376 - val_loss: 1.9951 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0005 - acc: 0.9400 - precision: 0.9920 - recall: 0.8849 - f1_score: 0.9341 - val_loss: 1.9859 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9914 - acc: 0.9400 - precision: 0.9929 - recall: 0.8919 - f1_score: 0.9385 - val_loss: 1.9767 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9823 - acc: 0.9400 - precision: 0.9926 - recall: 0.8891 - f1_score: 0.9363 - val_loss: 1.9676 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9732 - acc: 0.9400 - precision: 0.9930 - recall: 0.8940 - f1_score: 0.9400 - val_loss: 1.9586 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9642 - acc: 0.9400 - precision: 0.9933 - recall: 0.8921 - f1_score: 0.9391 - val_loss: 1.9496 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9553 - acc: 0.9400 - precision: 0.9919 - recall: 0.8892 - f1_score: 0.9368 - val_loss: 1.9406 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9463 - acc: 0.9400 - precision: 0.9930 - recall: 0.8896 - f1_score: 0.9380 - val_loss: 1.9317 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9375 - acc: 0.9400 - precision: 0.9926 - recall: 0.8886 - f1_score: 0.9373 - val_loss: 1.9228 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9287 - acc: 0.9400 - precision: 0.9935 - recall: 0.8895 - f1_score: 0.9380 - val_loss: 1.9140 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9199 - acc: 0.9400 - precision: 0.9920 - recall: 0.8851 - f1_score: 0.9346 - val_loss: 1.9052 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9111 - acc: 0.9400 - precision: 0.9941 - recall: 0.8898 - f1_score: 0.9388 - val_loss: 1.8965 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9024 - acc: 0.9400 - precision: 0.9933 - recall: 0.8892 - f1_score: 0.9371 - val_loss: 1.8878 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8938 - acc: 0.9400 - precision: 0.9942 - recall: 0.8897 - f1_score: 0.9377 - val_loss: 1.8791 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8852 - acc: 0.9400 - precision: 0.9928 - recall: 0.8900 - f1_score: 0.9372 - val_loss: 1.8705 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8767 - acc: 0.9400 - precision: 0.9929 - recall: 0.8892 - f1_score: 0.9379 - val_loss: 1.8620 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8682 - acc: 0.9400 - precision: 0.9931 - recall: 0.8903 - f1_score: 0.9378 - val_loss: 1.8535 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8597 - acc: 0.9400 - precision: 0.9938 - recall: 0.8909 - f1_score: 0.9380 - val_loss: 1.8450 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8513 - acc: 0.9400 - precision: 0.9931 - recall: 0.8889 - f1_score: 0.9373 - val_loss: 1.8366 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8429 - acc: 0.9400 - precision: 0.9934 - recall: 0.8932 - f1_score: 0.9383 - val_loss: 1.8282 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8346 - acc: 0.9400 - precision: 0.9928 - recall: 0.8890 - f1_score: 0.9371 - val_loss: 1.8199 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8263 - acc: 0.9400 - precision: 0.9930 - recall: 0.8892 - f1_score: 0.9367 - val_loss: 1.8116 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.8180 - acc: 0.9400 - precision: 0.9931 - recall: 0.8881 - f1_score: 0.9366 - val_loss: 1.8034 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8098 - acc: 0.9400 - precision: 0.9930 - recall: 0.8881 - f1_score: 0.9370 - val_loss: 1.7952 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8017 - acc: 0.9400 - precision: 0.9940 - recall: 0.8912 - f1_score: 0.9381 - val_loss: 1.7870 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7935 - acc: 0.9400 - precision: 0.9926 - recall: 0.8859 - f1_score: 0.9350 - val_loss: 1.7789 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7855 - acc: 0.9400 - precision: 0.9937 - recall: 0.8903 - f1_score: 0.9381 - val_loss: 1.7708 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7774 - acc: 0.9400 - precision: 0.9931 - recall: 0.8873 - f1_score: 0.9364 - val_loss: 1.7628 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7694 - acc: 0.9400 - precision: 0.9917 - recall: 0.8854 - f1_score: 0.9344 - val_loss: 1.7548 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7615 - acc: 0.9400 - precision: 0.9926 - recall: 0.8880 - f1_score: 0.9364 - val_loss: 1.7468 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7536 - acc: 0.9400 - precision: 0.9921 - recall: 0.8897 - f1_score: 0.9376 - val_loss: 1.7389 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7457 - acc: 0.9400 - precision: 0.9934 - recall: 0.8858 - f1_score: 0.9344 - val_loss: 1.7310 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7379 - acc: 0.9400 - precision: 0.9924 - recall: 0.8892 - f1_score: 0.9365 - val_loss: 1.7232 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7301 - acc: 0.9400 - precision: 0.9938 - recall: 0.8875 - f1_score: 0.9365 - val_loss: 1.7154 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7224 - acc: 0.9400 - precision: 0.9917 - recall: 0.8877 - f1_score: 0.9365 - val_loss: 1.7077 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7146 - acc: 0.9400 - precision: 0.9930 - recall: 0.8918 - f1_score: 0.9388 - val_loss: 1.7000 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7070 - acc: 0.9400 - precision: 0.9937 - recall: 0.8907 - f1_score: 0.9388 - val_loss: 1.6923 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6994 - acc: 0.9400 - precision: 0.9935 - recall: 0.8903 - f1_score: 0.9385 - val_loss: 1.6847 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6918 - acc: 0.9400 - precision: 0.9934 - recall: 0.8946 - f1_score: 0.9390 - val_loss: 1.6771 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6842 - acc: 0.9400 - precision: 0.9932 - recall: 0.8899 - f1_score: 0.9379 - val_loss: 1.6696 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6767 - acc: 0.9400 - precision: 0.9929 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 1.6621 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6692 - acc: 0.9400 - precision: 0.9907 - recall: 0.8886 - f1_score: 0.9346 - val_loss: 1.6546 - val_acc: 0.9557 - val_precision: 0.9681 - val_recall: 0.9183 - val_f1_score: 0.9376\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6618 - acc: 0.9400 - precision: 0.9937 - recall: 0.8874 - f1_score: 0.9369 - val_loss: 1.6472 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6544 - acc: 0.9400 - precision: 0.9928 - recall: 0.8884 - f1_score: 0.9368 - val_loss: 1.6398 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6471 - acc: 0.9400 - precision: 0.9933 - recall: 0.8893 - f1_score: 0.9376 - val_loss: 1.6324 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6397 - acc: 0.9400 - precision: 0.9933 - recall: 0.8864 - f1_score: 0.9355 - val_loss: 1.6251 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6325 - acc: 0.9400 - precision: 0.9933 - recall: 0.8882 - f1_score: 0.9364 - val_loss: 1.6178 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6252 - acc: 0.9400 - precision: 0.9938 - recall: 0.8889 - f1_score: 0.9352 - val_loss: 1.6106 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6180 - acc: 0.9400 - precision: 0.9942 - recall: 0.8891 - f1_score: 0.9375 - val_loss: 1.6034 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6109 - acc: 0.9400 - precision: 0.9936 - recall: 0.8898 - f1_score: 0.9375 - val_loss: 1.5962 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6037 - acc: 0.9400 - precision: 0.9926 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 1.5891 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5966 - acc: 0.9400 - precision: 0.9912 - recall: 0.8893 - f1_score: 0.9367 - val_loss: 1.5820 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5896 - acc: 0.9400 - precision: 0.9944 - recall: 0.8856 - f1_score: 0.9358 - val_loss: 1.5750 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5826 - acc: 0.9400 - precision: 0.9932 - recall: 0.8901 - f1_score: 0.9370 - val_loss: 1.5679 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.5756 - acc: 0.9400 - precision: 0.9921 - recall: 0.8899 - f1_score: 0.9370 - val_loss: 1.5610 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5686 - acc: 0.9400 - precision: 0.9920 - recall: 0.8905 - f1_score: 0.9376 - val_loss: 1.5540 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5617 - acc: 0.9400 - precision: 0.9928 - recall: 0.8865 - f1_score: 0.9358 - val_loss: 1.5471 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5548 - acc: 0.9400 - precision: 0.9922 - recall: 0.8924 - f1_score: 0.9390 - val_loss: 1.5402 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5480 - acc: 0.9400 - precision: 0.9923 - recall: 0.8895 - f1_score: 0.9372 - val_loss: 1.5334 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5412 - acc: 0.9400 - precision: 0.9933 - recall: 0.8897 - f1_score: 0.9371 - val_loss: 1.5266 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5344 - acc: 0.9400 - precision: 0.9940 - recall: 0.8838 - f1_score: 0.9336 - val_loss: 1.5198 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5277 - acc: 0.9400 - precision: 0.9922 - recall: 0.8862 - f1_score: 0.9353 - val_loss: 1.5131 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5210 - acc: 0.9400 - precision: 0.9940 - recall: 0.8863 - f1_score: 0.9354 - val_loss: 1.5064 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5143 - acc: 0.9400 - precision: 0.9929 - recall: 0.8910 - f1_score: 0.9380 - val_loss: 1.4997 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5077 - acc: 0.9400 - precision: 0.9926 - recall: 0.8861 - f1_score: 0.9353 - val_loss: 1.4931 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5011 - acc: 0.9400 - precision: 0.9935 - recall: 0.8889 - f1_score: 0.9368 - val_loss: 1.4865 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4945 - acc: 0.9400 - precision: 0.9927 - recall: 0.8938 - f1_score: 0.9394 - val_loss: 1.4800 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4880 - acc: 0.9400 - precision: 0.9940 - recall: 0.8868 - f1_score: 0.9364 - val_loss: 1.4734 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4815 - acc: 0.9400 - precision: 0.9929 - recall: 0.8898 - f1_score: 0.9374 - val_loss: 1.4670 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4750 - acc: 0.9400 - precision: 0.9927 - recall: 0.8907 - f1_score: 0.9384 - val_loss: 1.4605 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4686 - acc: 0.9400 - precision: 0.9943 - recall: 0.8904 - f1_score: 0.9386 - val_loss: 1.4541 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4622 - acc: 0.9400 - precision: 0.9935 - recall: 0.8875 - f1_score: 0.9369 - val_loss: 1.4477 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4559 - acc: 0.9400 - precision: 0.9929 - recall: 0.8892 - f1_score: 0.9365 - val_loss: 1.4413 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4495 - acc: 0.9400 - precision: 0.9934 - recall: 0.8905 - f1_score: 0.9375 - val_loss: 1.4350 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4432 - acc: 0.9400 - precision: 0.9936 - recall: 0.8833 - f1_score: 0.9333 - val_loss: 1.4287 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4370 - acc: 0.9400 - precision: 0.9933 - recall: 0.8889 - f1_score: 0.9378 - val_loss: 1.4225 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4307 - acc: 0.9400 - precision: 0.9920 - recall: 0.8832 - f1_score: 0.9323 - val_loss: 1.4162 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4245 - acc: 0.9400 - precision: 0.9939 - recall: 0.8866 - f1_score: 0.9359 - val_loss: 1.4100 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4184 - acc: 0.9400 - precision: 0.9923 - recall: 0.8916 - f1_score: 0.9374 - val_loss: 1.4039 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4122 - acc: 0.9400 - precision: 0.9933 - recall: 0.8953 - f1_score: 0.9408 - val_loss: 1.3977 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4061 - acc: 0.9400 - precision: 0.9925 - recall: 0.8873 - f1_score: 0.9355 - val_loss: 1.3916 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4000 - acc: 0.9400 - precision: 0.9921 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 1.3856 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3940 - acc: 0.9415 - precision: 0.9935 - recall: 0.8941 - f1_score: 0.9406 - val_loss: 1.3795 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3880 - acc: 0.9415 - precision: 0.9938 - recall: 0.8944 - f1_score: 0.9400 - val_loss: 1.3735 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3820 - acc: 0.9415 - precision: 0.9930 - recall: 0.8942 - f1_score: 0.9399 - val_loss: 1.3676 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3761 - acc: 0.9415 - precision: 0.9933 - recall: 0.8925 - f1_score: 0.9396 - val_loss: 1.3616 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3702 - acc: 0.9415 - precision: 0.9934 - recall: 0.8928 - f1_score: 0.9394 - val_loss: 1.3557 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3643 - acc: 0.9415 - precision: 0.9931 - recall: 0.8900 - f1_score: 0.9374 - val_loss: 1.3498 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3584 - acc: 0.9415 - precision: 0.9937 - recall: 0.8916 - f1_score: 0.9391 - val_loss: 1.3440 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3526 - acc: 0.9415 - precision: 0.9911 - recall: 0.8907 - f1_score: 0.9372 - val_loss: 1.3381 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3468 - acc: 0.9415 - precision: 0.9935 - recall: 0.8958 - f1_score: 0.9408 - val_loss: 1.3323 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3410 - acc: 0.9415 - precision: 0.9942 - recall: 0.8913 - f1_score: 0.9392 - val_loss: 1.3266 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3353 - acc: 0.9415 - precision: 0.9936 - recall: 0.8947 - f1_score: 0.9397 - val_loss: 1.3209 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3296 - acc: 0.9415 - precision: 0.9926 - recall: 0.8917 - f1_score: 0.9384 - val_loss: 1.3152 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3239 - acc: 0.9415 - precision: 0.9935 - recall: 0.8936 - f1_score: 0.9398 - val_loss: 1.3095 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3182 - acc: 0.9415 - precision: 0.9934 - recall: 0.8893 - f1_score: 0.9376 - val_loss: 1.3039 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3126 - acc: 0.9415 - precision: 0.9936 - recall: 0.8916 - f1_score: 0.9387 - val_loss: 1.2982 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3070 - acc: 0.9415 - precision: 0.9930 - recall: 0.8914 - f1_score: 0.9388 - val_loss: 1.2926 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3015 - acc: 0.9415 - precision: 0.9938 - recall: 0.8918 - f1_score: 0.9396 - val_loss: 1.2871 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2959 - acc: 0.9415 - precision: 0.9920 - recall: 0.8931 - f1_score: 0.9385 - val_loss: 1.2816 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2904 - acc: 0.9415 - precision: 0.9930 - recall: 0.8959 - f1_score: 0.9408 - val_loss: 1.2761 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2849 - acc: 0.9415 - precision: 0.9906 - recall: 0.8872 - f1_score: 0.9352 - val_loss: 1.2706 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2795 - acc: 0.9415 - precision: 0.9940 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 1.2651 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2741 - acc: 0.9415 - precision: 0.9925 - recall: 0.8926 - f1_score: 0.9389 - val_loss: 1.2597 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2687 - acc: 0.9415 - precision: 0.9928 - recall: 0.8886 - f1_score: 0.9369 - val_loss: 1.2543 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2633 - acc: 0.9415 - precision: 0.9932 - recall: 0.8964 - f1_score: 0.9405 - val_loss: 1.2490 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2580 - acc: 0.9415 - precision: 0.9918 - recall: 0.8981 - f1_score: 0.9408 - val_loss: 1.2436 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2527 - acc: 0.9415 - precision: 0.9926 - recall: 0.8909 - f1_score: 0.9379 - val_loss: 1.2383 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2474 - acc: 0.9415 - precision: 0.9934 - recall: 0.8915 - f1_score: 0.9391 - val_loss: 1.2331 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2421 - acc: 0.9415 - precision: 0.9933 - recall: 0.8931 - f1_score: 0.9398 - val_loss: 1.2278 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2369 - acc: 0.9415 - precision: 0.9937 - recall: 0.8968 - f1_score: 0.9416 - val_loss: 1.2226 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2317 - acc: 0.9415 - precision: 0.9935 - recall: 0.8987 - f1_score: 0.9424 - val_loss: 1.2174 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2265 - acc: 0.9415 - precision: 0.9933 - recall: 0.8943 - f1_score: 0.9398 - val_loss: 1.2122 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2214 - acc: 0.9415 - precision: 0.9933 - recall: 0.8919 - f1_score: 0.9393 - val_loss: 1.2071 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2163 - acc: 0.9415 - precision: 0.9925 - recall: 0.8890 - f1_score: 0.9365 - val_loss: 1.2020 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2112 - acc: 0.9415 - precision: 0.9940 - recall: 0.8887 - f1_score: 0.9374 - val_loss: 1.1969 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2061 - acc: 0.9415 - precision: 0.9937 - recall: 0.8924 - f1_score: 0.9394 - val_loss: 1.1918 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2010 - acc: 0.9415 - precision: 0.9931 - recall: 0.8923 - f1_score: 0.9392 - val_loss: 1.1868 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1960 - acc: 0.9415 - precision: 0.9915 - recall: 0.8911 - f1_score: 0.9376 - val_loss: 1.1818 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1910 - acc: 0.9415 - precision: 0.9932 - recall: 0.8921 - f1_score: 0.9383 - val_loss: 1.1768 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1861 - acc: 0.9415 - precision: 0.9923 - recall: 0.8898 - f1_score: 0.9370 - val_loss: 1.1718 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1811 - acc: 0.9415 - precision: 0.9932 - recall: 0.8921 - f1_score: 0.9389 - val_loss: 1.1669 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1762 - acc: 0.9415 - precision: 0.9941 - recall: 0.8940 - f1_score: 0.9407 - val_loss: 1.1620 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1713 - acc: 0.9415 - precision: 0.9930 - recall: 0.8849 - f1_score: 0.9338 - val_loss: 1.1571 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1664 - acc: 0.9415 - precision: 0.9934 - recall: 0.8923 - f1_score: 0.9394 - val_loss: 1.1522 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1616 - acc: 0.9415 - precision: 0.9938 - recall: 0.8937 - f1_score: 0.9404 - val_loss: 1.1474 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1568 - acc: 0.9415 - precision: 0.9933 - recall: 0.8914 - f1_score: 0.9390 - val_loss: 1.1426 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1520 - acc: 0.9415 - precision: 0.9933 - recall: 0.8914 - f1_score: 0.9381 - val_loss: 1.1378 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1472 - acc: 0.9415 - precision: 0.9942 - recall: 0.8950 - f1_score: 0.9407 - val_loss: 1.1330 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1425 - acc: 0.9415 - precision: 0.9935 - recall: 0.8939 - f1_score: 0.9398 - val_loss: 1.1282 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1378 - acc: 0.9415 - precision: 0.9935 - recall: 0.8929 - f1_score: 0.9398 - val_loss: 1.1235 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1331 - acc: 0.9415 - precision: 0.9932 - recall: 0.8936 - f1_score: 0.9399 - val_loss: 1.1189 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1284 - acc: 0.9415 - precision: 0.9933 - recall: 0.8932 - f1_score: 0.9396 - val_loss: 1.1142 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1237 - acc: 0.9415 - precision: 0.9940 - recall: 0.8887 - f1_score: 0.9362 - val_loss: 1.1095 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1191 - acc: 0.9415 - precision: 0.9934 - recall: 0.8924 - f1_score: 0.9397 - val_loss: 1.1049 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1145 - acc: 0.9415 - precision: 0.9936 - recall: 0.8926 - f1_score: 0.9396 - val_loss: 1.1003 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1099 - acc: 0.9415 - precision: 0.9926 - recall: 0.8938 - f1_score: 0.9400 - val_loss: 1.0958 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1054 - acc: 0.9415 - precision: 0.9931 - recall: 0.8890 - f1_score: 0.9376 - val_loss: 1.0912 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1009 - acc: 0.9415 - precision: 0.9929 - recall: 0.8924 - f1_score: 0.9391 - val_loss: 1.0867 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0964 - acc: 0.9415 - precision: 0.9944 - recall: 0.8929 - f1_score: 0.9403 - val_loss: 1.0822 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0919 - acc: 0.9415 - precision: 0.9929 - recall: 0.8894 - f1_score: 0.9373 - val_loss: 1.0777 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0874 - acc: 0.9415 - precision: 0.9930 - recall: 0.8969 - f1_score: 0.9413 - val_loss: 1.0733 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0830 - acc: 0.9415 - precision: 0.9942 - recall: 0.8950 - f1_score: 0.9406 - val_loss: 1.0688 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0786 - acc: 0.9415 - precision: 0.9928 - recall: 0.8887 - f1_score: 0.9370 - val_loss: 1.0644 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0742 - acc: 0.9415 - precision: 0.9935 - recall: 0.8923 - f1_score: 0.9394 - val_loss: 1.0600 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0698 - acc: 0.9415 - precision: 0.9928 - recall: 0.8942 - f1_score: 0.9399 - val_loss: 1.0557 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0655 - acc: 0.9415 - precision: 0.9932 - recall: 0.8940 - f1_score: 0.9399 - val_loss: 1.0513 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0611 - acc: 0.9415 - precision: 0.9941 - recall: 0.8864 - f1_score: 0.9352 - val_loss: 1.0470 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0568 - acc: 0.9415 - precision: 0.9923 - recall: 0.8887 - f1_score: 0.9364 - val_loss: 1.0427 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0525 - acc: 0.9415 - precision: 0.9940 - recall: 0.8938 - f1_score: 0.9405 - val_loss: 1.0384 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0483 - acc: 0.9415 - precision: 0.9920 - recall: 0.8931 - f1_score: 0.9392 - val_loss: 1.0342 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0441 - acc: 0.9415 - precision: 0.9939 - recall: 0.8935 - f1_score: 0.9393 - val_loss: 1.0299 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0398 - acc: 0.9415 - precision: 0.9938 - recall: 0.8859 - f1_score: 0.9354 - val_loss: 1.0257 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0356 - acc: 0.9415 - precision: 0.9936 - recall: 0.8952 - f1_score: 0.9408 - val_loss: 1.0215 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0315 - acc: 0.9415 - precision: 0.9931 - recall: 0.8941 - f1_score: 0.9394 - val_loss: 1.0174 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0273 - acc: 0.9415 - precision: 0.9939 - recall: 0.8962 - f1_score: 0.9410 - val_loss: 1.0132 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0232 - acc: 0.9415 - precision: 0.9929 - recall: 0.8959 - f1_score: 0.9411 - val_loss: 1.0091 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0191 - acc: 0.9415 - precision: 0.9933 - recall: 0.8950 - f1_score: 0.9405 - val_loss: 1.0050 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0150 - acc: 0.9415 - precision: 0.9934 - recall: 0.8896 - f1_score: 0.9378 - val_loss: 1.0009 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0109 - acc: 0.9415 - precision: 0.9924 - recall: 0.8919 - f1_score: 0.9382 - val_loss: 0.9968 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0069 - acc: 0.9415 - precision: 0.9926 - recall: 0.8914 - f1_score: 0.9377 - val_loss: 0.9928 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0029 - acc: 0.9415 - precision: 0.9931 - recall: 0.8914 - f1_score: 0.9387 - val_loss: 0.9888 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9989 - acc: 0.9415 - precision: 0.9915 - recall: 0.8897 - f1_score: 0.9366 - val_loss: 0.9848 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9949 - acc: 0.9415 - precision: 0.9924 - recall: 0.8893 - f1_score: 0.9374 - val_loss: 0.9808 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9909 - acc: 0.9415 - precision: 0.9932 - recall: 0.8916 - f1_score: 0.9385 - val_loss: 0.9768 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9870 - acc: 0.9415 - precision: 0.9937 - recall: 0.8914 - f1_score: 0.9381 - val_loss: 0.9729 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9830 - acc: 0.9415 - precision: 0.9931 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.9690 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9791 - acc: 0.9415 - precision: 0.9940 - recall: 0.8932 - f1_score: 0.9402 - val_loss: 0.9651 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9753 - acc: 0.9415 - precision: 0.9937 - recall: 0.8914 - f1_score: 0.9392 - val_loss: 0.9612 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9714 - acc: 0.9415 - precision: 0.9937 - recall: 0.8911 - f1_score: 0.9387 - val_loss: 0.9573 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9675 - acc: 0.9415 - precision: 0.9916 - recall: 0.8901 - f1_score: 0.9368 - val_loss: 0.9535 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9637 - acc: 0.9415 - precision: 0.9933 - recall: 0.8928 - f1_score: 0.9395 - val_loss: 0.9497 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9599 - acc: 0.9415 - precision: 0.9936 - recall: 0.8927 - f1_score: 0.9395 - val_loss: 0.9459 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9561 - acc: 0.9415 - precision: 0.9926 - recall: 0.8928 - f1_score: 0.9390 - val_loss: 0.9421 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9523 - acc: 0.9415 - precision: 0.9931 - recall: 0.8934 - f1_score: 0.9400 - val_loss: 0.9383 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9486 - acc: 0.9415 - precision: 0.9937 - recall: 0.8920 - f1_score: 0.9397 - val_loss: 0.9346 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9449 - acc: 0.9415 - precision: 0.9946 - recall: 0.8940 - f1_score: 0.9410 - val_loss: 0.9308 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9412 - acc: 0.9415 - precision: 0.9936 - recall: 0.8908 - f1_score: 0.9381 - val_loss: 0.9271 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9375 - acc: 0.9415 - precision: 0.9931 - recall: 0.8958 - f1_score: 0.9411 - val_loss: 0.9234 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9338 - acc: 0.9415 - precision: 0.9934 - recall: 0.8876 - f1_score: 0.9356 - val_loss: 0.9198 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9302 - acc: 0.9415 - precision: 0.9933 - recall: 0.8931 - f1_score: 0.9395 - val_loss: 0.9161 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9265 - acc: 0.9415 - precision: 0.9941 - recall: 0.8927 - f1_score: 0.9401 - val_loss: 0.9125 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9229 - acc: 0.9415 - precision: 0.9934 - recall: 0.8952 - f1_score: 0.9401 - val_loss: 0.9089 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9193 - acc: 0.9415 - precision: 0.9937 - recall: 0.8917 - f1_score: 0.9395 - val_loss: 0.9053 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9157 - acc: 0.9415 - precision: 0.9928 - recall: 0.8941 - f1_score: 0.9402 - val_loss: 0.9017 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9122 - acc: 0.9415 - precision: 0.9929 - recall: 0.8913 - f1_score: 0.9381 - val_loss: 0.8981 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9086 - acc: 0.9415 - precision: 0.9940 - recall: 0.8915 - f1_score: 0.9376 - val_loss: 0.8946 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9051 - acc: 0.9415 - precision: 0.9938 - recall: 0.8952 - f1_score: 0.9411 - val_loss: 0.8911 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9016 - acc: 0.9415 - precision: 0.9939 - recall: 0.8930 - f1_score: 0.9394 - val_loss: 0.8876 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8981 - acc: 0.9415 - precision: 0.9933 - recall: 0.8892 - f1_score: 0.9376 - val_loss: 0.8841 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8946 - acc: 0.9415 - precision: 0.9933 - recall: 0.8890 - f1_score: 0.9375 - val_loss: 0.8806 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8912 - acc: 0.9415 - precision: 0.9921 - recall: 0.8899 - f1_score: 0.9368 - val_loss: 0.8772 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8877 - acc: 0.9415 - precision: 0.9934 - recall: 0.8906 - f1_score: 0.9384 - val_loss: 0.8737 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8843 - acc: 0.9415 - precision: 0.9930 - recall: 0.8936 - f1_score: 0.9399 - val_loss: 0.8703 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8809 - acc: 0.9415 - precision: 0.9932 - recall: 0.8841 - f1_score: 0.9338 - val_loss: 0.8669 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8775 - acc: 0.9415 - precision: 0.9937 - recall: 0.8900 - f1_score: 0.9378 - val_loss: 0.8635 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8742 - acc: 0.9415 - precision: 0.9928 - recall: 0.8907 - f1_score: 0.9380 - val_loss: 0.8602 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8708 - acc: 0.9415 - precision: 0.9936 - recall: 0.8951 - f1_score: 0.9409 - val_loss: 0.8568 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8675 - acc: 0.9415 - precision: 0.9925 - recall: 0.8969 - f1_score: 0.9413 - val_loss: 0.8535 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8642 - acc: 0.9415 - precision: 0.9935 - recall: 0.8972 - f1_score: 0.9416 - val_loss: 0.8502 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8609 - acc: 0.9415 - precision: 0.9901 - recall: 0.8922 - f1_score: 0.9375 - val_loss: 0.8469 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8576 - acc: 0.9415 - precision: 0.9929 - recall: 0.8966 - f1_score: 0.9415 - val_loss: 0.8436 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8543 - acc: 0.9415 - precision: 0.9930 - recall: 0.8878 - f1_score: 0.9364 - val_loss: 0.8403 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8511 - acc: 0.9415 - precision: 0.9937 - recall: 0.8912 - f1_score: 0.9390 - val_loss: 0.8371 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8478 - acc: 0.9415 - precision: 0.9939 - recall: 0.8905 - f1_score: 0.9376 - val_loss: 0.8338 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8446 - acc: 0.9415 - precision: 0.9943 - recall: 0.8884 - f1_score: 0.9370 - val_loss: 0.8306 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8414 - acc: 0.9415 - precision: 0.9914 - recall: 0.8899 - f1_score: 0.9371 - val_loss: 0.8274 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8382 - acc: 0.9415 - precision: 0.9919 - recall: 0.8925 - f1_score: 0.9381 - val_loss: 0.8242 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8351 - acc: 0.9415 - precision: 0.9936 - recall: 0.8921 - f1_score: 0.9394 - val_loss: 0.8211 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8319 - acc: 0.9415 - precision: 0.9931 - recall: 0.8981 - f1_score: 0.9416 - val_loss: 0.8179 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8288 - acc: 0.9415 - precision: 0.9931 - recall: 0.8931 - f1_score: 0.9399 - val_loss: 0.8148 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8256 - acc: 0.9415 - precision: 0.9936 - recall: 0.8914 - f1_score: 0.9387 - val_loss: 0.8117 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8225 - acc: 0.9415 - precision: 0.9919 - recall: 0.8912 - f1_score: 0.9376 - val_loss: 0.8086 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8195 - acc: 0.9415 - precision: 0.9944 - recall: 0.8949 - f1_score: 0.9409 - val_loss: 0.8055 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8164 - acc: 0.9415 - precision: 0.9926 - recall: 0.8948 - f1_score: 0.9397 - val_loss: 0.8024 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8133 - acc: 0.9415 - precision: 0.9929 - recall: 0.8917 - f1_score: 0.9384 - val_loss: 0.7994 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8103 - acc: 0.9415 - precision: 0.9931 - recall: 0.8902 - f1_score: 0.9372 - val_loss: 0.7963 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8072 - acc: 0.9415 - precision: 0.9942 - recall: 0.8944 - f1_score: 0.9406 - val_loss: 0.7933 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8042 - acc: 0.9415 - precision: 0.9925 - recall: 0.8933 - f1_score: 0.9391 - val_loss: 0.7903 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8012 - acc: 0.9415 - precision: 0.9933 - recall: 0.8944 - f1_score: 0.9396 - val_loss: 0.7873 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7983 - acc: 0.9415 - precision: 0.9930 - recall: 0.8917 - f1_score: 0.9391 - val_loss: 0.7844 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7953 - acc: 0.9415 - precision: 0.9946 - recall: 0.8904 - f1_score: 0.9386 - val_loss: 0.7814 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7923 - acc: 0.9415 - precision: 0.9928 - recall: 0.8883 - f1_score: 0.9370 - val_loss: 0.7784 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7894 - acc: 0.9415 - precision: 0.9933 - recall: 0.8907 - f1_score: 0.9381 - val_loss: 0.7755 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7865 - acc: 0.9415 - precision: 0.9931 - recall: 0.8902 - f1_score: 0.9382 - val_loss: 0.7726 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7836 - acc: 0.9415 - precision: 0.9938 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 0.7697 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7807 - acc: 0.9415 - precision: 0.9916 - recall: 0.8866 - f1_score: 0.9347 - val_loss: 0.7668 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7778 - acc: 0.9415 - precision: 0.9925 - recall: 0.8943 - f1_score: 0.9402 - val_loss: 0.7639 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7750 - acc: 0.9415 - precision: 0.9928 - recall: 0.8929 - f1_score: 0.9389 - val_loss: 0.7611 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7721 - acc: 0.9415 - precision: 0.9917 - recall: 0.8908 - f1_score: 0.9377 - val_loss: 0.7582 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7693 - acc: 0.9415 - precision: 0.9934 - recall: 0.8907 - f1_score: 0.9391 - val_loss: 0.7554 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7664 - acc: 0.9415 - precision: 0.9928 - recall: 0.8878 - f1_score: 0.9357 - val_loss: 0.7526 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7636 - acc: 0.9415 - precision: 0.9941 - recall: 0.8919 - f1_score: 0.9389 - val_loss: 0.7498 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7609 - acc: 0.9415 - precision: 0.9928 - recall: 0.8914 - f1_score: 0.9386 - val_loss: 0.7470 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7581 - acc: 0.9415 - precision: 0.9938 - recall: 0.8906 - f1_score: 0.9384 - val_loss: 0.7442 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7553 - acc: 0.9415 - precision: 0.9929 - recall: 0.8926 - f1_score: 0.9393 - val_loss: 0.7415 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7526 - acc: 0.9415 - precision: 0.9896 - recall: 0.8887 - f1_score: 0.9346 - val_loss: 0.7387 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7498 - acc: 0.9415 - precision: 0.9928 - recall: 0.8937 - f1_score: 0.9386 - val_loss: 0.7360 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7471 - acc: 0.9415 - precision: 0.9929 - recall: 0.8933 - f1_score: 0.9394 - val_loss: 0.7332 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7444 - acc: 0.9415 - precision: 0.9926 - recall: 0.8928 - f1_score: 0.9394 - val_loss: 0.7305 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7417 - acc: 0.9415 - precision: 0.9934 - recall: 0.8941 - f1_score: 0.9395 - val_loss: 0.7278 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7390 - acc: 0.9415 - precision: 0.9935 - recall: 0.8922 - f1_score: 0.9392 - val_loss: 0.7251 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7364 - acc: 0.9415 - precision: 0.9932 - recall: 0.8925 - f1_score: 0.9389 - val_loss: 0.7225 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7337 - acc: 0.9415 - precision: 0.9915 - recall: 0.8900 - f1_score: 0.9375 - val_loss: 0.7198 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7311 - acc: 0.9415 - precision: 0.9931 - recall: 0.8953 - f1_score: 0.9404 - val_loss: 0.7172 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7284 - acc: 0.9415 - precision: 0.9938 - recall: 0.8884 - f1_score: 0.9376 - val_loss: 0.7146 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 464/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7258 - acc: 0.9415 - precision: 0.9931 - recall: 0.8914 - f1_score: 0.9388 - val_loss: 0.7120 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7232 - acc: 0.9415 - precision: 0.9939 - recall: 0.8926 - f1_score: 0.9397 - val_loss: 0.7094 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7206 - acc: 0.9415 - precision: 0.9921 - recall: 0.8887 - f1_score: 0.9363 - val_loss: 0.7068 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7181 - acc: 0.9415 - precision: 0.9929 - recall: 0.8950 - f1_score: 0.9403 - val_loss: 0.7042 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7155 - acc: 0.9415 - precision: 0.9939 - recall: 0.8927 - f1_score: 0.9399 - val_loss: 0.7016 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7130 - acc: 0.9415 - precision: 0.9920 - recall: 0.8956 - f1_score: 0.9396 - val_loss: 0.6991 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7104 - acc: 0.9415 - precision: 0.9930 - recall: 0.8919 - f1_score: 0.9389 - val_loss: 0.6965 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7079 - acc: 0.9415 - precision: 0.9931 - recall: 0.8887 - f1_score: 0.9363 - val_loss: 0.6940 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7054 - acc: 0.9415 - precision: 0.9917 - recall: 0.8893 - f1_score: 0.9370 - val_loss: 0.6915 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7029 - acc: 0.9415 - precision: 0.9931 - recall: 0.8945 - f1_score: 0.9405 - val_loss: 0.6890 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7004 - acc: 0.9415 - precision: 0.9924 - recall: 0.8879 - f1_score: 0.9360 - val_loss: 0.6865 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6979 - acc: 0.9415 - precision: 0.9941 - recall: 0.8895 - f1_score: 0.9366 - val_loss: 0.6841 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6955 - acc: 0.9415 - precision: 0.9937 - recall: 0.8886 - f1_score: 0.9363 - val_loss: 0.6816 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6930 - acc: 0.9415 - precision: 0.9930 - recall: 0.8895 - f1_score: 0.9378 - val_loss: 0.6792 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6906 - acc: 0.9415 - precision: 0.9930 - recall: 0.8896 - f1_score: 0.9373 - val_loss: 0.6767 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6882 - acc: 0.9415 - precision: 0.9934 - recall: 0.8913 - f1_score: 0.9388 - val_loss: 0.6743 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6858 - acc: 0.9415 - precision: 0.9938 - recall: 0.8925 - f1_score: 0.9397 - val_loss: 0.6719 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6834 - acc: 0.9415 - precision: 0.9933 - recall: 0.8928 - f1_score: 0.9397 - val_loss: 0.6695 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6810 - acc: 0.9415 - precision: 0.9930 - recall: 0.8894 - f1_score: 0.9366 - val_loss: 0.6671 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6786 - acc: 0.9415 - precision: 0.9921 - recall: 0.8884 - f1_score: 0.9353 - val_loss: 0.6647 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6762 - acc: 0.9415 - precision: 0.9938 - recall: 0.8906 - f1_score: 0.9384 - val_loss: 0.6624 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6739 - acc: 0.9415 - precision: 0.9926 - recall: 0.8908 - f1_score: 0.9378 - val_loss: 0.6600 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6716 - acc: 0.9415 - precision: 0.9926 - recall: 0.8914 - f1_score: 0.9376 - val_loss: 0.6577 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6692 - acc: 0.9415 - precision: 0.9925 - recall: 0.8957 - f1_score: 0.9408 - val_loss: 0.6553 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6669 - acc: 0.9415 - precision: 0.9930 - recall: 0.8928 - f1_score: 0.9390 - val_loss: 0.6530 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6646 - acc: 0.9415 - precision: 0.9925 - recall: 0.8932 - f1_score: 0.9392 - val_loss: 0.6507 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6623 - acc: 0.9415 - precision: 0.9941 - recall: 0.8902 - f1_score: 0.9387 - val_loss: 0.6484 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6600 - acc: 0.9415 - precision: 0.9928 - recall: 0.8914 - f1_score: 0.9386 - val_loss: 0.6461 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6578 - acc: 0.9415 - precision: 0.9929 - recall: 0.8941 - f1_score: 0.9401 - val_loss: 0.6439 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6555 - acc: 0.9415 - precision: 0.9929 - recall: 0.8910 - f1_score: 0.9367 - val_loss: 0.6416 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6533 - acc: 0.9415 - precision: 0.9934 - recall: 0.8905 - f1_score: 0.9382 - val_loss: 0.6394 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6510 - acc: 0.9415 - precision: 0.9926 - recall: 0.8970 - f1_score: 0.9408 - val_loss: 0.6371 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6488 - acc: 0.9415 - precision: 0.9933 - recall: 0.8946 - f1_score: 0.9402 - val_loss: 0.6349 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6466 - acc: 0.9415 - precision: 0.9935 - recall: 0.8950 - f1_score: 0.9406 - val_loss: 0.6327 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6444 - acc: 0.9415 - precision: 0.9938 - recall: 0.8927 - f1_score: 0.9397 - val_loss: 0.6305 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6422 - acc: 0.9415 - precision: 0.9933 - recall: 0.8908 - f1_score: 0.9373 - val_loss: 0.6283 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6400 - acc: 0.9415 - precision: 0.9907 - recall: 0.8902 - f1_score: 0.9370 - val_loss: 0.6261 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6379 - acc: 0.9415 - precision: 0.9926 - recall: 0.8923 - f1_score: 0.9387 - val_loss: 0.6239 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6357 - acc: 0.9415 - precision: 0.9938 - recall: 0.8950 - f1_score: 0.9400 - val_loss: 0.6218 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6336 - acc: 0.9415 - precision: 0.9920 - recall: 0.8917 - f1_score: 0.9384 - val_loss: 0.6196 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6314 - acc: 0.9415 - precision: 0.9926 - recall: 0.8909 - f1_score: 0.9380 - val_loss: 0.6175 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6293 - acc: 0.9415 - precision: 0.9931 - recall: 0.8925 - f1_score: 0.9395 - val_loss: 0.6154 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6272 - acc: 0.9415 - precision: 0.9928 - recall: 0.8914 - f1_score: 0.9385 - val_loss: 0.6132 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6251 - acc: 0.9415 - precision: 0.9941 - recall: 0.8906 - f1_score: 0.9383 - val_loss: 0.6111 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6230 - acc: 0.9415 - precision: 0.9933 - recall: 0.8907 - f1_score: 0.9368 - val_loss: 0.6090 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6209 - acc: 0.9415 - precision: 0.9926 - recall: 0.8924 - f1_score: 0.9389 - val_loss: 0.6069 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6188 - acc: 0.9415 - precision: 0.9938 - recall: 0.8926 - f1_score: 0.9385 - val_loss: 0.6049 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6168 - acc: 0.9415 - precision: 0.9933 - recall: 0.8900 - f1_score: 0.9373 - val_loss: 0.6028 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6147 - acc: 0.9415 - precision: 0.9925 - recall: 0.8922 - f1_score: 0.9392 - val_loss: 0.6007 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6127 - acc: 0.9415 - precision: 0.9925 - recall: 0.8885 - f1_score: 0.9365 - val_loss: 0.5987 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6106 - acc: 0.9415 - precision: 0.9933 - recall: 0.8917 - f1_score: 0.9387 - val_loss: 0.5967 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6086 - acc: 0.9415 - precision: 0.9926 - recall: 0.8897 - f1_score: 0.9367 - val_loss: 0.5946 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6066 - acc: 0.9415 - precision: 0.9928 - recall: 0.8863 - f1_score: 0.9348 - val_loss: 0.5926 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6046 - acc: 0.9415 - precision: 0.9923 - recall: 0.8934 - f1_score: 0.9388 - val_loss: 0.5906 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6026 - acc: 0.9415 - precision: 0.9926 - recall: 0.8929 - f1_score: 0.9391 - val_loss: 0.5886 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6006 - acc: 0.9415 - precision: 0.9941 - recall: 0.8918 - f1_score: 0.9395 - val_loss: 0.5866 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5987 - acc: 0.9415 - precision: 0.9926 - recall: 0.8931 - f1_score: 0.9397 - val_loss: 0.5846 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5967 - acc: 0.9415 - precision: 0.9937 - recall: 0.8904 - f1_score: 0.9380 - val_loss: 0.5827 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5947 - acc: 0.9415 - precision: 0.9938 - recall: 0.8958 - f1_score: 0.9415 - val_loss: 0.5807 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5928 - acc: 0.9415 - precision: 0.9937 - recall: 0.8892 - f1_score: 0.9370 - val_loss: 0.5788 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5909 - acc: 0.9415 - precision: 0.9902 - recall: 0.8878 - f1_score: 0.9354 - val_loss: 0.5768 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5889 - acc: 0.9415 - precision: 0.9926 - recall: 0.8852 - f1_score: 0.9352 - val_loss: 0.5749 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5870 - acc: 0.9415 - precision: 0.9930 - recall: 0.8907 - f1_score: 0.9378 - val_loss: 0.5730 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5851 - acc: 0.9415 - precision: 0.9936 - recall: 0.8915 - f1_score: 0.9396 - val_loss: 0.5711 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 528/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5832 - acc: 0.9415 - precision: 0.9929 - recall: 0.8920 - f1_score: 0.9392 - val_loss: 0.5692 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5813 - acc: 0.9415 - precision: 0.9932 - recall: 0.8942 - f1_score: 0.9395 - val_loss: 0.5673 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5795 - acc: 0.9415 - precision: 0.9931 - recall: 0.8923 - f1_score: 0.9392 - val_loss: 0.5654 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5776 - acc: 0.9415 - precision: 0.9934 - recall: 0.8906 - f1_score: 0.9382 - val_loss: 0.5635 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5757 - acc: 0.9415 - precision: 0.9937 - recall: 0.8924 - f1_score: 0.9392 - val_loss: 0.5617 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5739 - acc: 0.9415 - precision: 0.9923 - recall: 0.8964 - f1_score: 0.9408 - val_loss: 0.5598 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5720 - acc: 0.9415 - precision: 0.9935 - recall: 0.8936 - f1_score: 0.9391 - val_loss: 0.5580 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5702 - acc: 0.9415 - precision: 0.9916 - recall: 0.8914 - f1_score: 0.9372 - val_loss: 0.5561 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5684 - acc: 0.9415 - precision: 0.9936 - recall: 0.8871 - f1_score: 0.9355 - val_loss: 0.5543 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5666 - acc: 0.9415 - precision: 0.9933 - recall: 0.8990 - f1_score: 0.9419 - val_loss: 0.5525 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5648 - acc: 0.9415 - precision: 0.9926 - recall: 0.8897 - f1_score: 0.9373 - val_loss: 0.5507 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5630 - acc: 0.9415 - precision: 0.9925 - recall: 0.8932 - f1_score: 0.9395 - val_loss: 0.5489 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5612 - acc: 0.9415 - precision: 0.9928 - recall: 0.8978 - f1_score: 0.9415 - val_loss: 0.5471 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5594 - acc: 0.9415 - precision: 0.9919 - recall: 0.8921 - f1_score: 0.9377 - val_loss: 0.5453 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5577 - acc: 0.9415 - precision: 0.9938 - recall: 0.8908 - f1_score: 0.9386 - val_loss: 0.5435 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5559 - acc: 0.9415 - precision: 0.9932 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 0.5418 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5542 - acc: 0.9415 - precision: 0.9944 - recall: 0.8912 - f1_score: 0.9389 - val_loss: 0.5400 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5524 - acc: 0.9415 - precision: 0.9938 - recall: 0.8916 - f1_score: 0.9383 - val_loss: 0.5383 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5507 - acc: 0.9415 - precision: 0.9945 - recall: 0.8900 - f1_score: 0.9373 - val_loss: 0.5365 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5490 - acc: 0.9415 - precision: 0.9904 - recall: 0.8922 - f1_score: 0.9376 - val_loss: 0.5348 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5472 - acc: 0.9415 - precision: 0.9934 - recall: 0.8898 - f1_score: 0.9381 - val_loss: 0.5331 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5455 - acc: 0.9415 - precision: 0.9935 - recall: 0.8918 - f1_score: 0.9395 - val_loss: 0.5314 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5438 - acc: 0.9415 - precision: 0.9931 - recall: 0.8904 - f1_score: 0.9376 - val_loss: 0.5297 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5421 - acc: 0.9415 - precision: 0.9919 - recall: 0.8920 - f1_score: 0.9389 - val_loss: 0.5280 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5405 - acc: 0.9415 - precision: 0.9926 - recall: 0.8923 - f1_score: 0.9388 - val_loss: 0.5263 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5388 - acc: 0.9415 - precision: 0.9923 - recall: 0.8976 - f1_score: 0.9416 - val_loss: 0.5246 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5371 - acc: 0.9415 - precision: 0.9933 - recall: 0.8868 - f1_score: 0.9354 - val_loss: 0.5230 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5355 - acc: 0.9415 - precision: 0.9932 - recall: 0.8924 - f1_score: 0.9390 - val_loss: 0.5213 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5338 - acc: 0.9415 - precision: 0.9918 - recall: 0.8900 - f1_score: 0.9370 - val_loss: 0.5196 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5322 - acc: 0.9415 - precision: 0.9928 - recall: 0.8937 - f1_score: 0.9399 - val_loss: 0.5180 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5306 - acc: 0.9415 - precision: 0.9935 - recall: 0.8938 - f1_score: 0.9401 - val_loss: 0.5164 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5289 - acc: 0.9415 - precision: 0.9933 - recall: 0.8889 - f1_score: 0.9374 - val_loss: 0.5147 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5273 - acc: 0.9415 - precision: 0.9931 - recall: 0.8911 - f1_score: 0.9385 - val_loss: 0.5131 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5257 - acc: 0.9415 - precision: 0.9937 - recall: 0.8917 - f1_score: 0.9394 - val_loss: 0.5115 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5241 - acc: 0.9415 - precision: 0.9938 - recall: 0.8921 - f1_score: 0.9395 - val_loss: 0.5099 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5225 - acc: 0.9415 - precision: 0.9928 - recall: 0.8928 - f1_score: 0.9391 - val_loss: 0.5083 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5209 - acc: 0.9415 - precision: 0.9940 - recall: 0.8909 - f1_score: 0.9384 - val_loss: 0.5067 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5194 - acc: 0.9415 - precision: 0.9931 - recall: 0.8916 - f1_score: 0.9389 - val_loss: 0.5051 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5178 - acc: 0.9415 - precision: 0.9923 - recall: 0.8878 - f1_score: 0.9363 - val_loss: 0.5035 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5162 - acc: 0.9415 - precision: 0.9910 - recall: 0.8925 - f1_score: 0.9384 - val_loss: 0.5020 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5147 - acc: 0.9415 - precision: 0.9921 - recall: 0.8977 - f1_score: 0.9411 - val_loss: 0.5004 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5131 - acc: 0.9415 - precision: 0.9932 - recall: 0.8914 - f1_score: 0.9388 - val_loss: 0.4989 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5116 - acc: 0.9415 - precision: 0.9918 - recall: 0.8883 - f1_score: 0.9363 - val_loss: 0.4973 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5101 - acc: 0.9415 - precision: 0.9938 - recall: 0.8918 - f1_score: 0.9386 - val_loss: 0.4958 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5085 - acc: 0.9415 - precision: 0.9945 - recall: 0.8883 - f1_score: 0.9372 - val_loss: 0.4943 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5070 - acc: 0.9415 - precision: 0.9930 - recall: 0.8950 - f1_score: 0.9407 - val_loss: 0.4927 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5055 - acc: 0.9415 - precision: 0.9926 - recall: 0.8914 - f1_score: 0.9384 - val_loss: 0.4912 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5040 - acc: 0.9415 - precision: 0.9924 - recall: 0.8858 - f1_score: 0.9348 - val_loss: 0.4897 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5025 - acc: 0.9415 - precision: 0.9937 - recall: 0.8969 - f1_score: 0.9419 - val_loss: 0.4882 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5010 - acc: 0.9415 - precision: 0.9934 - recall: 0.8900 - f1_score: 0.9371 - val_loss: 0.4867 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4996 - acc: 0.9415 - precision: 0.9937 - recall: 0.8954 - f1_score: 0.9405 - val_loss: 0.4852 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4981 - acc: 0.9415 - precision: 0.9924 - recall: 0.8906 - f1_score: 0.9378 - val_loss: 0.4838 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4966 - acc: 0.9415 - precision: 0.9934 - recall: 0.8941 - f1_score: 0.9392 - val_loss: 0.4823 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4952 - acc: 0.9415 - precision: 0.9935 - recall: 0.8917 - f1_score: 0.9391 - val_loss: 0.4808 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4937 - acc: 0.9415 - precision: 0.9936 - recall: 0.8915 - f1_score: 0.9392 - val_loss: 0.4794 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4923 - acc: 0.9415 - precision: 0.9933 - recall: 0.8970 - f1_score: 0.9413 - val_loss: 0.4779 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4908 - acc: 0.9415 - precision: 0.9918 - recall: 0.8923 - f1_score: 0.9389 - val_loss: 0.4765 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4894 - acc: 0.9415 - precision: 0.9940 - recall: 0.8912 - f1_score: 0.9385 - val_loss: 0.4751 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4880 - acc: 0.9415 - precision: 0.9935 - recall: 0.8933 - f1_score: 0.9404 - val_loss: 0.4736 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4866 - acc: 0.9415 - precision: 0.9933 - recall: 0.8950 - f1_score: 0.9408 - val_loss: 0.4722 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4852 - acc: 0.9415 - precision: 0.9932 - recall: 0.8971 - f1_score: 0.9413 - val_loss: 0.4708 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4838 - acc: 0.9415 - precision: 0.9928 - recall: 0.8933 - f1_score: 0.9396 - val_loss: 0.4694 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4824 - acc: 0.9415 - precision: 0.9932 - recall: 0.8926 - f1_score: 0.9389 - val_loss: 0.4680 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4810 - acc: 0.9415 - precision: 0.9930 - recall: 0.8928 - f1_score: 0.9395 - val_loss: 0.4666 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4796 - acc: 0.9415 - precision: 0.9944 - recall: 0.8882 - f1_score: 0.9367 - val_loss: 0.4652 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4782 - acc: 0.9415 - precision: 0.9933 - recall: 0.8912 - f1_score: 0.9386 - val_loss: 0.4638 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4769 - acc: 0.9415 - precision: 0.9927 - recall: 0.8912 - f1_score: 0.9381 - val_loss: 0.4624 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4755 - acc: 0.9415 - precision: 0.9938 - recall: 0.8954 - f1_score: 0.9409 - val_loss: 0.4611 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4742 - acc: 0.9415 - precision: 0.9923 - recall: 0.8924 - f1_score: 0.9391 - val_loss: 0.4597 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4728 - acc: 0.9415 - precision: 0.9930 - recall: 0.8872 - f1_score: 0.9360 - val_loss: 0.4584 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4715 - acc: 0.9415 - precision: 0.9934 - recall: 0.8902 - f1_score: 0.9370 - val_loss: 0.4570 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4701 - acc: 0.9415 - precision: 0.9939 - recall: 0.8936 - f1_score: 0.9404 - val_loss: 0.4557 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4688 - acc: 0.9415 - precision: 0.9934 - recall: 0.8932 - f1_score: 0.9392 - val_loss: 0.4544 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4675 - acc: 0.9415 - precision: 0.9927 - recall: 0.8933 - f1_score: 0.9400 - val_loss: 0.4530 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4662 - acc: 0.9415 - precision: 0.9940 - recall: 0.8889 - f1_score: 0.9373 - val_loss: 0.4517 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4649 - acc: 0.9415 - precision: 0.9931 - recall: 0.8945 - f1_score: 0.9400 - val_loss: 0.4504 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4636 - acc: 0.9415 - precision: 0.9939 - recall: 0.8965 - f1_score: 0.9414 - val_loss: 0.4491 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4623 - acc: 0.9415 - precision: 0.9926 - recall: 0.8891 - f1_score: 0.9366 - val_loss: 0.4478 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4610 - acc: 0.9415 - precision: 0.9942 - recall: 0.8896 - f1_score: 0.9376 - val_loss: 0.4465 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4597 - acc: 0.9415 - precision: 0.9923 - recall: 0.8914 - f1_score: 0.9384 - val_loss: 0.4452 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4584 - acc: 0.9415 - precision: 0.9933 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 0.4439 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4572 - acc: 0.9415 - precision: 0.9910 - recall: 0.8878 - f1_score: 0.9353 - val_loss: 0.4426 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4559 - acc: 0.9415 - precision: 0.9944 - recall: 0.8855 - f1_score: 0.9348 - val_loss: 0.4414 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4546 - acc: 0.9415 - precision: 0.9937 - recall: 0.8899 - f1_score: 0.9378 - val_loss: 0.4401 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4534 - acc: 0.9415 - precision: 0.9920 - recall: 0.8930 - f1_score: 0.9392 - val_loss: 0.4388 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4521 - acc: 0.9415 - precision: 0.9941 - recall: 0.8900 - f1_score: 0.9384 - val_loss: 0.4376 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4509 - acc: 0.9415 - precision: 0.9941 - recall: 0.8912 - f1_score: 0.9389 - val_loss: 0.4363 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4497 - acc: 0.9415 - precision: 0.9933 - recall: 0.8917 - f1_score: 0.9389 - val_loss: 0.4351 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4484 - acc: 0.9415 - precision: 0.9928 - recall: 0.8940 - f1_score: 0.9389 - val_loss: 0.4339 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4472 - acc: 0.9415 - precision: 0.9927 - recall: 0.8924 - f1_score: 0.9387 - val_loss: 0.4326 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4460 - acc: 0.9415 - precision: 0.9920 - recall: 0.8921 - f1_score: 0.9388 - val_loss: 0.4314 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4448 - acc: 0.9415 - precision: 0.9941 - recall: 0.8915 - f1_score: 0.9389 - val_loss: 0.4302 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4436 - acc: 0.9415 - precision: 0.9919 - recall: 0.8950 - f1_score: 0.9390 - val_loss: 0.4290 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4424 - acc: 0.9415 - precision: 0.9931 - recall: 0.8897 - f1_score: 0.9374 - val_loss: 0.4278 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4412 - acc: 0.9415 - precision: 0.9933 - recall: 0.8939 - f1_score: 0.9400 - val_loss: 0.4266 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4400 - acc: 0.9415 - precision: 0.9925 - recall: 0.8927 - f1_score: 0.9389 - val_loss: 0.4254 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 624/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4388 - acc: 0.9415 - precision: 0.9939 - recall: 0.8932 - f1_score: 0.9389 - val_loss: 0.4242 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4377 - acc: 0.9415 - precision: 0.9938 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.4230 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4365 - acc: 0.9415 - precision: 0.9933 - recall: 0.8981 - f1_score: 0.9425 - val_loss: 0.4218 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4353 - acc: 0.9415 - precision: 0.9943 - recall: 0.8877 - f1_score: 0.9370 - val_loss: 0.4206 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4342 - acc: 0.9415 - precision: 0.9928 - recall: 0.8943 - f1_score: 0.9401 - val_loss: 0.4195 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4330 - acc: 0.9415 - precision: 0.9926 - recall: 0.8958 - f1_score: 0.9406 - val_loss: 0.4183 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4319 - acc: 0.9415 - precision: 0.9925 - recall: 0.8898 - f1_score: 0.9370 - val_loss: 0.4172 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4307 - acc: 0.9415 - precision: 0.9931 - recall: 0.8905 - f1_score: 0.9370 - val_loss: 0.4160 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4296 - acc: 0.9415 - precision: 0.9935 - recall: 0.8891 - f1_score: 0.9368 - val_loss: 0.4149 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4285 - acc: 0.9415 - precision: 0.9920 - recall: 0.8911 - f1_score: 0.9383 - val_loss: 0.4137 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4274 - acc: 0.9415 - precision: 0.9935 - recall: 0.8909 - f1_score: 0.9381 - val_loss: 0.4126 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4262 - acc: 0.9415 - precision: 0.9923 - recall: 0.8914 - f1_score: 0.9382 - val_loss: 0.4115 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4251 - acc: 0.9415 - precision: 0.9944 - recall: 0.8900 - f1_score: 0.9388 - val_loss: 0.4104 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4240 - acc: 0.9415 - precision: 0.9931 - recall: 0.8965 - f1_score: 0.9408 - val_loss: 0.4093 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4229 - acc: 0.9415 - precision: 0.9931 - recall: 0.8918 - f1_score: 0.9391 - val_loss: 0.4081 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4218 - acc: 0.9415 - precision: 0.9926 - recall: 0.8926 - f1_score: 0.9397 - val_loss: 0.4070 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4207 - acc: 0.9415 - precision: 0.9932 - recall: 0.8936 - f1_score: 0.9401 - val_loss: 0.4059 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4196 - acc: 0.9415 - precision: 0.9929 - recall: 0.8906 - f1_score: 0.9382 - val_loss: 0.4048 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4186 - acc: 0.9415 - precision: 0.9936 - recall: 0.8928 - f1_score: 0.9393 - val_loss: 0.4038 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4175 - acc: 0.9415 - precision: 0.9929 - recall: 0.8874 - f1_score: 0.9361 - val_loss: 0.4027 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4164 - acc: 0.9415 - precision: 0.9938 - recall: 0.8869 - f1_score: 0.9359 - val_loss: 0.4016 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4154 - acc: 0.9415 - precision: 0.9938 - recall: 0.8921 - f1_score: 0.9389 - val_loss: 0.4005 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4143 - acc: 0.9415 - precision: 0.9942 - recall: 0.8893 - f1_score: 0.9379 - val_loss: 0.3994 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4132 - acc: 0.9415 - precision: 0.9918 - recall: 0.8900 - f1_score: 0.9370 - val_loss: 0.3984 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4122 - acc: 0.9415 - precision: 0.9938 - recall: 0.8924 - f1_score: 0.9388 - val_loss: 0.3973 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4111 - acc: 0.9415 - precision: 0.9935 - recall: 0.8884 - f1_score: 0.9363 - val_loss: 0.3963 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4101 - acc: 0.9415 - precision: 0.9929 - recall: 0.8932 - f1_score: 0.9396 - val_loss: 0.3952 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4091 - acc: 0.9415 - precision: 0.9931 - recall: 0.8884 - f1_score: 0.9365 - val_loss: 0.3942 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4080 - acc: 0.9415 - precision: 0.9923 - recall: 0.8953 - f1_score: 0.9397 - val_loss: 0.3931 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4070 - acc: 0.9415 - precision: 0.9935 - recall: 0.8966 - f1_score: 0.9413 - val_loss: 0.3921 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4060 - acc: 0.9415 - precision: 0.9937 - recall: 0.8912 - f1_score: 0.9388 - val_loss: 0.3910 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4050 - acc: 0.9415 - precision: 0.9930 - recall: 0.8913 - f1_score: 0.9388 - val_loss: 0.3900 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4040 - acc: 0.9415 - precision: 0.9919 - recall: 0.8867 - f1_score: 0.9348 - val_loss: 0.3890 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4030 - acc: 0.9415 - precision: 0.9930 - recall: 0.8944 - f1_score: 0.9400 - val_loss: 0.3880 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4020 - acc: 0.9415 - precision: 0.9935 - recall: 0.8863 - f1_score: 0.9351 - val_loss: 0.3870 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4010 - acc: 0.9415 - precision: 0.9916 - recall: 0.8934 - f1_score: 0.9392 - val_loss: 0.3860 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4000 - acc: 0.9415 - precision: 0.9934 - recall: 0.8922 - f1_score: 0.9388 - val_loss: 0.3849 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3990 - acc: 0.9415 - precision: 0.9938 - recall: 0.8937 - f1_score: 0.9395 - val_loss: 0.3839 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3980 - acc: 0.9415 - precision: 0.9937 - recall: 0.8897 - f1_score: 0.9372 - val_loss: 0.3830 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3970 - acc: 0.9415 - precision: 0.9933 - recall: 0.8934 - f1_score: 0.9402 - val_loss: 0.3820 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3961 - acc: 0.9415 - precision: 0.9919 - recall: 0.8892 - f1_score: 0.9373 - val_loss: 0.3810 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3951 - acc: 0.9415 - precision: 0.9925 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.3800 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3941 - acc: 0.9415 - precision: 0.9928 - recall: 0.8941 - f1_score: 0.9396 - val_loss: 0.3790 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3932 - acc: 0.9415 - precision: 0.9932 - recall: 0.8921 - f1_score: 0.9387 - val_loss: 0.3781 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3922 - acc: 0.9415 - precision: 0.9914 - recall: 0.8927 - f1_score: 0.9382 - val_loss: 0.3771 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3913 - acc: 0.9415 - precision: 0.9934 - recall: 0.8923 - f1_score: 0.9390 - val_loss: 0.3761 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3903 - acc: 0.9415 - precision: 0.9934 - recall: 0.8927 - f1_score: 0.9384 - val_loss: 0.3752 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3894 - acc: 0.9415 - precision: 0.9932 - recall: 0.8853 - f1_score: 0.9342 - val_loss: 0.3742 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3884 - acc: 0.9415 - precision: 0.9935 - recall: 0.8909 - f1_score: 0.9385 - val_loss: 0.3733 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3875 - acc: 0.9415 - precision: 0.9928 - recall: 0.8918 - f1_score: 0.9387 - val_loss: 0.3723 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3866 - acc: 0.9415 - precision: 0.9935 - recall: 0.8907 - f1_score: 0.9385 - val_loss: 0.3714 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3857 - acc: 0.9415 - precision: 0.9938 - recall: 0.8889 - f1_score: 0.9377 - val_loss: 0.3705 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3847 - acc: 0.9415 - precision: 0.9933 - recall: 0.8943 - f1_score: 0.9405 - val_loss: 0.3695 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3838 - acc: 0.9415 - precision: 0.9931 - recall: 0.8926 - f1_score: 0.9395 - val_loss: 0.3686 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3829 - acc: 0.9415 - precision: 0.9935 - recall: 0.8926 - f1_score: 0.9391 - val_loss: 0.3677 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3820 - acc: 0.9415 - precision: 0.9912 - recall: 0.8908 - f1_score: 0.9370 - val_loss: 0.3668 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3811 - acc: 0.9415 - precision: 0.9937 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.3659 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3802 - acc: 0.9415 - precision: 0.9924 - recall: 0.8867 - f1_score: 0.9354 - val_loss: 0.3650 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3793 - acc: 0.9415 - precision: 0.9936 - recall: 0.8876 - f1_score: 0.9361 - val_loss: 0.3641 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3784 - acc: 0.9415 - precision: 0.9934 - recall: 0.8890 - f1_score: 0.9356 - val_loss: 0.3632 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3776 - acc: 0.9415 - precision: 0.9939 - recall: 0.8903 - f1_score: 0.9387 - val_loss: 0.3623 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3767 - acc: 0.9415 - precision: 0.9932 - recall: 0.8922 - f1_score: 0.9397 - val_loss: 0.3614 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3758 - acc: 0.9415 - precision: 0.9939 - recall: 0.8878 - f1_score: 0.9366 - val_loss: 0.3605 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3749 - acc: 0.9415 - precision: 0.9929 - recall: 0.8933 - f1_score: 0.9392 - val_loss: 0.3596 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3741 - acc: 0.9415 - precision: 0.9944 - recall: 0.8927 - f1_score: 0.9394 - val_loss: 0.3588 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3732 - acc: 0.9415 - precision: 0.9932 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 0.3579 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3724 - acc: 0.9415 - precision: 0.9926 - recall: 0.8936 - f1_score: 0.9394 - val_loss: 0.3570 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3715 - acc: 0.9415 - precision: 0.9941 - recall: 0.8929 - f1_score: 0.9401 - val_loss: 0.3561 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3707 - acc: 0.9415 - precision: 0.9921 - recall: 0.8927 - f1_score: 0.9393 - val_loss: 0.3553 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3698 - acc: 0.9415 - precision: 0.9923 - recall: 0.8941 - f1_score: 0.9397 - val_loss: 0.3544 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3690 - acc: 0.9415 - precision: 0.9938 - recall: 0.8908 - f1_score: 0.9383 - val_loss: 0.3536 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3681 - acc: 0.9415 - precision: 0.9925 - recall: 0.8911 - f1_score: 0.9376 - val_loss: 0.3527 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3673 - acc: 0.9415 - precision: 0.9929 - recall: 0.8920 - f1_score: 0.9394 - val_loss: 0.3519 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3665 - acc: 0.9415 - precision: 0.9938 - recall: 0.8925 - f1_score: 0.9398 - val_loss: 0.3510 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3656 - acc: 0.9415 - precision: 0.9934 - recall: 0.8946 - f1_score: 0.9403 - val_loss: 0.3502 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3648 - acc: 0.9415 - precision: 0.9938 - recall: 0.8922 - f1_score: 0.9395 - val_loss: 0.3493 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3640 - acc: 0.9415 - precision: 0.9938 - recall: 0.8946 - f1_score: 0.9404 - val_loss: 0.3485 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3632 - acc: 0.9415 - precision: 0.9935 - recall: 0.8949 - f1_score: 0.9400 - val_loss: 0.3477 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3624 - acc: 0.9415 - precision: 0.9926 - recall: 0.8929 - f1_score: 0.9395 - val_loss: 0.3469 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3616 - acc: 0.9415 - precision: 0.9931 - recall: 0.8930 - f1_score: 0.9387 - val_loss: 0.3461 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3608 - acc: 0.9415 - precision: 0.9928 - recall: 0.8926 - f1_score: 0.9393 - val_loss: 0.3452 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3600 - acc: 0.9415 - precision: 0.9939 - recall: 0.8911 - f1_score: 0.9380 - val_loss: 0.3444 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3592 - acc: 0.9415 - precision: 0.9925 - recall: 0.8873 - f1_score: 0.9354 - val_loss: 0.3436 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3584 - acc: 0.9415 - precision: 0.9941 - recall: 0.8906 - f1_score: 0.9388 - val_loss: 0.3428 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3576 - acc: 0.9415 - precision: 0.9931 - recall: 0.8935 - f1_score: 0.9392 - val_loss: 0.3420 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3568 - acc: 0.9415 - precision: 0.9935 - recall: 0.8925 - f1_score: 0.9394 - val_loss: 0.3412 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3560 - acc: 0.9415 - precision: 0.9927 - recall: 0.8969 - f1_score: 0.9412 - val_loss: 0.3404 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3553 - acc: 0.9415 - precision: 0.9922 - recall: 0.8892 - f1_score: 0.9369 - val_loss: 0.3396 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3545 - acc: 0.9415 - precision: 0.9925 - recall: 0.8897 - f1_score: 0.9361 - val_loss: 0.3388 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3537 - acc: 0.9415 - precision: 0.9933 - recall: 0.8937 - f1_score: 0.9404 - val_loss: 0.3381 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3529 - acc: 0.9415 - precision: 0.9933 - recall: 0.8928 - f1_score: 0.9400 - val_loss: 0.3373 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3522 - acc: 0.9415 - precision: 0.9919 - recall: 0.8925 - f1_score: 0.9393 - val_loss: 0.3365 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3514 - acc: 0.9415 - precision: 0.9934 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.3357 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3507 - acc: 0.9415 - precision: 0.9920 - recall: 0.8873 - f1_score: 0.9357 - val_loss: 0.3350 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3499 - acc: 0.9415 - precision: 0.9925 - recall: 0.8983 - f1_score: 0.9417 - val_loss: 0.3342 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3492 - acc: 0.9415 - precision: 0.9931 - recall: 0.8933 - f1_score: 0.9398 - val_loss: 0.3335 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 720/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3484 - acc: 0.9415 - precision: 0.9940 - recall: 0.8882 - f1_score: 0.9358 - val_loss: 0.3327 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3477 - acc: 0.9415 - precision: 0.9932 - recall: 0.8855 - f1_score: 0.9351 - val_loss: 0.3319 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3470 - acc: 0.9415 - precision: 0.9919 - recall: 0.8898 - f1_score: 0.9372 - val_loss: 0.3312 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3462 - acc: 0.9415 - precision: 0.9913 - recall: 0.8912 - f1_score: 0.9374 - val_loss: 0.3304 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3455 - acc: 0.9415 - precision: 0.9936 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 0.3297 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3448 - acc: 0.9415 - precision: 0.9929 - recall: 0.8895 - f1_score: 0.9367 - val_loss: 0.3289 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3440 - acc: 0.9415 - precision: 0.9926 - recall: 0.8905 - f1_score: 0.9374 - val_loss: 0.3282 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3433 - acc: 0.9415 - precision: 0.9934 - recall: 0.8932 - f1_score: 0.9392 - val_loss: 0.3275 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3426 - acc: 0.9415 - precision: 0.9924 - recall: 0.8932 - f1_score: 0.9394 - val_loss: 0.3268 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3419 - acc: 0.9415 - precision: 0.9937 - recall: 0.8909 - f1_score: 0.9381 - val_loss: 0.3260 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3412 - acc: 0.9415 - precision: 0.9897 - recall: 0.8842 - f1_score: 0.9330 - val_loss: 0.3253 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3405 - acc: 0.9415 - precision: 0.9933 - recall: 0.8918 - f1_score: 0.9388 - val_loss: 0.3246 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3398 - acc: 0.9415 - precision: 0.9914 - recall: 0.8908 - f1_score: 0.9374 - val_loss: 0.3239 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3391 - acc: 0.9415 - precision: 0.9936 - recall: 0.8918 - f1_score: 0.9395 - val_loss: 0.3231 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3384 - acc: 0.9415 - precision: 0.9932 - recall: 0.8908 - f1_score: 0.9374 - val_loss: 0.3224 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3377 - acc: 0.9415 - precision: 0.9923 - recall: 0.8895 - f1_score: 0.9371 - val_loss: 0.3217 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3370 - acc: 0.9415 - precision: 0.9933 - recall: 0.8907 - f1_score: 0.9386 - val_loss: 0.3210 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3363 - acc: 0.9415 - precision: 0.9934 - recall: 0.8938 - f1_score: 0.9402 - val_loss: 0.3203 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3356 - acc: 0.9415 - precision: 0.9931 - recall: 0.8948 - f1_score: 0.9394 - val_loss: 0.3196 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3349 - acc: 0.9415 - precision: 0.9938 - recall: 0.8892 - f1_score: 0.9378 - val_loss: 0.3189 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3343 - acc: 0.9415 - precision: 0.9929 - recall: 0.8918 - f1_score: 0.9388 - val_loss: 0.3182 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3336 - acc: 0.9415 - precision: 0.9934 - recall: 0.8931 - f1_score: 0.9397 - val_loss: 0.3175 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3329 - acc: 0.9415 - precision: 0.9911 - recall: 0.8917 - f1_score: 0.9378 - val_loss: 0.3169 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3322 - acc: 0.9415 - precision: 0.9934 - recall: 0.8928 - f1_score: 0.9396 - val_loss: 0.3162 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3316 - acc: 0.9415 - precision: 0.9931 - recall: 0.8910 - f1_score: 0.9390 - val_loss: 0.3155 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3309 - acc: 0.9415 - precision: 0.9926 - recall: 0.8903 - f1_score: 0.9379 - val_loss: 0.3148 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3303 - acc: 0.9415 - precision: 0.9928 - recall: 0.8918 - f1_score: 0.9386 - val_loss: 0.3142 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3296 - acc: 0.9415 - precision: 0.9926 - recall: 0.8928 - f1_score: 0.9393 - val_loss: 0.3135 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3290 - acc: 0.9415 - precision: 0.9913 - recall: 0.8882 - f1_score: 0.9359 - val_loss: 0.3128 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3283 - acc: 0.9415 - precision: 0.9928 - recall: 0.8923 - f1_score: 0.9393 - val_loss: 0.3122 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3277 - acc: 0.9415 - precision: 0.9927 - recall: 0.8925 - f1_score: 0.9390 - val_loss: 0.3115 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3270 - acc: 0.9415 - precision: 0.9928 - recall: 0.8907 - f1_score: 0.9381 - val_loss: 0.3109 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 752/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3264 - acc: 0.9415 - precision: 0.9931 - recall: 0.8928 - f1_score: 0.9390 - val_loss: 0.3102 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3257 - acc: 0.9415 - precision: 0.9937 - recall: 0.8902 - f1_score: 0.9363 - val_loss: 0.3096 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3251 - acc: 0.9415 - precision: 0.9935 - recall: 0.8945 - f1_score: 0.9404 - val_loss: 0.3089 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3245 - acc: 0.9415 - precision: 0.9934 - recall: 0.8928 - f1_score: 0.9392 - val_loss: 0.3083 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3238 - acc: 0.9415 - precision: 0.9941 - recall: 0.8929 - f1_score: 0.9390 - val_loss: 0.3077 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3232 - acc: 0.9415 - precision: 0.9935 - recall: 0.8891 - f1_score: 0.9372 - val_loss: 0.3070 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3226 - acc: 0.9415 - precision: 0.9939 - recall: 0.8881 - f1_score: 0.9367 - val_loss: 0.3064 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3220 - acc: 0.9415 - precision: 0.9939 - recall: 0.8913 - f1_score: 0.9381 - val_loss: 0.3057 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3214 - acc: 0.9415 - precision: 0.9923 - recall: 0.8914 - f1_score: 0.9385 - val_loss: 0.3051 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3208 - acc: 0.9415 - precision: 0.9928 - recall: 0.8870 - f1_score: 0.9346 - val_loss: 0.3045 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3201 - acc: 0.9415 - precision: 0.9926 - recall: 0.8919 - f1_score: 0.9366 - val_loss: 0.3039 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3195 - acc: 0.9415 - precision: 0.9926 - recall: 0.8916 - f1_score: 0.9388 - val_loss: 0.3033 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3189 - acc: 0.9415 - precision: 0.9934 - recall: 0.8884 - f1_score: 0.9369 - val_loss: 0.3027 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3183 - acc: 0.9415 - precision: 0.9935 - recall: 0.8936 - f1_score: 0.9399 - val_loss: 0.3020 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3177 - acc: 0.9415 - precision: 0.9929 - recall: 0.8930 - f1_score: 0.9379 - val_loss: 0.3014 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3171 - acc: 0.9415 - precision: 0.9926 - recall: 0.8902 - f1_score: 0.9377 - val_loss: 0.3008 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3165 - acc: 0.9415 - precision: 0.9933 - recall: 0.8962 - f1_score: 0.9411 - val_loss: 0.3002 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3159 - acc: 0.9415 - precision: 0.9921 - recall: 0.8883 - f1_score: 0.9358 - val_loss: 0.2996 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3154 - acc: 0.9415 - precision: 0.9928 - recall: 0.8952 - f1_score: 0.9406 - val_loss: 0.2990 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3148 - acc: 0.9415 - precision: 0.9931 - recall: 0.8889 - f1_score: 0.9373 - val_loss: 0.2984 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3142 - acc: 0.9415 - precision: 0.9945 - recall: 0.8913 - f1_score: 0.9389 - val_loss: 0.2978 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3136 - acc: 0.9415 - precision: 0.9938 - recall: 0.8938 - f1_score: 0.9403 - val_loss: 0.2972 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3130 - acc: 0.9415 - precision: 0.9933 - recall: 0.8916 - f1_score: 0.9379 - val_loss: 0.2966 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3125 - acc: 0.9415 - precision: 0.9929 - recall: 0.8934 - f1_score: 0.9395 - val_loss: 0.2961 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3119 - acc: 0.9415 - precision: 0.9928 - recall: 0.8898 - f1_score: 0.9372 - val_loss: 0.2955 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3113 - acc: 0.9415 - precision: 0.9915 - recall: 0.8924 - f1_score: 0.9383 - val_loss: 0.2949 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3107 - acc: 0.9415 - precision: 0.9935 - recall: 0.8937 - f1_score: 0.9394 - val_loss: 0.2943 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3102 - acc: 0.9415 - precision: 0.9939 - recall: 0.8926 - f1_score: 0.9391 - val_loss: 0.2937 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3096 - acc: 0.9415 - precision: 0.9937 - recall: 0.8962 - f1_score: 0.9409 - val_loss: 0.2932 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3091 - acc: 0.9415 - precision: 0.9931 - recall: 0.8946 - f1_score: 0.9408 - val_loss: 0.2926 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3085 - acc: 0.9415 - precision: 0.9919 - recall: 0.8945 - f1_score: 0.9394 - val_loss: 0.2920 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3079 - acc: 0.9415 - precision: 0.9924 - recall: 0.8912 - f1_score: 0.9387 - val_loss: 0.2914 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 784/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3074 - acc: 0.9415 - precision: 0.9916 - recall: 0.8948 - f1_score: 0.9395 - val_loss: 0.2909 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3068 - acc: 0.9415 - precision: 0.9944 - recall: 0.8929 - f1_score: 0.9395 - val_loss: 0.2903 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3063 - acc: 0.9415 - precision: 0.9933 - recall: 0.8924 - f1_score: 0.9394 - val_loss: 0.2898 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9431 - precision: 0.9930 - recall: 0.8989 - f1_score: 0.9424 - val_loss: 0.2892 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3052 - acc: 0.9431 - precision: 0.9928 - recall: 0.8923 - f1_score: 0.9388 - val_loss: 0.2887 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3047 - acc: 0.9431 - precision: 0.9928 - recall: 0.8955 - f1_score: 0.9413 - val_loss: 0.2881 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3041 - acc: 0.9431 - precision: 0.9923 - recall: 0.8957 - f1_score: 0.9403 - val_loss: 0.2875 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3036 - acc: 0.9431 - precision: 0.9925 - recall: 0.8938 - f1_score: 0.9394 - val_loss: 0.2870 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3031 - acc: 0.9431 - precision: 0.9928 - recall: 0.8950 - f1_score: 0.9405 - val_loss: 0.2865 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3025 - acc: 0.9431 - precision: 0.9931 - recall: 0.8904 - f1_score: 0.9377 - val_loss: 0.2859 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3020 - acc: 0.9431 - precision: 0.9918 - recall: 0.8935 - f1_score: 0.9400 - val_loss: 0.2853 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3015 - acc: 0.9431 - precision: 0.9939 - recall: 0.8967 - f1_score: 0.9409 - val_loss: 0.2848 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3010 - acc: 0.9431 - precision: 0.9928 - recall: 0.8928 - f1_score: 0.9390 - val_loss: 0.2843 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3004 - acc: 0.9431 - precision: 0.9936 - recall: 0.8930 - f1_score: 0.9400 - val_loss: 0.2837 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2999 - acc: 0.9431 - precision: 0.9929 - recall: 0.8959 - f1_score: 0.9414 - val_loss: 0.2832 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2994 - acc: 0.9431 - precision: 0.9933 - recall: 0.8962 - f1_score: 0.9416 - val_loss: 0.2827 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2989 - acc: 0.9431 - precision: 0.9929 - recall: 0.8945 - f1_score: 0.9405 - val_loss: 0.2822 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2984 - acc: 0.9431 - precision: 0.9931 - recall: 0.8948 - f1_score: 0.9407 - val_loss: 0.2816 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2979 - acc: 0.9431 - precision: 0.9936 - recall: 0.8912 - f1_score: 0.9390 - val_loss: 0.2811 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2974 - acc: 0.9431 - precision: 0.9934 - recall: 0.8945 - f1_score: 0.9409 - val_loss: 0.2806 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2969 - acc: 0.9431 - precision: 0.9930 - recall: 0.8934 - f1_score: 0.9387 - val_loss: 0.2801 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2964 - acc: 0.9431 - precision: 0.9941 - recall: 0.8951 - f1_score: 0.9417 - val_loss: 0.2795 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2959 - acc: 0.9431 - precision: 0.9931 - recall: 0.8933 - f1_score: 0.9394 - val_loss: 0.2790 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2954 - acc: 0.9431 - precision: 0.9905 - recall: 0.8914 - f1_score: 0.9371 - val_loss: 0.2785 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2949 - acc: 0.9431 - precision: 0.9926 - recall: 0.8957 - f1_score: 0.9409 - val_loss: 0.2780 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2944 - acc: 0.9431 - precision: 0.9928 - recall: 0.8970 - f1_score: 0.9416 - val_loss: 0.2775 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2939 - acc: 0.9431 - precision: 0.9935 - recall: 0.8946 - f1_score: 0.9407 - val_loss: 0.2770 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2934 - acc: 0.9431 - precision: 0.9936 - recall: 0.8923 - f1_score: 0.9389 - val_loss: 0.2765 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2929 - acc: 0.9431 - precision: 0.9931 - recall: 0.8952 - f1_score: 0.9404 - val_loss: 0.2760 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2924 - acc: 0.9431 - precision: 0.9919 - recall: 0.8924 - f1_score: 0.9379 - val_loss: 0.2755 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2920 - acc: 0.9431 - precision: 0.9923 - recall: 0.8960 - f1_score: 0.9409 - val_loss: 0.2750 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2915 - acc: 0.9431 - precision: 0.9937 - recall: 0.8949 - f1_score: 0.9408 - val_loss: 0.2745 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2910 - acc: 0.9431 - precision: 0.9926 - recall: 0.8972 - f1_score: 0.9408 - val_loss: 0.2740 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2905 - acc: 0.9431 - precision: 0.9931 - recall: 0.8921 - f1_score: 0.9381 - val_loss: 0.2735 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2901 - acc: 0.9431 - precision: 0.9930 - recall: 0.8973 - f1_score: 0.9420 - val_loss: 0.2730 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2896 - acc: 0.9431 - precision: 0.9935 - recall: 0.9004 - f1_score: 0.9435 - val_loss: 0.2726 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2891 - acc: 0.9431 - precision: 0.9934 - recall: 0.8985 - f1_score: 0.9427 - val_loss: 0.2721 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2887 - acc: 0.9431 - precision: 0.9917 - recall: 0.8959 - f1_score: 0.9403 - val_loss: 0.2716 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2882 - acc: 0.9431 - precision: 0.9937 - recall: 0.8971 - f1_score: 0.9420 - val_loss: 0.2711 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2877 - acc: 0.9431 - precision: 0.9945 - recall: 0.8967 - f1_score: 0.9417 - val_loss: 0.2706 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2873 - acc: 0.9431 - precision: 0.9937 - recall: 0.8953 - f1_score: 0.9405 - val_loss: 0.2702 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2868 - acc: 0.9431 - precision: 0.9931 - recall: 0.9012 - f1_score: 0.9438 - val_loss: 0.2697 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2864 - acc: 0.9431 - precision: 0.9926 - recall: 0.8977 - f1_score: 0.9416 - val_loss: 0.2692 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2859 - acc: 0.9431 - precision: 0.9934 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.2688 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2855 - acc: 0.9431 - precision: 0.9928 - recall: 0.8906 - f1_score: 0.9380 - val_loss: 0.2683 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2850 - acc: 0.9431 - precision: 0.9940 - recall: 0.8976 - f1_score: 0.9423 - val_loss: 0.2678 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2846 - acc: 0.9431 - precision: 0.9928 - recall: 0.8958 - f1_score: 0.9412 - val_loss: 0.2674 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2841 - acc: 0.9431 - precision: 0.9920 - recall: 0.8958 - f1_score: 0.9402 - val_loss: 0.2669 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2837 - acc: 0.9431 - precision: 0.9923 - recall: 0.8955 - f1_score: 0.9407 - val_loss: 0.2664 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2832 - acc: 0.9431 - precision: 0.9935 - recall: 0.8971 - f1_score: 0.9422 - val_loss: 0.2660 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2828 - acc: 0.9431 - precision: 0.9922 - recall: 0.8933 - f1_score: 0.9391 - val_loss: 0.2655 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2824 - acc: 0.9431 - precision: 0.9930 - recall: 0.8975 - f1_score: 0.9422 - val_loss: 0.2651 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2819 - acc: 0.9431 - precision: 0.9936 - recall: 0.8969 - f1_score: 0.9418 - val_loss: 0.2646 - val_acc: 0.9620 - val_precision: 0.9849 - val_recall: 0.9183 - val_f1_score: 0.9477\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2815 - acc: 0.9431 - precision: 0.9935 - recall: 0.8960 - f1_score: 0.9413 - val_loss: 0.2642 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2811 - acc: 0.9431 - precision: 0.9928 - recall: 0.8962 - f1_score: 0.9416 - val_loss: 0.2637 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2806 - acc: 0.9431 - precision: 0.9921 - recall: 0.8909 - f1_score: 0.9376 - val_loss: 0.2633 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2802 - acc: 0.9431 - precision: 0.9931 - recall: 0.8952 - f1_score: 0.9409 - val_loss: 0.2628 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2798 - acc: 0.9431 - precision: 0.9935 - recall: 0.8960 - f1_score: 0.9414 - val_loss: 0.2624 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2794 - acc: 0.9431 - precision: 0.9934 - recall: 0.8951 - f1_score: 0.9394 - val_loss: 0.2620 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2789 - acc: 0.9431 - precision: 0.9937 - recall: 0.8970 - f1_score: 0.9420 - val_loss: 0.2615 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9431 - precision: 0.9936 - recall: 0.8955 - f1_score: 0.9413 - val_loss: 0.2611 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2781 - acc: 0.9431 - precision: 0.9932 - recall: 0.8950 - f1_score: 0.9396 - val_loss: 0.2607 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2777 - acc: 0.9431 - precision: 0.9937 - recall: 0.8951 - f1_score: 0.9405 - val_loss: 0.2602 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2773 - acc: 0.9431 - precision: 0.9928 - recall: 0.8963 - f1_score: 0.9414 - val_loss: 0.2598 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2769 - acc: 0.9431 - precision: 0.9937 - recall: 0.8938 - f1_score: 0.9399 - val_loss: 0.2594 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2764 - acc: 0.9431 - precision: 0.9939 - recall: 0.8937 - f1_score: 0.9401 - val_loss: 0.2590 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9431 - precision: 0.9935 - recall: 0.8917 - f1_score: 0.9377 - val_loss: 0.2585 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2756 - acc: 0.9431 - precision: 0.9928 - recall: 0.8913 - f1_score: 0.9387 - val_loss: 0.2581 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2752 - acc: 0.9431 - precision: 0.9942 - recall: 0.8943 - f1_score: 0.9405 - val_loss: 0.2577 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2748 - acc: 0.9431 - precision: 0.9932 - recall: 0.8961 - f1_score: 0.9411 - val_loss: 0.2573 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9431 - precision: 0.9931 - recall: 0.8981 - f1_score: 0.9413 - val_loss: 0.2569 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9431 - precision: 0.9930 - recall: 0.8931 - f1_score: 0.9387 - val_loss: 0.2564 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2736 - acc: 0.9431 - precision: 0.9928 - recall: 0.8936 - f1_score: 0.9398 - val_loss: 0.2560 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2732 - acc: 0.9431 - precision: 0.9934 - recall: 0.8957 - f1_score: 0.9413 - val_loss: 0.2556 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2728 - acc: 0.9431 - precision: 0.9928 - recall: 0.8934 - f1_score: 0.9398 - val_loss: 0.2552 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2724 - acc: 0.9431 - precision: 0.9926 - recall: 0.8942 - f1_score: 0.9401 - val_loss: 0.2548 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9431 - precision: 0.9905 - recall: 0.8962 - f1_score: 0.9397 - val_loss: 0.2544 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2717 - acc: 0.9431 - precision: 0.9928 - recall: 0.8925 - f1_score: 0.9390 - val_loss: 0.2540 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2713 - acc: 0.9431 - precision: 0.9935 - recall: 0.8982 - f1_score: 0.9427 - val_loss: 0.2536 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2709 - acc: 0.9431 - precision: 0.9935 - recall: 0.8947 - f1_score: 0.9410 - val_loss: 0.2532 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2705 - acc: 0.9431 - precision: 0.9941 - recall: 0.8964 - f1_score: 0.9410 - val_loss: 0.2528 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9431 - precision: 0.9919 - recall: 0.8908 - f1_score: 0.9367 - val_loss: 0.2524 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9431 - precision: 0.9932 - recall: 0.8980 - f1_score: 0.9423 - val_loss: 0.2520 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2694 - acc: 0.9431 - precision: 0.9930 - recall: 0.8945 - f1_score: 0.9409 - val_loss: 0.2516 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2690 - acc: 0.9431 - precision: 0.9926 - recall: 0.8975 - f1_score: 0.9416 - val_loss: 0.2512 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2686 - acc: 0.9431 - precision: 0.9932 - recall: 0.8956 - f1_score: 0.9405 - val_loss: 0.2508 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2682 - acc: 0.9431 - precision: 0.9926 - recall: 0.8935 - f1_score: 0.9386 - val_loss: 0.2505 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2679 - acc: 0.9431 - precision: 0.9935 - recall: 0.8945 - f1_score: 0.9400 - val_loss: 0.2501 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2675 - acc: 0.9431 - precision: 0.9940 - recall: 0.8912 - f1_score: 0.9383 - val_loss: 0.2497 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2671 - acc: 0.9431 - precision: 0.9925 - recall: 0.8971 - f1_score: 0.9402 - val_loss: 0.2493 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2668 - acc: 0.9431 - precision: 0.9938 - recall: 0.8916 - f1_score: 0.9389 - val_loss: 0.2489 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2664 - acc: 0.9431 - precision: 0.9928 - recall: 0.8969 - f1_score: 0.9409 - val_loss: 0.2485 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2661 - acc: 0.9431 - precision: 0.9901 - recall: 0.8961 - f1_score: 0.9398 - val_loss: 0.2482 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2657 - acc: 0.9431 - precision: 0.9939 - recall: 0.8956 - f1_score: 0.9409 - val_loss: 0.2478 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2653 - acc: 0.9431 - precision: 0.9913 - recall: 0.8901 - f1_score: 0.9370 - val_loss: 0.2474 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2650 - acc: 0.9431 - precision: 0.9935 - recall: 0.8960 - f1_score: 0.9403 - val_loss: 0.2471 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 880/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2646 - acc: 0.9431 - precision: 0.9927 - recall: 0.8947 - f1_score: 0.9407 - val_loss: 0.2467 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2642 - acc: 0.9431 - precision: 0.9925 - recall: 0.8896 - f1_score: 0.9366 - val_loss: 0.2463 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2639 - acc: 0.9431 - precision: 0.9937 - recall: 0.8955 - f1_score: 0.9415 - val_loss: 0.2459 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2635 - acc: 0.9431 - precision: 0.9939 - recall: 0.8943 - f1_score: 0.9406 - val_loss: 0.2456 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2632 - acc: 0.9431 - precision: 0.9939 - recall: 0.8938 - f1_score: 0.9400 - val_loss: 0.2452 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2629 - acc: 0.9431 - precision: 0.9935 - recall: 0.8971 - f1_score: 0.9414 - val_loss: 0.2449 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2625 - acc: 0.9431 - precision: 0.9933 - recall: 0.8952 - f1_score: 0.9410 - val_loss: 0.2445 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2622 - acc: 0.9431 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9394 - val_loss: 0.2441 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2618 - acc: 0.9431 - precision: 0.9942 - recall: 0.8940 - f1_score: 0.9390 - val_loss: 0.2437 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2615 - acc: 0.9431 - precision: 0.9935 - recall: 0.8956 - f1_score: 0.9408 - val_loss: 0.2434 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2611 - acc: 0.9431 - precision: 0.9937 - recall: 0.8946 - f1_score: 0.9403 - val_loss: 0.2430 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2608 - acc: 0.9431 - precision: 0.9933 - recall: 0.8957 - f1_score: 0.9403 - val_loss: 0.2427 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2605 - acc: 0.9431 - precision: 0.9937 - recall: 0.8957 - f1_score: 0.9406 - val_loss: 0.2423 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2601 - acc: 0.9431 - precision: 0.9937 - recall: 0.8960 - f1_score: 0.9408 - val_loss: 0.2420 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9431 - precision: 0.9930 - recall: 0.8968 - f1_score: 0.9411 - val_loss: 0.2416 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2595 - acc: 0.9431 - precision: 0.9930 - recall: 0.8945 - f1_score: 0.9389 - val_loss: 0.2413 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2591 - acc: 0.9431 - precision: 0.9939 - recall: 0.8943 - f1_score: 0.9403 - val_loss: 0.2409 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2588 - acc: 0.9431 - precision: 0.9931 - recall: 0.8980 - f1_score: 0.9413 - val_loss: 0.2406 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9431 - precision: 0.9935 - recall: 0.8956 - f1_score: 0.9406 - val_loss: 0.2402 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9431 - precision: 0.9939 - recall: 0.8923 - f1_score: 0.9389 - val_loss: 0.2399 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9431 - precision: 0.9931 - recall: 0.8983 - f1_score: 0.9423 - val_loss: 0.2396 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9431 - precision: 0.9930 - recall: 0.8975 - f1_score: 0.9418 - val_loss: 0.2392 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9431 - precision: 0.9923 - recall: 0.8922 - f1_score: 0.9385 - val_loss: 0.2389 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2568 - acc: 0.9431 - precision: 0.9938 - recall: 0.8958 - f1_score: 0.9413 - val_loss: 0.2385 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9431 - precision: 0.9927 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.2382 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2562 - acc: 0.9431 - precision: 0.9934 - recall: 0.8963 - f1_score: 0.9411 - val_loss: 0.2379 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2559 - acc: 0.9431 - precision: 0.9939 - recall: 0.8944 - f1_score: 0.9397 - val_loss: 0.2375 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2556 - acc: 0.9431 - precision: 0.9917 - recall: 0.8938 - f1_score: 0.9392 - val_loss: 0.2372 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2552 - acc: 0.9431 - precision: 0.9925 - recall: 0.8958 - f1_score: 0.9400 - val_loss: 0.2369 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2549 - acc: 0.9431 - precision: 0.9940 - recall: 0.8922 - f1_score: 0.9392 - val_loss: 0.2365 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2546 - acc: 0.9431 - precision: 0.9934 - recall: 0.8958 - f1_score: 0.9414 - val_loss: 0.2362 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2543 - acc: 0.9431 - precision: 0.9929 - recall: 0.8946 - f1_score: 0.9404 - val_loss: 0.2359 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 912/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2540 - acc: 0.9431 - precision: 0.9931 - recall: 0.8953 - f1_score: 0.9406 - val_loss: 0.2356 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2537 - acc: 0.9431 - precision: 0.9933 - recall: 0.8958 - f1_score: 0.9410 - val_loss: 0.2352 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2534 - acc: 0.9431 - precision: 0.9919 - recall: 0.8957 - f1_score: 0.9411 - val_loss: 0.2349 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2531 - acc: 0.9431 - precision: 0.9938 - recall: 0.8934 - f1_score: 0.9398 - val_loss: 0.2346 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2528 - acc: 0.9431 - precision: 0.9937 - recall: 0.8961 - f1_score: 0.9412 - val_loss: 0.2343 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2525 - acc: 0.9431 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9403 - val_loss: 0.2340 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2522 - acc: 0.9431 - precision: 0.9923 - recall: 0.8942 - f1_score: 0.9392 - val_loss: 0.2336 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2519 - acc: 0.9431 - precision: 0.9934 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.2333 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2516 - acc: 0.9431 - precision: 0.9926 - recall: 0.8963 - f1_score: 0.9410 - val_loss: 0.2330 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2513 - acc: 0.9431 - precision: 0.9931 - recall: 0.8960 - f1_score: 0.9411 - val_loss: 0.2327 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2510 - acc: 0.9431 - precision: 0.9928 - recall: 0.8940 - f1_score: 0.9400 - val_loss: 0.2324 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2507 - acc: 0.9431 - precision: 0.9940 - recall: 0.8951 - f1_score: 0.9414 - val_loss: 0.2321 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2504 - acc: 0.9431 - precision: 0.9931 - recall: 0.8974 - f1_score: 0.9424 - val_loss: 0.2318 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2501 - acc: 0.9431 - precision: 0.9933 - recall: 0.8978 - f1_score: 0.9417 - val_loss: 0.2315 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2498 - acc: 0.9431 - precision: 0.9946 - recall: 0.8881 - f1_score: 0.9365 - val_loss: 0.2312 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2495 - acc: 0.9431 - precision: 0.9934 - recall: 0.8949 - f1_score: 0.9407 - val_loss: 0.2309 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2492 - acc: 0.9431 - precision: 0.9925 - recall: 0.8980 - f1_score: 0.9415 - val_loss: 0.2306 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9431 - precision: 0.9926 - recall: 0.8947 - f1_score: 0.9405 - val_loss: 0.2303 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2486 - acc: 0.9431 - precision: 0.9935 - recall: 0.8948 - f1_score: 0.9413 - val_loss: 0.2300 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9431 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9408 - val_loss: 0.2297 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2481 - acc: 0.9431 - precision: 0.9925 - recall: 0.8973 - f1_score: 0.9415 - val_loss: 0.2294 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9431 - precision: 0.9931 - recall: 0.8928 - f1_score: 0.9395 - val_loss: 0.2291 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2475 - acc: 0.9431 - precision: 0.9937 - recall: 0.8953 - f1_score: 0.9409 - val_loss: 0.2288 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2472 - acc: 0.9431 - precision: 0.9928 - recall: 0.8965 - f1_score: 0.9410 - val_loss: 0.2285 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9431 - precision: 0.9937 - recall: 0.8986 - f1_score: 0.9426 - val_loss: 0.2282 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9431 - precision: 0.9929 - recall: 0.8984 - f1_score: 0.9420 - val_loss: 0.2279 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9431 - precision: 0.9935 - recall: 0.8871 - f1_score: 0.9351 - val_loss: 0.2276 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2461 - acc: 0.9431 - precision: 0.9933 - recall: 0.8969 - f1_score: 0.9415 - val_loss: 0.2273 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9431 - precision: 0.9933 - recall: 0.8939 - f1_score: 0.9401 - val_loss: 0.2270 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9431 - precision: 0.9921 - recall: 0.8944 - f1_score: 0.9404 - val_loss: 0.2267 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9431 - precision: 0.9937 - recall: 0.8889 - f1_score: 0.9362 - val_loss: 0.2264 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9431 - precision: 0.9920 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 0.2261 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9431 - precision: 0.9922 - recall: 0.8964 - f1_score: 0.9405 - val_loss: 0.2259 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2445 - acc: 0.9431 - precision: 0.9919 - recall: 0.8958 - f1_score: 0.9408 - val_loss: 0.2256 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2442 - acc: 0.9431 - precision: 0.9937 - recall: 0.8932 - f1_score: 0.9399 - val_loss: 0.2253 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2440 - acc: 0.9431 - precision: 0.9925 - recall: 0.8955 - f1_score: 0.9399 - val_loss: 0.2250 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2437 - acc: 0.9431 - precision: 0.9937 - recall: 0.8949 - f1_score: 0.9401 - val_loss: 0.2247 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2435 - acc: 0.9431 - precision: 0.9926 - recall: 0.8969 - f1_score: 0.9413 - val_loss: 0.2245 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2432 - acc: 0.9447 - precision: 0.9920 - recall: 0.8957 - f1_score: 0.9405 - val_loss: 0.2242 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9447 - precision: 0.9933 - recall: 0.9028 - f1_score: 0.9447 - val_loss: 0.2239 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2427 - acc: 0.9447 - precision: 0.9941 - recall: 0.8986 - f1_score: 0.9418 - val_loss: 0.2236 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2424 - acc: 0.9447 - precision: 0.9931 - recall: 0.8955 - f1_score: 0.9400 - val_loss: 0.2234 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2422 - acc: 0.9447 - precision: 0.9930 - recall: 0.9052 - f1_score: 0.9458 - val_loss: 0.2231 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2419 - acc: 0.9447 - precision: 0.9942 - recall: 0.8968 - f1_score: 0.9424 - val_loss: 0.2228 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2416 - acc: 0.9447 - precision: 0.9933 - recall: 0.8988 - f1_score: 0.9423 - val_loss: 0.2225 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2414 - acc: 0.9447 - precision: 0.9923 - recall: 0.8988 - f1_score: 0.9423 - val_loss: 0.2223 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2411 - acc: 0.9447 - precision: 0.9910 - recall: 0.8983 - f1_score: 0.9415 - val_loss: 0.2220 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9447 - precision: 0.9935 - recall: 0.8982 - f1_score: 0.9427 - val_loss: 0.2217 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9447 - precision: 0.9933 - recall: 0.8987 - f1_score: 0.9428 - val_loss: 0.2215 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2404 - acc: 0.9447 - precision: 0.9933 - recall: 0.8968 - f1_score: 0.9410 - val_loss: 0.2212 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2401 - acc: 0.9447 - precision: 0.9929 - recall: 0.8994 - f1_score: 0.9423 - val_loss: 0.2209 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9447 - precision: 0.9935 - recall: 0.8990 - f1_score: 0.9429 - val_loss: 0.2207 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2396 - acc: 0.9447 - precision: 0.9937 - recall: 0.8986 - f1_score: 0.9427 - val_loss: 0.2204 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2394 - acc: 0.9447 - precision: 0.9934 - recall: 0.9041 - f1_score: 0.9456 - val_loss: 0.2201 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9447 - precision: 0.9933 - recall: 0.8999 - f1_score: 0.9432 - val_loss: 0.2199 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9447 - precision: 0.9933 - recall: 0.8954 - f1_score: 0.9402 - val_loss: 0.2196 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2387 - acc: 0.9447 - precision: 0.9913 - recall: 0.8931 - f1_score: 0.9389 - val_loss: 0.2193 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9447 - precision: 0.9925 - recall: 0.8985 - f1_score: 0.9426 - val_loss: 0.2191 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2382 - acc: 0.9447 - precision: 0.9923 - recall: 0.8988 - f1_score: 0.9424 - val_loss: 0.2188 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2380 - acc: 0.9447 - precision: 0.9923 - recall: 0.8978 - f1_score: 0.9411 - val_loss: 0.2186 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9447 - precision: 0.9916 - recall: 0.8966 - f1_score: 0.9406 - val_loss: 0.2183 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2375 - acc: 0.9447 - precision: 0.9931 - recall: 0.8951 - f1_score: 0.9400 - val_loss: 0.2181 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9447 - precision: 0.9933 - recall: 0.8989 - f1_score: 0.9425 - val_loss: 0.2178 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9447 - precision: 0.9926 - recall: 0.9001 - f1_score: 0.9431 - val_loss: 0.2176 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2368 - acc: 0.9447 - precision: 0.9937 - recall: 0.8976 - f1_score: 0.9424 - val_loss: 0.2173 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2365 - acc: 0.9447 - precision: 0.9938 - recall: 0.8958 - f1_score: 0.9404 - val_loss: 0.2171 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2363 - acc: 0.9447 - precision: 0.9946 - recall: 0.8993 - f1_score: 0.9437 - val_loss: 0.2168 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9447 - precision: 0.9938 - recall: 0.8995 - f1_score: 0.9434 - val_loss: 0.2166 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9447 - precision: 0.9928 - recall: 0.8966 - f1_score: 0.9416 - val_loss: 0.2163 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2356 - acc: 0.9447 - precision: 0.9931 - recall: 0.8980 - f1_score: 0.9419 - val_loss: 0.2161 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2354 - acc: 0.9447 - precision: 0.9931 - recall: 0.8976 - f1_score: 0.9416 - val_loss: 0.2159 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2352 - acc: 0.9447 - precision: 0.9907 - recall: 0.8952 - f1_score: 0.9390 - val_loss: 0.2156 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2349 - acc: 0.9463 - precision: 0.9931 - recall: 0.9015 - f1_score: 0.9438 - val_loss: 0.2154 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2347 - acc: 0.9447 - precision: 0.9925 - recall: 0.8944 - f1_score: 0.9400 - val_loss: 0.2151 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2345 - acc: 0.9463 - precision: 0.9929 - recall: 0.9007 - f1_score: 0.9436 - val_loss: 0.2149 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2343 - acc: 0.9463 - precision: 0.9923 - recall: 0.8995 - f1_score: 0.9422 - val_loss: 0.2147 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2340 - acc: 0.9463 - precision: 0.9934 - recall: 0.9038 - f1_score: 0.9453 - val_loss: 0.2144 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2338 - acc: 0.9447 - precision: 0.9939 - recall: 0.8991 - f1_score: 0.9430 - val_loss: 0.2142 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2336 - acc: 0.9447 - precision: 0.9929 - recall: 0.8972 - f1_score: 0.9413 - val_loss: 0.2139 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9463 - precision: 0.9929 - recall: 0.9041 - f1_score: 0.9458 - val_loss: 0.2137 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9447 - precision: 0.9941 - recall: 0.8978 - f1_score: 0.9423 - val_loss: 0.2135 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2329 - acc: 0.9463 - precision: 0.9926 - recall: 0.9017 - f1_score: 0.9439 - val_loss: 0.2132 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9463 - precision: 0.9939 - recall: 0.8962 - f1_score: 0.9409 - val_loss: 0.2130 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9463 - precision: 0.9928 - recall: 0.9004 - f1_score: 0.9438 - val_loss: 0.2128 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2323 - acc: 0.9447 - precision: 0.9931 - recall: 0.8981 - f1_score: 0.9420 - val_loss: 0.2125 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2321 - acc: 0.9463 - precision: 0.9935 - recall: 0.9035 - f1_score: 0.9454 - val_loss: 0.2123 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9463 - precision: 0.9933 - recall: 0.9052 - f1_score: 0.9458 - val_loss: 0.2121 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2317 - acc: 0.9463 - precision: 0.9937 - recall: 0.9031 - f1_score: 0.9450 - val_loss: 0.2118 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2315 - acc: 0.9463 - precision: 0.9940 - recall: 0.9064 - f1_score: 0.9476 - val_loss: 0.2116 - val_acc: 0.9557 - val_precision: 0.9728 - val_recall: 0.9183 - val_f1_score: 0.9415\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.1186 - acc: 0.6035 - precision: 0.5433 - recall: 0.6389 - f1_score: 0.5742 - val_loss: 5.9439 - val_acc: 0.6899 - val_precision: 0.6304 - val_recall: 0.9338 - val_f1_score: 0.7499\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9140 - acc: 0.7188 - precision: 0.6504 - recall: 0.9451 - f1_score: 0.7669 - val_loss: 5.8724 - val_acc: 0.6899 - val_precision: 0.6285 - val_recall: 0.9470 - val_f1_score: 0.7524\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8581 - acc: 0.7204 - precision: 0.6478 - recall: 0.9399 - f1_score: 0.7639 - val_loss: 5.8266 - val_acc: 0.6899 - val_precision: 0.6280 - val_recall: 0.9470 - val_f1_score: 0.7525\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8162 - acc: 0.7267 - precision: 0.6552 - recall: 0.9459 - f1_score: 0.7716 - val_loss: 5.7876 - val_acc: 0.6962 - val_precision: 0.6325 - val_recall: 0.9470 - val_f1_score: 0.7559\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7788 - acc: 0.7283 - precision: 0.6561 - recall: 0.9451 - f1_score: 0.7713 - val_loss: 5.7515 - val_acc: 0.7025 - val_precision: 0.6381 - val_recall: 0.9470 - val_f1_score: 0.7598\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7439 - acc: 0.7362 - precision: 0.6614 - recall: 0.9457 - f1_score: 0.7740 - val_loss: 5.7171 - val_acc: 0.7215 - val_precision: 0.6541 - val_recall: 0.9470 - val_f1_score: 0.7713\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7102 - acc: 0.7567 - precision: 0.6822 - recall: 0.9413 - f1_score: 0.7888 - val_loss: 5.6838 - val_acc: 0.7405 - val_precision: 0.6720 - val_recall: 0.9470 - val_f1_score: 0.7838\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.6775 - acc: 0.7725 - precision: 0.6970 - recall: 0.9443 - f1_score: 0.7972 - val_loss: 5.6513 - val_acc: 0.7595 - val_precision: 0.6889 - val_recall: 0.9470 - val_f1_score: 0.7956\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6454 - acc: 0.7867 - precision: 0.7178 - recall: 0.9430 - f1_score: 0.8131 - val_loss: 5.6194 - val_acc: 0.7658 - val_precision: 0.6958 - val_recall: 0.9470 - val_f1_score: 0.7999\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6139 - acc: 0.7915 - precision: 0.7252 - recall: 0.9396 - f1_score: 0.8153 - val_loss: 5.5879 - val_acc: 0.7722 - val_precision: 0.7022 - val_recall: 0.9470 - val_f1_score: 0.8044\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5828 - acc: 0.8073 - precision: 0.7384 - recall: 0.9436 - f1_score: 0.8253 - val_loss: 5.5569 - val_acc: 0.7911 - val_precision: 0.7278 - val_recall: 0.9353 - val_f1_score: 0.8160\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5521 - acc: 0.8215 - precision: 0.7582 - recall: 0.9406 - f1_score: 0.8375 - val_loss: 5.5263 - val_acc: 0.8165 - val_precision: 0.7550 - val_recall: 0.9353 - val_f1_score: 0.8340\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5218 - acc: 0.8231 - precision: 0.7572 - recall: 0.9353 - f1_score: 0.8343 - val_loss: 5.4960 - val_acc: 0.8291 - val_precision: 0.7703 - val_recall: 0.9353 - val_f1_score: 0.8432\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4917 - acc: 0.8404 - precision: 0.7828 - recall: 0.9358 - f1_score: 0.8487 - val_loss: 5.4660 - val_acc: 0.8418 - val_precision: 0.7858 - val_recall: 0.9353 - val_f1_score: 0.8529\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4620 - acc: 0.8499 - precision: 0.7992 - recall: 0.9274 - f1_score: 0.8570 - val_loss: 5.4363 - val_acc: 0.8671 - val_precision: 0.8227 - val_recall: 0.9353 - val_f1_score: 0.8739\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4325 - acc: 0.8626 - precision: 0.8171 - recall: 0.9305 - f1_score: 0.8688 - val_loss: 5.4069 - val_acc: 0.8797 - val_precision: 0.8444 - val_recall: 0.9353 - val_f1_score: 0.8847\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4033 - acc: 0.8720 - precision: 0.8362 - recall: 0.9216 - f1_score: 0.8744 - val_loss: 5.3777 - val_acc: 0.8797 - val_precision: 0.8444 - val_recall: 0.9353 - val_f1_score: 0.8847\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3743 - acc: 0.8784 - precision: 0.8466 - recall: 0.9219 - f1_score: 0.8796 - val_loss: 5.3487 - val_acc: 0.8861 - val_precision: 0.8522 - val_recall: 0.9353 - val_f1_score: 0.8895\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3456 - acc: 0.8878 - precision: 0.8621 - recall: 0.9221 - f1_score: 0.8891 - val_loss: 5.3200 - val_acc: 0.9114 - val_precision: 0.8905 - val_recall: 0.9353 - val_f1_score: 0.9113\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3171 - acc: 0.8957 - precision: 0.8732 - recall: 0.9255 - f1_score: 0.8957 - val_loss: 5.2915 - val_acc: 0.9177 - val_precision: 0.9002 - val_recall: 0.9353 - val_f1_score: 0.9167\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2888 - acc: 0.9005 - precision: 0.8818 - recall: 0.9212 - f1_score: 0.8990 - val_loss: 5.2632 - val_acc: 0.9114 - val_precision: 0.9002 - val_recall: 0.9252 - val_f1_score: 0.9111\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2607 - acc: 0.9052 - precision: 0.8857 - recall: 0.9201 - f1_score: 0.9011 - val_loss: 5.2352 - val_acc: 0.9177 - val_precision: 0.9107 - val_recall: 0.9252 - val_f1_score: 0.9167\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2329 - acc: 0.9131 - precision: 0.9032 - recall: 0.9223 - f1_score: 0.9113 - val_loss: 5.2074 - val_acc: 0.9241 - val_precision: 0.9224 - val_recall: 0.9252 - val_f1_score: 0.9229\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2053 - acc: 0.9147 - precision: 0.9115 - recall: 0.9218 - f1_score: 0.9144 - val_loss: 5.1798 - val_acc: 0.9241 - val_precision: 0.9224 - val_recall: 0.9252 - val_f1_score: 0.9229\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1779 - acc: 0.9163 - precision: 0.9155 - recall: 0.9170 - f1_score: 0.9145 - val_loss: 5.1524 - val_acc: 0.9304 - val_precision: 0.9351 - val_recall: 0.9252 - val_f1_score: 0.9293\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1506 - acc: 0.9179 - precision: 0.9179 - recall: 0.9126 - f1_score: 0.9137 - val_loss: 5.1251 - val_acc: 0.9304 - val_precision: 0.9351 - val_recall: 0.9252 - val_f1_score: 0.9293\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1236 - acc: 0.9194 - precision: 0.9296 - recall: 0.9078 - f1_score: 0.9170 - val_loss: 5.0981 - val_acc: 0.9304 - val_precision: 0.9351 - val_recall: 0.9252 - val_f1_score: 0.9293\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0968 - acc: 0.9194 - precision: 0.9279 - recall: 0.9047 - f1_score: 0.9149 - val_loss: 5.0713 - val_acc: 0.9304 - val_precision: 0.9351 - val_recall: 0.9252 - val_f1_score: 0.9293\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0701 - acc: 0.9210 - precision: 0.9305 - recall: 0.9083 - f1_score: 0.9182 - val_loss: 5.0447 - val_acc: 0.9304 - val_precision: 0.9351 - val_recall: 0.9252 - val_f1_score: 0.9293\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0437 - acc: 0.9242 - precision: 0.9417 - recall: 0.9035 - f1_score: 0.9208 - val_loss: 5.0183 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0174 - acc: 0.9258 - precision: 0.9420 - recall: 0.9052 - f1_score: 0.9218 - val_loss: 4.9920 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9913 - acc: 0.9210 - precision: 0.9435 - recall: 0.8942 - f1_score: 0.9171 - val_loss: 4.9659 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9654 - acc: 0.9210 - precision: 0.9395 - recall: 0.8925 - f1_score: 0.9127 - val_loss: 4.9400 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9397 - acc: 0.9210 - precision: 0.9453 - recall: 0.8924 - f1_score: 0.9172 - val_loss: 4.9143 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9141 - acc: 0.9226 - precision: 0.9497 - recall: 0.8959 - f1_score: 0.9211 - val_loss: 4.8887 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8887 - acc: 0.9242 - precision: 0.9516 - recall: 0.8924 - f1_score: 0.9196 - val_loss: 4.8633 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8634 - acc: 0.9273 - precision: 0.9601 - recall: 0.8917 - f1_score: 0.9237 - val_loss: 4.8381 - val_acc: 0.9367 - val_precision: 0.9466 - val_recall: 0.9252 - val_f1_score: 0.9352\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8384 - acc: 0.9289 - precision: 0.9604 - recall: 0.8915 - f1_score: 0.9234 - val_loss: 4.8130 - val_acc: 0.9430 - val_precision: 0.9587 - val_recall: 0.9252 - val_f1_score: 0.9409\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8134 - acc: 0.9289 - precision: 0.9603 - recall: 0.8911 - f1_score: 0.9236 - val_loss: 4.7881 - val_acc: 0.9430 - val_precision: 0.9587 - val_recall: 0.9252 - val_f1_score: 0.9409\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.7887 - acc: 0.9305 - precision: 0.9643 - recall: 0.8907 - f1_score: 0.9254 - val_loss: 4.7634 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7641 - acc: 0.9305 - precision: 0.9658 - recall: 0.8953 - f1_score: 0.9273 - val_loss: 4.7388 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7397 - acc: 0.9305 - precision: 0.9623 - recall: 0.8877 - f1_score: 0.9227 - val_loss: 4.7144 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7154 - acc: 0.9321 - precision: 0.9677 - recall: 0.8890 - f1_score: 0.9261 - val_loss: 4.6901 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 4.6901 - acc: 0.9200 - precision: 0.9231 - recall: 0.9231 - f1_score: 0.923 - 0s - loss: 4.6913 - acc: 0.9305 - precision: 0.9706 - recall: 0.8878 - f1_score: 0.9262 - val_loss: 4.6660 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6673 - acc: 0.9305 - precision: 0.9684 - recall: 0.8889 - f1_score: 0.9247 - val_loss: 4.6421 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6435 - acc: 0.9305 - precision: 0.9689 - recall: 0.8837 - f1_score: 0.9215 - val_loss: 4.6182 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6198 - acc: 0.9305 - precision: 0.9709 - recall: 0.8903 - f1_score: 0.9270 - val_loss: 4.5946 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5962 - acc: 0.9305 - precision: 0.9708 - recall: 0.8867 - f1_score: 0.9248 - val_loss: 4.5711 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5729 - acc: 0.9305 - precision: 0.9675 - recall: 0.8841 - f1_score: 0.9228 - val_loss: 4.5477 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5496 - acc: 0.9289 - precision: 0.9661 - recall: 0.8853 - f1_score: 0.9227 - val_loss: 4.5245 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5265 - acc: 0.9289 - precision: 0.9681 - recall: 0.8892 - f1_score: 0.9258 - val_loss: 4.5014 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5035 - acc: 0.9305 - precision: 0.9702 - recall: 0.8818 - f1_score: 0.9227 - val_loss: 4.4784 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4807 - acc: 0.9305 - precision: 0.9715 - recall: 0.8849 - f1_score: 0.9258 - val_loss: 4.4556 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4580 - acc: 0.9305 - precision: 0.9725 - recall: 0.8881 - f1_score: 0.9268 - val_loss: 4.4330 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4355 - acc: 0.9305 - precision: 0.9725 - recall: 0.8850 - f1_score: 0.9255 - val_loss: 4.4104 - val_acc: 0.9494 - val_precision: 0.9712 - val_recall: 0.9252 - val_f1_score: 0.9470\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4131 - acc: 0.9305 - precision: 0.9734 - recall: 0.8843 - f1_score: 0.9252 - val_loss: 4.3880 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3908 - acc: 0.9305 - precision: 0.9688 - recall: 0.8878 - f1_score: 0.9252 - val_loss: 4.3658 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3686 - acc: 0.9321 - precision: 0.9758 - recall: 0.8885 - f1_score: 0.9280 - val_loss: 4.3436 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3466 - acc: 0.9305 - precision: 0.9759 - recall: 0.8820 - f1_score: 0.9253 - val_loss: 4.3216 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3247 - acc: 0.9305 - precision: 0.9775 - recall: 0.8802 - f1_score: 0.9250 - val_loss: 4.2998 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3030 - acc: 0.9305 - precision: 0.9762 - recall: 0.8796 - f1_score: 0.9246 - val_loss: 4.2780 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2813 - acc: 0.9305 - precision: 0.9751 - recall: 0.8799 - f1_score: 0.9233 - val_loss: 4.2564 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2599 - acc: 0.9305 - precision: 0.9737 - recall: 0.8846 - f1_score: 0.9245 - val_loss: 4.2349 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2385 - acc: 0.9305 - precision: 0.9720 - recall: 0.8800 - f1_score: 0.9228 - val_loss: 4.2136 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2172 - acc: 0.9305 - precision: 0.9753 - recall: 0.8852 - f1_score: 0.9263 - val_loss: 4.1924 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1961 - acc: 0.9305 - precision: 0.9742 - recall: 0.8838 - f1_score: 0.9259 - val_loss: 4.1713 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1751 - acc: 0.9289 - precision: 0.9780 - recall: 0.8806 - f1_score: 0.9253 - val_loss: 4.1503 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1542 - acc: 0.9289 - precision: 0.9747 - recall: 0.8803 - f1_score: 0.9213 - val_loss: 4.1294 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1334 - acc: 0.9289 - precision: 0.9757 - recall: 0.8742 - f1_score: 0.9207 - val_loss: 4.1087 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1128 - acc: 0.9289 - precision: 0.9742 - recall: 0.8773 - f1_score: 0.9223 - val_loss: 4.0881 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0923 - acc: 0.9289 - precision: 0.9748 - recall: 0.8793 - f1_score: 0.9229 - val_loss: 4.0676 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.0719 - acc: 0.9273 - precision: 0.9765 - recall: 0.8740 - f1_score: 0.9213 - val_loss: 4.0472 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0516 - acc: 0.9273 - precision: 0.9741 - recall: 0.8785 - f1_score: 0.9215 - val_loss: 4.0269 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0314 - acc: 0.9273 - precision: 0.9769 - recall: 0.8726 - f1_score: 0.9201 - val_loss: 4.0068 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0113 - acc: 0.9289 - precision: 0.9786 - recall: 0.8757 - f1_score: 0.9235 - val_loss: 3.9867 - val_acc: 0.9557 - val_precision: 0.9849 - val_recall: 0.9252 - val_f1_score: 0.9534\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9914 - acc: 0.9289 - precision: 0.9784 - recall: 0.8760 - f1_score: 0.9229 - val_loss: 3.9668 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9715 - acc: 0.9289 - precision: 0.9770 - recall: 0.8729 - f1_score: 0.9214 - val_loss: 3.9470 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9518 - acc: 0.9289 - precision: 0.9785 - recall: 0.8731 - f1_score: 0.9212 - val_loss: 3.9273 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9322 - acc: 0.9289 - precision: 0.9792 - recall: 0.8657 - f1_score: 0.9162 - val_loss: 3.9078 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9127 - acc: 0.9289 - precision: 0.9810 - recall: 0.8738 - f1_score: 0.9229 - val_loss: 3.8883 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8933 - acc: 0.9305 - precision: 0.9823 - recall: 0.8767 - f1_score: 0.9253 - val_loss: 3.8689 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8741 - acc: 0.9305 - precision: 0.9789 - recall: 0.8724 - f1_score: 0.9220 - val_loss: 3.8497 - val_acc: 0.9494 - val_precision: 0.9849 - val_recall: 0.9120 - val_f1_score: 0.9467\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8549 - acc: 0.9305 - precision: 0.9825 - recall: 0.8774 - f1_score: 0.9260 - val_loss: 3.8305 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8358 - acc: 0.9305 - precision: 0.9811 - recall: 0.8754 - f1_score: 0.9234 - val_loss: 3.8115 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8168 - acc: 0.9305 - precision: 0.9825 - recall: 0.8744 - f1_score: 0.9238 - val_loss: 3.7925 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7980 - acc: 0.9305 - precision: 0.9828 - recall: 0.8757 - f1_score: 0.9245 - val_loss: 3.7737 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7792 - acc: 0.9305 - precision: 0.9824 - recall: 0.8758 - f1_score: 0.9248 - val_loss: 3.7550 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7606 - acc: 0.9305 - precision: 0.9811 - recall: 0.8724 - f1_score: 0.9228 - val_loss: 3.7364 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7421 - acc: 0.9305 - precision: 0.9838 - recall: 0.8733 - f1_score: 0.9242 - val_loss: 3.7179 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7236 - acc: 0.9305 - precision: 0.9836 - recall: 0.8773 - f1_score: 0.9257 - val_loss: 3.6995 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7053 - acc: 0.9305 - precision: 0.9848 - recall: 0.8743 - f1_score: 0.9236 - val_loss: 3.6812 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6870 - acc: 0.9305 - precision: 0.9791 - recall: 0.8773 - f1_score: 0.9238 - val_loss: 3.6630 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6689 - acc: 0.9305 - precision: 0.9821 - recall: 0.8752 - f1_score: 0.9244 - val_loss: 3.6448 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6509 - acc: 0.9305 - precision: 0.9835 - recall: 0.8763 - f1_score: 0.9252 - val_loss: 3.6268 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6329 - acc: 0.9305 - precision: 0.9816 - recall: 0.8738 - f1_score: 0.9238 - val_loss: 3.6089 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6151 - acc: 0.9305 - precision: 0.9826 - recall: 0.8760 - f1_score: 0.9251 - val_loss: 3.5911 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5974 - acc: 0.9305 - precision: 0.9826 - recall: 0.8742 - f1_score: 0.9236 - val_loss: 3.5734 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5798 - acc: 0.9305 - precision: 0.9806 - recall: 0.8769 - f1_score: 0.9231 - val_loss: 3.5558 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5622 - acc: 0.9305 - precision: 0.9835 - recall: 0.8741 - f1_score: 0.9245 - val_loss: 3.5383 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5448 - acc: 0.9305 - precision: 0.9816 - recall: 0.8766 - f1_score: 0.9253 - val_loss: 3.5209 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5274 - acc: 0.9305 - precision: 0.9822 - recall: 0.8772 - f1_score: 0.9250 - val_loss: 3.5036 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5102 - acc: 0.9305 - precision: 0.9826 - recall: 0.8807 - f1_score: 0.9269 - val_loss: 3.4864 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4930 - acc: 0.9305 - precision: 0.9817 - recall: 0.8726 - f1_score: 0.9211 - val_loss: 3.4692 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.4759 - acc: 0.9305 - precision: 0.9810 - recall: 0.8733 - f1_score: 0.9215 - val_loss: 3.4522 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4590 - acc: 0.9305 - precision: 0.9832 - recall: 0.8766 - f1_score: 0.9260 - val_loss: 3.4353 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4421 - acc: 0.9305 - precision: 0.9819 - recall: 0.8753 - f1_score: 0.9246 - val_loss: 3.4184 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4253 - acc: 0.9305 - precision: 0.9836 - recall: 0.8758 - f1_score: 0.9252 - val_loss: 3.4017 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4086 - acc: 0.9305 - precision: 0.9821 - recall: 0.8771 - f1_score: 0.9237 - val_loss: 3.3850 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3920 - acc: 0.9305 - precision: 0.9827 - recall: 0.8743 - f1_score: 0.9239 - val_loss: 3.3684 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3755 - acc: 0.9305 - precision: 0.9817 - recall: 0.8707 - f1_score: 0.9218 - val_loss: 3.3519 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3591 - acc: 0.9305 - precision: 0.9828 - recall: 0.8752 - f1_score: 0.9248 - val_loss: 3.3355 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3427 - acc: 0.9305 - precision: 0.9819 - recall: 0.8736 - f1_score: 0.9229 - val_loss: 3.3192 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3265 - acc: 0.9305 - precision: 0.9814 - recall: 0.8699 - f1_score: 0.9210 - val_loss: 3.3030 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3103 - acc: 0.9305 - precision: 0.9820 - recall: 0.8762 - f1_score: 0.9249 - val_loss: 3.2869 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2942 - acc: 0.9305 - precision: 0.9843 - recall: 0.8715 - f1_score: 0.9233 - val_loss: 3.2708 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2782 - acc: 0.9305 - precision: 0.9822 - recall: 0.8779 - f1_score: 0.9258 - val_loss: 3.2549 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2623 - acc: 0.9305 - precision: 0.9812 - recall: 0.8751 - f1_score: 0.9241 - val_loss: 3.2390 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2465 - acc: 0.9305 - precision: 0.9804 - recall: 0.8777 - f1_score: 0.9252 - val_loss: 3.2232 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2308 - acc: 0.9305 - precision: 0.9822 - recall: 0.8785 - f1_score: 0.9256 - val_loss: 3.2075 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2151 - acc: 0.9305 - precision: 0.9844 - recall: 0.8818 - f1_score: 0.9276 - val_loss: 3.1919 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1996 - acc: 0.9305 - precision: 0.9825 - recall: 0.8738 - f1_score: 0.9238 - val_loss: 3.1764 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1841 - acc: 0.9305 - precision: 0.9802 - recall: 0.8735 - f1_score: 0.9232 - val_loss: 3.1610 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1687 - acc: 0.9305 - precision: 0.9809 - recall: 0.8719 - f1_score: 0.9215 - val_loss: 3.1456 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1534 - acc: 0.9305 - precision: 0.9811 - recall: 0.8753 - f1_score: 0.9247 - val_loss: 3.1303 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1382 - acc: 0.9305 - precision: 0.9801 - recall: 0.8735 - f1_score: 0.9231 - val_loss: 3.1151 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1230 - acc: 0.9305 - precision: 0.9822 - recall: 0.8739 - f1_score: 0.9228 - val_loss: 3.1000 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1079 - acc: 0.9305 - precision: 0.9811 - recall: 0.8832 - f1_score: 0.9275 - val_loss: 3.0850 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0929 - acc: 0.9305 - precision: 0.9816 - recall: 0.8743 - f1_score: 0.9230 - val_loss: 3.0700 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0781 - acc: 0.9305 - precision: 0.9826 - recall: 0.8739 - f1_score: 0.9230 - val_loss: 3.0552 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0632 - acc: 0.9305 - precision: 0.9810 - recall: 0.8714 - f1_score: 0.9215 - val_loss: 3.0404 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0485 - acc: 0.9305 - precision: 0.9819 - recall: 0.8752 - f1_score: 0.9246 - val_loss: 3.0257 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0338 - acc: 0.9305 - precision: 0.9825 - recall: 0.8758 - f1_score: 0.9252 - val_loss: 3.0110 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0192 - acc: 0.9305 - precision: 0.9833 - recall: 0.8755 - f1_score: 0.9250 - val_loss: 2.9965 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0047 - acc: 0.9305 - precision: 0.9845 - recall: 0.8780 - f1_score: 0.9263 - val_loss: 2.9820 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9903 - acc: 0.9305 - precision: 0.9833 - recall: 0.8764 - f1_score: 0.9254 - val_loss: 2.9676 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.9759 - acc: 0.9305 - precision: 0.9812 - recall: 0.8757 - f1_score: 0.9242 - val_loss: 2.9533 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9617 - acc: 0.9305 - precision: 0.9814 - recall: 0.8724 - f1_score: 0.9230 - val_loss: 2.9390 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9475 - acc: 0.9305 - precision: 0.9815 - recall: 0.8722 - f1_score: 0.9206 - val_loss: 2.9249 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9333 - acc: 0.9305 - precision: 0.9824 - recall: 0.8741 - f1_score: 0.9241 - val_loss: 2.9108 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9193 - acc: 0.9305 - precision: 0.9803 - recall: 0.8758 - f1_score: 0.9245 - val_loss: 2.8968 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9053 - acc: 0.9305 - precision: 0.9834 - recall: 0.8775 - f1_score: 0.9255 - val_loss: 2.8828 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8914 - acc: 0.9305 - precision: 0.9838 - recall: 0.8724 - f1_score: 0.9226 - val_loss: 2.8689 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8776 - acc: 0.9305 - precision: 0.9813 - recall: 0.8782 - f1_score: 0.9252 - val_loss: 2.8552 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8638 - acc: 0.9305 - precision: 0.9818 - recall: 0.8769 - f1_score: 0.9252 - val_loss: 2.8414 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8502 - acc: 0.9305 - precision: 0.9801 - recall: 0.8785 - f1_score: 0.9253 - val_loss: 2.8278 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8366 - acc: 0.9305 - precision: 0.9827 - recall: 0.8790 - f1_score: 0.9246 - val_loss: 2.8142 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8230 - acc: 0.9305 - precision: 0.9837 - recall: 0.8726 - f1_score: 0.9223 - val_loss: 2.8007 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8095 - acc: 0.9305 - precision: 0.9801 - recall: 0.8745 - f1_score: 0.9238 - val_loss: 2.7873 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7962 - acc: 0.9305 - precision: 0.9824 - recall: 0.8817 - f1_score: 0.9273 - val_loss: 2.7739 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7828 - acc: 0.9305 - precision: 0.9820 - recall: 0.8808 - f1_score: 0.9272 - val_loss: 2.7606 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7696 - acc: 0.9305 - precision: 0.9811 - recall: 0.8738 - f1_score: 0.9225 - val_loss: 2.7474 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7564 - acc: 0.9305 - precision: 0.9796 - recall: 0.8806 - f1_score: 0.9248 - val_loss: 2.7342 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7433 - acc: 0.9305 - precision: 0.9812 - recall: 0.8724 - f1_score: 0.9224 - val_loss: 2.7212 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7302 - acc: 0.9305 - precision: 0.9807 - recall: 0.8746 - f1_score: 0.9234 - val_loss: 2.7082 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7173 - acc: 0.9305 - precision: 0.9828 - recall: 0.8795 - f1_score: 0.9270 - val_loss: 2.6952 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7044 - acc: 0.9305 - precision: 0.9838 - recall: 0.8682 - f1_score: 0.9211 - val_loss: 2.6824 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6915 - acc: 0.9305 - precision: 0.9813 - recall: 0.8781 - f1_score: 0.9254 - val_loss: 2.6695 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6788 - acc: 0.9305 - precision: 0.9812 - recall: 0.8743 - f1_score: 0.9238 - val_loss: 2.6568 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6661 - acc: 0.9305 - precision: 0.9813 - recall: 0.8776 - f1_score: 0.9248 - val_loss: 2.6441 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6534 - acc: 0.9305 - precision: 0.9814 - recall: 0.8750 - f1_score: 0.9242 - val_loss: 2.6315 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6409 - acc: 0.9305 - precision: 0.9849 - recall: 0.8755 - f1_score: 0.9259 - val_loss: 2.6190 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6284 - acc: 0.9305 - precision: 0.9820 - recall: 0.8751 - f1_score: 0.9243 - val_loss: 2.6065 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6159 - acc: 0.9305 - precision: 0.9833 - recall: 0.8741 - f1_score: 0.9247 - val_loss: 2.5941 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6036 - acc: 0.9305 - precision: 0.9821 - recall: 0.8756 - f1_score: 0.9241 - val_loss: 2.5818 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5913 - acc: 0.9305 - precision: 0.9811 - recall: 0.8774 - f1_score: 0.9246 - val_loss: 2.5695 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5790 - acc: 0.9305 - precision: 0.9837 - recall: 0.8741 - f1_score: 0.9238 - val_loss: 2.5573 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5668 - acc: 0.9305 - precision: 0.9836 - recall: 0.8789 - f1_score: 0.9273 - val_loss: 2.5452 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.5547 - acc: 0.9305 - precision: 0.9830 - recall: 0.8735 - f1_score: 0.9242 - val_loss: 2.5331 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5427 - acc: 0.9305 - precision: 0.9811 - recall: 0.8754 - f1_score: 0.9241 - val_loss: 2.5211 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5307 - acc: 0.9305 - precision: 0.9807 - recall: 0.8723 - f1_score: 0.9220 - val_loss: 2.5091 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5188 - acc: 0.9305 - precision: 0.9818 - recall: 0.8775 - f1_score: 0.9242 - val_loss: 2.4972 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5069 - acc: 0.9305 - precision: 0.9832 - recall: 0.8749 - f1_score: 0.9247 - val_loss: 2.4854 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4951 - acc: 0.9305 - precision: 0.9815 - recall: 0.8750 - f1_score: 0.9243 - val_loss: 2.4736 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4834 - acc: 0.9305 - precision: 0.9810 - recall: 0.8757 - f1_score: 0.9240 - val_loss: 2.4619 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4717 - acc: 0.9305 - precision: 0.9830 - recall: 0.8762 - f1_score: 0.9255 - val_loss: 2.4503 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4601 - acc: 0.9305 - precision: 0.9813 - recall: 0.8764 - f1_score: 0.9249 - val_loss: 2.4387 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4486 - acc: 0.9305 - precision: 0.9820 - recall: 0.8750 - f1_score: 0.9247 - val_loss: 2.4272 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4371 - acc: 0.9305 - precision: 0.9804 - recall: 0.8774 - f1_score: 0.9250 - val_loss: 2.4157 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4257 - acc: 0.9305 - precision: 0.9811 - recall: 0.8759 - f1_score: 0.9239 - val_loss: 2.4043 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4143 - acc: 0.9305 - precision: 0.9822 - recall: 0.8801 - f1_score: 0.9267 - val_loss: 2.3930 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4030 - acc: 0.9321 - precision: 0.9817 - recall: 0.8803 - f1_score: 0.9270 - val_loss: 2.3817 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3917 - acc: 0.9321 - precision: 0.9828 - recall: 0.8807 - f1_score: 0.9268 - val_loss: 2.3705 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3806 - acc: 0.9321 - precision: 0.9827 - recall: 0.8765 - f1_score: 0.9239 - val_loss: 2.3593 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3694 - acc: 0.9321 - precision: 0.9833 - recall: 0.8769 - f1_score: 0.9254 - val_loss: 2.3482 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3583 - acc: 0.9321 - precision: 0.9838 - recall: 0.8799 - f1_score: 0.9273 - val_loss: 2.3372 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3473 - acc: 0.9321 - precision: 0.9811 - recall: 0.8790 - f1_score: 0.9265 - val_loss: 2.3262 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3364 - acc: 0.9321 - precision: 0.9834 - recall: 0.8774 - f1_score: 0.9264 - val_loss: 2.3153 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3255 - acc: 0.9321 - precision: 0.9827 - recall: 0.8798 - f1_score: 0.9269 - val_loss: 2.3044 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3146 - acc: 0.9321 - precision: 0.9852 - recall: 0.8785 - f1_score: 0.9269 - val_loss: 2.2936 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3039 - acc: 0.9321 - precision: 0.9846 - recall: 0.8726 - f1_score: 0.9229 - val_loss: 2.2828 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2931 - acc: 0.9321 - precision: 0.9820 - recall: 0.8770 - f1_score: 0.9252 - val_loss: 2.2721 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2825 - acc: 0.9321 - precision: 0.9830 - recall: 0.8767 - f1_score: 0.9243 - val_loss: 2.2615 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2718 - acc: 0.9321 - precision: 0.9834 - recall: 0.8785 - f1_score: 0.9273 - val_loss: 2.2509 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2613 - acc: 0.9321 - precision: 0.9825 - recall: 0.8744 - f1_score: 0.9239 - val_loss: 2.2404 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2508 - acc: 0.9321 - precision: 0.9827 - recall: 0.8839 - f1_score: 0.9299 - val_loss: 2.2299 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2403 - acc: 0.9321 - precision: 0.9822 - recall: 0.8784 - f1_score: 0.9254 - val_loss: 2.2195 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2299 - acc: 0.9321 - precision: 0.9820 - recall: 0.8799 - f1_score: 0.9267 - val_loss: 2.2091 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2196 - acc: 0.9321 - precision: 0.9813 - recall: 0.8749 - f1_score: 0.9243 - val_loss: 2.1988 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2093 - acc: 0.9321 - precision: 0.9812 - recall: 0.8727 - f1_score: 0.9223 - val_loss: 2.1885 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.1991 - acc: 0.9321 - precision: 0.9813 - recall: 0.8761 - f1_score: 0.9250 - val_loss: 2.1783 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1889 - acc: 0.9321 - precision: 0.9822 - recall: 0.8783 - f1_score: 0.9267 - val_loss: 2.1682 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1788 - acc: 0.9321 - precision: 0.9815 - recall: 0.8800 - f1_score: 0.9267 - val_loss: 2.1581 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1687 - acc: 0.9321 - precision: 0.9828 - recall: 0.8782 - f1_score: 0.9269 - val_loss: 2.1480 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1587 - acc: 0.9321 - precision: 0.9827 - recall: 0.8747 - f1_score: 0.9236 - val_loss: 2.1380 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1487 - acc: 0.9321 - precision: 0.9826 - recall: 0.8794 - f1_score: 0.9274 - val_loss: 2.1281 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1388 - acc: 0.9321 - precision: 0.9837 - recall: 0.8750 - f1_score: 0.9237 - val_loss: 2.1182 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1289 - acc: 0.9321 - precision: 0.9819 - recall: 0.8808 - f1_score: 0.9276 - val_loss: 2.1084 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1191 - acc: 0.9321 - precision: 0.9825 - recall: 0.8799 - f1_score: 0.9272 - val_loss: 2.0986 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1093 - acc: 0.9321 - precision: 0.9809 - recall: 0.8762 - f1_score: 0.9248 - val_loss: 2.0888 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0996 - acc: 0.9321 - precision: 0.9806 - recall: 0.8781 - f1_score: 0.9253 - val_loss: 2.0791 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0900 - acc: 0.9321 - precision: 0.9838 - recall: 0.8796 - f1_score: 0.9266 - val_loss: 2.0695 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0804 - acc: 0.9321 - precision: 0.9817 - recall: 0.8751 - f1_score: 0.9228 - val_loss: 2.0599 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0708 - acc: 0.9321 - precision: 0.9818 - recall: 0.8794 - f1_score: 0.9263 - val_loss: 2.0504 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0613 - acc: 0.9336 - precision: 0.9828 - recall: 0.8778 - f1_score: 0.9251 - val_loss: 2.0409 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0518 - acc: 0.9321 - precision: 0.9828 - recall: 0.8824 - f1_score: 0.9284 - val_loss: 2.0315 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0424 - acc: 0.9321 - precision: 0.9804 - recall: 0.8776 - f1_score: 0.9252 - val_loss: 2.0221 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0331 - acc: 0.9336 - precision: 0.9811 - recall: 0.8779 - f1_score: 0.9256 - val_loss: 2.0128 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0237 - acc: 0.9336 - precision: 0.9805 - recall: 0.8837 - f1_score: 0.9285 - val_loss: 2.0035 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0145 - acc: 0.9336 - precision: 0.9823 - recall: 0.8771 - f1_score: 0.9256 - val_loss: 1.9942 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0053 - acc: 0.9336 - precision: 0.9809 - recall: 0.8811 - f1_score: 0.9276 - val_loss: 1.9850 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9961 - acc: 0.9336 - precision: 0.9800 - recall: 0.8837 - f1_score: 0.9270 - val_loss: 1.9759 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9870 - acc: 0.9336 - precision: 0.9828 - recall: 0.8790 - f1_score: 0.9275 - val_loss: 1.9668 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9779 - acc: 0.9336 - precision: 0.9817 - recall: 0.8838 - f1_score: 0.9285 - val_loss: 1.9578 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9689 - acc: 0.9336 - precision: 0.9840 - recall: 0.8838 - f1_score: 0.9304 - val_loss: 1.9488 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9599 - acc: 0.9336 - precision: 0.9816 - recall: 0.8758 - f1_score: 0.9238 - val_loss: 1.9398 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9510 - acc: 0.9336 - precision: 0.9829 - recall: 0.8785 - f1_score: 0.9266 - val_loss: 1.9309 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9421 - acc: 0.9336 - precision: 0.9838 - recall: 0.8847 - f1_score: 0.9296 - val_loss: 1.9220 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9332 - acc: 0.9336 - precision: 0.9835 - recall: 0.8827 - f1_score: 0.9275 - val_loss: 1.9132 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9244 - acc: 0.9336 - precision: 0.9842 - recall: 0.8806 - f1_score: 0.9277 - val_loss: 1.9044 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9157 - acc: 0.9336 - precision: 0.9832 - recall: 0.8816 - f1_score: 0.9285 - val_loss: 1.8957 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9070 - acc: 0.9336 - precision: 0.9830 - recall: 0.8775 - f1_score: 0.9259 - val_loss: 1.8870 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.8983 - acc: 0.9336 - precision: 0.9826 - recall: 0.8855 - f1_score: 0.9302 - val_loss: 1.8784 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8897 - acc: 0.9336 - precision: 0.9829 - recall: 0.8829 - f1_score: 0.9291 - val_loss: 1.8698 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8811 - acc: 0.9336 - precision: 0.9799 - recall: 0.8833 - f1_score: 0.9274 - val_loss: 1.8613 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8726 - acc: 0.9336 - precision: 0.9836 - recall: 0.8790 - f1_score: 0.9264 - val_loss: 1.8528 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8641 - acc: 0.9336 - precision: 0.9813 - recall: 0.8797 - f1_score: 0.9266 - val_loss: 1.8443 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8557 - acc: 0.9352 - precision: 0.9795 - recall: 0.8831 - f1_score: 0.9276 - val_loss: 1.8359 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8473 - acc: 0.9368 - precision: 0.9858 - recall: 0.8873 - f1_score: 0.9328 - val_loss: 1.8275 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8390 - acc: 0.9368 - precision: 0.9855 - recall: 0.8854 - f1_score: 0.9312 - val_loss: 1.8192 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8307 - acc: 0.9368 - precision: 0.9847 - recall: 0.8875 - f1_score: 0.9320 - val_loss: 1.8109 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8224 - acc: 0.9368 - precision: 0.9859 - recall: 0.8863 - f1_score: 0.9326 - val_loss: 1.8027 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8142 - acc: 0.9368 - precision: 0.9840 - recall: 0.8877 - f1_score: 0.9314 - val_loss: 1.7945 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8060 - acc: 0.9368 - precision: 0.9861 - recall: 0.8845 - f1_score: 0.9301 - val_loss: 1.7864 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7979 - acc: 0.9368 - precision: 0.9869 - recall: 0.8849 - f1_score: 0.9315 - val_loss: 1.7783 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7898 - acc: 0.9368 - precision: 0.9844 - recall: 0.8817 - f1_score: 0.9288 - val_loss: 1.7702 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7817 - acc: 0.9368 - precision: 0.9859 - recall: 0.8833 - f1_score: 0.9293 - val_loss: 1.7622 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7737 - acc: 0.9368 - precision: 0.9862 - recall: 0.8849 - f1_score: 0.9321 - val_loss: 1.7542 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7658 - acc: 0.9368 - precision: 0.9843 - recall: 0.8900 - f1_score: 0.9329 - val_loss: 1.7462 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7578 - acc: 0.9368 - precision: 0.9862 - recall: 0.8882 - f1_score: 0.9326 - val_loss: 1.7383 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7499 - acc: 0.9368 - precision: 0.9866 - recall: 0.8814 - f1_score: 0.9302 - val_loss: 1.7305 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7421 - acc: 0.9368 - precision: 0.9856 - recall: 0.8828 - f1_score: 0.9298 - val_loss: 1.7226 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7343 - acc: 0.9368 - precision: 0.9851 - recall: 0.8841 - f1_score: 0.9305 - val_loss: 1.7149 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7265 - acc: 0.9368 - precision: 0.9848 - recall: 0.8767 - f1_score: 0.9255 - val_loss: 1.7071 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7188 - acc: 0.9384 - precision: 0.9866 - recall: 0.8874 - f1_score: 0.9334 - val_loss: 1.6994 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7111 - acc: 0.9384 - precision: 0.9845 - recall: 0.8858 - f1_score: 0.9317 - val_loss: 1.6918 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7035 - acc: 0.9384 - precision: 0.9852 - recall: 0.8872 - f1_score: 0.9331 - val_loss: 1.6842 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6959 - acc: 0.9384 - precision: 0.9850 - recall: 0.8884 - f1_score: 0.9333 - val_loss: 1.6766 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6883 - acc: 0.9384 - precision: 0.9851 - recall: 0.8886 - f1_score: 0.9338 - val_loss: 1.6690 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6808 - acc: 0.9384 - precision: 0.9866 - recall: 0.8886 - f1_score: 0.9339 - val_loss: 1.6615 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6733 - acc: 0.9384 - precision: 0.9868 - recall: 0.8908 - f1_score: 0.9355 - val_loss: 1.6541 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6659 - acc: 0.9384 - precision: 0.9854 - recall: 0.8899 - f1_score: 0.9343 - val_loss: 1.6466 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6585 - acc: 0.9384 - precision: 0.9843 - recall: 0.8885 - f1_score: 0.9332 - val_loss: 1.6393 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6511 - acc: 0.9384 - precision: 0.9856 - recall: 0.8922 - f1_score: 0.9351 - val_loss: 1.6319 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.6438 - acc: 0.9384 - precision: 0.9850 - recall: 0.8902 - f1_score: 0.9339 - val_loss: 1.6246 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6365 - acc: 0.9384 - precision: 0.9855 - recall: 0.8891 - f1_score: 0.9339 - val_loss: 1.6173 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6292 - acc: 0.9384 - precision: 0.9846 - recall: 0.8885 - f1_score: 0.9329 - val_loss: 1.6101 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6220 - acc: 0.9384 - precision: 0.9853 - recall: 0.8884 - f1_score: 0.9333 - val_loss: 1.6029 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6148 - acc: 0.9384 - precision: 0.9847 - recall: 0.8865 - f1_score: 0.9322 - val_loss: 1.5957 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6077 - acc: 0.9384 - precision: 0.9855 - recall: 0.8901 - f1_score: 0.9343 - val_loss: 1.5886 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6006 - acc: 0.9384 - precision: 0.9862 - recall: 0.8887 - f1_score: 0.9333 - val_loss: 1.5815 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5935 - acc: 0.9384 - precision: 0.9859 - recall: 0.8862 - f1_score: 0.9323 - val_loss: 1.5745 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5865 - acc: 0.9384 - precision: 0.9860 - recall: 0.8895 - f1_score: 0.9324 - val_loss: 1.5675 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5795 - acc: 0.9384 - precision: 0.9881 - recall: 0.8907 - f1_score: 0.9366 - val_loss: 1.5605 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5725 - acc: 0.9384 - precision: 0.9890 - recall: 0.8837 - f1_score: 0.9321 - val_loss: 1.5535 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5656 - acc: 0.9384 - precision: 0.9875 - recall: 0.8895 - f1_score: 0.9351 - val_loss: 1.5466 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5587 - acc: 0.9384 - precision: 0.9843 - recall: 0.8879 - f1_score: 0.9325 - val_loss: 1.5397 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5519 - acc: 0.9384 - precision: 0.9851 - recall: 0.8851 - f1_score: 0.9315 - val_loss: 1.5329 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5450 - acc: 0.9384 - precision: 0.9849 - recall: 0.8882 - f1_score: 0.9330 - val_loss: 1.5261 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5383 - acc: 0.9384 - precision: 0.9870 - recall: 0.8876 - f1_score: 0.9327 - val_loss: 1.5194 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5315 - acc: 0.9384 - precision: 0.9864 - recall: 0.8857 - f1_score: 0.9314 - val_loss: 1.5126 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5248 - acc: 0.9384 - precision: 0.9856 - recall: 0.8870 - f1_score: 0.9328 - val_loss: 1.5059 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5181 - acc: 0.9384 - precision: 0.9848 - recall: 0.8836 - f1_score: 0.9303 - val_loss: 1.4993 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5115 - acc: 0.9384 - precision: 0.9871 - recall: 0.8892 - f1_score: 0.9342 - val_loss: 1.4926 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5049 - acc: 0.9384 - precision: 0.9845 - recall: 0.8898 - f1_score: 0.9340 - val_loss: 1.4860 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4983 - acc: 0.9384 - precision: 0.9854 - recall: 0.8875 - f1_score: 0.9327 - val_loss: 1.4795 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4917 - acc: 0.9384 - precision: 0.9856 - recall: 0.8796 - f1_score: 0.9282 - val_loss: 1.4730 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4852 - acc: 0.9384 - precision: 0.9873 - recall: 0.8868 - f1_score: 0.9330 - val_loss: 1.4665 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4788 - acc: 0.9384 - precision: 0.9861 - recall: 0.8877 - f1_score: 0.9335 - val_loss: 1.4600 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4723 - acc: 0.9384 - precision: 0.9863 - recall: 0.8886 - f1_score: 0.9342 - val_loss: 1.4536 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4659 - acc: 0.9384 - precision: 0.9855 - recall: 0.8885 - f1_score: 0.9333 - val_loss: 1.4472 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4595 - acc: 0.9384 - precision: 0.9858 - recall: 0.8879 - f1_score: 0.9337 - val_loss: 1.4409 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4532 - acc: 0.9400 - precision: 0.9870 - recall: 0.8908 - f1_score: 0.9356 - val_loss: 1.4345 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4469 - acc: 0.9400 - precision: 0.9859 - recall: 0.8953 - f1_score: 0.9376 - val_loss: 1.4282 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4406 - acc: 0.9400 - precision: 0.9862 - recall: 0.8911 - f1_score: 0.9357 - val_loss: 1.4220 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4344 - acc: 0.9400 - precision: 0.9864 - recall: 0.8875 - f1_score: 0.9330 - val_loss: 1.4158 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4282 - acc: 0.9400 - precision: 0.9847 - recall: 0.8936 - f1_score: 0.9362 - val_loss: 1.4096 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4220 - acc: 0.9400 - precision: 0.9862 - recall: 0.8949 - f1_score: 0.9370 - val_loss: 1.4034 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4158 - acc: 0.9400 - precision: 0.9856 - recall: 0.8942 - f1_score: 0.9358 - val_loss: 1.3973 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4097 - acc: 0.9400 - precision: 0.9841 - recall: 0.8919 - f1_score: 0.9353 - val_loss: 1.3912 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4036 - acc: 0.9400 - precision: 0.9865 - recall: 0.8888 - f1_score: 0.9345 - val_loss: 1.3851 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3976 - acc: 0.9400 - precision: 0.9836 - recall: 0.8911 - f1_score: 0.9344 - val_loss: 1.3791 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3916 - acc: 0.9400 - precision: 0.9865 - recall: 0.8932 - f1_score: 0.9363 - val_loss: 1.3731 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3856 - acc: 0.9400 - precision: 0.9862 - recall: 0.8889 - f1_score: 0.9337 - val_loss: 1.3671 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3796 - acc: 0.9400 - precision: 0.9856 - recall: 0.8913 - f1_score: 0.9348 - val_loss: 1.3611 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3737 - acc: 0.9400 - precision: 0.9871 - recall: 0.8880 - f1_score: 0.9338 - val_loss: 1.3552 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3678 - acc: 0.9400 - precision: 0.9864 - recall: 0.8879 - f1_score: 0.9336 - val_loss: 1.3493 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3619 - acc: 0.9400 - precision: 0.9869 - recall: 0.8925 - f1_score: 0.9358 - val_loss: 1.3435 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3560 - acc: 0.9400 - precision: 0.9861 - recall: 0.8937 - f1_score: 0.9361 - val_loss: 1.3377 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3503 - acc: 0.9400 - precision: 0.9833 - recall: 0.8898 - f1_score: 0.9325 - val_loss: 1.3319 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3445 - acc: 0.9400 - precision: 0.9849 - recall: 0.8879 - f1_score: 0.9329 - val_loss: 1.3261 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3387 - acc: 0.9400 - precision: 0.9857 - recall: 0.8927 - f1_score: 0.9363 - val_loss: 1.3204 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3330 - acc: 0.9400 - precision: 0.9864 - recall: 0.8903 - f1_score: 0.9351 - val_loss: 1.3147 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3273 - acc: 0.9400 - precision: 0.9852 - recall: 0.8897 - f1_score: 0.9340 - val_loss: 1.3090 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3216 - acc: 0.9400 - precision: 0.9860 - recall: 0.8918 - f1_score: 0.9355 - val_loss: 1.3034 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3160 - acc: 0.9400 - precision: 0.9867 - recall: 0.8892 - f1_score: 0.9342 - val_loss: 1.2977 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3104 - acc: 0.9400 - precision: 0.9866 - recall: 0.8914 - f1_score: 0.9347 - val_loss: 1.2922 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3048 - acc: 0.9400 - precision: 0.9847 - recall: 0.8909 - f1_score: 0.9345 - val_loss: 1.2866 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2993 - acc: 0.9400 - precision: 0.9860 - recall: 0.8913 - f1_score: 0.9354 - val_loss: 1.2811 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2938 - acc: 0.9400 - precision: 0.9865 - recall: 0.8927 - f1_score: 0.9359 - val_loss: 1.2756 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2883 - acc: 0.9400 - precision: 0.9879 - recall: 0.8931 - f1_score: 0.9371 - val_loss: 1.2701 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2828 - acc: 0.9415 - precision: 0.9898 - recall: 0.8953 - f1_score: 0.9390 - val_loss: 1.2646 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2774 - acc: 0.9415 - precision: 0.9884 - recall: 0.8884 - f1_score: 0.9345 - val_loss: 1.2592 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2720 - acc: 0.9415 - precision: 0.9900 - recall: 0.8895 - f1_score: 0.9348 - val_loss: 1.2538 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2666 - acc: 0.9415 - precision: 0.9895 - recall: 0.8947 - f1_score: 0.9375 - val_loss: 1.2485 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2613 - acc: 0.9415 - precision: 0.9889 - recall: 0.8913 - f1_score: 0.9372 - val_loss: 1.2431 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2559 - acc: 0.9415 - precision: 0.9890 - recall: 0.8886 - f1_score: 0.9350 - val_loss: 1.2378 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2507 - acc: 0.9415 - precision: 0.9886 - recall: 0.8895 - f1_score: 0.9356 - val_loss: 1.2325 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2454 - acc: 0.9415 - precision: 0.9901 - recall: 0.8930 - f1_score: 0.9386 - val_loss: 1.2273 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2401 - acc: 0.9415 - precision: 0.9904 - recall: 0.8930 - f1_score: 0.9382 - val_loss: 1.2221 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2349 - acc: 0.9415 - precision: 0.9879 - recall: 0.8944 - f1_score: 0.9375 - val_loss: 1.2169 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2297 - acc: 0.9415 - precision: 0.9904 - recall: 0.8926 - f1_score: 0.9374 - val_loss: 1.2117 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2246 - acc: 0.9415 - precision: 0.9914 - recall: 0.8851 - f1_score: 0.9340 - val_loss: 1.2065 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2194 - acc: 0.9415 - precision: 0.9873 - recall: 0.8872 - f1_score: 0.9332 - val_loss: 1.2014 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2143 - acc: 0.9415 - precision: 0.9889 - recall: 0.8911 - f1_score: 0.9354 - val_loss: 1.1963 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2093 - acc: 0.9415 - precision: 0.9892 - recall: 0.8926 - f1_score: 0.9375 - val_loss: 1.1913 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2042 - acc: 0.9415 - precision: 0.9889 - recall: 0.8935 - f1_score: 0.9379 - val_loss: 1.1862 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1992 - acc: 0.9415 - precision: 0.9890 - recall: 0.8909 - f1_score: 0.9357 - val_loss: 1.1812 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1942 - acc: 0.9415 - precision: 0.9889 - recall: 0.8876 - f1_score: 0.9346 - val_loss: 1.1762 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1892 - acc: 0.9415 - precision: 0.9894 - recall: 0.8919 - f1_score: 0.9371 - val_loss: 1.1712 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1842 - acc: 0.9415 - precision: 0.9896 - recall: 0.8893 - f1_score: 0.9356 - val_loss: 1.1663 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1793 - acc: 0.9415 - precision: 0.9889 - recall: 0.8882 - f1_score: 0.9346 - val_loss: 1.1614 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1744 - acc: 0.9415 - precision: 0.9894 - recall: 0.8928 - f1_score: 0.9366 - val_loss: 1.1565 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1695 - acc: 0.9415 - precision: 0.9874 - recall: 0.8896 - f1_score: 0.9345 - val_loss: 1.1516 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1647 - acc: 0.9415 - precision: 0.9895 - recall: 0.8896 - f1_score: 0.9356 - val_loss: 1.1468 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1599 - acc: 0.9415 - precision: 0.9900 - recall: 0.8911 - f1_score: 0.9371 - val_loss: 1.1420 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1551 - acc: 0.9415 - precision: 0.9892 - recall: 0.8907 - f1_score: 0.9363 - val_loss: 1.1372 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1503 - acc: 0.9415 - precision: 0.9886 - recall: 0.8901 - f1_score: 0.9354 - val_loss: 1.1324 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1455 - acc: 0.9415 - precision: 0.9891 - recall: 0.8945 - f1_score: 0.9375 - val_loss: 1.1277 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1408 - acc: 0.9415 - precision: 0.9905 - recall: 0.8909 - f1_score: 0.9370 - val_loss: 1.1230 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1361 - acc: 0.9415 - precision: 0.9897 - recall: 0.8909 - f1_score: 0.9366 - val_loss: 1.1183 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1314 - acc: 0.9415 - precision: 0.9914 - recall: 0.8955 - f1_score: 0.9390 - val_loss: 1.1136 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1268 - acc: 0.9415 - precision: 0.9902 - recall: 0.8914 - f1_score: 0.9367 - val_loss: 1.1089 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1221 - acc: 0.9415 - precision: 0.9874 - recall: 0.8914 - f1_score: 0.9361 - val_loss: 1.1043 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1175 - acc: 0.9415 - precision: 0.9877 - recall: 0.8888 - f1_score: 0.9350 - val_loss: 1.0997 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1129 - acc: 0.9415 - precision: 0.9892 - recall: 0.8920 - f1_score: 0.9374 - val_loss: 1.0951 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1084 - acc: 0.9415 - precision: 0.9889 - recall: 0.8910 - f1_score: 0.9364 - val_loss: 1.0906 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1038 - acc: 0.9415 - precision: 0.9901 - recall: 0.8908 - f1_score: 0.9365 - val_loss: 1.0861 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0993 - acc: 0.9415 - precision: 0.9896 - recall: 0.8919 - f1_score: 0.9376 - val_loss: 1.0816 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0948 - acc: 0.9415 - precision: 0.9899 - recall: 0.8919 - f1_score: 0.9370 - val_loss: 1.0771 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0903 - acc: 0.9415 - precision: 0.9890 - recall: 0.8923 - f1_score: 0.9370 - val_loss: 1.0726 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0859 - acc: 0.9415 - precision: 0.9896 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 1.0682 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0815 - acc: 0.9415 - precision: 0.9899 - recall: 0.8940 - f1_score: 0.9379 - val_loss: 1.0638 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0771 - acc: 0.9415 - precision: 0.9898 - recall: 0.8912 - f1_score: 0.9377 - val_loss: 1.0594 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0727 - acc: 0.9415 - precision: 0.9890 - recall: 0.8892 - f1_score: 0.9357 - val_loss: 1.0550 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0683 - acc: 0.9415 - precision: 0.9891 - recall: 0.8907 - f1_score: 0.9365 - val_loss: 1.0507 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0640 - acc: 0.9431 - precision: 0.9925 - recall: 0.8876 - f1_score: 0.9361 - val_loss: 1.0463 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0597 - acc: 0.9431 - precision: 0.9920 - recall: 0.8897 - f1_score: 0.9371 - val_loss: 1.0420 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0554 - acc: 0.9431 - precision: 0.9936 - recall: 0.8896 - f1_score: 0.9383 - val_loss: 1.0378 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0511 - acc: 0.9431 - precision: 0.9926 - recall: 0.8908 - f1_score: 0.9384 - val_loss: 1.0335 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0469 - acc: 0.9431 - precision: 0.9920 - recall: 0.8900 - f1_score: 0.9376 - val_loss: 1.0293 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0427 - acc: 0.9431 - precision: 0.9935 - recall: 0.8892 - f1_score: 0.9373 - val_loss: 1.0251 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0385 - acc: 0.9431 - precision: 0.9937 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 1.0209 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0343 - acc: 0.9431 - precision: 0.9940 - recall: 0.8915 - f1_score: 0.9386 - val_loss: 1.0167 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0301 - acc: 0.9431 - precision: 0.9929 - recall: 0.8948 - f1_score: 0.9405 - val_loss: 1.0125 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0260 - acc: 0.9431 - precision: 0.9917 - recall: 0.8917 - f1_score: 0.9380 - val_loss: 1.0084 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0219 - acc: 0.9431 - precision: 0.9922 - recall: 0.8931 - f1_score: 0.9381 - val_loss: 1.0043 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0177 - acc: 0.9431 - precision: 0.9928 - recall: 0.8893 - f1_score: 0.9378 - val_loss: 1.0002 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0137 - acc: 0.9431 - precision: 0.9926 - recall: 0.8906 - f1_score: 0.9377 - val_loss: 0.9961 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0096 - acc: 0.9431 - precision: 0.9921 - recall: 0.8911 - f1_score: 0.9379 - val_loss: 0.9921 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0056 - acc: 0.9431 - precision: 0.9923 - recall: 0.8903 - f1_score: 0.9383 - val_loss: 0.9881 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0016 - acc: 0.9431 - precision: 0.9937 - recall: 0.8935 - f1_score: 0.9404 - val_loss: 0.9841 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9976 - acc: 0.9431 - precision: 0.9923 - recall: 0.8963 - f1_score: 0.9411 - val_loss: 0.9801 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9936 - acc: 0.9431 - precision: 0.9928 - recall: 0.8915 - f1_score: 0.9378 - val_loss: 0.9761 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9897 - acc: 0.9431 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9399 - val_loss: 0.9722 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9857 - acc: 0.9431 - precision: 0.9948 - recall: 0.8862 - f1_score: 0.9354 - val_loss: 0.9682 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9818 - acc: 0.9431 - precision: 0.9928 - recall: 0.8916 - f1_score: 0.9372 - val_loss: 0.9643 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9779 - acc: 0.9431 - precision: 0.9933 - recall: 0.8955 - f1_score: 0.9408 - val_loss: 0.9605 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9740 - acc: 0.9431 - precision: 0.9930 - recall: 0.8937 - f1_score: 0.9398 - val_loss: 0.9566 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9702 - acc: 0.9431 - precision: 0.9935 - recall: 0.8909 - f1_score: 0.9375 - val_loss: 0.9528 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9664 - acc: 0.9431 - precision: 0.9928 - recall: 0.8898 - f1_score: 0.9372 - val_loss: 0.9489 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9625 - acc: 0.9431 - precision: 0.9934 - recall: 0.8942 - f1_score: 0.9401 - val_loss: 0.9451 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9587 - acc: 0.9431 - precision: 0.9912 - recall: 0.8903 - f1_score: 0.9377 - val_loss: 0.9413 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9550 - acc: 0.9431 - precision: 0.9922 - recall: 0.8862 - f1_score: 0.9347 - val_loss: 0.9376 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9512 - acc: 0.9431 - precision: 0.9921 - recall: 0.8943 - f1_score: 0.9392 - val_loss: 0.9338 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9475 - acc: 0.9431 - precision: 0.9926 - recall: 0.8944 - f1_score: 0.9403 - val_loss: 0.9301 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9438 - acc: 0.9431 - precision: 0.9916 - recall: 0.8948 - f1_score: 0.9397 - val_loss: 0.9264 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9401 - acc: 0.9431 - precision: 0.9932 - recall: 0.8907 - f1_score: 0.9385 - val_loss: 0.9227 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9364 - acc: 0.9431 - precision: 0.9938 - recall: 0.8887 - f1_score: 0.9372 - val_loss: 0.9190 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9327 - acc: 0.9431 - precision: 0.9928 - recall: 0.8902 - f1_score: 0.9379 - val_loss: 0.9154 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9291 - acc: 0.9431 - precision: 0.9903 - recall: 0.8891 - f1_score: 0.9364 - val_loss: 0.9117 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9254 - acc: 0.9431 - precision: 0.9934 - recall: 0.8929 - f1_score: 0.9398 - val_loss: 0.9081 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9218 - acc: 0.9431 - precision: 0.9931 - recall: 0.8942 - f1_score: 0.9399 - val_loss: 0.9045 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9182 - acc: 0.9431 - precision: 0.9931 - recall: 0.8911 - f1_score: 0.9383 - val_loss: 0.9009 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9147 - acc: 0.9431 - precision: 0.9914 - recall: 0.8941 - f1_score: 0.9389 - val_loss: 0.8974 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9111 - acc: 0.9431 - precision: 0.9939 - recall: 0.8854 - f1_score: 0.9351 - val_loss: 0.8938 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9076 - acc: 0.9431 - precision: 0.9935 - recall: 0.8909 - f1_score: 0.9382 - val_loss: 0.8903 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9041 - acc: 0.9431 - precision: 0.9927 - recall: 0.8900 - f1_score: 0.9380 - val_loss: 0.8868 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9006 - acc: 0.9431 - precision: 0.9921 - recall: 0.8925 - f1_score: 0.9381 - val_loss: 0.8833 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8971 - acc: 0.9431 - precision: 0.9923 - recall: 0.8886 - f1_score: 0.9364 - val_loss: 0.8798 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8936 - acc: 0.9431 - precision: 0.9944 - recall: 0.8926 - f1_score: 0.9393 - val_loss: 0.8764 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8902 - acc: 0.9431 - precision: 0.9921 - recall: 0.8921 - f1_score: 0.9387 - val_loss: 0.8729 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8868 - acc: 0.9431 - precision: 0.9925 - recall: 0.8870 - f1_score: 0.9349 - val_loss: 0.8695 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8834 - acc: 0.9431 - precision: 0.9915 - recall: 0.8941 - f1_score: 0.9376 - val_loss: 0.8661 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8800 - acc: 0.9431 - precision: 0.9928 - recall: 0.8937 - f1_score: 0.9399 - val_loss: 0.8627 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8766 - acc: 0.9431 - precision: 0.9922 - recall: 0.8912 - f1_score: 0.9381 - val_loss: 0.8594 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8732 - acc: 0.9431 - precision: 0.9915 - recall: 0.8932 - f1_score: 0.9391 - val_loss: 0.8560 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8699 - acc: 0.9431 - precision: 0.9938 - recall: 0.8878 - f1_score: 0.9366 - val_loss: 0.8527 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8666 - acc: 0.9431 - precision: 0.9931 - recall: 0.8889 - f1_score: 0.9368 - val_loss: 0.8494 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8632 - acc: 0.9431 - precision: 0.9926 - recall: 0.8891 - f1_score: 0.9369 - val_loss: 0.8461 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8600 - acc: 0.9431 - precision: 0.9928 - recall: 0.8909 - f1_score: 0.9377 - val_loss: 0.8428 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8567 - acc: 0.9431 - precision: 0.9923 - recall: 0.8903 - f1_score: 0.9374 - val_loss: 0.8395 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8534 - acc: 0.9431 - precision: 0.9935 - recall: 0.8891 - f1_score: 0.9370 - val_loss: 0.8363 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8502 - acc: 0.9431 - precision: 0.9928 - recall: 0.8949 - f1_score: 0.9402 - val_loss: 0.8330 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8470 - acc: 0.9431 - precision: 0.9934 - recall: 0.8972 - f1_score: 0.9414 - val_loss: 0.8298 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8437 - acc: 0.9431 - precision: 0.9933 - recall: 0.8882 - f1_score: 0.9359 - val_loss: 0.8266 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8406 - acc: 0.9431 - precision: 0.9932 - recall: 0.8908 - f1_score: 0.9387 - val_loss: 0.8234 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8374 - acc: 0.9431 - precision: 0.9922 - recall: 0.8881 - f1_score: 0.9361 - val_loss: 0.8202 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8342 - acc: 0.9431 - precision: 0.9934 - recall: 0.8909 - f1_score: 0.9378 - val_loss: 0.8171 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8311 - acc: 0.9431 - precision: 0.9936 - recall: 0.8871 - f1_score: 0.9360 - val_loss: 0.8140 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8279 - acc: 0.9431 - precision: 0.9931 - recall: 0.8934 - f1_score: 0.9397 - val_loss: 0.8108 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8248 - acc: 0.9431 - precision: 0.9938 - recall: 0.8915 - f1_score: 0.9390 - val_loss: 0.8077 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8217 - acc: 0.9447 - precision: 0.9925 - recall: 0.8915 - f1_score: 0.9385 - val_loss: 0.8046 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8187 - acc: 0.9447 - precision: 0.9944 - recall: 0.8882 - f1_score: 0.9357 - val_loss: 0.8016 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8156 - acc: 0.9447 - precision: 0.9934 - recall: 0.9010 - f1_score: 0.9437 - val_loss: 0.7985 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8125 - acc: 0.9447 - precision: 0.9928 - recall: 0.8938 - f1_score: 0.9387 - val_loss: 0.7955 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8095 - acc: 0.9447 - precision: 0.9939 - recall: 0.8926 - f1_score: 0.9385 - val_loss: 0.7924 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8065 - acc: 0.9447 - precision: 0.9944 - recall: 0.8930 - f1_score: 0.9398 - val_loss: 0.7894 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8035 - acc: 0.9447 - precision: 0.9924 - recall: 0.8947 - f1_score: 0.9399 - val_loss: 0.7864 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8005 - acc: 0.9447 - precision: 0.9934 - recall: 0.8955 - f1_score: 0.9400 - val_loss: 0.7834 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7975 - acc: 0.9447 - precision: 0.9936 - recall: 0.8915 - f1_score: 0.9382 - val_loss: 0.7805 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7946 - acc: 0.9447 - precision: 0.9907 - recall: 0.8918 - f1_score: 0.9379 - val_loss: 0.7775 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7916 - acc: 0.9447 - precision: 0.9911 - recall: 0.8960 - f1_score: 0.9400 - val_loss: 0.7746 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7887 - acc: 0.9447 - precision: 0.9939 - recall: 0.8928 - f1_score: 0.9402 - val_loss: 0.7717 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7858 - acc: 0.9447 - precision: 0.9922 - recall: 0.8943 - f1_score: 0.9400 - val_loss: 0.7688 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7829 - acc: 0.9447 - precision: 0.9937 - recall: 0.8936 - f1_score: 0.9403 - val_loss: 0.7659 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7800 - acc: 0.9447 - precision: 0.9937 - recall: 0.8924 - f1_score: 0.9385 - val_loss: 0.7630 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7771 - acc: 0.9447 - precision: 0.9929 - recall: 0.8906 - f1_score: 0.9372 - val_loss: 0.7601 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7743 - acc: 0.9447 - precision: 0.9928 - recall: 0.8911 - f1_score: 0.9378 - val_loss: 0.7573 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7714 - acc: 0.9447 - precision: 0.9921 - recall: 0.8942 - f1_score: 0.9388 - val_loss: 0.7544 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7686 - acc: 0.9447 - precision: 0.9919 - recall: 0.8938 - f1_score: 0.9389 - val_loss: 0.7516 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7658 - acc: 0.9447 - precision: 0.9919 - recall: 0.8880 - f1_score: 0.9356 - val_loss: 0.7488 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7630 - acc: 0.9447 - precision: 0.9929 - recall: 0.8972 - f1_score: 0.9411 - val_loss: 0.7460 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7602 - acc: 0.9447 - precision: 0.9931 - recall: 0.8940 - f1_score: 0.9402 - val_loss: 0.7432 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7574 - acc: 0.9447 - precision: 0.9928 - recall: 0.8967 - f1_score: 0.9405 - val_loss: 0.7405 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7547 - acc: 0.9447 - precision: 0.9933 - recall: 0.8940 - f1_score: 0.9400 - val_loss: 0.7377 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7519 - acc: 0.9447 - precision: 0.9925 - recall: 0.8941 - f1_score: 0.9395 - val_loss: 0.7350 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7492 - acc: 0.9447 - precision: 0.9939 - recall: 0.8911 - f1_score: 0.9387 - val_loss: 0.7323 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7465 - acc: 0.9447 - precision: 0.9912 - recall: 0.8964 - f1_score: 0.9402 - val_loss: 0.7295 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7438 - acc: 0.9447 - precision: 0.9939 - recall: 0.8948 - f1_score: 0.9403 - val_loss: 0.7269 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7411 - acc: 0.9447 - precision: 0.9914 - recall: 0.8874 - f1_score: 0.9354 - val_loss: 0.7242 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7384 - acc: 0.9447 - precision: 0.9925 - recall: 0.8932 - f1_score: 0.9392 - val_loss: 0.7215 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7358 - acc: 0.9447 - precision: 0.9928 - recall: 0.8966 - f1_score: 0.9412 - val_loss: 0.7188 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7331 - acc: 0.9447 - precision: 0.9925 - recall: 0.8939 - f1_score: 0.9400 - val_loss: 0.7162 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7305 - acc: 0.9447 - precision: 0.9926 - recall: 0.8960 - f1_score: 0.9404 - val_loss: 0.7136 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7279 - acc: 0.9447 - precision: 0.9940 - recall: 0.8979 - f1_score: 0.9427 - val_loss: 0.7110 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7253 - acc: 0.9447 - precision: 0.9937 - recall: 0.8963 - f1_score: 0.9418 - val_loss: 0.7084 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7227 - acc: 0.9447 - precision: 0.9925 - recall: 0.8896 - f1_score: 0.9366 - val_loss: 0.7058 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7201 - acc: 0.9447 - precision: 0.9941 - recall: 0.8978 - f1_score: 0.9421 - val_loss: 0.7032 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7175 - acc: 0.9447 - precision: 0.9937 - recall: 0.8923 - f1_score: 0.9393 - val_loss: 0.7006 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7150 - acc: 0.9447 - precision: 0.9936 - recall: 0.8962 - f1_score: 0.9412 - val_loss: 0.6981 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7124 - acc: 0.9447 - precision: 0.9933 - recall: 0.8930 - f1_score: 0.9390 - val_loss: 0.6955 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7099 - acc: 0.9447 - precision: 0.9925 - recall: 0.8945 - f1_score: 0.9394 - val_loss: 0.6930 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7074 - acc: 0.9447 - precision: 0.9918 - recall: 0.8998 - f1_score: 0.9424 - val_loss: 0.6905 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7049 - acc: 0.9447 - precision: 0.9923 - recall: 0.8974 - f1_score: 0.9410 - val_loss: 0.6880 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7024 - acc: 0.9447 - precision: 0.9926 - recall: 0.8951 - f1_score: 0.9407 - val_loss: 0.6855 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6999 - acc: 0.9447 - precision: 0.9917 - recall: 0.8956 - f1_score: 0.9406 - val_loss: 0.6830 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6974 - acc: 0.9447 - precision: 0.9931 - recall: 0.8938 - f1_score: 0.9401 - val_loss: 0.6806 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6950 - acc: 0.9447 - precision: 0.9943 - recall: 0.8882 - f1_score: 0.9371 - val_loss: 0.6781 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6925 - acc: 0.9447 - precision: 0.9915 - recall: 0.8930 - f1_score: 0.9384 - val_loss: 0.6757 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6901 - acc: 0.9447 - precision: 0.9933 - recall: 0.8940 - f1_score: 0.9395 - val_loss: 0.6732 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6877 - acc: 0.9447 - precision: 0.9934 - recall: 0.8915 - f1_score: 0.9381 - val_loss: 0.6708 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6853 - acc: 0.9447 - precision: 0.9927 - recall: 0.8948 - f1_score: 0.9401 - val_loss: 0.6684 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6829 - acc: 0.9447 - precision: 0.9935 - recall: 0.8948 - f1_score: 0.9406 - val_loss: 0.6660 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6805 - acc: 0.9447 - precision: 0.9921 - recall: 0.8963 - f1_score: 0.9408 - val_loss: 0.6637 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6781 - acc: 0.9447 - precision: 0.9931 - recall: 0.8973 - f1_score: 0.9413 - val_loss: 0.6613 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6758 - acc: 0.9447 - precision: 0.9933 - recall: 0.8888 - f1_score: 0.9372 - val_loss: 0.6589 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6734 - acc: 0.9447 - precision: 0.9919 - recall: 0.8950 - f1_score: 0.9397 - val_loss: 0.6566 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6711 - acc: 0.9447 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9392 - val_loss: 0.6543 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6688 - acc: 0.9447 - precision: 0.9938 - recall: 0.8947 - f1_score: 0.9407 - val_loss: 0.6519 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6665 - acc: 0.9447 - precision: 0.9913 - recall: 0.8983 - f1_score: 0.9414 - val_loss: 0.6496 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6642 - acc: 0.9447 - precision: 0.9930 - recall: 0.8988 - f1_score: 0.9416 - val_loss: 0.6473 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6619 - acc: 0.9447 - precision: 0.9940 - recall: 0.8950 - f1_score: 0.9410 - val_loss: 0.6451 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6596 - acc: 0.9447 - precision: 0.9912 - recall: 0.8938 - f1_score: 0.9395 - val_loss: 0.6428 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6573 - acc: 0.9447 - precision: 0.9945 - recall: 0.8953 - f1_score: 0.9411 - val_loss: 0.6405 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6551 - acc: 0.9447 - precision: 0.9923 - recall: 0.8946 - f1_score: 0.9396 - val_loss: 0.6383 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6528 - acc: 0.9447 - precision: 0.9937 - recall: 0.8939 - f1_score: 0.9403 - val_loss: 0.6360 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6506 - acc: 0.9447 - precision: 0.9941 - recall: 0.8920 - f1_score: 0.9385 - val_loss: 0.6338 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6484 - acc: 0.9447 - precision: 0.9932 - recall: 0.8962 - f1_score: 0.9412 - val_loss: 0.6316 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6462 - acc: 0.9447 - precision: 0.9919 - recall: 0.8982 - f1_score: 0.9414 - val_loss: 0.6294 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6440 - acc: 0.9447 - precision: 0.9938 - recall: 0.8962 - f1_score: 0.9415 - val_loss: 0.6272 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6418 - acc: 0.9447 - precision: 0.9926 - recall: 0.8991 - f1_score: 0.9427 - val_loss: 0.6250 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6396 - acc: 0.9447 - precision: 0.9934 - recall: 0.9017 - f1_score: 0.9440 - val_loss: 0.6228 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6374 - acc: 0.9447 - precision: 0.9928 - recall: 0.8938 - f1_score: 0.9401 - val_loss: 0.6207 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6353 - acc: 0.9447 - precision: 0.9914 - recall: 0.8934 - f1_score: 0.9391 - val_loss: 0.6185 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6331 - acc: 0.9447 - precision: 0.9928 - recall: 0.8922 - f1_score: 0.9383 - val_loss: 0.6164 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6310 - acc: 0.9447 - precision: 0.9926 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 0.6142 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6289 - acc: 0.9447 - precision: 0.9919 - recall: 0.8960 - f1_score: 0.9398 - val_loss: 0.6121 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6268 - acc: 0.9447 - precision: 0.9926 - recall: 0.8943 - f1_score: 0.9391 - val_loss: 0.6100 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6247 - acc: 0.9447 - precision: 0.9937 - recall: 0.8946 - f1_score: 0.9404 - val_loss: 0.6079 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6226 - acc: 0.9447 - precision: 0.9938 - recall: 0.8955 - f1_score: 0.9406 - val_loss: 0.6058 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6205 - acc: 0.9447 - precision: 0.9932 - recall: 0.8939 - f1_score: 0.9406 - val_loss: 0.6037 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6184 - acc: 0.9447 - precision: 0.9931 - recall: 0.8915 - f1_score: 0.9379 - val_loss: 0.6017 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6164 - acc: 0.9447 - precision: 0.9934 - recall: 0.8925 - f1_score: 0.9386 - val_loss: 0.5996 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6143 - acc: 0.9447 - precision: 0.9928 - recall: 0.8936 - f1_score: 0.9400 - val_loss: 0.5975 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6123 - acc: 0.9447 - precision: 0.9933 - recall: 0.8972 - f1_score: 0.9415 - val_loss: 0.5955 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6102 - acc: 0.9447 - precision: 0.9943 - recall: 0.8896 - f1_score: 0.9367 - val_loss: 0.5935 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6082 - acc: 0.9447 - precision: 0.9931 - recall: 0.8970 - f1_score: 0.9415 - val_loss: 0.5914 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6062 - acc: 0.9447 - precision: 0.9931 - recall: 0.8955 - f1_score: 0.9403 - val_loss: 0.5894 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6042 - acc: 0.9447 - precision: 0.9922 - recall: 0.8909 - f1_score: 0.9379 - val_loss: 0.5874 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6022 - acc: 0.9447 - precision: 0.9925 - recall: 0.8950 - f1_score: 0.9399 - val_loss: 0.5855 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6002 - acc: 0.9447 - precision: 0.9925 - recall: 0.8951 - f1_score: 0.9403 - val_loss: 0.5835 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5983 - acc: 0.9447 - precision: 0.9917 - recall: 0.8916 - f1_score: 0.9378 - val_loss: 0.5815 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5963 - acc: 0.9447 - precision: 0.9930 - recall: 0.8969 - f1_score: 0.9415 - val_loss: 0.5795 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5944 - acc: 0.9447 - precision: 0.9939 - recall: 0.8898 - f1_score: 0.9378 - val_loss: 0.5776 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5924 - acc: 0.9447 - precision: 0.9930 - recall: 0.8878 - f1_score: 0.9365 - val_loss: 0.5757 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5905 - acc: 0.9447 - precision: 0.9918 - recall: 0.8952 - f1_score: 0.9404 - val_loss: 0.5737 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5886 - acc: 0.9447 - precision: 0.9914 - recall: 0.8982 - f1_score: 0.9413 - val_loss: 0.5718 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5867 - acc: 0.9447 - precision: 0.9935 - recall: 0.8920 - f1_score: 0.9387 - val_loss: 0.5699 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5848 - acc: 0.9447 - precision: 0.9928 - recall: 0.8911 - f1_score: 0.9386 - val_loss: 0.5680 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5829 - acc: 0.9447 - precision: 0.9926 - recall: 0.8925 - f1_score: 0.9386 - val_loss: 0.5661 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5810 - acc: 0.9447 - precision: 0.9931 - recall: 0.8966 - f1_score: 0.9417 - val_loss: 0.5642 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5791 - acc: 0.9447 - precision: 0.9912 - recall: 0.8954 - f1_score: 0.9393 - val_loss: 0.5623 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5773 - acc: 0.9447 - precision: 0.9945 - recall: 0.8974 - f1_score: 0.9424 - val_loss: 0.5605 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5754 - acc: 0.9447 - precision: 0.9935 - recall: 0.8943 - f1_score: 0.9401 - val_loss: 0.5586 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5736 - acc: 0.9447 - precision: 0.9938 - recall: 0.8929 - f1_score: 0.9398 - val_loss: 0.5568 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5717 - acc: 0.9447 - precision: 0.9907 - recall: 0.8895 - f1_score: 0.9367 - val_loss: 0.5549 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5699 - acc: 0.9447 - precision: 0.9917 - recall: 0.8870 - f1_score: 0.9347 - val_loss: 0.5531 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5681 - acc: 0.9447 - precision: 0.9921 - recall: 0.8944 - f1_score: 0.9401 - val_loss: 0.5513 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5663 - acc: 0.9447 - precision: 0.9926 - recall: 0.8964 - f1_score: 0.9406 - val_loss: 0.5495 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5645 - acc: 0.9447 - precision: 0.9913 - recall: 0.8923 - f1_score: 0.9381 - val_loss: 0.5477 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5627 - acc: 0.9447 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9393 - val_loss: 0.5459 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5609 - acc: 0.9447 - precision: 0.9930 - recall: 0.8922 - f1_score: 0.9388 - val_loss: 0.5441 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5591 - acc: 0.9447 - precision: 0.9925 - recall: 0.8973 - f1_score: 0.9413 - val_loss: 0.5423 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5574 - acc: 0.9447 - precision: 0.9921 - recall: 0.8951 - f1_score: 0.9398 - val_loss: 0.5406 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5556 - acc: 0.9447 - precision: 0.9947 - recall: 0.8969 - f1_score: 0.9422 - val_loss: 0.5388 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5539 - acc: 0.9447 - precision: 0.9936 - recall: 0.8956 - f1_score: 0.9409 - val_loss: 0.5371 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5521 - acc: 0.9447 - precision: 0.9947 - recall: 0.8939 - f1_score: 0.9402 - val_loss: 0.5353 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5504 - acc: 0.9447 - precision: 0.9918 - recall: 0.8920 - f1_score: 0.9383 - val_loss: 0.5336 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5487 - acc: 0.9447 - precision: 0.9931 - recall: 0.8946 - f1_score: 0.9398 - val_loss: 0.5319 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5469 - acc: 0.9447 - precision: 0.9938 - recall: 0.8935 - f1_score: 0.9398 - val_loss: 0.5301 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5452 - acc: 0.9447 - precision: 0.9940 - recall: 0.8983 - f1_score: 0.9428 - val_loss: 0.5284 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5435 - acc: 0.9447 - precision: 0.9931 - recall: 0.8939 - f1_score: 0.9401 - val_loss: 0.5267 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5419 - acc: 0.9447 - precision: 0.9930 - recall: 0.8892 - f1_score: 0.9369 - val_loss: 0.5251 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5402 - acc: 0.9447 - precision: 0.9938 - recall: 0.8944 - f1_score: 0.9406 - val_loss: 0.5234 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5385 - acc: 0.9447 - precision: 0.9935 - recall: 0.8948 - f1_score: 0.9408 - val_loss: 0.5217 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5368 - acc: 0.9447 - precision: 0.9918 - recall: 0.8947 - f1_score: 0.9400 - val_loss: 0.5200 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5352 - acc: 0.9447 - precision: 0.9931 - recall: 0.8956 - f1_score: 0.9404 - val_loss: 0.5184 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5335 - acc: 0.9447 - precision: 0.9923 - recall: 0.8903 - f1_score: 0.9376 - val_loss: 0.5167 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5319 - acc: 0.9447 - precision: 0.9928 - recall: 0.8943 - f1_score: 0.9394 - val_loss: 0.5151 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5303 - acc: 0.9447 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9411 - val_loss: 0.5135 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5287 - acc: 0.9447 - precision: 0.9929 - recall: 0.8971 - f1_score: 0.9418 - val_loss: 0.5118 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5270 - acc: 0.9447 - precision: 0.9921 - recall: 0.8936 - f1_score: 0.9374 - val_loss: 0.5102 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5254 - acc: 0.9447 - precision: 0.9927 - recall: 0.8929 - f1_score: 0.9383 - val_loss: 0.5086 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5238 - acc: 0.9447 - precision: 0.9918 - recall: 0.8939 - f1_score: 0.9399 - val_loss: 0.5070 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5222 - acc: 0.9447 - precision: 0.9917 - recall: 0.8944 - f1_score: 0.9397 - val_loss: 0.5054 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5207 - acc: 0.9447 - precision: 0.9921 - recall: 0.8899 - f1_score: 0.9366 - val_loss: 0.5038 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5191 - acc: 0.9447 - precision: 0.9947 - recall: 0.8940 - f1_score: 0.9412 - val_loss: 0.5023 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5175 - acc: 0.9447 - precision: 0.9933 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 0.5007 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5160 - acc: 0.9447 - precision: 0.9899 - recall: 0.8910 - f1_score: 0.9373 - val_loss: 0.4991 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5144 - acc: 0.9447 - precision: 0.9921 - recall: 0.8986 - f1_score: 0.9415 - val_loss: 0.4976 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5129 - acc: 0.9447 - precision: 0.9934 - recall: 0.8974 - f1_score: 0.9420 - val_loss: 0.4960 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5113 - acc: 0.9447 - precision: 0.9939 - recall: 0.8937 - f1_score: 0.9399 - val_loss: 0.4945 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5098 - acc: 0.9447 - precision: 0.9923 - recall: 0.8906 - f1_score: 0.9376 - val_loss: 0.4930 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5083 - acc: 0.9447 - precision: 0.9934 - recall: 0.8941 - f1_score: 0.9403 - val_loss: 0.4914 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5067 - acc: 0.9447 - precision: 0.9920 - recall: 0.8941 - f1_score: 0.9396 - val_loss: 0.4899 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5052 - acc: 0.9447 - precision: 0.9923 - recall: 0.8954 - f1_score: 0.9406 - val_loss: 0.4884 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5037 - acc: 0.9447 - precision: 0.9926 - recall: 0.8961 - f1_score: 0.9412 - val_loss: 0.4869 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5022 - acc: 0.9447 - precision: 0.9935 - recall: 0.8947 - f1_score: 0.9402 - val_loss: 0.4854 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5008 - acc: 0.9447 - precision: 0.9933 - recall: 0.8940 - f1_score: 0.9391 - val_loss: 0.4839 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4993 - acc: 0.9447 - precision: 0.9927 - recall: 0.8938 - f1_score: 0.9399 - val_loss: 0.4825 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4978 - acc: 0.9447 - precision: 0.9928 - recall: 0.8986 - f1_score: 0.9418 - val_loss: 0.4810 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4964 - acc: 0.9447 - precision: 0.9904 - recall: 0.8922 - f1_score: 0.9380 - val_loss: 0.4795 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4949 - acc: 0.9447 - precision: 0.9933 - recall: 0.8914 - f1_score: 0.9387 - val_loss: 0.4781 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 584/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4934 - acc: 0.9447 - precision: 0.9941 - recall: 0.8953 - f1_score: 0.9414 - val_loss: 0.4766 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4920 - acc: 0.9447 - precision: 0.9925 - recall: 0.8952 - f1_score: 0.9407 - val_loss: 0.4752 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4906 - acc: 0.9447 - precision: 0.9913 - recall: 0.9001 - f1_score: 0.9419 - val_loss: 0.4737 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4891 - acc: 0.9447 - precision: 0.9928 - recall: 0.8963 - f1_score: 0.9409 - val_loss: 0.4723 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4877 - acc: 0.9447 - precision: 0.9928 - recall: 0.8971 - f1_score: 0.9411 - val_loss: 0.4709 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4863 - acc: 0.9447 - precision: 0.9929 - recall: 0.8956 - f1_score: 0.9399 - val_loss: 0.4695 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4849 - acc: 0.9447 - precision: 0.9935 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.4681 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4835 - acc: 0.9447 - precision: 0.9932 - recall: 0.8952 - f1_score: 0.9406 - val_loss: 0.4667 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4821 - acc: 0.9447 - precision: 0.9922 - recall: 0.8947 - f1_score: 0.9402 - val_loss: 0.4653 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4807 - acc: 0.9447 - precision: 0.9931 - recall: 0.8910 - f1_score: 0.9373 - val_loss: 0.4639 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4793 - acc: 0.9447 - precision: 0.9931 - recall: 0.8947 - f1_score: 0.9394 - val_loss: 0.4625 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4780 - acc: 0.9447 - precision: 0.9934 - recall: 0.8928 - f1_score: 0.9393 - val_loss: 0.4611 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4766 - acc: 0.9447 - precision: 0.9934 - recall: 0.8942 - f1_score: 0.9400 - val_loss: 0.4598 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4752 - acc: 0.9447 - precision: 0.9932 - recall: 0.8957 - f1_score: 0.9411 - val_loss: 0.4584 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4739 - acc: 0.9447 - precision: 0.9939 - recall: 0.8915 - f1_score: 0.9384 - val_loss: 0.4570 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4725 - acc: 0.9447 - precision: 0.9925 - recall: 0.8978 - f1_score: 0.9419 - val_loss: 0.4557 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4712 - acc: 0.9447 - precision: 0.9941 - recall: 0.8929 - f1_score: 0.9400 - val_loss: 0.4543 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4699 - acc: 0.9447 - precision: 0.9934 - recall: 0.8953 - f1_score: 0.9410 - val_loss: 0.4530 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4685 - acc: 0.9447 - precision: 0.9922 - recall: 0.8913 - f1_score: 0.9378 - val_loss: 0.4517 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4672 - acc: 0.9447 - precision: 0.9926 - recall: 0.8959 - f1_score: 0.9409 - val_loss: 0.4504 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4659 - acc: 0.9447 - precision: 0.9930 - recall: 0.8901 - f1_score: 0.9370 - val_loss: 0.4491 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4646 - acc: 0.9447 - precision: 0.9933 - recall: 0.8948 - f1_score: 0.9412 - val_loss: 0.4477 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4633 - acc: 0.9447 - precision: 0.9932 - recall: 0.8937 - f1_score: 0.9395 - val_loss: 0.4464 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4620 - acc: 0.9447 - precision: 0.9918 - recall: 0.8911 - f1_score: 0.9366 - val_loss: 0.4451 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4607 - acc: 0.9447 - precision: 0.9917 - recall: 0.8955 - f1_score: 0.9405 - val_loss: 0.4438 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4594 - acc: 0.9447 - precision: 0.9929 - recall: 0.8927 - f1_score: 0.9396 - val_loss: 0.4426 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4582 - acc: 0.9447 - precision: 0.9928 - recall: 0.8930 - f1_score: 0.9397 - val_loss: 0.4413 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4569 - acc: 0.9447 - precision: 0.9898 - recall: 0.9003 - f1_score: 0.9413 - val_loss: 0.4400 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4556 - acc: 0.9447 - precision: 0.9915 - recall: 0.8958 - f1_score: 0.9407 - val_loss: 0.4387 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4544 - acc: 0.9447 - precision: 0.9933 - recall: 0.8894 - f1_score: 0.9369 - val_loss: 0.4375 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4531 - acc: 0.9447 - precision: 0.9917 - recall: 0.8962 - f1_score: 0.9404 - val_loss: 0.4362 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4519 - acc: 0.9447 - precision: 0.9934 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.4350 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 616/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4506 - acc: 0.9447 - precision: 0.9915 - recall: 0.8984 - f1_score: 0.9418 - val_loss: 0.4338 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4494 - acc: 0.9447 - precision: 0.9925 - recall: 0.8925 - f1_score: 0.9393 - val_loss: 0.4325 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4482 - acc: 0.9447 - precision: 0.9930 - recall: 0.8933 - f1_score: 0.9395 - val_loss: 0.4313 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4470 - acc: 0.9447 - precision: 0.9924 - recall: 0.8956 - f1_score: 0.9404 - val_loss: 0.4301 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4457 - acc: 0.9447 - precision: 0.9928 - recall: 0.8944 - f1_score: 0.9395 - val_loss: 0.4288 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4445 - acc: 0.9447 - precision: 0.9940 - recall: 0.8942 - f1_score: 0.9408 - val_loss: 0.4276 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4433 - acc: 0.9447 - precision: 0.9926 - recall: 0.8969 - f1_score: 0.9415 - val_loss: 0.4264 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4421 - acc: 0.9447 - precision: 0.9935 - recall: 0.8937 - f1_score: 0.9400 - val_loss: 0.4252 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4409 - acc: 0.9447 - precision: 0.9941 - recall: 0.8976 - f1_score: 0.9419 - val_loss: 0.4240 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4398 - acc: 0.9447 - precision: 0.9928 - recall: 0.8945 - f1_score: 0.9397 - val_loss: 0.4228 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4386 - acc: 0.9447 - precision: 0.9926 - recall: 0.8957 - f1_score: 0.9402 - val_loss: 0.4217 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4374 - acc: 0.9447 - precision: 0.9935 - recall: 0.8938 - f1_score: 0.9404 - val_loss: 0.4205 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4362 - acc: 0.9447 - precision: 0.9938 - recall: 0.8924 - f1_score: 0.9392 - val_loss: 0.4193 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4351 - acc: 0.9447 - precision: 0.9928 - recall: 0.8919 - f1_score: 0.9383 - val_loss: 0.4181 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4339 - acc: 0.9447 - precision: 0.9920 - recall: 0.8919 - f1_score: 0.9384 - val_loss: 0.4170 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4328 - acc: 0.9447 - precision: 0.9926 - recall: 0.8945 - f1_score: 0.9398 - val_loss: 0.4158 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4316 - acc: 0.9447 - precision: 0.9921 - recall: 0.8959 - f1_score: 0.9409 - val_loss: 0.4147 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4305 - acc: 0.9447 - precision: 0.9924 - recall: 0.8924 - f1_score: 0.9386 - val_loss: 0.4135 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4293 - acc: 0.9447 - precision: 0.9919 - recall: 0.8930 - f1_score: 0.9382 - val_loss: 0.4124 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4282 - acc: 0.9447 - precision: 0.9931 - recall: 0.8940 - f1_score: 0.9401 - val_loss: 0.4112 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4271 - acc: 0.9447 - precision: 0.9926 - recall: 0.8939 - f1_score: 0.9395 - val_loss: 0.4101 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4260 - acc: 0.9447 - precision: 0.9929 - recall: 0.8953 - f1_score: 0.9404 - val_loss: 0.4090 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4248 - acc: 0.9447 - precision: 0.9935 - recall: 0.8956 - f1_score: 0.9411 - val_loss: 0.4079 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4237 - acc: 0.9447 - precision: 0.9938 - recall: 0.8911 - f1_score: 0.9372 - val_loss: 0.4068 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4226 - acc: 0.9447 - precision: 0.9934 - recall: 0.8929 - f1_score: 0.9391 - val_loss: 0.4057 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4215 - acc: 0.9447 - precision: 0.9928 - recall: 0.8926 - f1_score: 0.9388 - val_loss: 0.4046 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4204 - acc: 0.9447 - precision: 0.9940 - recall: 0.8934 - f1_score: 0.9391 - val_loss: 0.4035 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4194 - acc: 0.9431 - precision: 0.9902 - recall: 0.8939 - f1_score: 0.9386 - val_loss: 0.4024 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4183 - acc: 0.9447 - precision: 0.9937 - recall: 0.8923 - f1_score: 0.9388 - val_loss: 0.4013 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4172 - acc: 0.9447 - precision: 0.9907 - recall: 0.8933 - f1_score: 0.9378 - val_loss: 0.4002 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4161 - acc: 0.9447 - precision: 0.9936 - recall: 0.8926 - f1_score: 0.9392 - val_loss: 0.3992 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4151 - acc: 0.9447 - precision: 0.9929 - recall: 0.8925 - f1_score: 0.9381 - val_loss: 0.3981 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4140 - acc: 0.9447 - precision: 0.9917 - recall: 0.8956 - f1_score: 0.9405 - val_loss: 0.3970 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4129 - acc: 0.9447 - precision: 0.9931 - recall: 0.8946 - f1_score: 0.9403 - val_loss: 0.3960 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4119 - acc: 0.9447 - precision: 0.9918 - recall: 0.8903 - f1_score: 0.9377 - val_loss: 0.3949 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4108 - acc: 0.9447 - precision: 0.9938 - recall: 0.8954 - f1_score: 0.9409 - val_loss: 0.3939 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4098 - acc: 0.9447 - precision: 0.9926 - recall: 0.8904 - f1_score: 0.9378 - val_loss: 0.3928 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4088 - acc: 0.9447 - precision: 0.9933 - recall: 0.8920 - f1_score: 0.9390 - val_loss: 0.3918 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4077 - acc: 0.9447 - precision: 0.9939 - recall: 0.8969 - f1_score: 0.9411 - val_loss: 0.3907 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4067 - acc: 0.9447 - precision: 0.9922 - recall: 0.8971 - f1_score: 0.9412 - val_loss: 0.3897 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4057 - acc: 0.9447 - precision: 0.9924 - recall: 0.8938 - f1_score: 0.9401 - val_loss: 0.3887 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4047 - acc: 0.9447 - precision: 0.9938 - recall: 0.8956 - f1_score: 0.9412 - val_loss: 0.3877 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4037 - acc: 0.9447 - precision: 0.9935 - recall: 0.8944 - f1_score: 0.9408 - val_loss: 0.3867 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4027 - acc: 0.9447 - precision: 0.9920 - recall: 0.8905 - f1_score: 0.9374 - val_loss: 0.3856 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4017 - acc: 0.9447 - precision: 0.9941 - recall: 0.8959 - f1_score: 0.9406 - val_loss: 0.3846 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4007 - acc: 0.9447 - precision: 0.9937 - recall: 0.8956 - f1_score: 0.9412 - val_loss: 0.3836 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3997 - acc: 0.9447 - precision: 0.9928 - recall: 0.8930 - f1_score: 0.9397 - val_loss: 0.3826 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3987 - acc: 0.9431 - precision: 0.9921 - recall: 0.8915 - f1_score: 0.9371 - val_loss: 0.3817 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3977 - acc: 0.9447 - precision: 0.9919 - recall: 0.8975 - f1_score: 0.9411 - val_loss: 0.3807 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3967 - acc: 0.9431 - precision: 0.9888 - recall: 0.8887 - f1_score: 0.9345 - val_loss: 0.3797 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3957 - acc: 0.9447 - precision: 0.9925 - recall: 0.8974 - f1_score: 0.9414 - val_loss: 0.3787 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3948 - acc: 0.9447 - precision: 0.9944 - recall: 0.8912 - f1_score: 0.9392 - val_loss: 0.3777 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3938 - acc: 0.9431 - precision: 0.9902 - recall: 0.8968 - f1_score: 0.9409 - val_loss: 0.3768 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3928 - acc: 0.9447 - precision: 0.9929 - recall: 0.8940 - f1_score: 0.9404 - val_loss: 0.3758 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3919 - acc: 0.9447 - precision: 0.9936 - recall: 0.8904 - f1_score: 0.9379 - val_loss: 0.3748 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3909 - acc: 0.9447 - precision: 0.9917 - recall: 0.8923 - f1_score: 0.9375 - val_loss: 0.3739 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3900 - acc: 0.9447 - precision: 0.9936 - recall: 0.8931 - f1_score: 0.9399 - val_loss: 0.3729 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3891 - acc: 0.9447 - precision: 0.9926 - recall: 0.8929 - f1_score: 0.9388 - val_loss: 0.3720 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9447 - precision: 0.9925 - recall: 0.8953 - f1_score: 0.9406 - val_loss: 0.3711 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3872 - acc: 0.9447 - precision: 0.9928 - recall: 0.8955 - f1_score: 0.9402 - val_loss: 0.3701 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3863 - acc: 0.9447 - precision: 0.9912 - recall: 0.8916 - f1_score: 0.9381 - val_loss: 0.3692 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3853 - acc: 0.9447 - precision: 0.9936 - recall: 0.8942 - f1_score: 0.9400 - val_loss: 0.3683 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3844 - acc: 0.9431 - precision: 0.9913 - recall: 0.8944 - f1_score: 0.9384 - val_loss: 0.3673 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3835 - acc: 0.9447 - precision: 0.9918 - recall: 0.8923 - f1_score: 0.9383 - val_loss: 0.3664 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 680/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3826 - acc: 0.9447 - precision: 0.9925 - recall: 0.8918 - f1_score: 0.9372 - val_loss: 0.3655 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3817 - acc: 0.9447 - precision: 0.9924 - recall: 0.8947 - f1_score: 0.9398 - val_loss: 0.3646 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3808 - acc: 0.9431 - precision: 0.9900 - recall: 0.8952 - f1_score: 0.9396 - val_loss: 0.3637 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3799 - acc: 0.9431 - precision: 0.9894 - recall: 0.8959 - f1_score: 0.9395 - val_loss: 0.3628 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3790 - acc: 0.9431 - precision: 0.9891 - recall: 0.8966 - f1_score: 0.9391 - val_loss: 0.3619 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3781 - acc: 0.9447 - precision: 0.9935 - recall: 0.8927 - f1_score: 0.9393 - val_loss: 0.3610 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3772 - acc: 0.9431 - precision: 0.9889 - recall: 0.8894 - f1_score: 0.9352 - val_loss: 0.3601 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3764 - acc: 0.9431 - precision: 0.9892 - recall: 0.8931 - f1_score: 0.9378 - val_loss: 0.3593 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3755 - acc: 0.9447 - precision: 0.9934 - recall: 0.8913 - f1_score: 0.9374 - val_loss: 0.3584 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3746 - acc: 0.9447 - precision: 0.9923 - recall: 0.8925 - f1_score: 0.9386 - val_loss: 0.3575 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3737 - acc: 0.9431 - precision: 0.9891 - recall: 0.8982 - f1_score: 0.9402 - val_loss: 0.3566 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3729 - acc: 0.9431 - precision: 0.9904 - recall: 0.8946 - f1_score: 0.9395 - val_loss: 0.3557 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3720 - acc: 0.9431 - precision: 0.9906 - recall: 0.8915 - f1_score: 0.9376 - val_loss: 0.3549 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3712 - acc: 0.9431 - precision: 0.9894 - recall: 0.8857 - f1_score: 0.9319 - val_loss: 0.3540 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3703 - acc: 0.9431 - precision: 0.9894 - recall: 0.8897 - f1_score: 0.9351 - val_loss: 0.3532 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3695 - acc: 0.9431 - precision: 0.9891 - recall: 0.8987 - f1_score: 0.9408 - val_loss: 0.3523 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3686 - acc: 0.9431 - precision: 0.9885 - recall: 0.8965 - f1_score: 0.9392 - val_loss: 0.3515 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3678 - acc: 0.9431 - precision: 0.9887 - recall: 0.8961 - f1_score: 0.9395 - val_loss: 0.3506 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3669 - acc: 0.9447 - precision: 0.9932 - recall: 0.8898 - f1_score: 0.9374 - val_loss: 0.3498 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3661 - acc: 0.9431 - precision: 0.9895 - recall: 0.8936 - f1_score: 0.9372 - val_loss: 0.3490 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3653 - acc: 0.9431 - precision: 0.9885 - recall: 0.8948 - f1_score: 0.9381 - val_loss: 0.3481 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3645 - acc: 0.9431 - precision: 0.9903 - recall: 0.8901 - f1_score: 0.9364 - val_loss: 0.3473 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3636 - acc: 0.9431 - precision: 0.9883 - recall: 0.8936 - f1_score: 0.9373 - val_loss: 0.3465 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3628 - acc: 0.9431 - precision: 0.9887 - recall: 0.8904 - f1_score: 0.9361 - val_loss: 0.3457 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3620 - acc: 0.9431 - precision: 0.9898 - recall: 0.8956 - f1_score: 0.9395 - val_loss: 0.3448 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3612 - acc: 0.9431 - precision: 0.9903 - recall: 0.8951 - f1_score: 0.9395 - val_loss: 0.3440 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3604 - acc: 0.9431 - precision: 0.9897 - recall: 0.8964 - f1_score: 0.9395 - val_loss: 0.3432 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3596 - acc: 0.9431 - precision: 0.9900 - recall: 0.8974 - f1_score: 0.9399 - val_loss: 0.3424 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3588 - acc: 0.9431 - precision: 0.9901 - recall: 0.8954 - f1_score: 0.9392 - val_loss: 0.3416 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3580 - acc: 0.9431 - precision: 0.9887 - recall: 0.8907 - f1_score: 0.9360 - val_loss: 0.3408 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3572 - acc: 0.9431 - precision: 0.9895 - recall: 0.8955 - f1_score: 0.9388 - val_loss: 0.3400 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3564 - acc: 0.9431 - precision: 0.9891 - recall: 0.8945 - f1_score: 0.9378 - val_loss: 0.3392 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3556 - acc: 0.9431 - precision: 0.9910 - recall: 0.8838 - f1_score: 0.9314 - val_loss: 0.3385 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3549 - acc: 0.9431 - precision: 0.9903 - recall: 0.8976 - f1_score: 0.9402 - val_loss: 0.3377 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3541 - acc: 0.9431 - precision: 0.9895 - recall: 0.8932 - f1_score: 0.9378 - val_loss: 0.3369 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3533 - acc: 0.9431 - precision: 0.9888 - recall: 0.8935 - f1_score: 0.9376 - val_loss: 0.3361 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3526 - acc: 0.9431 - precision: 0.9874 - recall: 0.8990 - f1_score: 0.9391 - val_loss: 0.3354 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3518 - acc: 0.9431 - precision: 0.9883 - recall: 0.8894 - f1_score: 0.9351 - val_loss: 0.3346 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3510 - acc: 0.9431 - precision: 0.9895 - recall: 0.8922 - f1_score: 0.9370 - val_loss: 0.3338 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3503 - acc: 0.9431 - precision: 0.9874 - recall: 0.8920 - f1_score: 0.9362 - val_loss: 0.3331 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3495 - acc: 0.9431 - precision: 0.9901 - recall: 0.8964 - f1_score: 0.9389 - val_loss: 0.3323 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3488 - acc: 0.9431 - precision: 0.9893 - recall: 0.8908 - f1_score: 0.9354 - val_loss: 0.3315 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3480 - acc: 0.9431 - precision: 0.9899 - recall: 0.8910 - f1_score: 0.9368 - val_loss: 0.3308 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3473 - acc: 0.9431 - precision: 0.9903 - recall: 0.8930 - f1_score: 0.9381 - val_loss: 0.3300 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3466 - acc: 0.9431 - precision: 0.9879 - recall: 0.8947 - f1_score: 0.9375 - val_loss: 0.3293 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3458 - acc: 0.9431 - precision: 0.9896 - recall: 0.8923 - f1_score: 0.9373 - val_loss: 0.3286 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3451 - acc: 0.9431 - precision: 0.9890 - recall: 0.8954 - f1_score: 0.9389 - val_loss: 0.3278 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3444 - acc: 0.9431 - precision: 0.9912 - recall: 0.8947 - f1_score: 0.9394 - val_loss: 0.3271 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3436 - acc: 0.9431 - precision: 0.9898 - recall: 0.8962 - f1_score: 0.9402 - val_loss: 0.3264 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3429 - acc: 0.9431 - precision: 0.9902 - recall: 0.8983 - f1_score: 0.9407 - val_loss: 0.3256 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3422 - acc: 0.9431 - precision: 0.9886 - recall: 0.8922 - f1_score: 0.9365 - val_loss: 0.3249 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3415 - acc: 0.9431 - precision: 0.9897 - recall: 0.8929 - f1_score: 0.9377 - val_loss: 0.3242 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3408 - acc: 0.9431 - precision: 0.9903 - recall: 0.8925 - f1_score: 0.9374 - val_loss: 0.3235 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3401 - acc: 0.9431 - precision: 0.9889 - recall: 0.9002 - f1_score: 0.9407 - val_loss: 0.3228 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3393 - acc: 0.9431 - precision: 0.9875 - recall: 0.8930 - f1_score: 0.9372 - val_loss: 0.3221 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3386 - acc: 0.9431 - precision: 0.9903 - recall: 0.8932 - f1_score: 0.9384 - val_loss: 0.3213 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3379 - acc: 0.9431 - precision: 0.9884 - recall: 0.8945 - f1_score: 0.9374 - val_loss: 0.3206 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3373 - acc: 0.9431 - precision: 0.9885 - recall: 0.8900 - f1_score: 0.9359 - val_loss: 0.3199 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3366 - acc: 0.9431 - precision: 0.9887 - recall: 0.8964 - f1_score: 0.9391 - val_loss: 0.3192 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3359 - acc: 0.9431 - precision: 0.9889 - recall: 0.8932 - f1_score: 0.9359 - val_loss: 0.3186 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3352 - acc: 0.9431 - precision: 0.9901 - recall: 0.8956 - f1_score: 0.9391 - val_loss: 0.3179 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3345 - acc: 0.9431 - precision: 0.9882 - recall: 0.8960 - f1_score: 0.9391 - val_loss: 0.3172 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3338 - acc: 0.9431 - precision: 0.9883 - recall: 0.8917 - f1_score: 0.9362 - val_loss: 0.3165 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3331 - acc: 0.9431 - precision: 0.9891 - recall: 0.8968 - f1_score: 0.9395 - val_loss: 0.3158 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3325 - acc: 0.9431 - precision: 0.9903 - recall: 0.8943 - f1_score: 0.9391 - val_loss: 0.3151 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3318 - acc: 0.9431 - precision: 0.9894 - recall: 0.8955 - f1_score: 0.9391 - val_loss: 0.3145 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3311 - acc: 0.9431 - precision: 0.9897 - recall: 0.8958 - f1_score: 0.9393 - val_loss: 0.3138 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3305 - acc: 0.9431 - precision: 0.9893 - recall: 0.8939 - f1_score: 0.9382 - val_loss: 0.3131 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3298 - acc: 0.9431 - precision: 0.9915 - recall: 0.8929 - f1_score: 0.9384 - val_loss: 0.3125 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3292 - acc: 0.9431 - precision: 0.9897 - recall: 0.8968 - f1_score: 0.9399 - val_loss: 0.3118 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3285 - acc: 0.9431 - precision: 0.9902 - recall: 0.8963 - f1_score: 0.9394 - val_loss: 0.3111 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3279 - acc: 0.9431 - precision: 0.9900 - recall: 0.8993 - f1_score: 0.9401 - val_loss: 0.3105 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3272 - acc: 0.9431 - precision: 0.9875 - recall: 0.8907 - f1_score: 0.9353 - val_loss: 0.3098 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3266 - acc: 0.9431 - precision: 0.9900 - recall: 0.8962 - f1_score: 0.9403 - val_loss: 0.3092 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3259 - acc: 0.9431 - precision: 0.9908 - recall: 0.8946 - f1_score: 0.9389 - val_loss: 0.3085 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3253 - acc: 0.9431 - precision: 0.9883 - recall: 0.8949 - f1_score: 0.9382 - val_loss: 0.3079 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3246 - acc: 0.9431 - precision: 0.9892 - recall: 0.8935 - f1_score: 0.9383 - val_loss: 0.3072 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3240 - acc: 0.9431 - precision: 0.9899 - recall: 0.8918 - f1_score: 0.9375 - val_loss: 0.3066 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3234 - acc: 0.9431 - precision: 0.9895 - recall: 0.8923 - f1_score: 0.9366 - val_loss: 0.3060 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3228 - acc: 0.9431 - precision: 0.9909 - recall: 0.8902 - f1_score: 0.9358 - val_loss: 0.3053 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3221 - acc: 0.9431 - precision: 0.9891 - recall: 0.8976 - f1_score: 0.9403 - val_loss: 0.3047 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3215 - acc: 0.9431 - precision: 0.9900 - recall: 0.8972 - f1_score: 0.9400 - val_loss: 0.3041 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3209 - acc: 0.9431 - precision: 0.9895 - recall: 0.8916 - f1_score: 0.9370 - val_loss: 0.3035 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3203 - acc: 0.9431 - precision: 0.9895 - recall: 0.8942 - f1_score: 0.9389 - val_loss: 0.3028 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3197 - acc: 0.9431 - precision: 0.9891 - recall: 0.8922 - f1_score: 0.9372 - val_loss: 0.3022 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3191 - acc: 0.9431 - precision: 0.9897 - recall: 0.8947 - f1_score: 0.9372 - val_loss: 0.3016 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3185 - acc: 0.9431 - precision: 0.9875 - recall: 0.8922 - f1_score: 0.9359 - val_loss: 0.3010 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3178 - acc: 0.9431 - precision: 0.9897 - recall: 0.8950 - f1_score: 0.9389 - val_loss: 0.3004 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9431 - precision: 0.9883 - recall: 0.8929 - f1_score: 0.9374 - val_loss: 0.2998 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3166 - acc: 0.9431 - precision: 0.9892 - recall: 0.8928 - f1_score: 0.9371 - val_loss: 0.2992 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3160 - acc: 0.9431 - precision: 0.9903 - recall: 0.8964 - f1_score: 0.9400 - val_loss: 0.2986 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3155 - acc: 0.9431 - precision: 0.9899 - recall: 0.8941 - f1_score: 0.9380 - val_loss: 0.2980 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3149 - acc: 0.9431 - precision: 0.9883 - recall: 0.8976 - f1_score: 0.9387 - val_loss: 0.2974 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3143 - acc: 0.9431 - precision: 0.9907 - recall: 0.8936 - f1_score: 0.9379 - val_loss: 0.2968 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3137 - acc: 0.9431 - precision: 0.9896 - recall: 0.8957 - f1_score: 0.9391 - val_loss: 0.2962 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3131 - acc: 0.9431 - precision: 0.9898 - recall: 0.8979 - f1_score: 0.9392 - val_loss: 0.2956 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3125 - acc: 0.9431 - precision: 0.9904 - recall: 0.8966 - f1_score: 0.9405 - val_loss: 0.2950 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3119 - acc: 0.9431 - precision: 0.9897 - recall: 0.8953 - f1_score: 0.9384 - val_loss: 0.2944 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3114 - acc: 0.9431 - precision: 0.9892 - recall: 0.8951 - f1_score: 0.9380 - val_loss: 0.2939 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3108 - acc: 0.9431 - precision: 0.9885 - recall: 0.8941 - f1_score: 0.9372 - val_loss: 0.2933 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3102 - acc: 0.9431 - precision: 0.9895 - recall: 0.8888 - f1_score: 0.9342 - val_loss: 0.2927 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3097 - acc: 0.9431 - precision: 0.9894 - recall: 0.8954 - f1_score: 0.9391 - val_loss: 0.2921 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3091 - acc: 0.9431 - precision: 0.9899 - recall: 0.8949 - f1_score: 0.9387 - val_loss: 0.2916 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3085 - acc: 0.9431 - precision: 0.9895 - recall: 0.8951 - f1_score: 0.9381 - val_loss: 0.2910 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3080 - acc: 0.9431 - precision: 0.9890 - recall: 0.8917 - f1_score: 0.9369 - val_loss: 0.2904 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3074 - acc: 0.9431 - precision: 0.9891 - recall: 0.8920 - f1_score: 0.9371 - val_loss: 0.2898 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3069 - acc: 0.9431 - precision: 0.9868 - recall: 0.8947 - f1_score: 0.9379 - val_loss: 0.2893 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3063 - acc: 0.9431 - precision: 0.9902 - recall: 0.8928 - f1_score: 0.9371 - val_loss: 0.2887 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9431 - precision: 0.9897 - recall: 0.8929 - f1_score: 0.9374 - val_loss: 0.2882 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3052 - acc: 0.9431 - precision: 0.9897 - recall: 0.8966 - f1_score: 0.9401 - val_loss: 0.2876 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3047 - acc: 0.9431 - precision: 0.9900 - recall: 0.8929 - f1_score: 0.9372 - val_loss: 0.2871 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3041 - acc: 0.9431 - precision: 0.9897 - recall: 0.8947 - f1_score: 0.9385 - val_loss: 0.2865 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3036 - acc: 0.9431 - precision: 0.9888 - recall: 0.8997 - f1_score: 0.9407 - val_loss: 0.2860 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3031 - acc: 0.9431 - precision: 0.9908 - recall: 0.8934 - f1_score: 0.9387 - val_loss: 0.2854 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3025 - acc: 0.9431 - precision: 0.9900 - recall: 0.8943 - f1_score: 0.9387 - val_loss: 0.2849 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3020 - acc: 0.9431 - precision: 0.9893 - recall: 0.8979 - f1_score: 0.9406 - val_loss: 0.2843 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3015 - acc: 0.9431 - precision: 0.9891 - recall: 0.8942 - f1_score: 0.9380 - val_loss: 0.2838 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3009 - acc: 0.9431 - precision: 0.9897 - recall: 0.8924 - f1_score: 0.9372 - val_loss: 0.2833 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3004 - acc: 0.9431 - precision: 0.9900 - recall: 0.8962 - f1_score: 0.9401 - val_loss: 0.2827 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2999 - acc: 0.9431 - precision: 0.9900 - recall: 0.8944 - f1_score: 0.9391 - val_loss: 0.2822 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2994 - acc: 0.9431 - precision: 0.9900 - recall: 0.8947 - f1_score: 0.9379 - val_loss: 0.2817 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2989 - acc: 0.9431 - precision: 0.9893 - recall: 0.8948 - f1_score: 0.9390 - val_loss: 0.2812 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2983 - acc: 0.9431 - precision: 0.9900 - recall: 0.8955 - f1_score: 0.9399 - val_loss: 0.2806 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9431 - precision: 0.9895 - recall: 0.8987 - f1_score: 0.9395 - val_loss: 0.2801 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2973 - acc: 0.9431 - precision: 0.9898 - recall: 0.8950 - f1_score: 0.9385 - val_loss: 0.2796 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2968 - acc: 0.9431 - precision: 0.9898 - recall: 0.8982 - f1_score: 0.9412 - val_loss: 0.2791 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2963 - acc: 0.9431 - precision: 0.9894 - recall: 0.8963 - f1_score: 0.9399 - val_loss: 0.2786 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2958 - acc: 0.9431 - precision: 0.9861 - recall: 0.8944 - f1_score: 0.9370 - val_loss: 0.2780 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 808/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2953 - acc: 0.9431 - precision: 0.9895 - recall: 0.8959 - f1_score: 0.9392 - val_loss: 0.2775 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2948 - acc: 0.9431 - precision: 0.9897 - recall: 0.8920 - f1_score: 0.9377 - val_loss: 0.2770 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2943 - acc: 0.9431 - precision: 0.9902 - recall: 0.8935 - f1_score: 0.9373 - val_loss: 0.2765 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2938 - acc: 0.9431 - precision: 0.9904 - recall: 0.8961 - f1_score: 0.9396 - val_loss: 0.2760 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2933 - acc: 0.9431 - precision: 0.9889 - recall: 0.8932 - f1_score: 0.9381 - val_loss: 0.2755 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2928 - acc: 0.9431 - precision: 0.9896 - recall: 0.8937 - f1_score: 0.9383 - val_loss: 0.2750 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2923 - acc: 0.9431 - precision: 0.9882 - recall: 0.8976 - f1_score: 0.9395 - val_loss: 0.2745 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2918 - acc: 0.9431 - precision: 0.9881 - recall: 0.8932 - f1_score: 0.9369 - val_loss: 0.2740 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2914 - acc: 0.9431 - precision: 0.9883 - recall: 0.8936 - f1_score: 0.9375 - val_loss: 0.2736 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2909 - acc: 0.9431 - precision: 0.9896 - recall: 0.8941 - f1_score: 0.9386 - val_loss: 0.2731 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2904 - acc: 0.9431 - precision: 0.9901 - recall: 0.9000 - f1_score: 0.9413 - val_loss: 0.2726 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2899 - acc: 0.9431 - precision: 0.9899 - recall: 0.8957 - f1_score: 0.9395 - val_loss: 0.2721 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2894 - acc: 0.9431 - precision: 0.9883 - recall: 0.8922 - f1_score: 0.9366 - val_loss: 0.2716 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2890 - acc: 0.9431 - precision: 0.9892 - recall: 0.8925 - f1_score: 0.9380 - val_loss: 0.2711 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2885 - acc: 0.9431 - precision: 0.9899 - recall: 0.8939 - f1_score: 0.9384 - val_loss: 0.2707 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2880 - acc: 0.9431 - precision: 0.9893 - recall: 0.8914 - f1_score: 0.9356 - val_loss: 0.2702 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2876 - acc: 0.9431 - precision: 0.9895 - recall: 0.8959 - f1_score: 0.9396 - val_loss: 0.2697 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2871 - acc: 0.9431 - precision: 0.9904 - recall: 0.8984 - f1_score: 0.9407 - val_loss: 0.2692 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2866 - acc: 0.9431 - precision: 0.9883 - recall: 0.8947 - f1_score: 0.9388 - val_loss: 0.2688 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2862 - acc: 0.9431 - precision: 0.9896 - recall: 0.8935 - f1_score: 0.9383 - val_loss: 0.2683 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2857 - acc: 0.9431 - precision: 0.9909 - recall: 0.8948 - f1_score: 0.9396 - val_loss: 0.2678 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2853 - acc: 0.9431 - precision: 0.9888 - recall: 0.8950 - f1_score: 0.9389 - val_loss: 0.2674 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9431 - precision: 0.9900 - recall: 0.8933 - f1_score: 0.9377 - val_loss: 0.2669 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2844 - acc: 0.9431 - precision: 0.9892 - recall: 0.9011 - f1_score: 0.9424 - val_loss: 0.2664 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2839 - acc: 0.9431 - precision: 0.9890 - recall: 0.8946 - f1_score: 0.9386 - val_loss: 0.2660 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2834 - acc: 0.9431 - precision: 0.9888 - recall: 0.8912 - f1_score: 0.9368 - val_loss: 0.2655 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2830 - acc: 0.9431 - precision: 0.9882 - recall: 0.8927 - f1_score: 0.9372 - val_loss: 0.2651 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2826 - acc: 0.9431 - precision: 0.9915 - recall: 0.8892 - f1_score: 0.9354 - val_loss: 0.2646 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2821 - acc: 0.9431 - precision: 0.9891 - recall: 0.8952 - f1_score: 0.9384 - val_loss: 0.2642 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2817 - acc: 0.9431 - precision: 0.9905 - recall: 0.8954 - f1_score: 0.9394 - val_loss: 0.2637 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2812 - acc: 0.9431 - precision: 0.9884 - recall: 0.8934 - f1_score: 0.9381 - val_loss: 0.2633 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2808 - acc: 0.9431 - precision: 0.9889 - recall: 0.8951 - f1_score: 0.9387 - val_loss: 0.2628 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2804 - acc: 0.9431 - precision: 0.9886 - recall: 0.8932 - f1_score: 0.9374 - val_loss: 0.2624 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2799 - acc: 0.9431 - precision: 0.9896 - recall: 0.8952 - f1_score: 0.9378 - val_loss: 0.2620 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2795 - acc: 0.9431 - precision: 0.9890 - recall: 0.8948 - f1_score: 0.9381 - val_loss: 0.2615 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2791 - acc: 0.9431 - precision: 0.9898 - recall: 0.8927 - f1_score: 0.9377 - val_loss: 0.2611 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2787 - acc: 0.9431 - precision: 0.9887 - recall: 0.8953 - f1_score: 0.9385 - val_loss: 0.2607 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2782 - acc: 0.9431 - precision: 0.9900 - recall: 0.8921 - f1_score: 0.9363 - val_loss: 0.2602 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2778 - acc: 0.9431 - precision: 0.9894 - recall: 0.8971 - f1_score: 0.9395 - val_loss: 0.2598 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2774 - acc: 0.9431 - precision: 0.9896 - recall: 0.8959 - f1_score: 0.9385 - val_loss: 0.2594 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2770 - acc: 0.9431 - precision: 0.9895 - recall: 0.8967 - f1_score: 0.9398 - val_loss: 0.2590 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2766 - acc: 0.9431 - precision: 0.9889 - recall: 0.8972 - f1_score: 0.9396 - val_loss: 0.2585 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2761 - acc: 0.9431 - precision: 0.9889 - recall: 0.8947 - f1_score: 0.9379 - val_loss: 0.2581 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2757 - acc: 0.9431 - precision: 0.9906 - recall: 0.9028 - f1_score: 0.9433 - val_loss: 0.2577 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2753 - acc: 0.9431 - precision: 0.9889 - recall: 0.8896 - f1_score: 0.9349 - val_loss: 0.2573 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2749 - acc: 0.9431 - precision: 0.9908 - recall: 0.8968 - f1_score: 0.9399 - val_loss: 0.2569 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2745 - acc: 0.9431 - precision: 0.9894 - recall: 0.8910 - f1_score: 0.9355 - val_loss: 0.2565 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2741 - acc: 0.9431 - precision: 0.9894 - recall: 0.8956 - f1_score: 0.9383 - val_loss: 0.2560 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2737 - acc: 0.9431 - precision: 0.9902 - recall: 0.8939 - f1_score: 0.9386 - val_loss: 0.2556 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2733 - acc: 0.9431 - precision: 0.9887 - recall: 0.8949 - f1_score: 0.9382 - val_loss: 0.2552 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2729 - acc: 0.9431 - precision: 0.9892 - recall: 0.8945 - f1_score: 0.9386 - val_loss: 0.2548 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2725 - acc: 0.9431 - precision: 0.9887 - recall: 0.8963 - f1_score: 0.9396 - val_loss: 0.2544 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9431 - precision: 0.9895 - recall: 0.8998 - f1_score: 0.9412 - val_loss: 0.2540 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2717 - acc: 0.9431 - precision: 0.9902 - recall: 0.8928 - f1_score: 0.9377 - val_loss: 0.2536 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2713 - acc: 0.9431 - precision: 0.9883 - recall: 0.8929 - f1_score: 0.9363 - val_loss: 0.2532 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2709 - acc: 0.9431 - precision: 0.9901 - recall: 0.8947 - f1_score: 0.9388 - val_loss: 0.2528 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2705 - acc: 0.9431 - precision: 0.9880 - recall: 0.8949 - f1_score: 0.9382 - val_loss: 0.2524 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9431 - precision: 0.9884 - recall: 0.8928 - f1_score: 0.9377 - val_loss: 0.2520 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9431 - precision: 0.9894 - recall: 0.8948 - f1_score: 0.9387 - val_loss: 0.2516 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9431 - precision: 0.9884 - recall: 0.8952 - f1_score: 0.9380 - val_loss: 0.2512 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2689 - acc: 0.9431 - precision: 0.9898 - recall: 0.8936 - f1_score: 0.9387 - val_loss: 0.2508 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2686 - acc: 0.9431 - precision: 0.9897 - recall: 0.8920 - f1_score: 0.9372 - val_loss: 0.2504 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2682 - acc: 0.9431 - precision: 0.9902 - recall: 0.8957 - f1_score: 0.9396 - val_loss: 0.2500 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2678 - acc: 0.9431 - precision: 0.9901 - recall: 0.8911 - f1_score: 0.9366 - val_loss: 0.2497 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2674 - acc: 0.9431 - precision: 0.9888 - recall: 0.8962 - f1_score: 0.9394 - val_loss: 0.2493 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2671 - acc: 0.9431 - precision: 0.9892 - recall: 0.8951 - f1_score: 0.9386 - val_loss: 0.2489 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2667 - acc: 0.9431 - precision: 0.9881 - recall: 0.8949 - f1_score: 0.9377 - val_loss: 0.2485 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2663 - acc: 0.9431 - precision: 0.9906 - recall: 0.8943 - f1_score: 0.9389 - val_loss: 0.2481 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2659 - acc: 0.9431 - precision: 0.9906 - recall: 0.8926 - f1_score: 0.9380 - val_loss: 0.2478 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2656 - acc: 0.9431 - precision: 0.9897 - recall: 0.8922 - f1_score: 0.9371 - val_loss: 0.2474 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9431 - precision: 0.9885 - recall: 0.8924 - f1_score: 0.9368 - val_loss: 0.2470 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9431 - precision: 0.9890 - recall: 0.8951 - f1_score: 0.9389 - val_loss: 0.2467 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2645 - acc: 0.9431 - precision: 0.9888 - recall: 0.8969 - f1_score: 0.9397 - val_loss: 0.2463 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2641 - acc: 0.9431 - precision: 0.9904 - recall: 0.8990 - f1_score: 0.9417 - val_loss: 0.2459 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2638 - acc: 0.9431 - precision: 0.9902 - recall: 0.8920 - f1_score: 0.9365 - val_loss: 0.2456 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2634 - acc: 0.9431 - precision: 0.9902 - recall: 0.8888 - f1_score: 0.9351 - val_loss: 0.2452 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2630 - acc: 0.9431 - precision: 0.9897 - recall: 0.8942 - f1_score: 0.9381 - val_loss: 0.2448 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2627 - acc: 0.9431 - precision: 0.9913 - recall: 0.9011 - f1_score: 0.9416 - val_loss: 0.2445 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2623 - acc: 0.9431 - precision: 0.9901 - recall: 0.8957 - f1_score: 0.9394 - val_loss: 0.2441 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2620 - acc: 0.9431 - precision: 0.9895 - recall: 0.8931 - f1_score: 0.9372 - val_loss: 0.2437 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2616 - acc: 0.9431 - precision: 0.9904 - recall: 0.8917 - f1_score: 0.9373 - val_loss: 0.2434 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2613 - acc: 0.9431 - precision: 0.9890 - recall: 0.8922 - f1_score: 0.9377 - val_loss: 0.2430 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2609 - acc: 0.9431 - precision: 0.9890 - recall: 0.8976 - f1_score: 0.9399 - val_loss: 0.2427 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2606 - acc: 0.9431 - precision: 0.9879 - recall: 0.8959 - f1_score: 0.9386 - val_loss: 0.2423 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9431 - precision: 0.9890 - recall: 0.8952 - f1_score: 0.9386 - val_loss: 0.2420 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2599 - acc: 0.9431 - precision: 0.9898 - recall: 0.8953 - f1_score: 0.9393 - val_loss: 0.2416 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2595 - acc: 0.9431 - precision: 0.9905 - recall: 0.8950 - f1_score: 0.9392 - val_loss: 0.2413 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2592 - acc: 0.9431 - precision: 0.9895 - recall: 0.8930 - f1_score: 0.9381 - val_loss: 0.2409 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2589 - acc: 0.9431 - precision: 0.9880 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 0.2406 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9431 - precision: 0.9885 - recall: 0.8970 - f1_score: 0.9398 - val_loss: 0.2402 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2582 - acc: 0.9431 - precision: 0.9892 - recall: 0.8969 - f1_score: 0.9402 - val_loss: 0.2399 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2579 - acc: 0.9431 - precision: 0.9898 - recall: 0.8954 - f1_score: 0.9396 - val_loss: 0.2396 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9431 - precision: 0.9886 - recall: 0.8952 - f1_score: 0.9387 - val_loss: 0.2392 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9431 - precision: 0.9908 - recall: 0.8917 - f1_score: 0.9372 - val_loss: 0.2389 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2569 - acc: 0.9431 - precision: 0.9911 - recall: 0.8953 - f1_score: 0.9396 - val_loss: 0.2385 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9431 - precision: 0.9887 - recall: 0.8950 - f1_score: 0.9389 - val_loss: 0.2382 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 904/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2562 - acc: 0.9431 - precision: 0.9902 - recall: 0.8939 - f1_score: 0.9387 - val_loss: 0.2379 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2559 - acc: 0.9431 - precision: 0.9887 - recall: 0.8924 - f1_score: 0.9373 - val_loss: 0.2375 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2556 - acc: 0.9431 - precision: 0.9905 - recall: 0.8952 - f1_score: 0.9391 - val_loss: 0.2372 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2552 - acc: 0.9431 - precision: 0.9892 - recall: 0.8935 - f1_score: 0.9380 - val_loss: 0.2369 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2549 - acc: 0.9431 - precision: 0.9879 - recall: 0.8971 - f1_score: 0.9389 - val_loss: 0.2365 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2546 - acc: 0.9431 - precision: 0.9896 - recall: 0.8959 - f1_score: 0.9394 - val_loss: 0.2362 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2543 - acc: 0.9431 - precision: 0.9901 - recall: 0.8971 - f1_score: 0.9406 - val_loss: 0.2359 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2540 - acc: 0.9431 - precision: 0.9897 - recall: 0.8956 - f1_score: 0.9398 - val_loss: 0.2356 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2536 - acc: 0.9431 - precision: 0.9908 - recall: 0.8970 - f1_score: 0.9397 - val_loss: 0.2352 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2533 - acc: 0.9431 - precision: 0.9897 - recall: 0.8945 - f1_score: 0.9374 - val_loss: 0.2349 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2530 - acc: 0.9431 - precision: 0.9871 - recall: 0.8939 - f1_score: 0.9375 - val_loss: 0.2346 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2527 - acc: 0.9431 - precision: 0.9902 - recall: 0.8942 - f1_score: 0.9386 - val_loss: 0.2343 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2524 - acc: 0.9431 - precision: 0.9890 - recall: 0.8941 - f1_score: 0.9382 - val_loss: 0.2340 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2521 - acc: 0.9431 - precision: 0.9904 - recall: 0.8955 - f1_score: 0.9399 - val_loss: 0.2337 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2518 - acc: 0.9431 - precision: 0.9897 - recall: 0.8941 - f1_score: 0.9382 - val_loss: 0.2333 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2515 - acc: 0.9431 - precision: 0.9884 - recall: 0.8931 - f1_score: 0.9370 - val_loss: 0.2330 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2512 - acc: 0.9431 - precision: 0.9911 - recall: 0.8913 - f1_score: 0.9376 - val_loss: 0.2327 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2508 - acc: 0.9431 - precision: 0.9889 - recall: 0.8950 - f1_score: 0.9378 - val_loss: 0.2324 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2505 - acc: 0.9431 - precision: 0.9898 - recall: 0.8933 - f1_score: 0.9382 - val_loss: 0.2321 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2502 - acc: 0.9431 - precision: 0.9898 - recall: 0.8959 - f1_score: 0.9393 - val_loss: 0.2318 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2499 - acc: 0.9431 - precision: 0.9890 - recall: 0.8998 - f1_score: 0.9411 - val_loss: 0.2315 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9431 - precision: 0.9888 - recall: 0.8970 - f1_score: 0.9389 - val_loss: 0.2312 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9431 - precision: 0.9894 - recall: 0.8908 - f1_score: 0.9361 - val_loss: 0.2309 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2490 - acc: 0.9431 - precision: 0.9898 - recall: 0.8939 - f1_score: 0.9385 - val_loss: 0.2306 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2488 - acc: 0.9431 - precision: 0.9901 - recall: 0.8932 - f1_score: 0.9383 - val_loss: 0.2303 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2485 - acc: 0.9431 - precision: 0.9906 - recall: 0.8922 - f1_score: 0.9383 - val_loss: 0.2300 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2482 - acc: 0.9431 - precision: 0.9889 - recall: 0.8941 - f1_score: 0.9375 - val_loss: 0.2297 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2479 - acc: 0.9431 - precision: 0.9900 - recall: 0.8958 - f1_score: 0.9386 - val_loss: 0.2294 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2476 - acc: 0.9431 - precision: 0.9885 - recall: 0.8918 - f1_score: 0.9362 - val_loss: 0.2291 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2473 - acc: 0.9431 - precision: 0.9892 - recall: 0.8984 - f1_score: 0.9407 - val_loss: 0.2288 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9431 - precision: 0.9917 - recall: 0.8915 - f1_score: 0.9378 - val_loss: 0.2285 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9431 - precision: 0.9899 - recall: 0.8944 - f1_score: 0.9391 - val_loss: 0.2282 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2465 - acc: 0.9431 - precision: 0.9887 - recall: 0.9006 - f1_score: 0.9408 - val_loss: 0.2280 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2462 - acc: 0.9431 - precision: 0.9908 - recall: 0.8923 - f1_score: 0.9380 - val_loss: 0.2277 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9431 - precision: 0.9892 - recall: 0.9001 - f1_score: 0.9412 - val_loss: 0.2274 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9431 - precision: 0.9903 - recall: 0.8892 - f1_score: 0.9353 - val_loss: 0.2271 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9431 - precision: 0.9885 - recall: 0.8937 - f1_score: 0.9370 - val_loss: 0.2268 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9431 - precision: 0.9905 - recall: 0.8978 - f1_score: 0.9405 - val_loss: 0.2265 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9431 - precision: 0.9890 - recall: 0.8992 - f1_score: 0.9411 - val_loss: 0.2263 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2445 - acc: 0.9431 - precision: 0.9894 - recall: 0.8914 - f1_score: 0.9364 - val_loss: 0.2260 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2442 - acc: 0.9431 - precision: 0.9895 - recall: 0.8937 - f1_score: 0.9384 - val_loss: 0.2257 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2439 - acc: 0.9431 - precision: 0.9894 - recall: 0.8941 - f1_score: 0.9379 - val_loss: 0.2254 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2437 - acc: 0.9431 - precision: 0.9890 - recall: 0.8915 - f1_score: 0.9371 - val_loss: 0.2251 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2434 - acc: 0.9431 - precision: 0.9889 - recall: 0.8938 - f1_score: 0.9383 - val_loss: 0.2249 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2431 - acc: 0.9431 - precision: 0.9897 - recall: 0.8945 - f1_score: 0.9388 - val_loss: 0.2246 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2429 - acc: 0.9431 - precision: 0.9889 - recall: 0.8950 - f1_score: 0.9381 - val_loss: 0.2243 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9431 - precision: 0.9908 - recall: 0.8948 - f1_score: 0.9391 - val_loss: 0.2240 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9431 - precision: 0.9884 - recall: 0.8874 - f1_score: 0.9337 - val_loss: 0.2238 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2421 - acc: 0.9431 - precision: 0.9892 - recall: 0.8950 - f1_score: 0.9386 - val_loss: 0.2235 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2418 - acc: 0.9431 - precision: 0.9885 - recall: 0.8988 - f1_score: 0.9398 - val_loss: 0.2232 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2415 - acc: 0.9431 - precision: 0.9895 - recall: 0.8959 - f1_score: 0.9393 - val_loss: 0.2229 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2413 - acc: 0.9431 - precision: 0.9895 - recall: 0.8963 - f1_score: 0.9393 - val_loss: 0.2227 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2410 - acc: 0.9431 - precision: 0.9893 - recall: 0.8938 - f1_score: 0.9384 - val_loss: 0.2224 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2407 - acc: 0.9431 - precision: 0.9889 - recall: 0.8942 - f1_score: 0.9376 - val_loss: 0.2221 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2405 - acc: 0.9431 - precision: 0.9912 - recall: 0.8899 - f1_score: 0.9349 - val_loss: 0.2219 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9431 - precision: 0.9896 - recall: 0.8908 - f1_score: 0.9355 - val_loss: 0.2216 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2400 - acc: 0.9431 - precision: 0.9905 - recall: 0.8948 - f1_score: 0.9395 - val_loss: 0.2213 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2397 - acc: 0.9431 - precision: 0.9894 - recall: 0.8960 - f1_score: 0.9394 - val_loss: 0.2211 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2394 - acc: 0.9431 - precision: 0.9890 - recall: 0.8962 - f1_score: 0.9391 - val_loss: 0.2208 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9431 - precision: 0.9887 - recall: 0.8942 - f1_score: 0.9378 - val_loss: 0.2206 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9431 - precision: 0.9891 - recall: 0.8944 - f1_score: 0.9381 - val_loss: 0.2203 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2387 - acc: 0.9431 - precision: 0.9892 - recall: 0.8962 - f1_score: 0.9397 - val_loss: 0.2200 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9431 - precision: 0.9890 - recall: 0.8935 - f1_score: 0.9370 - val_loss: 0.2198 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2382 - acc: 0.9431 - precision: 0.9904 - recall: 0.8934 - f1_score: 0.9372 - val_loss: 0.2195 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2379 - acc: 0.9431 - precision: 0.9890 - recall: 0.8958 - f1_score: 0.9389 - val_loss: 0.2193 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9431 - precision: 0.9888 - recall: 0.8921 - f1_score: 0.9375 - val_loss: 0.2190 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2375 - acc: 0.9431 - precision: 0.9894 - recall: 0.8957 - f1_score: 0.9392 - val_loss: 0.2188 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9431 - precision: 0.9890 - recall: 0.9004 - f1_score: 0.9405 - val_loss: 0.2185 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9431 - precision: 0.9891 - recall: 0.8928 - f1_score: 0.9372 - val_loss: 0.2183 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2367 - acc: 0.9431 - precision: 0.9902 - recall: 0.8912 - f1_score: 0.9369 - val_loss: 0.2180 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2365 - acc: 0.9431 - precision: 0.9900 - recall: 0.8964 - f1_score: 0.9395 - val_loss: 0.2178 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2362 - acc: 0.9431 - precision: 0.9887 - recall: 0.8971 - f1_score: 0.9396 - val_loss: 0.2175 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9431 - precision: 0.9889 - recall: 0.8948 - f1_score: 0.9388 - val_loss: 0.2173 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9431 - precision: 0.9905 - recall: 0.8933 - f1_score: 0.9380 - val_loss: 0.2171 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9431 - precision: 0.9902 - recall: 0.8915 - f1_score: 0.9371 - val_loss: 0.2168 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9431 - precision: 0.9900 - recall: 0.8954 - f1_score: 0.9397 - val_loss: 0.2166 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9431 - precision: 0.9867 - recall: 0.8940 - f1_score: 0.9372 - val_loss: 0.2163 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2348 - acc: 0.9431 - precision: 0.9872 - recall: 0.8881 - f1_score: 0.9340 - val_loss: 0.2161 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9431 - precision: 0.9906 - recall: 0.8922 - f1_score: 0.9375 - val_loss: 0.2158 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2343 - acc: 0.9431 - precision: 0.9900 - recall: 0.8956 - f1_score: 0.9395 - val_loss: 0.2156 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9431 - precision: 0.9904 - recall: 0.8942 - f1_score: 0.9390 - val_loss: 0.2154 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9431 - precision: 0.9904 - recall: 0.8960 - f1_score: 0.9393 - val_loss: 0.2151 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2336 - acc: 0.9431 - precision: 0.9895 - recall: 0.8930 - f1_score: 0.9381 - val_loss: 0.2149 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9431 - precision: 0.9895 - recall: 0.8970 - f1_score: 0.9398 - val_loss: 0.2147 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9431 - precision: 0.9880 - recall: 0.8901 - f1_score: 0.9349 - val_loss: 0.2144 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2330 - acc: 0.9431 - precision: 0.9905 - recall: 0.8948 - f1_score: 0.9396 - val_loss: 0.2142 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9431 - precision: 0.9895 - recall: 0.8965 - f1_score: 0.9399 - val_loss: 0.2140 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9431 - precision: 0.9879 - recall: 0.8937 - f1_score: 0.9377 - val_loss: 0.2137 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2323 - acc: 0.9431 - precision: 0.9905 - recall: 0.8893 - f1_score: 0.9355 - val_loss: 0.2135 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2321 - acc: 0.9431 - precision: 0.9907 - recall: 0.8934 - f1_score: 0.9374 - val_loss: 0.2133 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2318 - acc: 0.9431 - precision: 0.9892 - recall: 0.8945 - f1_score: 0.9382 - val_loss: 0.2131 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2316 - acc: 0.9431 - precision: 0.9887 - recall: 0.8947 - f1_score: 0.9376 - val_loss: 0.2128 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2314 - acc: 0.9431 - precision: 0.9881 - recall: 0.8974 - f1_score: 0.9392 - val_loss: 0.2126 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2312 - acc: 0.9431 - precision: 0.9890 - recall: 0.8924 - f1_score: 0.9376 - val_loss: 0.2124 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9431 - precision: 0.9890 - recall: 0.8949 - f1_score: 0.9388 - val_loss: 0.2122 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9431 - precision: 0.9903 - recall: 0.8937 - f1_score: 0.9384 - val_loss: 0.2119 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      "Epoch 1000/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2305 - acc: 0.9431 - precision: 0.9898 - recall: 0.8928 - f1_score: 0.9376 - val_loss: 0.2117 - val_acc: 0.9557 - val_precision: 1.0000 - val_recall: 0.9120 - val_f1_score: 0.9534\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.1348 - acc: 0.3823 - precision: 0.3740 - recall: 0.6166 - f1_score: 0.4566 - val_loss: 5.9325 - val_acc: 0.5633 - val_precision: 0.5552 - val_recall: 1.0000 - val_f1_score: 0.7128\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9284 - acc: 0.5434 - precision: 0.5142 - recall: 0.9939 - f1_score: 0.6763 - val_loss: 5.8549 - val_acc: 0.5696 - val_precision: 0.5588 - val_recall: 1.0000 - val_f1_score: 0.7158\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8697 - acc: 0.5498 - precision: 0.5163 - recall: 0.9970 - f1_score: 0.6773 - val_loss: 5.8057 - val_acc: 0.5823 - val_precision: 0.5662 - val_recall: 1.0000 - val_f1_score: 0.7219\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8254 - acc: 0.5561 - precision: 0.5213 - recall: 0.9971 - f1_score: 0.6829 - val_loss: 5.7641 - val_acc: 0.5823 - val_precision: 0.5662 - val_recall: 1.0000 - val_f1_score: 0.7219\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7859 - acc: 0.5750 - precision: 0.5318 - recall: 0.9972 - f1_score: 0.6903 - val_loss: 5.7263 - val_acc: 0.5949 - val_precision: 0.5739 - val_recall: 1.0000 - val_f1_score: 0.7281\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7489 - acc: 0.5845 - precision: 0.5365 - recall: 0.9919 - f1_score: 0.6948 - val_loss: 5.6904 - val_acc: 0.6076 - val_precision: 0.5820 - val_recall: 1.0000 - val_f1_score: 0.7344\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7134 - acc: 0.6098 - precision: 0.5520 - recall: 0.9939 - f1_score: 0.7033 - val_loss: 5.6559 - val_acc: 0.6266 - val_precision: 0.5943 - val_recall: 1.0000 - val_f1_score: 0.7441\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6788 - acc: 0.6240 - precision: 0.5615 - recall: 0.9944 - f1_score: 0.7141 - val_loss: 5.6224 - val_acc: 0.6266 - val_precision: 0.5960 - val_recall: 0.9883 - val_f1_score: 0.7419\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6450 - acc: 0.6367 - precision: 0.5720 - recall: 0.9872 - f1_score: 0.7200 - val_loss: 5.5896 - val_acc: 0.6519 - val_precision: 0.6119 - val_recall: 0.9883 - val_f1_score: 0.7546\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6119 - acc: 0.6477 - precision: 0.5786 - recall: 0.9796 - f1_score: 0.7255 - val_loss: 5.5574 - val_acc: 0.6772 - val_precision: 0.6293 - val_recall: 0.9883 - val_f1_score: 0.7683\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5793 - acc: 0.6730 - precision: 0.6016 - recall: 0.9805 - f1_score: 0.7434 - val_loss: 5.5258 - val_acc: 0.6899 - val_precision: 0.6411 - val_recall: 0.9770 - val_f1_score: 0.7733\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5471 - acc: 0.6951 - precision: 0.6139 - recall: 0.9795 - f1_score: 0.7511 - val_loss: 5.4945 - val_acc: 0.7089 - val_precision: 0.6567 - val_recall: 0.9770 - val_f1_score: 0.7849\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5153 - acc: 0.7141 - precision: 0.6342 - recall: 0.9792 - f1_score: 0.7658 - val_loss: 5.4637 - val_acc: 0.7278 - val_precision: 0.6734 - val_recall: 0.9770 - val_f1_score: 0.7964\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4839 - acc: 0.7346 - precision: 0.6510 - recall: 0.9778 - f1_score: 0.7790 - val_loss: 5.4333 - val_acc: 0.7405 - val_precision: 0.6834 - val_recall: 0.9770 - val_f1_score: 0.8037\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4529 - acc: 0.7425 - precision: 0.6550 - recall: 0.9750 - f1_score: 0.7809 - val_loss: 5.4033 - val_acc: 0.7658 - val_precision: 0.7070 - val_recall: 0.9770 - val_f1_score: 0.8196\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4222 - acc: 0.7583 - precision: 0.6721 - recall: 0.9702 - f1_score: 0.7927 - val_loss: 5.3735 - val_acc: 0.7722 - val_precision: 0.7146 - val_recall: 0.9770 - val_f1_score: 0.8250\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3917 - acc: 0.7788 - precision: 0.6925 - recall: 0.9669 - f1_score: 0.8031 - val_loss: 5.3441 - val_acc: 0.7975 - val_precision: 0.7419 - val_recall: 0.9770 - val_f1_score: 0.8421\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3616 - acc: 0.7946 - precision: 0.7117 - recall: 0.9608 - f1_score: 0.8161 - val_loss: 5.3149 - val_acc: 0.8038 - val_precision: 0.7529 - val_recall: 0.9653 - val_f1_score: 0.8444\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3318 - acc: 0.8104 - precision: 0.7307 - recall: 0.9618 - f1_score: 0.8282 - val_loss: 5.2861 - val_acc: 0.8228 - val_precision: 0.7702 - val_recall: 0.9653 - val_f1_score: 0.8560\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3023 - acc: 0.8262 - precision: 0.7473 - recall: 0.9614 - f1_score: 0.8387 - val_loss: 5.2575 - val_acc: 0.8354 - val_precision: 0.7852 - val_recall: 0.9653 - val_f1_score: 0.8649\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2730 - acc: 0.8389 - precision: 0.7675 - recall: 0.9606 - f1_score: 0.8498 - val_loss: 5.2291 - val_acc: 0.8418 - val_precision: 0.7922 - val_recall: 0.9653 - val_f1_score: 0.8693\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2440 - acc: 0.8483 - precision: 0.7811 - recall: 0.9488 - f1_score: 0.8544 - val_loss: 5.2010 - val_acc: 0.8544 - val_precision: 0.8064 - val_recall: 0.9653 - val_f1_score: 0.8781\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2153 - acc: 0.8594 - precision: 0.8009 - recall: 0.9472 - f1_score: 0.8663 - val_loss: 5.1732 - val_acc: 0.8544 - val_precision: 0.8138 - val_recall: 0.9540 - val_f1_score: 0.8773\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1868 - acc: 0.8752 - precision: 0.8203 - recall: 0.9478 - f1_score: 0.8773 - val_loss: 5.1456 - val_acc: 0.8608 - val_precision: 0.8219 - val_recall: 0.9540 - val_f1_score: 0.8820\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1586 - acc: 0.8878 - precision: 0.8387 - recall: 0.9512 - f1_score: 0.8857 - val_loss: 5.1183 - val_acc: 0.8671 - val_precision: 0.8305 - val_recall: 0.9540 - val_f1_score: 0.8868\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1306 - acc: 0.8894 - precision: 0.8387 - recall: 0.9419 - f1_score: 0.8860 - val_loss: 5.0911 - val_acc: 0.8671 - val_precision: 0.8305 - val_recall: 0.9540 - val_f1_score: 0.8868\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1029 - acc: 0.8942 - precision: 0.8528 - recall: 0.9431 - f1_score: 0.8941 - val_loss: 5.0642 - val_acc: 0.8797 - val_precision: 0.8495 - val_recall: 0.9540 - val_f1_score: 0.8970\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0753 - acc: 0.8957 - precision: 0.8571 - recall: 0.9402 - f1_score: 0.8952 - val_loss: 5.0375 - val_acc: 0.8861 - val_precision: 0.8662 - val_recall: 0.9422 - val_f1_score: 0.9003\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0480 - acc: 0.8973 - precision: 0.8607 - recall: 0.9398 - f1_score: 0.8974 - val_loss: 5.0110 - val_acc: 0.8987 - val_precision: 0.8855 - val_recall: 0.9422 - val_f1_score: 0.9103\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0209 - acc: 0.8973 - precision: 0.8631 - recall: 0.9273 - f1_score: 0.8930 - val_loss: 4.9847 - val_acc: 0.9051 - val_precision: 0.8982 - val_recall: 0.9422 - val_f1_score: 0.9160\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9940 - acc: 0.9068 - precision: 0.8818 - recall: 0.9303 - f1_score: 0.9044 - val_loss: 4.9586 - val_acc: 0.9114 - val_precision: 0.9062 - val_recall: 0.9422 - val_f1_score: 0.9207\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.9674 - acc: 0.9068 - precision: 0.8821 - recall: 0.9344 - f1_score: 0.9041 - val_loss: 4.9327 - val_acc: 0.9304 - val_precision: 0.9373 - val_recall: 0.9422 - val_f1_score: 0.9379\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9409 - acc: 0.9052 - precision: 0.8864 - recall: 0.9259 - f1_score: 0.9050 - val_loss: 4.9070 - val_acc: 0.9367 - val_precision: 0.9479 - val_recall: 0.9422 - val_f1_score: 0.9433\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9147 - acc: 0.9084 - precision: 0.8952 - recall: 0.9161 - f1_score: 0.9035 - val_loss: 4.8814 - val_acc: 0.9367 - val_precision: 0.9479 - val_recall: 0.9422 - val_f1_score: 0.9433\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8886 - acc: 0.9068 - precision: 0.8921 - recall: 0.9178 - f1_score: 0.9032 - val_loss: 4.8561 - val_acc: 0.9304 - val_precision: 0.9479 - val_recall: 0.9305 - val_f1_score: 0.9366\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8628 - acc: 0.9194 - precision: 0.9160 - recall: 0.9183 - f1_score: 0.9155 - val_loss: 4.8309 - val_acc: 0.9304 - val_precision: 0.9578 - val_recall: 0.9192 - val_f1_score: 0.9362\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8371 - acc: 0.9258 - precision: 0.9286 - recall: 0.9177 - f1_score: 0.9214 - val_loss: 4.8059 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8116 - acc: 0.9258 - precision: 0.9307 - recall: 0.9187 - f1_score: 0.9229 - val_loss: 4.7811 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7863 - acc: 0.9273 - precision: 0.9344 - recall: 0.9105 - f1_score: 0.9210 - val_loss: 4.7565 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7612 - acc: 0.9289 - precision: 0.9415 - recall: 0.9146 - f1_score: 0.9257 - val_loss: 4.7320 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7363 - acc: 0.9352 - precision: 0.9525 - recall: 0.9134 - f1_score: 0.9305 - val_loss: 4.7077 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7115 - acc: 0.9368 - precision: 0.9554 - recall: 0.9133 - f1_score: 0.9329 - val_loss: 4.6836 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6869 - acc: 0.9352 - precision: 0.9577 - recall: 0.9055 - f1_score: 0.9297 - val_loss: 4.6596 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6625 - acc: 0.9336 - precision: 0.9615 - recall: 0.9043 - f1_score: 0.9302 - val_loss: 4.6358 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6383 - acc: 0.9352 - precision: 0.9628 - recall: 0.9018 - f1_score: 0.9298 - val_loss: 4.6122 - val_acc: 0.9304 - val_precision: 0.9673 - val_recall: 0.9079 - val_f1_score: 0.9352\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6142 - acc: 0.9352 - precision: 0.9635 - recall: 0.9018 - f1_score: 0.9303 - val_loss: 4.5887 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5903 - acc: 0.9321 - precision: 0.9649 - recall: 0.8904 - f1_score: 0.9252 - val_loss: 4.5653 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5665 - acc: 0.9321 - precision: 0.9658 - recall: 0.8914 - f1_score: 0.9261 - val_loss: 4.5421 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5429 - acc: 0.9321 - precision: 0.9678 - recall: 0.8937 - f1_score: 0.9274 - val_loss: 4.5191 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5195 - acc: 0.9321 - precision: 0.9665 - recall: 0.8878 - f1_score: 0.9245 - val_loss: 4.4962 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4962 - acc: 0.9336 - precision: 0.9733 - recall: 0.8870 - f1_score: 0.9247 - val_loss: 4.4734 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4731 - acc: 0.9336 - precision: 0.9720 - recall: 0.8884 - f1_score: 0.9272 - val_loss: 4.4508 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4501 - acc: 0.9336 - precision: 0.9715 - recall: 0.8888 - f1_score: 0.9276 - val_loss: 4.4283 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4273 - acc: 0.9336 - precision: 0.9711 - recall: 0.8867 - f1_score: 0.9259 - val_loss: 4.4060 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4046 - acc: 0.9336 - precision: 0.9707 - recall: 0.8870 - f1_score: 0.9260 - val_loss: 4.3838 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3820 - acc: 0.9336 - precision: 0.9712 - recall: 0.8883 - f1_score: 0.9266 - val_loss: 4.3617 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3596 - acc: 0.9336 - precision: 0.9717 - recall: 0.8877 - f1_score: 0.9259 - val_loss: 4.3398 - val_acc: 0.9430 - val_precision: 0.9883 - val_recall: 0.9079 - val_f1_score: 0.9457\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3374 - acc: 0.9352 - precision: 0.9762 - recall: 0.8875 - f1_score: 0.9283 - val_loss: 4.3181 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3153 - acc: 0.9368 - precision: 0.9794 - recall: 0.8880 - f1_score: 0.9297 - val_loss: 4.2964 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2933 - acc: 0.9368 - precision: 0.9804 - recall: 0.8881 - f1_score: 0.9298 - val_loss: 4.2749 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2714 - acc: 0.9368 - precision: 0.9798 - recall: 0.8910 - f1_score: 0.9328 - val_loss: 4.2535 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2497 - acc: 0.9384 - precision: 0.9825 - recall: 0.8871 - f1_score: 0.9296 - val_loss: 4.2322 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2282 - acc: 0.9384 - precision: 0.9803 - recall: 0.8884 - f1_score: 0.9308 - val_loss: 4.2111 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.2067 - acc: 0.9384 - precision: 0.9806 - recall: 0.8821 - f1_score: 0.9276 - val_loss: 4.1901 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1854 - acc: 0.9384 - precision: 0.9832 - recall: 0.8881 - f1_score: 0.9323 - val_loss: 4.1692 - val_acc: 0.9367 - val_precision: 0.9883 - val_recall: 0.8962 - val_f1_score: 0.9387\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1642 - acc: 0.9384 - precision: 0.9829 - recall: 0.8890 - f1_score: 0.9323 - val_loss: 4.1484 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1432 - acc: 0.9384 - precision: 0.9803 - recall: 0.8858 - f1_score: 0.9292 - val_loss: 4.1278 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1222 - acc: 0.9384 - precision: 0.9834 - recall: 0.8832 - f1_score: 0.9276 - val_loss: 4.1073 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8619 - val_f1_score: 0.9191\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1014 - acc: 0.9384 - precision: 0.9827 - recall: 0.8867 - f1_score: 0.9310 - val_loss: 4.0869 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8450 - val_f1_score: 0.9090\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0808 - acc: 0.9384 - precision: 0.9823 - recall: 0.8904 - f1_score: 0.9333 - val_loss: 4.0666 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8450 - val_f1_score: 0.9090\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0602 - acc: 0.9384 - precision: 0.9788 - recall: 0.8850 - f1_score: 0.9290 - val_loss: 4.0464 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8450 - val_f1_score: 0.9090\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0398 - acc: 0.9384 - precision: 0.9820 - recall: 0.8902 - f1_score: 0.9317 - val_loss: 4.0264 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0195 - acc: 0.9384 - precision: 0.9818 - recall: 0.8889 - f1_score: 0.9321 - val_loss: 4.0064 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9993 - acc: 0.9384 - precision: 0.9811 - recall: 0.8944 - f1_score: 0.9339 - val_loss: 3.9866 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9792 - acc: 0.9368 - precision: 0.9827 - recall: 0.8847 - f1_score: 0.9301 - val_loss: 3.9669 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9593 - acc: 0.9368 - precision: 0.9817 - recall: 0.8835 - f1_score: 0.9285 - val_loss: 3.9473 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9394 - acc: 0.9368 - precision: 0.9807 - recall: 0.8857 - f1_score: 0.9298 - val_loss: 3.9278 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9197 - acc: 0.9368 - precision: 0.9820 - recall: 0.8893 - f1_score: 0.9319 - val_loss: 3.9084 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9001 - acc: 0.9368 - precision: 0.9826 - recall: 0.8874 - f1_score: 0.9314 - val_loss: 3.8892 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8806 - acc: 0.9368 - precision: 0.9829 - recall: 0.8849 - f1_score: 0.9302 - val_loss: 3.8700 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8613 - acc: 0.9368 - precision: 0.9803 - recall: 0.8849 - f1_score: 0.9289 - val_loss: 3.8510 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8420 - acc: 0.9368 - precision: 0.9803 - recall: 0.8877 - f1_score: 0.9298 - val_loss: 3.8320 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8228 - acc: 0.9368 - precision: 0.9826 - recall: 0.8850 - f1_score: 0.9301 - val_loss: 3.8132 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8038 - acc: 0.9384 - precision: 0.9856 - recall: 0.8860 - f1_score: 0.9320 - val_loss: 3.7945 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7849 - acc: 0.9384 - precision: 0.9856 - recall: 0.8838 - f1_score: 0.9299 - val_loss: 3.7759 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7660 - acc: 0.9384 - precision: 0.9864 - recall: 0.8838 - f1_score: 0.9301 - val_loss: 3.7574 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7474 - acc: 0.9384 - precision: 0.9860 - recall: 0.8882 - f1_score: 0.9331 - val_loss: 3.7389 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7287 - acc: 0.9384 - precision: 0.9876 - recall: 0.8838 - f1_score: 0.9313 - val_loss: 3.7206 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7102 - acc: 0.9384 - precision: 0.9864 - recall: 0.8877 - f1_score: 0.9327 - val_loss: 3.7024 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6918 - acc: 0.9384 - precision: 0.9854 - recall: 0.8853 - f1_score: 0.9310 - val_loss: 3.6843 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6735 - acc: 0.9384 - precision: 0.9858 - recall: 0.8867 - f1_score: 0.9322 - val_loss: 3.6663 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6554 - acc: 0.9384 - precision: 0.9856 - recall: 0.8834 - f1_score: 0.9286 - val_loss: 3.6484 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6373 - acc: 0.9384 - precision: 0.9855 - recall: 0.8859 - f1_score: 0.9311 - val_loss: 3.6306 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6193 - acc: 0.9384 - precision: 0.9862 - recall: 0.8855 - f1_score: 0.9316 - val_loss: 3.6129 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6014 - acc: 0.9384 - precision: 0.9841 - recall: 0.8883 - f1_score: 0.9325 - val_loss: 3.5953 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.5836 - acc: 0.9384 - precision: 0.9867 - recall: 0.8819 - f1_score: 0.9294 - val_loss: 3.5778 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5659 - acc: 0.9384 - precision: 0.9857 - recall: 0.8871 - f1_score: 0.9322 - val_loss: 3.5604 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5484 - acc: 0.9384 - precision: 0.9857 - recall: 0.8851 - f1_score: 0.9311 - val_loss: 3.5430 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5309 - acc: 0.9384 - precision: 0.9857 - recall: 0.8826 - f1_score: 0.9302 - val_loss: 3.5258 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5135 - acc: 0.9384 - precision: 0.9838 - recall: 0.8836 - f1_score: 0.9296 - val_loss: 3.5087 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4962 - acc: 0.9384 - precision: 0.9862 - recall: 0.8865 - f1_score: 0.9326 - val_loss: 3.4916 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4790 - acc: 0.9384 - precision: 0.9865 - recall: 0.8875 - f1_score: 0.9338 - val_loss: 3.4747 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4620 - acc: 0.9384 - precision: 0.9849 - recall: 0.8889 - f1_score: 0.9333 - val_loss: 3.4578 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4450 - acc: 0.9384 - precision: 0.9850 - recall: 0.8877 - f1_score: 0.9312 - val_loss: 3.4411 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4280 - acc: 0.9384 - precision: 0.9867 - recall: 0.8845 - f1_score: 0.9318 - val_loss: 3.4244 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4112 - acc: 0.9384 - precision: 0.9861 - recall: 0.8891 - f1_score: 0.9336 - val_loss: 3.4078 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3945 - acc: 0.9384 - precision: 0.9838 - recall: 0.8869 - f1_score: 0.9317 - val_loss: 3.3913 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3779 - acc: 0.9384 - precision: 0.9864 - recall: 0.8846 - f1_score: 0.9321 - val_loss: 3.3749 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3614 - acc: 0.9384 - precision: 0.9851 - recall: 0.8838 - f1_score: 0.9309 - val_loss: 3.3586 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3449 - acc: 0.9384 - precision: 0.9855 - recall: 0.8857 - f1_score: 0.9326 - val_loss: 3.3424 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3286 - acc: 0.9384 - precision: 0.9835 - recall: 0.8858 - f1_score: 0.9313 - val_loss: 3.3263 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3123 - acc: 0.9384 - precision: 0.9838 - recall: 0.8827 - f1_score: 0.9291 - val_loss: 3.3102 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2961 - acc: 0.9384 - precision: 0.9846 - recall: 0.8837 - f1_score: 0.9303 - val_loss: 3.2943 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2800 - acc: 0.9400 - precision: 0.9889 - recall: 0.8875 - f1_score: 0.9341 - val_loss: 3.2784 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2641 - acc: 0.9400 - precision: 0.9905 - recall: 0.8874 - f1_score: 0.9349 - val_loss: 3.2626 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2481 - acc: 0.9400 - precision: 0.9875 - recall: 0.8893 - f1_score: 0.9333 - val_loss: 3.2469 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2323 - acc: 0.9400 - precision: 0.9904 - recall: 0.8862 - f1_score: 0.9345 - val_loss: 3.2313 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2166 - acc: 0.9400 - precision: 0.9905 - recall: 0.8843 - f1_score: 0.9320 - val_loss: 3.2157 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2010 - acc: 0.9400 - precision: 0.9890 - recall: 0.8847 - f1_score: 0.9321 - val_loss: 3.2003 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1854 - acc: 0.9400 - precision: 0.9884 - recall: 0.8849 - f1_score: 0.9328 - val_loss: 3.1849 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1699 - acc: 0.9400 - precision: 0.9897 - recall: 0.8858 - f1_score: 0.9337 - val_loss: 3.1696 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1545 - acc: 0.9400 - precision: 0.9892 - recall: 0.8870 - f1_score: 0.9340 - val_loss: 3.1545 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1392 - acc: 0.9400 - precision: 0.9897 - recall: 0.8813 - f1_score: 0.9299 - val_loss: 3.1393 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1240 - acc: 0.9400 - precision: 0.9900 - recall: 0.8858 - f1_score: 0.9335 - val_loss: 3.1243 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1088 - acc: 0.9400 - precision: 0.9895 - recall: 0.8823 - f1_score: 0.9306 - val_loss: 3.1093 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0938 - acc: 0.9400 - precision: 0.9903 - recall: 0.8830 - f1_score: 0.9321 - val_loss: 3.0944 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0788 - acc: 0.9400 - precision: 0.9904 - recall: 0.8847 - f1_score: 0.9324 - val_loss: 3.0796 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.0639 - acc: 0.9400 - precision: 0.9908 - recall: 0.8768 - f1_score: 0.9267 - val_loss: 3.0649 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0491 - acc: 0.9400 - precision: 0.9899 - recall: 0.8871 - f1_score: 0.9347 - val_loss: 3.0503 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0343 - acc: 0.9400 - precision: 0.9879 - recall: 0.8833 - f1_score: 0.9321 - val_loss: 3.0357 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0197 - acc: 0.9400 - precision: 0.9901 - recall: 0.8881 - f1_score: 0.9358 - val_loss: 3.0212 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0051 - acc: 0.9400 - precision: 0.9898 - recall: 0.8875 - f1_score: 0.9345 - val_loss: 3.0068 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9906 - acc: 0.9400 - precision: 0.9884 - recall: 0.8848 - f1_score: 0.9328 - val_loss: 2.9925 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9762 - acc: 0.9400 - precision: 0.9894 - recall: 0.8831 - f1_score: 0.9324 - val_loss: 2.9782 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9618 - acc: 0.9400 - precision: 0.9896 - recall: 0.8849 - f1_score: 0.9333 - val_loss: 2.9640 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9476 - acc: 0.9400 - precision: 0.9883 - recall: 0.8840 - f1_score: 0.9322 - val_loss: 2.9499 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9334 - acc: 0.9400 - precision: 0.9890 - recall: 0.8832 - f1_score: 0.9312 - val_loss: 2.9359 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9193 - acc: 0.9400 - precision: 0.9895 - recall: 0.8854 - f1_score: 0.9340 - val_loss: 2.9219 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9052 - acc: 0.9400 - precision: 0.9889 - recall: 0.8860 - f1_score: 0.9338 - val_loss: 2.9080 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8913 - acc: 0.9400 - precision: 0.9897 - recall: 0.8863 - f1_score: 0.9340 - val_loss: 2.8942 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8774 - acc: 0.9400 - precision: 0.9881 - recall: 0.8863 - f1_score: 0.9328 - val_loss: 2.8805 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8636 - acc: 0.9400 - precision: 0.9891 - recall: 0.8867 - f1_score: 0.9340 - val_loss: 2.8668 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8498 - acc: 0.9400 - precision: 0.9849 - recall: 0.8798 - f1_score: 0.9279 - val_loss: 2.8532 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8362 - acc: 0.9400 - precision: 0.9865 - recall: 0.8923 - f1_score: 0.9356 - val_loss: 2.8397 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8226 - acc: 0.9400 - precision: 0.9902 - recall: 0.8841 - f1_score: 0.9329 - val_loss: 2.8262 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8091 - acc: 0.9400 - precision: 0.9896 - recall: 0.8835 - f1_score: 0.9324 - val_loss: 2.8129 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7956 - acc: 0.9400 - precision: 0.9894 - recall: 0.8840 - f1_score: 0.9331 - val_loss: 2.7996 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7822 - acc: 0.9400 - precision: 0.9909 - recall: 0.8836 - f1_score: 0.9327 - val_loss: 2.7863 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7689 - acc: 0.9400 - precision: 0.9896 - recall: 0.8882 - f1_score: 0.9343 - val_loss: 2.7731 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7557 - acc: 0.9400 - precision: 0.9896 - recall: 0.8825 - f1_score: 0.9310 - val_loss: 2.7600 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7425 - acc: 0.9400 - precision: 0.9889 - recall: 0.8852 - f1_score: 0.9332 - val_loss: 2.7470 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7294 - acc: 0.9400 - precision: 0.9886 - recall: 0.8865 - f1_score: 0.9342 - val_loss: 2.7341 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7164 - acc: 0.9400 - precision: 0.9891 - recall: 0.8853 - f1_score: 0.9329 - val_loss: 2.7212 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7035 - acc: 0.9400 - precision: 0.9885 - recall: 0.8858 - f1_score: 0.9328 - val_loss: 2.7084 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6906 - acc: 0.9400 - precision: 0.9897 - recall: 0.8824 - f1_score: 0.9313 - val_loss: 2.6956 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6778 - acc: 0.9400 - precision: 0.9909 - recall: 0.8860 - f1_score: 0.9344 - val_loss: 2.6829 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6650 - acc: 0.9400 - precision: 0.9895 - recall: 0.8827 - f1_score: 0.9310 - val_loss: 2.6703 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6523 - acc: 0.9400 - precision: 0.9854 - recall: 0.8787 - f1_score: 0.9280 - val_loss: 2.6577 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6397 - acc: 0.9400 - precision: 0.9893 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 2.6452 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.6272 - acc: 0.9400 - precision: 0.9888 - recall: 0.8868 - f1_score: 0.9331 - val_loss: 2.6328 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6147 - acc: 0.9400 - precision: 0.9893 - recall: 0.8836 - f1_score: 0.9325 - val_loss: 2.6204 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6023 - acc: 0.9400 - precision: 0.9896 - recall: 0.8834 - f1_score: 0.9326 - val_loss: 2.6081 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5900 - acc: 0.9400 - precision: 0.9897 - recall: 0.8839 - f1_score: 0.9326 - val_loss: 2.5959 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5777 - acc: 0.9400 - precision: 0.9891 - recall: 0.8892 - f1_score: 0.9356 - val_loss: 2.5837 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5655 - acc: 0.9400 - precision: 0.9865 - recall: 0.8848 - f1_score: 0.9316 - val_loss: 2.5716 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5533 - acc: 0.9400 - precision: 0.9898 - recall: 0.8831 - f1_score: 0.9311 - val_loss: 2.5596 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5412 - acc: 0.9400 - precision: 0.9888 - recall: 0.8860 - f1_score: 0.9339 - val_loss: 2.5476 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5292 - acc: 0.9400 - precision: 0.9899 - recall: 0.8853 - f1_score: 0.9331 - val_loss: 2.5357 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5173 - acc: 0.9400 - precision: 0.9890 - recall: 0.8834 - f1_score: 0.9318 - val_loss: 2.5238 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5054 - acc: 0.9400 - precision: 0.9887 - recall: 0.8862 - f1_score: 0.9330 - val_loss: 2.5120 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4935 - acc: 0.9400 - precision: 0.9897 - recall: 0.8842 - f1_score: 0.9333 - val_loss: 2.5003 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4818 - acc: 0.9400 - precision: 0.9889 - recall: 0.8854 - f1_score: 0.9333 - val_loss: 2.4887 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4701 - acc: 0.9400 - precision: 0.9888 - recall: 0.8790 - f1_score: 0.9293 - val_loss: 2.4771 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4584 - acc: 0.9400 - precision: 0.9902 - recall: 0.8801 - f1_score: 0.9303 - val_loss: 2.4655 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4468 - acc: 0.9400 - precision: 0.9883 - recall: 0.8860 - f1_score: 0.9332 - val_loss: 2.4540 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4353 - acc: 0.9400 - precision: 0.9896 - recall: 0.8830 - f1_score: 0.9310 - val_loss: 2.4426 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4238 - acc: 0.9400 - precision: 0.9903 - recall: 0.8878 - f1_score: 0.9356 - val_loss: 2.4312 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4124 - acc: 0.9400 - precision: 0.9883 - recall: 0.8857 - f1_score: 0.9338 - val_loss: 2.4199 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4011 - acc: 0.9400 - precision: 0.9862 - recall: 0.8806 - f1_score: 0.9289 - val_loss: 2.4087 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3898 - acc: 0.9400 - precision: 0.9888 - recall: 0.8834 - f1_score: 0.9322 - val_loss: 2.3975 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3786 - acc: 0.9400 - precision: 0.9886 - recall: 0.8816 - f1_score: 0.9315 - val_loss: 2.3864 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3674 - acc: 0.9400 - precision: 0.9884 - recall: 0.8860 - f1_score: 0.9326 - val_loss: 2.3753 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3563 - acc: 0.9400 - precision: 0.9887 - recall: 0.8829 - f1_score: 0.9306 - val_loss: 2.3643 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3453 - acc: 0.9400 - precision: 0.9886 - recall: 0.8862 - f1_score: 0.9336 - val_loss: 2.3533 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3343 - acc: 0.9400 - precision: 0.9899 - recall: 0.8874 - f1_score: 0.9337 - val_loss: 2.3424 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3234 - acc: 0.9400 - precision: 0.9875 - recall: 0.8823 - f1_score: 0.9312 - val_loss: 2.3316 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3125 - acc: 0.9400 - precision: 0.9890 - recall: 0.8853 - f1_score: 0.9323 - val_loss: 2.3208 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3017 - acc: 0.9400 - precision: 0.9890 - recall: 0.8762 - f1_score: 0.9244 - val_loss: 2.3101 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2909 - acc: 0.9400 - precision: 0.9900 - recall: 0.8873 - f1_score: 0.9345 - val_loss: 2.2994 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2802 - acc: 0.9400 - precision: 0.9887 - recall: 0.8884 - f1_score: 0.9341 - val_loss: 2.2888 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2696 - acc: 0.9400 - precision: 0.9893 - recall: 0.8857 - f1_score: 0.9327 - val_loss: 2.2782 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.2590 - acc: 0.9400 - precision: 0.9890 - recall: 0.8858 - f1_score: 0.9341 - val_loss: 2.2677 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2484 - acc: 0.9400 - precision: 0.9900 - recall: 0.8856 - f1_score: 0.9339 - val_loss: 2.2573 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2379 - acc: 0.9400 - precision: 0.9883 - recall: 0.8866 - f1_score: 0.9337 - val_loss: 2.2469 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2275 - acc: 0.9400 - precision: 0.9874 - recall: 0.8865 - f1_score: 0.9325 - val_loss: 2.2365 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2171 - acc: 0.9415 - precision: 0.9895 - recall: 0.8851 - f1_score: 0.9325 - val_loss: 2.2262 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2068 - acc: 0.9415 - precision: 0.9902 - recall: 0.8859 - f1_score: 0.9333 - val_loss: 2.2160 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1966 - acc: 0.9415 - precision: 0.9895 - recall: 0.8885 - f1_score: 0.9351 - val_loss: 2.2058 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1864 - acc: 0.9415 - precision: 0.9878 - recall: 0.8900 - f1_score: 0.9354 - val_loss: 2.1957 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1762 - acc: 0.9415 - precision: 0.9892 - recall: 0.8869 - f1_score: 0.9342 - val_loss: 2.1856 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1661 - acc: 0.9415 - precision: 0.9900 - recall: 0.8882 - f1_score: 0.9344 - val_loss: 2.1756 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1561 - acc: 0.9415 - precision: 0.9872 - recall: 0.8870 - f1_score: 0.9333 - val_loss: 2.1656 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1461 - acc: 0.9415 - precision: 0.9885 - recall: 0.8866 - f1_score: 0.9341 - val_loss: 2.1557 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1361 - acc: 0.9415 - precision: 0.9892 - recall: 0.8852 - f1_score: 0.9315 - val_loss: 2.1458 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1262 - acc: 0.9415 - precision: 0.9895 - recall: 0.8917 - f1_score: 0.9374 - val_loss: 2.1360 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1164 - acc: 0.9415 - precision: 0.9897 - recall: 0.8907 - f1_score: 0.9358 - val_loss: 2.1262 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1066 - acc: 0.9415 - precision: 0.9906 - recall: 0.8900 - f1_score: 0.9363 - val_loss: 2.1165 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0969 - acc: 0.9415 - precision: 0.9892 - recall: 0.8882 - f1_score: 0.9351 - val_loss: 2.1068 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0872 - acc: 0.9415 - precision: 0.9893 - recall: 0.8884 - f1_score: 0.9329 - val_loss: 2.0972 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0775 - acc: 0.9415 - precision: 0.9898 - recall: 0.8863 - f1_score: 0.9335 - val_loss: 2.0876 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0680 - acc: 0.9415 - precision: 0.9900 - recall: 0.8907 - f1_score: 0.9364 - val_loss: 2.0781 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0584 - acc: 0.9431 - precision: 0.9927 - recall: 0.8887 - f1_score: 0.9372 - val_loss: 2.0686 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0489 - acc: 0.9415 - precision: 0.9892 - recall: 0.8899 - f1_score: 0.9350 - val_loss: 2.0592 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0395 - acc: 0.9431 - precision: 0.9940 - recall: 0.8861 - f1_score: 0.9362 - val_loss: 2.0499 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0301 - acc: 0.9431 - precision: 0.9910 - recall: 0.8848 - f1_score: 0.9340 - val_loss: 2.0405 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0208 - acc: 0.9431 - precision: 0.9928 - recall: 0.8878 - f1_score: 0.9344 - val_loss: 2.0313 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0115 - acc: 0.9431 - precision: 0.9930 - recall: 0.8896 - f1_score: 0.9369 - val_loss: 2.0221 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0023 - acc: 0.9431 - precision: 0.9904 - recall: 0.8881 - f1_score: 0.9356 - val_loss: 2.0129 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9931 - acc: 0.9431 - precision: 0.9929 - recall: 0.8899 - f1_score: 0.9378 - val_loss: 2.0037 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9839 - acc: 0.9431 - precision: 0.9935 - recall: 0.8893 - f1_score: 0.9377 - val_loss: 1.9947 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9748 - acc: 0.9431 - precision: 0.9934 - recall: 0.8882 - f1_score: 0.9371 - val_loss: 1.9856 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9658 - acc: 0.9431 - precision: 0.9929 - recall: 0.8870 - f1_score: 0.9361 - val_loss: 1.9766 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9568 - acc: 0.9431 - precision: 0.9931 - recall: 0.8900 - f1_score: 0.9379 - val_loss: 1.9677 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.9478 - acc: 0.9431 - precision: 0.9928 - recall: 0.8882 - f1_score: 0.9362 - val_loss: 1.9588 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9389 - acc: 0.9431 - precision: 0.9911 - recall: 0.8851 - f1_score: 0.9331 - val_loss: 1.9499 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9301 - acc: 0.9431 - precision: 0.9923 - recall: 0.8848 - f1_score: 0.9346 - val_loss: 1.9411 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9212 - acc: 0.9431 - precision: 0.9921 - recall: 0.8933 - f1_score: 0.9382 - val_loss: 1.9324 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9125 - acc: 0.9431 - precision: 0.9931 - recall: 0.8888 - f1_score: 0.9364 - val_loss: 1.9237 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9037 - acc: 0.9431 - precision: 0.9910 - recall: 0.8861 - f1_score: 0.9347 - val_loss: 1.9150 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8951 - acc: 0.9431 - precision: 0.9910 - recall: 0.8914 - f1_score: 0.9373 - val_loss: 1.9064 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8864 - acc: 0.9431 - precision: 0.9923 - recall: 0.8895 - f1_score: 0.9373 - val_loss: 1.8978 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8779 - acc: 0.9431 - precision: 0.9926 - recall: 0.8855 - f1_score: 0.9352 - val_loss: 1.8893 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8693 - acc: 0.9431 - precision: 0.9918 - recall: 0.8872 - f1_score: 0.9355 - val_loss: 1.8808 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8608 - acc: 0.9431 - precision: 0.9944 - recall: 0.8873 - f1_score: 0.9369 - val_loss: 1.8723 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8524 - acc: 0.9431 - precision: 0.9933 - recall: 0.8870 - f1_score: 0.9365 - val_loss: 1.8639 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8439 - acc: 0.9431 - precision: 0.9921 - recall: 0.8895 - f1_score: 0.9371 - val_loss: 1.8555 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8356 - acc: 0.9431 - precision: 0.9923 - recall: 0.8867 - f1_score: 0.9357 - val_loss: 1.8472 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8272 - acc: 0.9431 - precision: 0.9910 - recall: 0.8876 - f1_score: 0.9358 - val_loss: 1.8390 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8190 - acc: 0.9431 - precision: 0.9935 - recall: 0.8862 - f1_score: 0.9358 - val_loss: 1.8307 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8107 - acc: 0.9431 - precision: 0.9941 - recall: 0.8818 - f1_score: 0.9324 - val_loss: 1.8225 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8025 - acc: 0.9431 - precision: 0.9934 - recall: 0.8850 - f1_score: 0.9345 - val_loss: 1.8144 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7944 - acc: 0.9431 - precision: 0.9917 - recall: 0.8857 - f1_score: 0.9332 - val_loss: 1.8063 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7863 - acc: 0.9431 - precision: 0.9929 - recall: 0.8885 - f1_score: 0.9356 - val_loss: 1.7982 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7782 - acc: 0.9431 - precision: 0.9932 - recall: 0.8880 - f1_score: 0.9365 - val_loss: 1.7902 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7702 - acc: 0.9431 - precision: 0.9930 - recall: 0.8897 - f1_score: 0.9377 - val_loss: 1.7822 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7622 - acc: 0.9431 - precision: 0.9922 - recall: 0.8893 - f1_score: 0.9373 - val_loss: 1.7743 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7543 - acc: 0.9431 - precision: 0.9928 - recall: 0.8895 - f1_score: 0.9366 - val_loss: 1.7664 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7464 - acc: 0.9431 - precision: 0.9924 - recall: 0.8886 - f1_score: 0.9373 - val_loss: 1.7585 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7385 - acc: 0.9431 - precision: 0.9891 - recall: 0.8890 - f1_score: 0.9357 - val_loss: 1.7507 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7307 - acc: 0.9431 - precision: 0.9934 - recall: 0.8891 - f1_score: 0.9361 - val_loss: 1.7429 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7229 - acc: 0.9431 - precision: 0.9928 - recall: 0.8853 - f1_score: 0.9352 - val_loss: 1.7352 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7152 - acc: 0.9431 - precision: 0.9925 - recall: 0.8876 - f1_score: 0.9364 - val_loss: 1.7275 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7075 - acc: 0.9431 - precision: 0.9920 - recall: 0.8896 - f1_score: 0.9364 - val_loss: 1.7198 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6998 - acc: 0.9431 - precision: 0.9919 - recall: 0.8873 - f1_score: 0.9355 - val_loss: 1.7122 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6922 - acc: 0.9431 - precision: 0.9931 - recall: 0.8879 - f1_score: 0.9355 - val_loss: 1.7046 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.6846 - acc: 0.9431 - precision: 0.9918 - recall: 0.8903 - f1_score: 0.9372 - val_loss: 1.6971 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6771 - acc: 0.9431 - precision: 0.9916 - recall: 0.8929 - f1_score: 0.9381 - val_loss: 1.6896 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6696 - acc: 0.9431 - precision: 0.9933 - recall: 0.8920 - f1_score: 0.9387 - val_loss: 1.6821 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6621 - acc: 0.9431 - precision: 0.9931 - recall: 0.8856 - f1_score: 0.9351 - val_loss: 1.6747 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6547 - acc: 0.9431 - precision: 0.9916 - recall: 0.8895 - f1_score: 0.9368 - val_loss: 1.6673 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6473 - acc: 0.9431 - precision: 0.9928 - recall: 0.8894 - f1_score: 0.9366 - val_loss: 1.6600 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6400 - acc: 0.9431 - precision: 0.9926 - recall: 0.8878 - f1_score: 0.9361 - val_loss: 1.6527 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6326 - acc: 0.9431 - precision: 0.9918 - recall: 0.8893 - f1_score: 0.9362 - val_loss: 1.6454 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6254 - acc: 0.9431 - precision: 0.9934 - recall: 0.8861 - f1_score: 0.9342 - val_loss: 1.6381 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6181 - acc: 0.9431 - precision: 0.9929 - recall: 0.8870 - f1_score: 0.9358 - val_loss: 1.6309 - val_acc: 0.9051 - val_precision: 0.9878 - val_recall: 0.8337 - val_f1_score: 0.9025\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6109 - acc: 0.9431 - precision: 0.9921 - recall: 0.8870 - f1_score: 0.9350 - val_loss: 1.6238 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6038 - acc: 0.9431 - precision: 0.9925 - recall: 0.8891 - f1_score: 0.9373 - val_loss: 1.6167 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5967 - acc: 0.9431 - precision: 0.9925 - recall: 0.8847 - f1_score: 0.9339 - val_loss: 1.6096 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5896 - acc: 0.9431 - precision: 0.9931 - recall: 0.8900 - f1_score: 0.9369 - val_loss: 1.6025 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5825 - acc: 0.9431 - precision: 0.9921 - recall: 0.8862 - f1_score: 0.9347 - val_loss: 1.5955 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5755 - acc: 0.9431 - precision: 0.9931 - recall: 0.8908 - f1_score: 0.9380 - val_loss: 1.5885 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5685 - acc: 0.9431 - precision: 0.9923 - recall: 0.8860 - f1_score: 0.9344 - val_loss: 1.5816 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5616 - acc: 0.9431 - precision: 0.9938 - recall: 0.8870 - f1_score: 0.9367 - val_loss: 1.5747 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5547 - acc: 0.9431 - precision: 0.9933 - recall: 0.8854 - f1_score: 0.9350 - val_loss: 1.5678 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5478 - acc: 0.9431 - precision: 0.9919 - recall: 0.8859 - f1_score: 0.9345 - val_loss: 1.5610 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5410 - acc: 0.9431 - precision: 0.9940 - recall: 0.8857 - f1_score: 0.9348 - val_loss: 1.5542 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5342 - acc: 0.9431 - precision: 0.9939 - recall: 0.8864 - f1_score: 0.9364 - val_loss: 1.5474 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5274 - acc: 0.9431 - precision: 0.9934 - recall: 0.8858 - f1_score: 0.9340 - val_loss: 1.5407 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5207 - acc: 0.9431 - precision: 0.9940 - recall: 0.8849 - f1_score: 0.9354 - val_loss: 1.5340 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5140 - acc: 0.9431 - precision: 0.9928 - recall: 0.8848 - f1_score: 0.9337 - val_loss: 1.5273 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5074 - acc: 0.9431 - precision: 0.9921 - recall: 0.8871 - f1_score: 0.9358 - val_loss: 1.5207 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5007 - acc: 0.9431 - precision: 0.9926 - recall: 0.8902 - f1_score: 0.9379 - val_loss: 1.5141 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4942 - acc: 0.9431 - precision: 0.9918 - recall: 0.8917 - f1_score: 0.9379 - val_loss: 1.5075 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4876 - acc: 0.9431 - precision: 0.9922 - recall: 0.8852 - f1_score: 0.9347 - val_loss: 1.5010 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4811 - acc: 0.9431 - precision: 0.9912 - recall: 0.8893 - f1_score: 0.9362 - val_loss: 1.4945 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4746 - acc: 0.9431 - precision: 0.9934 - recall: 0.8886 - f1_score: 0.9358 - val_loss: 1.4881 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4681 - acc: 0.9431 - precision: 0.9919 - recall: 0.8903 - f1_score: 0.9375 - val_loss: 1.4816 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4617 - acc: 0.9431 - precision: 0.9925 - recall: 0.8885 - f1_score: 0.9361 - val_loss: 1.4752 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4553 - acc: 0.9431 - precision: 0.9934 - recall: 0.8891 - f1_score: 0.9363 - val_loss: 1.4689 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4490 - acc: 0.9431 - precision: 0.9929 - recall: 0.8879 - f1_score: 0.9357 - val_loss: 1.4626 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4426 - acc: 0.9431 - precision: 0.9931 - recall: 0.8836 - f1_score: 0.9331 - val_loss: 1.4563 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4364 - acc: 0.9431 - precision: 0.9921 - recall: 0.8893 - f1_score: 0.9367 - val_loss: 1.4500 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4301 - acc: 0.9431 - precision: 0.9935 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 1.4438 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4239 - acc: 0.9431 - precision: 0.9913 - recall: 0.8915 - f1_score: 0.9373 - val_loss: 1.4376 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4177 - acc: 0.9431 - precision: 0.9906 - recall: 0.8919 - f1_score: 0.9371 - val_loss: 1.4314 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4115 - acc: 0.9431 - precision: 0.9917 - recall: 0.8867 - f1_score: 0.9350 - val_loss: 1.4253 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4054 - acc: 0.9431 - precision: 0.9933 - recall: 0.8927 - f1_score: 0.9386 - val_loss: 1.4192 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3993 - acc: 0.9431 - precision: 0.9928 - recall: 0.8882 - f1_score: 0.9369 - val_loss: 1.4131 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3932 - acc: 0.9431 - precision: 0.9937 - recall: 0.8898 - f1_score: 0.9371 - val_loss: 1.4071 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3872 - acc: 0.9431 - precision: 0.9938 - recall: 0.8895 - f1_score: 0.9379 - val_loss: 1.4011 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3812 - acc: 0.9431 - precision: 0.9923 - recall: 0.8911 - f1_score: 0.9375 - val_loss: 1.3951 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3752 - acc: 0.9431 - precision: 0.9926 - recall: 0.8889 - f1_score: 0.9375 - val_loss: 1.3892 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3693 - acc: 0.9431 - precision: 0.9913 - recall: 0.8841 - f1_score: 0.9329 - val_loss: 1.3832 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3634 - acc: 0.9431 - precision: 0.9937 - recall: 0.8884 - f1_score: 0.9373 - val_loss: 1.3774 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3575 - acc: 0.9431 - precision: 0.9928 - recall: 0.8880 - f1_score: 0.9365 - val_loss: 1.3715 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3516 - acc: 0.9431 - precision: 0.9932 - recall: 0.8865 - f1_score: 0.9355 - val_loss: 1.3657 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3458 - acc: 0.9431 - precision: 0.9919 - recall: 0.8888 - f1_score: 0.9370 - val_loss: 1.3599 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3400 - acc: 0.9431 - precision: 0.9922 - recall: 0.8876 - f1_score: 0.9361 - val_loss: 1.3541 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3343 - acc: 0.9431 - precision: 0.9940 - recall: 0.8892 - f1_score: 0.9371 - val_loss: 1.3484 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3285 - acc: 0.9431 - precision: 0.9912 - recall: 0.8866 - f1_score: 0.9351 - val_loss: 1.3427 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3228 - acc: 0.9431 - precision: 0.9933 - recall: 0.8888 - f1_score: 0.9372 - val_loss: 1.3370 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3171 - acc: 0.9431 - precision: 0.9922 - recall: 0.8877 - f1_score: 0.9350 - val_loss: 1.3313 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3115 - acc: 0.9431 - precision: 0.9923 - recall: 0.8873 - f1_score: 0.9360 - val_loss: 1.3257 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3059 - acc: 0.9431 - precision: 0.9923 - recall: 0.8883 - f1_score: 0.9367 - val_loss: 1.3201 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3003 - acc: 0.9431 - precision: 0.9937 - recall: 0.8871 - f1_score: 0.9358 - val_loss: 1.3146 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2947 - acc: 0.9431 - precision: 0.9934 - recall: 0.8898 - f1_score: 0.9378 - val_loss: 1.3090 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2892 - acc: 0.9431 - precision: 0.9929 - recall: 0.8884 - f1_score: 0.9359 - val_loss: 1.3035 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2837 - acc: 0.9431 - precision: 0.9904 - recall: 0.8834 - f1_score: 0.9330 - val_loss: 1.2981 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2782 - acc: 0.9431 - precision: 0.9925 - recall: 0.8902 - f1_score: 0.9372 - val_loss: 1.2926 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 320/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2728 - acc: 0.9431 - precision: 0.9926 - recall: 0.8852 - f1_score: 0.9345 - val_loss: 1.2872 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2674 - acc: 0.9431 - precision: 0.9938 - recall: 0.8890 - f1_score: 0.9365 - val_loss: 1.2818 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2620 - acc: 0.9431 - precision: 0.9928 - recall: 0.8943 - f1_score: 0.9402 - val_loss: 1.2764 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2566 - acc: 0.9431 - precision: 0.9923 - recall: 0.8857 - f1_score: 0.9351 - val_loss: 1.2711 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2513 - acc: 0.9431 - precision: 0.9939 - recall: 0.8910 - f1_score: 0.9388 - val_loss: 1.2658 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2460 - acc: 0.9431 - precision: 0.9915 - recall: 0.8815 - f1_score: 0.9295 - val_loss: 1.2605 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2407 - acc: 0.9431 - precision: 0.9922 - recall: 0.8874 - f1_score: 0.9359 - val_loss: 1.2552 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2355 - acc: 0.9431 - precision: 0.9928 - recall: 0.8859 - f1_score: 0.9346 - val_loss: 1.2500 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2302 - acc: 0.9431 - precision: 0.9927 - recall: 0.8887 - f1_score: 0.9366 - val_loss: 1.2448 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2250 - acc: 0.9431 - precision: 0.9913 - recall: 0.8901 - f1_score: 0.9365 - val_loss: 1.2396 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2199 - acc: 0.9431 - precision: 0.9935 - recall: 0.8894 - f1_score: 0.9369 - val_loss: 1.2345 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2147 - acc: 0.9431 - precision: 0.9919 - recall: 0.8896 - f1_score: 0.9375 - val_loss: 1.2293 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2096 - acc: 0.9431 - precision: 0.9936 - recall: 0.8907 - f1_score: 0.9379 - val_loss: 1.2242 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2045 - acc: 0.9431 - precision: 0.9912 - recall: 0.8909 - f1_score: 0.9373 - val_loss: 1.2192 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1994 - acc: 0.9431 - precision: 0.9931 - recall: 0.8952 - f1_score: 0.9401 - val_loss: 1.2141 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1944 - acc: 0.9431 - precision: 0.9935 - recall: 0.8774 - f1_score: 0.9294 - val_loss: 1.2091 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1894 - acc: 0.9431 - precision: 0.9910 - recall: 0.8869 - f1_score: 0.9347 - val_loss: 1.2041 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1844 - acc: 0.9431 - precision: 0.9928 - recall: 0.8859 - f1_score: 0.9346 - val_loss: 1.1991 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1794 - acc: 0.9431 - precision: 0.9944 - recall: 0.8853 - f1_score: 0.9357 - val_loss: 1.1942 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1745 - acc: 0.9431 - precision: 0.9918 - recall: 0.8840 - f1_score: 0.9343 - val_loss: 1.1893 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1696 - acc: 0.9431 - precision: 0.9910 - recall: 0.8890 - f1_score: 0.9356 - val_loss: 1.1844 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1647 - acc: 0.9431 - precision: 0.9913 - recall: 0.8898 - f1_score: 0.9367 - val_loss: 1.1795 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1598 - acc: 0.9431 - precision: 0.9933 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 1.1747 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1550 - acc: 0.9431 - precision: 0.9929 - recall: 0.8893 - f1_score: 0.9376 - val_loss: 1.1698 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1502 - acc: 0.9431 - precision: 0.9924 - recall: 0.8897 - f1_score: 0.9376 - val_loss: 1.1651 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1454 - acc: 0.9431 - precision: 0.9917 - recall: 0.8872 - f1_score: 0.9352 - val_loss: 1.1603 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1406 - acc: 0.9431 - precision: 0.9926 - recall: 0.8860 - f1_score: 0.9353 - val_loss: 1.1555 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1359 - acc: 0.9431 - precision: 0.9925 - recall: 0.8888 - f1_score: 0.9361 - val_loss: 1.1508 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1312 - acc: 0.9431 - precision: 0.9925 - recall: 0.8915 - f1_score: 0.9380 - val_loss: 1.1461 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1265 - acc: 0.9431 - precision: 0.9934 - recall: 0.8834 - f1_score: 0.9339 - val_loss: 1.1414 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1218 - acc: 0.9431 - precision: 0.9935 - recall: 0.8887 - f1_score: 0.9375 - val_loss: 1.1368 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1172 - acc: 0.9431 - precision: 0.9922 - recall: 0.8918 - f1_score: 0.9378 - val_loss: 1.1322 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1126 - acc: 0.9431 - precision: 0.9926 - recall: 0.8884 - f1_score: 0.9373 - val_loss: 1.1276 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1080 - acc: 0.9431 - precision: 0.9922 - recall: 0.8900 - f1_score: 0.9368 - val_loss: 1.1230 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1034 - acc: 0.9431 - precision: 0.9938 - recall: 0.8893 - f1_score: 0.9373 - val_loss: 1.1184 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0988 - acc: 0.9431 - precision: 0.9919 - recall: 0.8833 - f1_score: 0.9335 - val_loss: 1.1139 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0943 - acc: 0.9431 - precision: 0.9920 - recall: 0.8855 - f1_score: 0.9349 - val_loss: 1.1094 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0898 - acc: 0.9431 - precision: 0.9928 - recall: 0.8918 - f1_score: 0.9376 - val_loss: 1.1049 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0853 - acc: 0.9431 - precision: 0.9922 - recall: 0.8878 - f1_score: 0.9354 - val_loss: 1.1004 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0809 - acc: 0.9431 - precision: 0.9928 - recall: 0.8874 - f1_score: 0.9354 - val_loss: 1.0960 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0765 - acc: 0.9431 - precision: 0.9900 - recall: 0.8865 - f1_score: 0.9343 - val_loss: 1.0916 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0720 - acc: 0.9431 - precision: 0.9908 - recall: 0.8882 - f1_score: 0.9355 - val_loss: 1.0872 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0677 - acc: 0.9431 - precision: 0.9922 - recall: 0.8915 - f1_score: 0.9374 - val_loss: 1.0828 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0633 - acc: 0.9431 - precision: 0.9937 - recall: 0.8856 - f1_score: 0.9354 - val_loss: 1.0785 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0589 - acc: 0.9431 - precision: 0.9934 - recall: 0.8901 - f1_score: 0.9383 - val_loss: 1.0741 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0546 - acc: 0.9431 - precision: 0.9938 - recall: 0.8879 - f1_score: 0.9364 - val_loss: 1.0698 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0503 - acc: 0.9431 - precision: 0.9913 - recall: 0.8869 - f1_score: 0.9352 - val_loss: 1.0655 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0460 - acc: 0.9431 - precision: 0.9929 - recall: 0.8907 - f1_score: 0.9384 - val_loss: 1.0613 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0418 - acc: 0.9431 - precision: 0.9928 - recall: 0.8882 - f1_score: 0.9365 - val_loss: 1.0570 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0375 - acc: 0.9431 - precision: 0.9939 - recall: 0.8901 - f1_score: 0.9370 - val_loss: 1.0528 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0333 - acc: 0.9431 - precision: 0.9941 - recall: 0.8907 - f1_score: 0.9389 - val_loss: 1.0486 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0291 - acc: 0.9431 - precision: 0.9926 - recall: 0.8840 - f1_score: 0.9328 - val_loss: 1.0444 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0250 - acc: 0.9431 - precision: 0.9926 - recall: 0.8889 - f1_score: 0.9376 - val_loss: 1.0403 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0208 - acc: 0.9431 - precision: 0.9931 - recall: 0.8873 - f1_score: 0.9362 - val_loss: 1.0361 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0167 - acc: 0.9431 - precision: 0.9931 - recall: 0.8873 - f1_score: 0.9364 - val_loss: 1.0320 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0126 - acc: 0.9431 - precision: 0.9929 - recall: 0.8870 - f1_score: 0.9359 - val_loss: 1.0279 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0085 - acc: 0.9431 - precision: 0.9925 - recall: 0.8889 - f1_score: 0.9360 - val_loss: 1.0239 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0044 - acc: 0.9431 - precision: 0.9931 - recall: 0.8903 - f1_score: 0.9382 - val_loss: 1.0198 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0004 - acc: 0.9431 - precision: 0.9931 - recall: 0.8899 - f1_score: 0.9382 - val_loss: 1.0158 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9964 - acc: 0.9431 - precision: 0.9928 - recall: 0.8857 - f1_score: 0.9342 - val_loss: 1.0118 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9924 - acc: 0.9431 - precision: 0.9935 - recall: 0.8895 - f1_score: 0.9385 - val_loss: 1.0078 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9884 - acc: 0.9431 - precision: 0.9928 - recall: 0.8879 - f1_score: 0.9370 - val_loss: 1.0038 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9844 - acc: 0.9431 - precision: 0.9934 - recall: 0.8890 - f1_score: 0.9369 - val_loss: 0.9999 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9805 - acc: 0.9431 - precision: 0.9934 - recall: 0.8890 - f1_score: 0.9375 - val_loss: 0.9960 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 384/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9766 - acc: 0.9431 - precision: 0.9919 - recall: 0.8911 - f1_score: 0.9376 - val_loss: 0.9920 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9727 - acc: 0.9431 - precision: 0.9942 - recall: 0.8853 - f1_score: 0.9351 - val_loss: 0.9882 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9688 - acc: 0.9431 - precision: 0.9938 - recall: 0.8868 - f1_score: 0.9357 - val_loss: 0.9843 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9649 - acc: 0.9431 - precision: 0.9933 - recall: 0.8897 - f1_score: 0.9371 - val_loss: 0.9804 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9611 - acc: 0.9431 - precision: 0.9916 - recall: 0.8893 - f1_score: 0.9361 - val_loss: 0.9766 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9573 - acc: 0.9431 - precision: 0.9913 - recall: 0.8902 - f1_score: 0.9362 - val_loss: 0.9728 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9534 - acc: 0.9431 - precision: 0.9923 - recall: 0.8877 - f1_score: 0.9366 - val_loss: 0.9690 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9497 - acc: 0.9431 - precision: 0.9926 - recall: 0.8921 - f1_score: 0.9383 - val_loss: 0.9652 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9459 - acc: 0.9431 - precision: 0.9920 - recall: 0.8868 - f1_score: 0.9358 - val_loss: 0.9615 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9422 - acc: 0.9431 - precision: 0.9929 - recall: 0.8914 - f1_score: 0.9382 - val_loss: 0.9577 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9384 - acc: 0.9431 - precision: 0.9927 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 0.9540 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9347 - acc: 0.9431 - precision: 0.9932 - recall: 0.8885 - f1_score: 0.9376 - val_loss: 0.9503 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9310 - acc: 0.9431 - precision: 0.9920 - recall: 0.8860 - f1_score: 0.9346 - val_loss: 0.9467 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9274 - acc: 0.9431 - precision: 0.9934 - recall: 0.8899 - f1_score: 0.9368 - val_loss: 0.9430 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9237 - acc: 0.9431 - precision: 0.9919 - recall: 0.8893 - f1_score: 0.9366 - val_loss: 0.9394 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9201 - acc: 0.9431 - precision: 0.9930 - recall: 0.8872 - f1_score: 0.9359 - val_loss: 0.9358 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9165 - acc: 0.9431 - precision: 0.9937 - recall: 0.8941 - f1_score: 0.9398 - val_loss: 0.9322 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9129 - acc: 0.9431 - precision: 0.9904 - recall: 0.8924 - f1_score: 0.9378 - val_loss: 0.9286 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9093 - acc: 0.9431 - precision: 0.9924 - recall: 0.8875 - f1_score: 0.9362 - val_loss: 0.9250 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9057 - acc: 0.9431 - precision: 0.9916 - recall: 0.8943 - f1_score: 0.9394 - val_loss: 0.9215 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9022 - acc: 0.9431 - precision: 0.9931 - recall: 0.8883 - f1_score: 0.9348 - val_loss: 0.9179 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8987 - acc: 0.9431 - precision: 0.9929 - recall: 0.8854 - f1_score: 0.9342 - val_loss: 0.9144 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8952 - acc: 0.9431 - precision: 0.9928 - recall: 0.8872 - f1_score: 0.9362 - val_loss: 0.9109 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8917 - acc: 0.9431 - precision: 0.9917 - recall: 0.8865 - f1_score: 0.9352 - val_loss: 0.9075 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8882 - acc: 0.9431 - precision: 0.9929 - recall: 0.8869 - f1_score: 0.9347 - val_loss: 0.9040 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8847 - acc: 0.9431 - precision: 0.9915 - recall: 0.8821 - f1_score: 0.9319 - val_loss: 0.9006 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8813 - acc: 0.9431 - precision: 0.9918 - recall: 0.8885 - f1_score: 0.9360 - val_loss: 0.8972 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8779 - acc: 0.9431 - precision: 0.9935 - recall: 0.8906 - f1_score: 0.9380 - val_loss: 0.8937 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8745 - acc: 0.9431 - precision: 0.9921 - recall: 0.8873 - f1_score: 0.9359 - val_loss: 0.8904 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8711 - acc: 0.9431 - precision: 0.9937 - recall: 0.8839 - f1_score: 0.9346 - val_loss: 0.8870 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8677 - acc: 0.9431 - precision: 0.9926 - recall: 0.8887 - f1_score: 0.9358 - val_loss: 0.8836 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8644 - acc: 0.9431 - precision: 0.9926 - recall: 0.8948 - f1_score: 0.9397 - val_loss: 0.8803 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 416/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8611 - acc: 0.9431 - precision: 0.9925 - recall: 0.8925 - f1_score: 0.9388 - val_loss: 0.8770 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8577 - acc: 0.9431 - precision: 0.9929 - recall: 0.8919 - f1_score: 0.9381 - val_loss: 0.8737 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8545 - acc: 0.9431 - precision: 0.9901 - recall: 0.8867 - f1_score: 0.9345 - val_loss: 0.8704 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8512 - acc: 0.9431 - precision: 0.9929 - recall: 0.8841 - f1_score: 0.9343 - val_loss: 0.8671 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8479 - acc: 0.9431 - precision: 0.9932 - recall: 0.8879 - f1_score: 0.9361 - val_loss: 0.8639 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8447 - acc: 0.9431 - precision: 0.9939 - recall: 0.8877 - f1_score: 0.9360 - val_loss: 0.8606 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8414 - acc: 0.9431 - precision: 0.9926 - recall: 0.8890 - f1_score: 0.9370 - val_loss: 0.8574 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8382 - acc: 0.9431 - precision: 0.9917 - recall: 0.8893 - f1_score: 0.9352 - val_loss: 0.8542 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8350 - acc: 0.9431 - precision: 0.9939 - recall: 0.8891 - f1_score: 0.9368 - val_loss: 0.8510 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8318 - acc: 0.9431 - precision: 0.9914 - recall: 0.8870 - f1_score: 0.9351 - val_loss: 0.8478 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8287 - acc: 0.9431 - precision: 0.9928 - recall: 0.8913 - f1_score: 0.9384 - val_loss: 0.8447 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8255 - acc: 0.9431 - precision: 0.9929 - recall: 0.8860 - f1_score: 0.9357 - val_loss: 0.8415 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8224 - acc: 0.9431 - precision: 0.9898 - recall: 0.8843 - f1_score: 0.9331 - val_loss: 0.8384 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8193 - acc: 0.9431 - precision: 0.9919 - recall: 0.8884 - f1_score: 0.9359 - val_loss: 0.8353 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8162 - acc: 0.9431 - precision: 0.9932 - recall: 0.8886 - f1_score: 0.9365 - val_loss: 0.8322 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8131 - acc: 0.9431 - precision: 0.9925 - recall: 0.8848 - f1_score: 0.9347 - val_loss: 0.8291 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8100 - acc: 0.9431 - precision: 0.9920 - recall: 0.8911 - f1_score: 0.9370 - val_loss: 0.8261 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8069 - acc: 0.9431 - precision: 0.9921 - recall: 0.8903 - f1_score: 0.9370 - val_loss: 0.8230 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8039 - acc: 0.9431 - precision: 0.9926 - recall: 0.8847 - f1_score: 0.9346 - val_loss: 0.8200 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8009 - acc: 0.9431 - precision: 0.9928 - recall: 0.8805 - f1_score: 0.9320 - val_loss: 0.8170 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7979 - acc: 0.9431 - precision: 0.9933 - recall: 0.8877 - f1_score: 0.9364 - val_loss: 0.8140 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7949 - acc: 0.9431 - precision: 0.9924 - recall: 0.8905 - f1_score: 0.9371 - val_loss: 0.8110 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7919 - acc: 0.9431 - precision: 0.9930 - recall: 0.8883 - f1_score: 0.9351 - val_loss: 0.8080 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7889 - acc: 0.9431 - precision: 0.9916 - recall: 0.8867 - f1_score: 0.9347 - val_loss: 0.8051 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7860 - acc: 0.9431 - precision: 0.9927 - recall: 0.8908 - f1_score: 0.9373 - val_loss: 0.8021 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7830 - acc: 0.9431 - precision: 0.9923 - recall: 0.8929 - f1_score: 0.9384 - val_loss: 0.7992 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7801 - acc: 0.9431 - precision: 0.9931 - recall: 0.8859 - f1_score: 0.9343 - val_loss: 0.7963 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7772 - acc: 0.9431 - precision: 0.9934 - recall: 0.8880 - f1_score: 0.9358 - val_loss: 0.7934 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7743 - acc: 0.9431 - precision: 0.9931 - recall: 0.8904 - f1_score: 0.9380 - val_loss: 0.7905 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7714 - acc: 0.9431 - precision: 0.9934 - recall: 0.8901 - f1_score: 0.9382 - val_loss: 0.7877 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7686 - acc: 0.9431 - precision: 0.9928 - recall: 0.8888 - f1_score: 0.9373 - val_loss: 0.7848 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7657 - acc: 0.9431 - precision: 0.9937 - recall: 0.8875 - f1_score: 0.9365 - val_loss: 0.7820 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7629 - acc: 0.9431 - precision: 0.9937 - recall: 0.8896 - f1_score: 0.9377 - val_loss: 0.7791 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7601 - acc: 0.9431 - precision: 0.9933 - recall: 0.8906 - f1_score: 0.9378 - val_loss: 0.7763 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7573 - acc: 0.9431 - precision: 0.9935 - recall: 0.8852 - f1_score: 0.9355 - val_loss: 0.7735 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7545 - acc: 0.9431 - precision: 0.9937 - recall: 0.8870 - f1_score: 0.9367 - val_loss: 0.7708 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7517 - acc: 0.9431 - precision: 0.9923 - recall: 0.8919 - f1_score: 0.9377 - val_loss: 0.7680 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7490 - acc: 0.9431 - precision: 0.9941 - recall: 0.8903 - f1_score: 0.9376 - val_loss: 0.7652 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7462 - acc: 0.9431 - precision: 0.9937 - recall: 0.8826 - f1_score: 0.9337 - val_loss: 0.7625 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7435 - acc: 0.9431 - precision: 0.9926 - recall: 0.8914 - f1_score: 0.9382 - val_loss: 0.7598 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7408 - acc: 0.9431 - precision: 0.9928 - recall: 0.8931 - f1_score: 0.9382 - val_loss: 0.7571 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7380 - acc: 0.9431 - precision: 0.9937 - recall: 0.8829 - f1_score: 0.9316 - val_loss: 0.7544 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7353 - acc: 0.9431 - precision: 0.9936 - recall: 0.8924 - f1_score: 0.9389 - val_loss: 0.7517 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7327 - acc: 0.9431 - precision: 0.9938 - recall: 0.8874 - f1_score: 0.9368 - val_loss: 0.7490 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7300 - acc: 0.9431 - precision: 0.9915 - recall: 0.8888 - f1_score: 0.9353 - val_loss: 0.7464 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7274 - acc: 0.9431 - precision: 0.9939 - recall: 0.8859 - f1_score: 0.9345 - val_loss: 0.7437 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7247 - acc: 0.9431 - precision: 0.9912 - recall: 0.8936 - f1_score: 0.9383 - val_loss: 0.7411 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7221 - acc: 0.9431 - precision: 0.9936 - recall: 0.8872 - f1_score: 0.9367 - val_loss: 0.7385 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7195 - acc: 0.9431 - precision: 0.9922 - recall: 0.8863 - f1_score: 0.9349 - val_loss: 0.7359 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7169 - acc: 0.9431 - precision: 0.9931 - recall: 0.8868 - f1_score: 0.9349 - val_loss: 0.7333 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7143 - acc: 0.9431 - precision: 0.9920 - recall: 0.8917 - f1_score: 0.9372 - val_loss: 0.7307 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7117 - acc: 0.9431 - precision: 0.9908 - recall: 0.8850 - f1_score: 0.9337 - val_loss: 0.7282 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7092 - acc: 0.9431 - precision: 0.9935 - recall: 0.8881 - f1_score: 0.9372 - val_loss: 0.7256 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7066 - acc: 0.9431 - precision: 0.9926 - recall: 0.8861 - f1_score: 0.9342 - val_loss: 0.7231 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7041 - acc: 0.9431 - precision: 0.9930 - recall: 0.8863 - f1_score: 0.9351 - val_loss: 0.7205 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7016 - acc: 0.9431 - precision: 0.9935 - recall: 0.8897 - f1_score: 0.9385 - val_loss: 0.7180 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6990 - acc: 0.9431 - precision: 0.9935 - recall: 0.8870 - f1_score: 0.9352 - val_loss: 0.7155 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6966 - acc: 0.9431 - precision: 0.9934 - recall: 0.8915 - f1_score: 0.9385 - val_loss: 0.7130 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6941 - acc: 0.9431 - precision: 0.9925 - recall: 0.8895 - f1_score: 0.9368 - val_loss: 0.7106 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6916 - acc: 0.9431 - precision: 0.9929 - recall: 0.8869 - f1_score: 0.9355 - val_loss: 0.7081 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6891 - acc: 0.9431 - precision: 0.9937 - recall: 0.8967 - f1_score: 0.9407 - val_loss: 0.7057 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6867 - acc: 0.9431 - precision: 0.9934 - recall: 0.8890 - f1_score: 0.9378 - val_loss: 0.7032 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6843 - acc: 0.9431 - precision: 0.9928 - recall: 0.8924 - f1_score: 0.9385 - val_loss: 0.7008 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6818 - acc: 0.9431 - precision: 0.9931 - recall: 0.8877 - f1_score: 0.9354 - val_loss: 0.6984 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 480/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6794 - acc: 0.9431 - precision: 0.9935 - recall: 0.8840 - f1_score: 0.9334 - val_loss: 0.6960 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6770 - acc: 0.9431 - precision: 0.9923 - recall: 0.8854 - f1_score: 0.9350 - val_loss: 0.6936 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6746 - acc: 0.9431 - precision: 0.9928 - recall: 0.8857 - f1_score: 0.9350 - val_loss: 0.6912 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6723 - acc: 0.9431 - precision: 0.9921 - recall: 0.8843 - f1_score: 0.9322 - val_loss: 0.6888 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6699 - acc: 0.9431 - precision: 0.9923 - recall: 0.8905 - f1_score: 0.9377 - val_loss: 0.6865 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6676 - acc: 0.9431 - precision: 0.9934 - recall: 0.8883 - f1_score: 0.9351 - val_loss: 0.6842 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6652 - acc: 0.9431 - precision: 0.9944 - recall: 0.8891 - f1_score: 0.9369 - val_loss: 0.6818 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6629 - acc: 0.9431 - precision: 0.9923 - recall: 0.8879 - f1_score: 0.9363 - val_loss: 0.6795 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6606 - acc: 0.9431 - precision: 0.9937 - recall: 0.8849 - f1_score: 0.9340 - val_loss: 0.6772 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6583 - acc: 0.9431 - precision: 0.9925 - recall: 0.8860 - f1_score: 0.9351 - val_loss: 0.6749 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6560 - acc: 0.9431 - precision: 0.9935 - recall: 0.8909 - f1_score: 0.9386 - val_loss: 0.6726 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6537 - acc: 0.9431 - precision: 0.9933 - recall: 0.8870 - f1_score: 0.9360 - val_loss: 0.6704 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6514 - acc: 0.9431 - precision: 0.9913 - recall: 0.8860 - f1_score: 0.9344 - val_loss: 0.6681 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6492 - acc: 0.9431 - precision: 0.9937 - recall: 0.8912 - f1_score: 0.9386 - val_loss: 0.6658 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6469 - acc: 0.9431 - precision: 0.9936 - recall: 0.8859 - f1_score: 0.9358 - val_loss: 0.6636 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6447 - acc: 0.9431 - precision: 0.9930 - recall: 0.8873 - f1_score: 0.9367 - val_loss: 0.6614 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6425 - acc: 0.9431 - precision: 0.9926 - recall: 0.8884 - f1_score: 0.9357 - val_loss: 0.6592 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6403 - acc: 0.9431 - precision: 0.9943 - recall: 0.8876 - f1_score: 0.9368 - val_loss: 0.6569 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6381 - acc: 0.9431 - precision: 0.9928 - recall: 0.8882 - f1_score: 0.9371 - val_loss: 0.6548 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6359 - acc: 0.9431 - precision: 0.9910 - recall: 0.8880 - f1_score: 0.9359 - val_loss: 0.6526 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6337 - acc: 0.9431 - precision: 0.9930 - recall: 0.8898 - f1_score: 0.9370 - val_loss: 0.6504 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6315 - acc: 0.9431 - precision: 0.9919 - recall: 0.8877 - f1_score: 0.9361 - val_loss: 0.6482 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6294 - acc: 0.9431 - precision: 0.9917 - recall: 0.8873 - f1_score: 0.9358 - val_loss: 0.6461 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6272 - acc: 0.9431 - precision: 0.9941 - recall: 0.8873 - f1_score: 0.9360 - val_loss: 0.6439 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6251 - acc: 0.9431 - precision: 0.9928 - recall: 0.8900 - f1_score: 0.9377 - val_loss: 0.6418 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6230 - acc: 0.9431 - precision: 0.9931 - recall: 0.8887 - f1_score: 0.9369 - val_loss: 0.6397 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6208 - acc: 0.9431 - precision: 0.9923 - recall: 0.8885 - f1_score: 0.9366 - val_loss: 0.6376 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6187 - acc: 0.9431 - precision: 0.9930 - recall: 0.8891 - f1_score: 0.9368 - val_loss: 0.6355 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6166 - acc: 0.9431 - precision: 0.9936 - recall: 0.8908 - f1_score: 0.9372 - val_loss: 0.6334 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6146 - acc: 0.9431 - precision: 0.9931 - recall: 0.8888 - f1_score: 0.9367 - val_loss: 0.6313 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6125 - acc: 0.9431 - precision: 0.9929 - recall: 0.8882 - f1_score: 0.9362 - val_loss: 0.6293 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6104 - acc: 0.9431 - precision: 0.9919 - recall: 0.8909 - f1_score: 0.9369 - val_loss: 0.6272 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 512/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6084 - acc: 0.9431 - precision: 0.9935 - recall: 0.8875 - f1_score: 0.9368 - val_loss: 0.6252 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6063 - acc: 0.9431 - precision: 0.9904 - recall: 0.8854 - f1_score: 0.9342 - val_loss: 0.6231 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6043 - acc: 0.9431 - precision: 0.9925 - recall: 0.8912 - f1_score: 0.9378 - val_loss: 0.6211 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6023 - acc: 0.9431 - precision: 0.9910 - recall: 0.8854 - f1_score: 0.9336 - val_loss: 0.6191 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6003 - acc: 0.9431 - precision: 0.9907 - recall: 0.8869 - f1_score: 0.9351 - val_loss: 0.6171 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5983 - acc: 0.9431 - precision: 0.9929 - recall: 0.8873 - f1_score: 0.9349 - val_loss: 0.6151 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5963 - acc: 0.9431 - precision: 0.9912 - recall: 0.8915 - f1_score: 0.9377 - val_loss: 0.6131 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5943 - acc: 0.9431 - precision: 0.9906 - recall: 0.8877 - f1_score: 0.9346 - val_loss: 0.6111 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5923 - acc: 0.9431 - precision: 0.9928 - recall: 0.8912 - f1_score: 0.9380 - val_loss: 0.6091 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5903 - acc: 0.9431 - precision: 0.9921 - recall: 0.8882 - f1_score: 0.9367 - val_loss: 0.6072 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5884 - acc: 0.9431 - precision: 0.9926 - recall: 0.8979 - f1_score: 0.9411 - val_loss: 0.6052 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5864 - acc: 0.9431 - precision: 0.9926 - recall: 0.8853 - f1_score: 0.9347 - val_loss: 0.6033 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5845 - acc: 0.9431 - precision: 0.9939 - recall: 0.8875 - f1_score: 0.9359 - val_loss: 0.6014 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5826 - acc: 0.9431 - precision: 0.9933 - recall: 0.8886 - f1_score: 0.9357 - val_loss: 0.5995 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5807 - acc: 0.9431 - precision: 0.9917 - recall: 0.8878 - f1_score: 0.9336 - val_loss: 0.5975 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5788 - acc: 0.9431 - precision: 0.9924 - recall: 0.8903 - f1_score: 0.9371 - val_loss: 0.5956 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5769 - acc: 0.9431 - precision: 0.9939 - recall: 0.8899 - f1_score: 0.9380 - val_loss: 0.5938 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5750 - acc: 0.9431 - precision: 0.9931 - recall: 0.8894 - f1_score: 0.9371 - val_loss: 0.5919 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5731 - acc: 0.9431 - precision: 0.9938 - recall: 0.8911 - f1_score: 0.9380 - val_loss: 0.5900 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5713 - acc: 0.9431 - precision: 0.9934 - recall: 0.8925 - f1_score: 0.9388 - val_loss: 0.5881 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5694 - acc: 0.9431 - precision: 0.9930 - recall: 0.8887 - f1_score: 0.9372 - val_loss: 0.5863 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5675 - acc: 0.9431 - precision: 0.9915 - recall: 0.8886 - f1_score: 0.9363 - val_loss: 0.5844 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5657 - acc: 0.9431 - precision: 0.9935 - recall: 0.8808 - f1_score: 0.9321 - val_loss: 0.5826 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5639 - acc: 0.9431 - precision: 0.9923 - recall: 0.8894 - f1_score: 0.9376 - val_loss: 0.5808 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5620 - acc: 0.9431 - precision: 0.9915 - recall: 0.8890 - f1_score: 0.9364 - val_loss: 0.5790 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5602 - acc: 0.9431 - precision: 0.9919 - recall: 0.8886 - f1_score: 0.9369 - val_loss: 0.5772 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5584 - acc: 0.9431 - precision: 0.9928 - recall: 0.8911 - f1_score: 0.9379 - val_loss: 0.5754 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5566 - acc: 0.9431 - precision: 0.9933 - recall: 0.8873 - f1_score: 0.9356 - val_loss: 0.5736 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5549 - acc: 0.9447 - precision: 0.9968 - recall: 0.8902 - f1_score: 0.9394 - val_loss: 0.5718 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5531 - acc: 0.9431 - precision: 0.9929 - recall: 0.8887 - f1_score: 0.9362 - val_loss: 0.5700 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5513 - acc: 0.9431 - precision: 0.9926 - recall: 0.8918 - f1_score: 0.9386 - val_loss: 0.5683 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5496 - acc: 0.9431 - precision: 0.9931 - recall: 0.8886 - f1_score: 0.9363 - val_loss: 0.5665 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5478 - acc: 0.9447 - precision: 0.9961 - recall: 0.8870 - f1_score: 0.9377 - val_loss: 0.5648 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5461 - acc: 0.9431 - precision: 0.9915 - recall: 0.8894 - f1_score: 0.9364 - val_loss: 0.5630 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5443 - acc: 0.9431 - precision: 0.9928 - recall: 0.8915 - f1_score: 0.9383 - val_loss: 0.5613 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5426 - acc: 0.9431 - precision: 0.9919 - recall: 0.8888 - f1_score: 0.9360 - val_loss: 0.5596 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5409 - acc: 0.9431 - precision: 0.9923 - recall: 0.8848 - f1_score: 0.9346 - val_loss: 0.5578 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5392 - acc: 0.9431 - precision: 0.9916 - recall: 0.8885 - f1_score: 0.9366 - val_loss: 0.5561 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5375 - acc: 0.9447 - precision: 0.9970 - recall: 0.8881 - f1_score: 0.9380 - val_loss: 0.5545 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5358 - acc: 0.9431 - precision: 0.9918 - recall: 0.8889 - f1_score: 0.9357 - val_loss: 0.5528 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5341 - acc: 0.9447 - precision: 0.9961 - recall: 0.8923 - f1_score: 0.9397 - val_loss: 0.5511 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5324 - acc: 0.9431 - precision: 0.9922 - recall: 0.8836 - f1_score: 0.9334 - val_loss: 0.5494 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5308 - acc: 0.9447 - precision: 0.9958 - recall: 0.8896 - f1_score: 0.9386 - val_loss: 0.5478 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5291 - acc: 0.9447 - precision: 0.9962 - recall: 0.8869 - f1_score: 0.9369 - val_loss: 0.5461 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5275 - acc: 0.9447 - precision: 0.9962 - recall: 0.8898 - f1_score: 0.9390 - val_loss: 0.5445 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5258 - acc: 0.9431 - precision: 0.9921 - recall: 0.8872 - f1_score: 0.9362 - val_loss: 0.5428 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5242 - acc: 0.9447 - precision: 0.9964 - recall: 0.8868 - f1_score: 0.9365 - val_loss: 0.5412 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5226 - acc: 0.9447 - precision: 0.9958 - recall: 0.8872 - f1_score: 0.9378 - val_loss: 0.5396 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5209 - acc: 0.9447 - precision: 0.9966 - recall: 0.8899 - f1_score: 0.9394 - val_loss: 0.5380 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5193 - acc: 0.9447 - precision: 0.9958 - recall: 0.8897 - f1_score: 0.9387 - val_loss: 0.5364 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5177 - acc: 0.9447 - precision: 0.9966 - recall: 0.8891 - f1_score: 0.9390 - val_loss: 0.5348 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5161 - acc: 0.9447 - precision: 0.9958 - recall: 0.8909 - f1_score: 0.9379 - val_loss: 0.5332 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5146 - acc: 0.9447 - precision: 0.9967 - recall: 0.8872 - f1_score: 0.9381 - val_loss: 0.5316 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5130 - acc: 0.9447 - precision: 0.9966 - recall: 0.8903 - f1_score: 0.9396 - val_loss: 0.5300 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5114 - acc: 0.9431 - precision: 0.9915 - recall: 0.8927 - f1_score: 0.9387 - val_loss: 0.5285 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5099 - acc: 0.9447 - precision: 0.9962 - recall: 0.8910 - f1_score: 0.9397 - val_loss: 0.5269 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5083 - acc: 0.9447 - precision: 0.9961 - recall: 0.8888 - f1_score: 0.9384 - val_loss: 0.5254 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5067 - acc: 0.9447 - precision: 0.9956 - recall: 0.8865 - f1_score: 0.9368 - val_loss: 0.5238 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5052 - acc: 0.9447 - precision: 0.9967 - recall: 0.8896 - f1_score: 0.9392 - val_loss: 0.5223 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5037 - acc: 0.9447 - precision: 0.9961 - recall: 0.8909 - f1_score: 0.9400 - val_loss: 0.5208 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5021 - acc: 0.9447 - precision: 0.9964 - recall: 0.8920 - f1_score: 0.9408 - val_loss: 0.5193 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5006 - acc: 0.9447 - precision: 0.9962 - recall: 0.8931 - f1_score: 0.9396 - val_loss: 0.5177 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4991 - acc: 0.9447 - precision: 0.9961 - recall: 0.8917 - f1_score: 0.9402 - val_loss: 0.5162 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4976 - acc: 0.9447 - precision: 0.9968 - recall: 0.8913 - f1_score: 0.9395 - val_loss: 0.5147 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 576/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4961 - acc: 0.9447 - precision: 0.9968 - recall: 0.8941 - f1_score: 0.9409 - val_loss: 0.5132 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4946 - acc: 0.9447 - precision: 0.9968 - recall: 0.8875 - f1_score: 0.9378 - val_loss: 0.5118 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4932 - acc: 0.9447 - precision: 0.9956 - recall: 0.8907 - f1_score: 0.9389 - val_loss: 0.5103 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4917 - acc: 0.9447 - precision: 0.9962 - recall: 0.8899 - f1_score: 0.9386 - val_loss: 0.5088 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4902 - acc: 0.9447 - precision: 0.9968 - recall: 0.8867 - f1_score: 0.9371 - val_loss: 0.5073 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4888 - acc: 0.9447 - precision: 0.9961 - recall: 0.8927 - f1_score: 0.9402 - val_loss: 0.5059 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4873 - acc: 0.9447 - precision: 0.9964 - recall: 0.8877 - f1_score: 0.9380 - val_loss: 0.5044 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4859 - acc: 0.9447 - precision: 0.9961 - recall: 0.8910 - f1_score: 0.9393 - val_loss: 0.5030 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4844 - acc: 0.9447 - precision: 0.9967 - recall: 0.8901 - f1_score: 0.9393 - val_loss: 0.5016 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4830 - acc: 0.9447 - precision: 0.9962 - recall: 0.8873 - f1_score: 0.9379 - val_loss: 0.5002 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4816 - acc: 0.9447 - precision: 0.9973 - recall: 0.8867 - f1_score: 0.9374 - val_loss: 0.4987 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4802 - acc: 0.9447 - precision: 0.9958 - recall: 0.8843 - f1_score: 0.9357 - val_loss: 0.4973 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4788 - acc: 0.9447 - precision: 0.9971 - recall: 0.8892 - f1_score: 0.9386 - val_loss: 0.4959 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4774 - acc: 0.9447 - precision: 0.9962 - recall: 0.8915 - f1_score: 0.9399 - val_loss: 0.4945 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4760 - acc: 0.9447 - precision: 0.9961 - recall: 0.8908 - f1_score: 0.9395 - val_loss: 0.4931 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4746 - acc: 0.9447 - precision: 0.9966 - recall: 0.8878 - f1_score: 0.9379 - val_loss: 0.4917 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4732 - acc: 0.9447 - precision: 0.9968 - recall: 0.8895 - f1_score: 0.9389 - val_loss: 0.4903 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4718 - acc: 0.9447 - precision: 0.9967 - recall: 0.8900 - f1_score: 0.9391 - val_loss: 0.4890 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4704 - acc: 0.9447 - precision: 0.9939 - recall: 0.8845 - f1_score: 0.9350 - val_loss: 0.4876 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4691 - acc: 0.9447 - precision: 0.9968 - recall: 0.8897 - f1_score: 0.9390 - val_loss: 0.4863 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4677 - acc: 0.9447 - precision: 0.9972 - recall: 0.8889 - f1_score: 0.9389 - val_loss: 0.4849 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4664 - acc: 0.9447 - precision: 0.9961 - recall: 0.8897 - f1_score: 0.9386 - val_loss: 0.4836 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4650 - acc: 0.9447 - precision: 0.9967 - recall: 0.8896 - f1_score: 0.9388 - val_loss: 0.4822 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4637 - acc: 0.9447 - precision: 0.9961 - recall: 0.8914 - f1_score: 0.9399 - val_loss: 0.4809 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4624 - acc: 0.9447 - precision: 0.9970 - recall: 0.8897 - f1_score: 0.9392 - val_loss: 0.4796 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4611 - acc: 0.9447 - precision: 0.9966 - recall: 0.8866 - f1_score: 0.9372 - val_loss: 0.4782 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4597 - acc: 0.9447 - precision: 0.9958 - recall: 0.8915 - f1_score: 0.9397 - val_loss: 0.4769 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4584 - acc: 0.9447 - precision: 0.9964 - recall: 0.8883 - f1_score: 0.9376 - val_loss: 0.4756 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4571 - acc: 0.9447 - precision: 0.9962 - recall: 0.8915 - f1_score: 0.9393 - val_loss: 0.4743 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4558 - acc: 0.9447 - precision: 0.9961 - recall: 0.8902 - f1_score: 0.9378 - val_loss: 0.4730 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4545 - acc: 0.9447 - precision: 0.9954 - recall: 0.8858 - f1_score: 0.9369 - val_loss: 0.4717 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4533 - acc: 0.9447 - precision: 0.9961 - recall: 0.8879 - f1_score: 0.9381 - val_loss: 0.4705 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4520 - acc: 0.9447 - precision: 0.9966 - recall: 0.8875 - f1_score: 0.9374 - val_loss: 0.4692 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4507 - acc: 0.9447 - precision: 0.9954 - recall: 0.8862 - f1_score: 0.9366 - val_loss: 0.4679 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4494 - acc: 0.9447 - precision: 0.9971 - recall: 0.8882 - f1_score: 0.9381 - val_loss: 0.4667 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4482 - acc: 0.9447 - precision: 0.9958 - recall: 0.8881 - f1_score: 0.9369 - val_loss: 0.4654 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4469 - acc: 0.9447 - precision: 0.9967 - recall: 0.8888 - f1_score: 0.9393 - val_loss: 0.4642 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4457 - acc: 0.9447 - precision: 0.9970 - recall: 0.8901 - f1_score: 0.9397 - val_loss: 0.4629 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4444 - acc: 0.9447 - precision: 0.9964 - recall: 0.8797 - f1_score: 0.9306 - val_loss: 0.4617 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4432 - acc: 0.9447 - precision: 0.9958 - recall: 0.8848 - f1_score: 0.9362 - val_loss: 0.4605 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4420 - acc: 0.9447 - precision: 0.9961 - recall: 0.8871 - f1_score: 0.9377 - val_loss: 0.4592 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4408 - acc: 0.9447 - precision: 0.9964 - recall: 0.8865 - f1_score: 0.9372 - val_loss: 0.4580 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4395 - acc: 0.9447 - precision: 0.9970 - recall: 0.8878 - f1_score: 0.9378 - val_loss: 0.4568 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4383 - acc: 0.9447 - precision: 0.9964 - recall: 0.8899 - f1_score: 0.9390 - val_loss: 0.4556 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4371 - acc: 0.9463 - precision: 0.9971 - recall: 0.8948 - f1_score: 0.9417 - val_loss: 0.4544 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4359 - acc: 0.9447 - precision: 0.9957 - recall: 0.8940 - f1_score: 0.9406 - val_loss: 0.4532 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4347 - acc: 0.9463 - precision: 0.9960 - recall: 0.8951 - f1_score: 0.9420 - val_loss: 0.4520 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4335 - acc: 0.9463 - precision: 0.9964 - recall: 0.8928 - f1_score: 0.9406 - val_loss: 0.4508 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4324 - acc: 0.9463 - precision: 0.9972 - recall: 0.8931 - f1_score: 0.9413 - val_loss: 0.4497 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4312 - acc: 0.9463 - precision: 0.9967 - recall: 0.8929 - f1_score: 0.9415 - val_loss: 0.4485 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4300 - acc: 0.9463 - precision: 0.9954 - recall: 0.8912 - f1_score: 0.9396 - val_loss: 0.4473 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4288 - acc: 0.9447 - precision: 0.9962 - recall: 0.8916 - f1_score: 0.9396 - val_loss: 0.4462 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4277 - acc: 0.9447 - precision: 0.9954 - recall: 0.8832 - f1_score: 0.9347 - val_loss: 0.4450 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4265 - acc: 0.9463 - precision: 0.9962 - recall: 0.8929 - f1_score: 0.9404 - val_loss: 0.4439 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4254 - acc: 0.9463 - precision: 0.9966 - recall: 0.8931 - f1_score: 0.9409 - val_loss: 0.4427 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4242 - acc: 0.9463 - precision: 0.9953 - recall: 0.8959 - f1_score: 0.9409 - val_loss: 0.4416 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4231 - acc: 0.9447 - precision: 0.9971 - recall: 0.8868 - f1_score: 0.9381 - val_loss: 0.4404 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4220 - acc: 0.9463 - precision: 0.9951 - recall: 0.8910 - f1_score: 0.9395 - val_loss: 0.4393 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4208 - acc: 0.9463 - precision: 0.9966 - recall: 0.8953 - f1_score: 0.9420 - val_loss: 0.4382 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4197 - acc: 0.9463 - precision: 0.9967 - recall: 0.8910 - f1_score: 0.9403 - val_loss: 0.4371 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4186 - acc: 0.9447 - precision: 0.9964 - recall: 0.8868 - f1_score: 0.9370 - val_loss: 0.4360 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4175 - acc: 0.9463 - precision: 0.9963 - recall: 0.8904 - f1_score: 0.9397 - val_loss: 0.4349 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4164 - acc: 0.9463 - precision: 0.9962 - recall: 0.8933 - f1_score: 0.9415 - val_loss: 0.4338 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4153 - acc: 0.9463 - precision: 0.9970 - recall: 0.8904 - f1_score: 0.9397 - val_loss: 0.4327 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4142 - acc: 0.9463 - precision: 0.9966 - recall: 0.8908 - f1_score: 0.9388 - val_loss: 0.4316 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4131 - acc: 0.9447 - precision: 0.9970 - recall: 0.8861 - f1_score: 0.9364 - val_loss: 0.4305 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4120 - acc: 0.9463 - precision: 0.9956 - recall: 0.8874 - f1_score: 0.9377 - val_loss: 0.4294 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4109 - acc: 0.9463 - precision: 0.9967 - recall: 0.8979 - f1_score: 0.9436 - val_loss: 0.4283 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4099 - acc: 0.9447 - precision: 0.9967 - recall: 0.8901 - f1_score: 0.9388 - val_loss: 0.4273 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4088 - acc: 0.9463 - precision: 0.9974 - recall: 0.8923 - f1_score: 0.9412 - val_loss: 0.4262 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4077 - acc: 0.9463 - precision: 0.9956 - recall: 0.8909 - f1_score: 0.9387 - val_loss: 0.4252 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4067 - acc: 0.9463 - precision: 0.9964 - recall: 0.8948 - f1_score: 0.9423 - val_loss: 0.4241 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4056 - acc: 0.9463 - precision: 0.9964 - recall: 0.8913 - f1_score: 0.9393 - val_loss: 0.4231 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4046 - acc: 0.9447 - precision: 0.9962 - recall: 0.8906 - f1_score: 0.9395 - val_loss: 0.4220 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4035 - acc: 0.9463 - precision: 0.9961 - recall: 0.8951 - f1_score: 0.9410 - val_loss: 0.4210 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4025 - acc: 0.9463 - precision: 0.9962 - recall: 0.8919 - f1_score: 0.9401 - val_loss: 0.4199 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4015 - acc: 0.9463 - precision: 0.9961 - recall: 0.8909 - f1_score: 0.9394 - val_loss: 0.4189 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4004 - acc: 0.9463 - precision: 0.9968 - recall: 0.8876 - f1_score: 0.9382 - val_loss: 0.4179 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3994 - acc: 0.9463 - precision: 0.9964 - recall: 0.8974 - f1_score: 0.9428 - val_loss: 0.4169 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3984 - acc: 0.9463 - precision: 0.9966 - recall: 0.8918 - f1_score: 0.9401 - val_loss: 0.4159 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3974 - acc: 0.9463 - precision: 0.9965 - recall: 0.8935 - f1_score: 0.9405 - val_loss: 0.4149 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3964 - acc: 0.9463 - precision: 0.9958 - recall: 0.8929 - f1_score: 0.9409 - val_loss: 0.4139 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3954 - acc: 0.9463 - precision: 0.9939 - recall: 0.8917 - f1_score: 0.9392 - val_loss: 0.4128 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3944 - acc: 0.9463 - precision: 0.9964 - recall: 0.8936 - f1_score: 0.9416 - val_loss: 0.4119 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3934 - acc: 0.9463 - precision: 0.9972 - recall: 0.8901 - f1_score: 0.9392 - val_loss: 0.4109 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3924 - acc: 0.9463 - precision: 0.9964 - recall: 0.8898 - f1_score: 0.9394 - val_loss: 0.4099 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3914 - acc: 0.9447 - precision: 0.9934 - recall: 0.8860 - f1_score: 0.9356 - val_loss: 0.4089 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3904 - acc: 0.9463 - precision: 0.9964 - recall: 0.8930 - f1_score: 0.9404 - val_loss: 0.4079 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3894 - acc: 0.9463 - precision: 0.9964 - recall: 0.8880 - f1_score: 0.9376 - val_loss: 0.4069 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3885 - acc: 0.9463 - precision: 0.9966 - recall: 0.8935 - f1_score: 0.9405 - val_loss: 0.4060 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3875 - acc: 0.9463 - precision: 0.9954 - recall: 0.8895 - f1_score: 0.9386 - val_loss: 0.4050 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3865 - acc: 0.9463 - precision: 0.9962 - recall: 0.8926 - f1_score: 0.9400 - val_loss: 0.4041 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3856 - acc: 0.9463 - precision: 0.9964 - recall: 0.8908 - f1_score: 0.9392 - val_loss: 0.4031 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3846 - acc: 0.9463 - precision: 0.9956 - recall: 0.8929 - f1_score: 0.9404 - val_loss: 0.4022 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3837 - acc: 0.9463 - precision: 0.9944 - recall: 0.8856 - f1_score: 0.9359 - val_loss: 0.4012 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3827 - acc: 0.9463 - precision: 0.9971 - recall: 0.8909 - f1_score: 0.9388 - val_loss: 0.4003 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3818 - acc: 0.9463 - precision: 0.9958 - recall: 0.8920 - f1_score: 0.9401 - val_loss: 0.3993 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3809 - acc: 0.9463 - precision: 0.9951 - recall: 0.8901 - f1_score: 0.9383 - val_loss: 0.3984 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3799 - acc: 0.9463 - precision: 0.9958 - recall: 0.8912 - f1_score: 0.9389 - val_loss: 0.3975 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3790 - acc: 0.9463 - precision: 0.9968 - recall: 0.8916 - f1_score: 0.9400 - val_loss: 0.3966 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3781 - acc: 0.9463 - precision: 0.9973 - recall: 0.8900 - f1_score: 0.9387 - val_loss: 0.3956 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3772 - acc: 0.9463 - precision: 0.9957 - recall: 0.8938 - f1_score: 0.9412 - val_loss: 0.3947 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3762 - acc: 0.9463 - precision: 0.9962 - recall: 0.8899 - f1_score: 0.9383 - val_loss: 0.3938 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3753 - acc: 0.9463 - precision: 0.9961 - recall: 0.8927 - f1_score: 0.9398 - val_loss: 0.3929 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3744 - acc: 0.9463 - precision: 0.9962 - recall: 0.8893 - f1_score: 0.9376 - val_loss: 0.3920 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3735 - acc: 0.9463 - precision: 0.9961 - recall: 0.8946 - f1_score: 0.9412 - val_loss: 0.3911 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3726 - acc: 0.9463 - precision: 0.9962 - recall: 0.8938 - f1_score: 0.9407 - val_loss: 0.3902 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3718 - acc: 0.9463 - precision: 0.9961 - recall: 0.8943 - f1_score: 0.9411 - val_loss: 0.3894 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3709 - acc: 0.9463 - precision: 0.9967 - recall: 0.8877 - f1_score: 0.9376 - val_loss: 0.3885 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3700 - acc: 0.9463 - precision: 0.9967 - recall: 0.8938 - f1_score: 0.9413 - val_loss: 0.3876 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3691 - acc: 0.9463 - precision: 0.9966 - recall: 0.8991 - f1_score: 0.9437 - val_loss: 0.3867 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3682 - acc: 0.9463 - precision: 0.9962 - recall: 0.8918 - f1_score: 0.9399 - val_loss: 0.3859 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3674 - acc: 0.9463 - precision: 0.9956 - recall: 0.8915 - f1_score: 0.9402 - val_loss: 0.3850 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3665 - acc: 0.9463 - precision: 0.9962 - recall: 0.8906 - f1_score: 0.9398 - val_loss: 0.3841 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3656 - acc: 0.9463 - precision: 0.9967 - recall: 0.8899 - f1_score: 0.9385 - val_loss: 0.3833 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3648 - acc: 0.9463 - precision: 0.9967 - recall: 0.8918 - f1_score: 0.9405 - val_loss: 0.3824 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3639 - acc: 0.9463 - precision: 0.9962 - recall: 0.8933 - f1_score: 0.9404 - val_loss: 0.3816 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3631 - acc: 0.9463 - precision: 0.9967 - recall: 0.8946 - f1_score: 0.9421 - val_loss: 0.3807 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3622 - acc: 0.9463 - precision: 0.9954 - recall: 0.8896 - f1_score: 0.9382 - val_loss: 0.3799 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3614 - acc: 0.9463 - precision: 0.9967 - recall: 0.8920 - f1_score: 0.9400 - val_loss: 0.3791 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3605 - acc: 0.9463 - precision: 0.9971 - recall: 0.8920 - f1_score: 0.9397 - val_loss: 0.3782 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3597 - acc: 0.9463 - precision: 0.9958 - recall: 0.8880 - f1_score: 0.9381 - val_loss: 0.3774 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3589 - acc: 0.9463 - precision: 0.9958 - recall: 0.8890 - f1_score: 0.9387 - val_loss: 0.3766 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3580 - acc: 0.9463 - precision: 0.9962 - recall: 0.8897 - f1_score: 0.9390 - val_loss: 0.3757 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3572 - acc: 0.9463 - precision: 0.9958 - recall: 0.8905 - f1_score: 0.9393 - val_loss: 0.3749 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3564 - acc: 0.9463 - precision: 0.9971 - recall: 0.8950 - f1_score: 0.9420 - val_loss: 0.3741 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3556 - acc: 0.9463 - precision: 0.9970 - recall: 0.8890 - f1_score: 0.9393 - val_loss: 0.3733 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3548 - acc: 0.9463 - precision: 0.9962 - recall: 0.8937 - f1_score: 0.9415 - val_loss: 0.3725 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 704/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3540 - acc: 0.9463 - precision: 0.9962 - recall: 0.8937 - f1_score: 0.9411 - val_loss: 0.3717 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3532 - acc: 0.9463 - precision: 0.9972 - recall: 0.8923 - f1_score: 0.9398 - val_loss: 0.3709 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3524 - acc: 0.9463 - precision: 0.9968 - recall: 0.8941 - f1_score: 0.9414 - val_loss: 0.3701 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3516 - acc: 0.9463 - precision: 0.9966 - recall: 0.8926 - f1_score: 0.9409 - val_loss: 0.3693 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3508 - acc: 0.9463 - precision: 0.9966 - recall: 0.8917 - f1_score: 0.9407 - val_loss: 0.3685 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3500 - acc: 0.9463 - precision: 0.9961 - recall: 0.8935 - f1_score: 0.9411 - val_loss: 0.3677 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3492 - acc: 0.9463 - precision: 0.9962 - recall: 0.8937 - f1_score: 0.9412 - val_loss: 0.3670 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3484 - acc: 0.9463 - precision: 0.9951 - recall: 0.8911 - f1_score: 0.9392 - val_loss: 0.3662 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3477 - acc: 0.9463 - precision: 0.9967 - recall: 0.8934 - f1_score: 0.9410 - val_loss: 0.3654 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3469 - acc: 0.9463 - precision: 0.9971 - recall: 0.8879 - f1_score: 0.9383 - val_loss: 0.3646 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3461 - acc: 0.9463 - precision: 0.9961 - recall: 0.8883 - f1_score: 0.9378 - val_loss: 0.3639 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3453 - acc: 0.9463 - precision: 0.9967 - recall: 0.8844 - f1_score: 0.9333 - val_loss: 0.3631 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3446 - acc: 0.9463 - precision: 0.9961 - recall: 0.8949 - f1_score: 0.9418 - val_loss: 0.3624 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3438 - acc: 0.9463 - precision: 0.9967 - recall: 0.8926 - f1_score: 0.9409 - val_loss: 0.3616 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3431 - acc: 0.9463 - precision: 0.9968 - recall: 0.8914 - f1_score: 0.9397 - val_loss: 0.3609 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3423 - acc: 0.9463 - precision: 0.9970 - recall: 0.8930 - f1_score: 0.9416 - val_loss: 0.3601 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3416 - acc: 0.9463 - precision: 0.9966 - recall: 0.8917 - f1_score: 0.9397 - val_loss: 0.3594 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3408 - acc: 0.9463 - precision: 0.9960 - recall: 0.8932 - f1_score: 0.9409 - val_loss: 0.3586 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3401 - acc: 0.9463 - precision: 0.9966 - recall: 0.8970 - f1_score: 0.9429 - val_loss: 0.3579 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3393 - acc: 0.9463 - precision: 0.9965 - recall: 0.8925 - f1_score: 0.9400 - val_loss: 0.3572 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3386 - acc: 0.9463 - precision: 0.9970 - recall: 0.8921 - f1_score: 0.9410 - val_loss: 0.3564 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3379 - acc: 0.9463 - precision: 0.9961 - recall: 0.8931 - f1_score: 0.9410 - val_loss: 0.3557 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3371 - acc: 0.9463 - precision: 0.9956 - recall: 0.8900 - f1_score: 0.9381 - val_loss: 0.3550 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3364 - acc: 0.9463 - precision: 0.9966 - recall: 0.8953 - f1_score: 0.9419 - val_loss: 0.3543 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3357 - acc: 0.9463 - precision: 0.9963 - recall: 0.8908 - f1_score: 0.9391 - val_loss: 0.3536 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3350 - acc: 0.9463 - precision: 0.9964 - recall: 0.8905 - f1_score: 0.9395 - val_loss: 0.3528 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3343 - acc: 0.9463 - precision: 0.9951 - recall: 0.8926 - f1_score: 0.9403 - val_loss: 0.3521 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3336 - acc: 0.9463 - precision: 0.9962 - recall: 0.8939 - f1_score: 0.9408 - val_loss: 0.3514 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3328 - acc: 0.9463 - precision: 0.9964 - recall: 0.8951 - f1_score: 0.9422 - val_loss: 0.3507 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3321 - acc: 0.9463 - precision: 0.9958 - recall: 0.8940 - f1_score: 0.9411 - val_loss: 0.3500 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9463 - precision: 0.9971 - recall: 0.8899 - f1_score: 0.9392 - val_loss: 0.3493 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3307 - acc: 0.9463 - precision: 0.9964 - recall: 0.8934 - f1_score: 0.9392 - val_loss: 0.3487 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 736/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3301 - acc: 0.9463 - precision: 0.9966 - recall: 0.8963 - f1_score: 0.9429 - val_loss: 0.3480 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3294 - acc: 0.9463 - precision: 0.9970 - recall: 0.8896 - f1_score: 0.9391 - val_loss: 0.3473 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3287 - acc: 0.9463 - precision: 0.9968 - recall: 0.8916 - f1_score: 0.9405 - val_loss: 0.3466 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3280 - acc: 0.9463 - precision: 0.9964 - recall: 0.8890 - f1_score: 0.9390 - val_loss: 0.3459 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3273 - acc: 0.9463 - precision: 0.9947 - recall: 0.8833 - f1_score: 0.9339 - val_loss: 0.3453 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3266 - acc: 0.9463 - precision: 0.9967 - recall: 0.8925 - f1_score: 0.9405 - val_loss: 0.3446 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3259 - acc: 0.9463 - precision: 0.9968 - recall: 0.8939 - f1_score: 0.9411 - val_loss: 0.3439 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3253 - acc: 0.9463 - precision: 0.9958 - recall: 0.8904 - f1_score: 0.9396 - val_loss: 0.3432 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3246 - acc: 0.9463 - precision: 0.9970 - recall: 0.8942 - f1_score: 0.9418 - val_loss: 0.3426 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3239 - acc: 0.9463 - precision: 0.9961 - recall: 0.8881 - f1_score: 0.9378 - val_loss: 0.3419 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3233 - acc: 0.9463 - precision: 0.9968 - recall: 0.8972 - f1_score: 0.9430 - val_loss: 0.3413 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3226 - acc: 0.9463 - precision: 0.9956 - recall: 0.8917 - f1_score: 0.9397 - val_loss: 0.3406 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3220 - acc: 0.9463 - precision: 0.9964 - recall: 0.8942 - f1_score: 0.9411 - val_loss: 0.3400 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3213 - acc: 0.9463 - precision: 0.9951 - recall: 0.8934 - f1_score: 0.9405 - val_loss: 0.3393 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3207 - acc: 0.9463 - precision: 0.9962 - recall: 0.8903 - f1_score: 0.9396 - val_loss: 0.3387 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3200 - acc: 0.9463 - precision: 0.9971 - recall: 0.8935 - f1_score: 0.9406 - val_loss: 0.3380 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3194 - acc: 0.9463 - precision: 0.9966 - recall: 0.8901 - f1_score: 0.9388 - val_loss: 0.3374 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3187 - acc: 0.9463 - precision: 0.9968 - recall: 0.8874 - f1_score: 0.9374 - val_loss: 0.3368 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3181 - acc: 0.9463 - precision: 0.9967 - recall: 0.8894 - f1_score: 0.9388 - val_loss: 0.3361 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3174 - acc: 0.9463 - precision: 0.9956 - recall: 0.8860 - f1_score: 0.9365 - val_loss: 0.3355 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3168 - acc: 0.9463 - precision: 0.9966 - recall: 0.8920 - f1_score: 0.9407 - val_loss: 0.3349 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3162 - acc: 0.9463 - precision: 0.9974 - recall: 0.8911 - f1_score: 0.9401 - val_loss: 0.3343 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3156 - acc: 0.9463 - precision: 0.9951 - recall: 0.8913 - f1_score: 0.9388 - val_loss: 0.3336 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3149 - acc: 0.9463 - precision: 0.9951 - recall: 0.8893 - f1_score: 0.9390 - val_loss: 0.3330 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3143 - acc: 0.9463 - precision: 0.9962 - recall: 0.8900 - f1_score: 0.9390 - val_loss: 0.3324 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3137 - acc: 0.9463 - precision: 0.9954 - recall: 0.8890 - f1_score: 0.9383 - val_loss: 0.3318 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3131 - acc: 0.9463 - precision: 0.9966 - recall: 0.8925 - f1_score: 0.9409 - val_loss: 0.3312 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3125 - acc: 0.9463 - precision: 0.9947 - recall: 0.8884 - f1_score: 0.9370 - val_loss: 0.3306 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3119 - acc: 0.9463 - precision: 0.9966 - recall: 0.8918 - f1_score: 0.9395 - val_loss: 0.3300 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3112 - acc: 0.9463 - precision: 0.9961 - recall: 0.8892 - f1_score: 0.9382 - val_loss: 0.3294 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3106 - acc: 0.9463 - precision: 0.9958 - recall: 0.8921 - f1_score: 0.9400 - val_loss: 0.3288 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3100 - acc: 0.9463 - precision: 0.9962 - recall: 0.8910 - f1_score: 0.9397 - val_loss: 0.3282 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3094 - acc: 0.9463 - precision: 0.9966 - recall: 0.8932 - f1_score: 0.9412 - val_loss: 0.3276 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3088 - acc: 0.9463 - precision: 0.9958 - recall: 0.8904 - f1_score: 0.9390 - val_loss: 0.3270 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3082 - acc: 0.9463 - precision: 0.9966 - recall: 0.8915 - f1_score: 0.9394 - val_loss: 0.3264 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3077 - acc: 0.9463 - precision: 0.9964 - recall: 0.8922 - f1_score: 0.9403 - val_loss: 0.3258 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3071 - acc: 0.9463 - precision: 0.9964 - recall: 0.8877 - f1_score: 0.9378 - val_loss: 0.3252 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3065 - acc: 0.9463 - precision: 0.9968 - recall: 0.8913 - f1_score: 0.9406 - val_loss: 0.3247 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3059 - acc: 0.9463 - precision: 0.9968 - recall: 0.8974 - f1_score: 0.9435 - val_loss: 0.3241 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3053 - acc: 0.9463 - precision: 0.9964 - recall: 0.8896 - f1_score: 0.9386 - val_loss: 0.3235 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3047 - acc: 0.9463 - precision: 0.9970 - recall: 0.8929 - f1_score: 0.9401 - val_loss: 0.3229 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3042 - acc: 0.9463 - precision: 0.9967 - recall: 0.8920 - f1_score: 0.9399 - val_loss: 0.3224 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3036 - acc: 0.9463 - precision: 0.9964 - recall: 0.8906 - f1_score: 0.9401 - val_loss: 0.3218 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3030 - acc: 0.9463 - precision: 0.9964 - recall: 0.8925 - f1_score: 0.9405 - val_loss: 0.3212 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3025 - acc: 0.9463 - precision: 0.9964 - recall: 0.8912 - f1_score: 0.9404 - val_loss: 0.3207 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3019 - acc: 0.9463 - precision: 0.9967 - recall: 0.8903 - f1_score: 0.9388 - val_loss: 0.3201 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3013 - acc: 0.9463 - precision: 0.9970 - recall: 0.8902 - f1_score: 0.9401 - val_loss: 0.3196 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3008 - acc: 0.9463 - precision: 0.9961 - recall: 0.8911 - f1_score: 0.9386 - val_loss: 0.3190 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3002 - acc: 0.9463 - precision: 0.9961 - recall: 0.8884 - f1_score: 0.9385 - val_loss: 0.3185 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2997 - acc: 0.9463 - precision: 0.9967 - recall: 0.8895 - f1_score: 0.9392 - val_loss: 0.3179 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2991 - acc: 0.9463 - precision: 0.9958 - recall: 0.8913 - f1_score: 0.9396 - val_loss: 0.3174 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2986 - acc: 0.9463 - precision: 0.9967 - recall: 0.8936 - f1_score: 0.9413 - val_loss: 0.3168 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2980 - acc: 0.9463 - precision: 0.9956 - recall: 0.8929 - f1_score: 0.9396 - val_loss: 0.3163 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2975 - acc: 0.9463 - precision: 0.9971 - recall: 0.8933 - f1_score: 0.9408 - val_loss: 0.3158 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2969 - acc: 0.9463 - precision: 0.9961 - recall: 0.8950 - f1_score: 0.9413 - val_loss: 0.3152 - val_acc: 0.9114 - val_precision: 0.9878 - val_recall: 0.8454 - val_f1_score: 0.9098\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2964 - acc: 0.9463 - precision: 0.9962 - recall: 0.8952 - f1_score: 0.9414 - val_loss: 0.3147 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2958 - acc: 0.9463 - precision: 0.9964 - recall: 0.8918 - f1_score: 0.9400 - val_loss: 0.3142 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2953 - acc: 0.9463 - precision: 0.9962 - recall: 0.8925 - f1_score: 0.9404 - val_loss: 0.3136 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2948 - acc: 0.9463 - precision: 0.9968 - recall: 0.8959 - f1_score: 0.9418 - val_loss: 0.3131 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2942 - acc: 0.9463 - precision: 0.9964 - recall: 0.8856 - f1_score: 0.9360 - val_loss: 0.3126 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2937 - acc: 0.9463 - precision: 0.9966 - recall: 0.8908 - f1_score: 0.9402 - val_loss: 0.3121 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2932 - acc: 0.9463 - precision: 0.9966 - recall: 0.8944 - f1_score: 0.9423 - val_loss: 0.3116 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2927 - acc: 0.9463 - precision: 0.9970 - recall: 0.8901 - f1_score: 0.9387 - val_loss: 0.3110 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2921 - acc: 0.9463 - precision: 0.9962 - recall: 0.8929 - f1_score: 0.9402 - val_loss: 0.3105 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2916 - acc: 0.9463 - precision: 0.9966 - recall: 0.8942 - f1_score: 0.9421 - val_loss: 0.3100 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2911 - acc: 0.9463 - precision: 0.9962 - recall: 0.8945 - f1_score: 0.9416 - val_loss: 0.3095 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2906 - acc: 0.9463 - precision: 0.9971 - recall: 0.8889 - f1_score: 0.9385 - val_loss: 0.3090 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2901 - acc: 0.9463 - precision: 0.9968 - recall: 0.8930 - f1_score: 0.9413 - val_loss: 0.3085 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2896 - acc: 0.9463 - precision: 0.9971 - recall: 0.8923 - f1_score: 0.9409 - val_loss: 0.3080 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2891 - acc: 0.9463 - precision: 0.9971 - recall: 0.8955 - f1_score: 0.9428 - val_loss: 0.3075 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2886 - acc: 0.9463 - precision: 0.9964 - recall: 0.8903 - f1_score: 0.9389 - val_loss: 0.3070 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2881 - acc: 0.9463 - precision: 0.9960 - recall: 0.8948 - f1_score: 0.9413 - val_loss: 0.3065 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2876 - acc: 0.9463 - precision: 0.9966 - recall: 0.8915 - f1_score: 0.9400 - val_loss: 0.3060 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2871 - acc: 0.9463 - precision: 0.9956 - recall: 0.8885 - f1_score: 0.9377 - val_loss: 0.3055 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2866 - acc: 0.9447 - precision: 0.9923 - recall: 0.8931 - f1_score: 0.9394 - val_loss: 0.3050 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2861 - acc: 0.9463 - precision: 0.9964 - recall: 0.8902 - f1_score: 0.9391 - val_loss: 0.3046 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2856 - acc: 0.9463 - precision: 0.9961 - recall: 0.8919 - f1_score: 0.9396 - val_loss: 0.3041 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2851 - acc: 0.9463 - precision: 0.9954 - recall: 0.8948 - f1_score: 0.9415 - val_loss: 0.3036 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2846 - acc: 0.9463 - precision: 0.9968 - recall: 0.8931 - f1_score: 0.9408 - val_loss: 0.3031 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2841 - acc: 0.9447 - precision: 0.9895 - recall: 0.8912 - f1_score: 0.9372 - val_loss: 0.3027 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2836 - acc: 0.9463 - precision: 0.9956 - recall: 0.8901 - f1_score: 0.9387 - val_loss: 0.3022 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2832 - acc: 0.9463 - precision: 0.9967 - recall: 0.8914 - f1_score: 0.9398 - val_loss: 0.3017 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2827 - acc: 0.9463 - precision: 0.9968 - recall: 0.8909 - f1_score: 0.9400 - val_loss: 0.3012 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2822 - acc: 0.9463 - precision: 0.9967 - recall: 0.8936 - f1_score: 0.9414 - val_loss: 0.3008 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2817 - acc: 0.9463 - precision: 0.9966 - recall: 0.8908 - f1_score: 0.9398 - val_loss: 0.3003 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2813 - acc: 0.9463 - precision: 0.9968 - recall: 0.8963 - f1_score: 0.9431 - val_loss: 0.2998 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2808 - acc: 0.9463 - precision: 0.9944 - recall: 0.8924 - f1_score: 0.9394 - val_loss: 0.2994 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2803 - acc: 0.9463 - precision: 0.9956 - recall: 0.8893 - f1_score: 0.9378 - val_loss: 0.2989 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2799 - acc: 0.9463 - precision: 0.9958 - recall: 0.8865 - f1_score: 0.9363 - val_loss: 0.2985 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2794 - acc: 0.9463 - precision: 0.9954 - recall: 0.8881 - f1_score: 0.9370 - val_loss: 0.2980 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2789 - acc: 0.9463 - precision: 0.9961 - recall: 0.8949 - f1_score: 0.9413 - val_loss: 0.2975 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9463 - precision: 0.9951 - recall: 0.8899 - f1_score: 0.9387 - val_loss: 0.2971 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2780 - acc: 0.9463 - precision: 0.9966 - recall: 0.8932 - f1_score: 0.9411 - val_loss: 0.2966 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2776 - acc: 0.9463 - precision: 0.9966 - recall: 0.8896 - f1_score: 0.9383 - val_loss: 0.2962 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2771 - acc: 0.9463 - precision: 0.9944 - recall: 0.8844 - f1_score: 0.9340 - val_loss: 0.2957 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2767 - acc: 0.9463 - precision: 0.9958 - recall: 0.8920 - f1_score: 0.9400 - val_loss: 0.2953 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2762 - acc: 0.9463 - precision: 0.9962 - recall: 0.8935 - f1_score: 0.9415 - val_loss: 0.2949 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2758 - acc: 0.9447 - precision: 0.9927 - recall: 0.8931 - f1_score: 0.9391 - val_loss: 0.2944 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2753 - acc: 0.9447 - precision: 0.9925 - recall: 0.8924 - f1_score: 0.9393 - val_loss: 0.2940 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2749 - acc: 0.9463 - precision: 0.9973 - recall: 0.8909 - f1_score: 0.9399 - val_loss: 0.2935 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9463 - precision: 0.9954 - recall: 0.8902 - f1_score: 0.9392 - val_loss: 0.2931 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9463 - precision: 0.9964 - recall: 0.8944 - f1_score: 0.9406 - val_loss: 0.2927 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2736 - acc: 0.9447 - precision: 0.9927 - recall: 0.8937 - f1_score: 0.9372 - val_loss: 0.2922 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2731 - acc: 0.9447 - precision: 0.9927 - recall: 0.8900 - f1_score: 0.9375 - val_loss: 0.2918 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2727 - acc: 0.9447 - precision: 0.9928 - recall: 0.8910 - f1_score: 0.9363 - val_loss: 0.2914 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2723 - acc: 0.9447 - precision: 0.9946 - recall: 0.8923 - f1_score: 0.9387 - val_loss: 0.2909 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2718 - acc: 0.9463 - precision: 0.9974 - recall: 0.8901 - f1_score: 0.9375 - val_loss: 0.2905 - val_acc: 0.9177 - val_precision: 0.9878 - val_recall: 0.8623 - val_f1_score: 0.9199\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2714 - acc: 0.9463 - precision: 0.9967 - recall: 0.8961 - f1_score: 0.9430 - val_loss: 0.2901 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2710 - acc: 0.9447 - precision: 0.9924 - recall: 0.8922 - f1_score: 0.9389 - val_loss: 0.2897 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2706 - acc: 0.9463 - precision: 0.9962 - recall: 0.8943 - f1_score: 0.9401 - val_loss: 0.2893 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2701 - acc: 0.9463 - precision: 0.9968 - recall: 0.8977 - f1_score: 0.9430 - val_loss: 0.2888 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9463 - precision: 0.9965 - recall: 0.8921 - f1_score: 0.9408 - val_loss: 0.2884 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9463 - precision: 0.9962 - recall: 0.8886 - f1_score: 0.9387 - val_loss: 0.2880 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2689 - acc: 0.9463 - precision: 0.9961 - recall: 0.8897 - f1_score: 0.9386 - val_loss: 0.2876 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2685 - acc: 0.9447 - precision: 0.9933 - recall: 0.8914 - f1_score: 0.9376 - val_loss: 0.2872 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2681 - acc: 0.9463 - precision: 0.9966 - recall: 0.8902 - f1_score: 0.9390 - val_loss: 0.2868 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2676 - acc: 0.9447 - precision: 0.9917 - recall: 0.8870 - f1_score: 0.9357 - val_loss: 0.2864 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2672 - acc: 0.9463 - precision: 0.9954 - recall: 0.8862 - f1_score: 0.9367 - val_loss: 0.2860 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2668 - acc: 0.9463 - precision: 0.9966 - recall: 0.8903 - f1_score: 0.9394 - val_loss: 0.2856 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2664 - acc: 0.9463 - precision: 0.9967 - recall: 0.8945 - f1_score: 0.9420 - val_loss: 0.2852 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2660 - acc: 0.9463 - precision: 0.9964 - recall: 0.8924 - f1_score: 0.9391 - val_loss: 0.2848 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2656 - acc: 0.9463 - precision: 0.9947 - recall: 0.8918 - f1_score: 0.9393 - val_loss: 0.2844 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9447 - precision: 0.9931 - recall: 0.8915 - f1_score: 0.9388 - val_loss: 0.2840 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9463 - precision: 0.9954 - recall: 0.8959 - f1_score: 0.9414 - val_loss: 0.2836 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2644 - acc: 0.9447 - precision: 0.9910 - recall: 0.8922 - f1_score: 0.9384 - val_loss: 0.2832 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2640 - acc: 0.9447 - precision: 0.9944 - recall: 0.8912 - f1_score: 0.9395 - val_loss: 0.2829 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2636 - acc: 0.9447 - precision: 0.9913 - recall: 0.8892 - f1_score: 0.9363 - val_loss: 0.2825 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2633 - acc: 0.9447 - precision: 0.9906 - recall: 0.8885 - f1_score: 0.9355 - val_loss: 0.2821 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 864/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2629 - acc: 0.9447 - precision: 0.9917 - recall: 0.8936 - f1_score: 0.9382 - val_loss: 0.2817 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2625 - acc: 0.9447 - precision: 0.9921 - recall: 0.8903 - f1_score: 0.9369 - val_loss: 0.2813 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2621 - acc: 0.9447 - precision: 0.9930 - recall: 0.8934 - f1_score: 0.9397 - val_loss: 0.2809 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2617 - acc: 0.9447 - precision: 0.9922 - recall: 0.8912 - f1_score: 0.9380 - val_loss: 0.2806 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2613 - acc: 0.9447 - precision: 0.9938 - recall: 0.8907 - f1_score: 0.9380 - val_loss: 0.2802 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2609 - acc: 0.9447 - precision: 0.9940 - recall: 0.8971 - f1_score: 0.9416 - val_loss: 0.2798 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2606 - acc: 0.9447 - precision: 0.9933 - recall: 0.8950 - f1_score: 0.9403 - val_loss: 0.2795 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9447 - precision: 0.9933 - recall: 0.8896 - f1_score: 0.9380 - val_loss: 0.2791 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9447 - precision: 0.9918 - recall: 0.8913 - f1_score: 0.9370 - val_loss: 0.2787 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2594 - acc: 0.9447 - precision: 0.9928 - recall: 0.8970 - f1_score: 0.9405 - val_loss: 0.2784 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2591 - acc: 0.9447 - precision: 0.9922 - recall: 0.8903 - f1_score: 0.9369 - val_loss: 0.2780 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2587 - acc: 0.9447 - precision: 0.9937 - recall: 0.8929 - f1_score: 0.9390 - val_loss: 0.2776 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2583 - acc: 0.9447 - precision: 0.9937 - recall: 0.8894 - f1_score: 0.9382 - val_loss: 0.2773 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2580 - acc: 0.9447 - precision: 0.9944 - recall: 0.8954 - f1_score: 0.9414 - val_loss: 0.2769 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2576 - acc: 0.9447 - precision: 0.9938 - recall: 0.8913 - f1_score: 0.9392 - val_loss: 0.2765 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9447 - precision: 0.9923 - recall: 0.8939 - f1_score: 0.9395 - val_loss: 0.2762 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2569 - acc: 0.9447 - precision: 0.9921 - recall: 0.8953 - f1_score: 0.9400 - val_loss: 0.2758 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9447 - precision: 0.9926 - recall: 0.8952 - f1_score: 0.9400 - val_loss: 0.2755 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2561 - acc: 0.9447 - precision: 0.9917 - recall: 0.8905 - f1_score: 0.9378 - val_loss: 0.2751 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2558 - acc: 0.9447 - precision: 0.9917 - recall: 0.8921 - f1_score: 0.9388 - val_loss: 0.2748 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2554 - acc: 0.9447 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9396 - val_loss: 0.2744 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2551 - acc: 0.9447 - precision: 0.9923 - recall: 0.8908 - f1_score: 0.9378 - val_loss: 0.2741 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2547 - acc: 0.9447 - precision: 0.9937 - recall: 0.8889 - f1_score: 0.9376 - val_loss: 0.2738 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2544 - acc: 0.9447 - precision: 0.9938 - recall: 0.8889 - f1_score: 0.9365 - val_loss: 0.2734 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2540 - acc: 0.9447 - precision: 0.9928 - recall: 0.8941 - f1_score: 0.9398 - val_loss: 0.2731 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2537 - acc: 0.9447 - precision: 0.9935 - recall: 0.8957 - f1_score: 0.9416 - val_loss: 0.2727 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2533 - acc: 0.9447 - precision: 0.9936 - recall: 0.8913 - f1_score: 0.9380 - val_loss: 0.2724 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2530 - acc: 0.9447 - precision: 0.9933 - recall: 0.8906 - f1_score: 0.9379 - val_loss: 0.2721 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9447 - precision: 0.9939 - recall: 0.8888 - f1_score: 0.9366 - val_loss: 0.2717 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2523 - acc: 0.9447 - precision: 0.9928 - recall: 0.8897 - f1_score: 0.9373 - val_loss: 0.2714 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2519 - acc: 0.9447 - precision: 0.9915 - recall: 0.8899 - f1_score: 0.9375 - val_loss: 0.2710 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2516 - acc: 0.9447 - precision: 0.9937 - recall: 0.8907 - f1_score: 0.9383 - val_loss: 0.2707 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2513 - acc: 0.9447 - precision: 0.9926 - recall: 0.8937 - f1_score: 0.9398 - val_loss: 0.2704 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2509 - acc: 0.9447 - precision: 0.9947 - recall: 0.8879 - f1_score: 0.9358 - val_loss: 0.2701 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2506 - acc: 0.9447 - precision: 0.9916 - recall: 0.8946 - f1_score: 0.9395 - val_loss: 0.2697 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9447 - precision: 0.9933 - recall: 0.8931 - f1_score: 0.9396 - val_loss: 0.2694 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2499 - acc: 0.9447 - precision: 0.9926 - recall: 0.8934 - f1_score: 0.9400 - val_loss: 0.2691 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9447 - precision: 0.9933 - recall: 0.8893 - f1_score: 0.9373 - val_loss: 0.2688 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9447 - precision: 0.9918 - recall: 0.8872 - f1_score: 0.9353 - val_loss: 0.2684 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9447 - precision: 0.9935 - recall: 0.8903 - f1_score: 0.9376 - val_loss: 0.2681 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2486 - acc: 0.9447 - precision: 0.9921 - recall: 0.8958 - f1_score: 0.9408 - val_loss: 0.2678 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2483 - acc: 0.9447 - precision: 0.9931 - recall: 0.8921 - f1_score: 0.9385 - val_loss: 0.2675 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2480 - acc: 0.9447 - precision: 0.9936 - recall: 0.8932 - f1_score: 0.9394 - val_loss: 0.2671 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2476 - acc: 0.9447 - precision: 0.9919 - recall: 0.8917 - f1_score: 0.9380 - val_loss: 0.2668 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2473 - acc: 0.9447 - precision: 0.9924 - recall: 0.8892 - f1_score: 0.9373 - val_loss: 0.2665 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9447 - precision: 0.9928 - recall: 0.8903 - f1_score: 0.9380 - val_loss: 0.2662 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9447 - precision: 0.9932 - recall: 0.8904 - f1_score: 0.9380 - val_loss: 0.2659 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9447 - precision: 0.9930 - recall: 0.8941 - f1_score: 0.9398 - val_loss: 0.2656 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2461 - acc: 0.9447 - precision: 0.9946 - recall: 0.8887 - f1_score: 0.9375 - val_loss: 0.2653 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2457 - acc: 0.9447 - precision: 0.9929 - recall: 0.8969 - f1_score: 0.9417 - val_loss: 0.2650 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2454 - acc: 0.9447 - precision: 0.9923 - recall: 0.8931 - f1_score: 0.9395 - val_loss: 0.2647 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2451 - acc: 0.9447 - precision: 0.9938 - recall: 0.8951 - f1_score: 0.9402 - val_loss: 0.2644 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9447 - precision: 0.9913 - recall: 0.8930 - f1_score: 0.9392 - val_loss: 0.2641 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2445 - acc: 0.9447 - precision: 0.9924 - recall: 0.8895 - f1_score: 0.9348 - val_loss: 0.2638 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2442 - acc: 0.9447 - precision: 0.9931 - recall: 0.8895 - f1_score: 0.9378 - val_loss: 0.2635 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2439 - acc: 0.9447 - precision: 0.9927 - recall: 0.8934 - f1_score: 0.9395 - val_loss: 0.2632 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2436 - acc: 0.9447 - precision: 0.9919 - recall: 0.8932 - f1_score: 0.9394 - val_loss: 0.2629 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2433 - acc: 0.9447 - precision: 0.9938 - recall: 0.8918 - f1_score: 0.9385 - val_loss: 0.2626 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2430 - acc: 0.9447 - precision: 0.9935 - recall: 0.8902 - f1_score: 0.9382 - val_loss: 0.2623 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2427 - acc: 0.9447 - precision: 0.9924 - recall: 0.8931 - f1_score: 0.9390 - val_loss: 0.2620 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2424 - acc: 0.9447 - precision: 0.9928 - recall: 0.8933 - f1_score: 0.9394 - val_loss: 0.2617 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2421 - acc: 0.9447 - precision: 0.9919 - recall: 0.8894 - f1_score: 0.9368 - val_loss: 0.2614 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2418 - acc: 0.9447 - precision: 0.9926 - recall: 0.8917 - f1_score: 0.9387 - val_loss: 0.2611 - val_acc: 0.9241 - val_precision: 0.9883 - val_recall: 0.8736 - val_f1_score: 0.9261\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2415 - acc: 0.9447 - precision: 0.9924 - recall: 0.8931 - f1_score: 0.9383 - val_loss: 0.2609 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 928/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2412 - acc: 0.9447 - precision: 0.9928 - recall: 0.8937 - f1_score: 0.9403 - val_loss: 0.2606 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9447 - precision: 0.9933 - recall: 0.8934 - f1_score: 0.9396 - val_loss: 0.2603 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9447 - precision: 0.9933 - recall: 0.9013 - f1_score: 0.9433 - val_loss: 0.2600 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2403 - acc: 0.9447 - precision: 0.9934 - recall: 0.8950 - f1_score: 0.9400 - val_loss: 0.2597 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2400 - acc: 0.9447 - precision: 0.9935 - recall: 0.8955 - f1_score: 0.9403 - val_loss: 0.2594 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2397 - acc: 0.9447 - precision: 0.9935 - recall: 0.8913 - f1_score: 0.9384 - val_loss: 0.2591 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2395 - acc: 0.9447 - precision: 0.9923 - recall: 0.8938 - f1_score: 0.9391 - val_loss: 0.2589 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9447 - precision: 0.9895 - recall: 0.8847 - f1_score: 0.9331 - val_loss: 0.2586 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9447 - precision: 0.9919 - recall: 0.8916 - f1_score: 0.9384 - val_loss: 0.2583 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9447 - precision: 0.9940 - recall: 0.8897 - f1_score: 0.9365 - val_loss: 0.2580 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2383 - acc: 0.9447 - precision: 0.9939 - recall: 0.8936 - f1_score: 0.9396 - val_loss: 0.2578 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2381 - acc: 0.9447 - precision: 0.9925 - recall: 0.8863 - f1_score: 0.9353 - val_loss: 0.2575 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2378 - acc: 0.9447 - precision: 0.9921 - recall: 0.8905 - f1_score: 0.9377 - val_loss: 0.2572 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2375 - acc: 0.9447 - precision: 0.9918 - recall: 0.8899 - f1_score: 0.9375 - val_loss: 0.2569 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9447 - precision: 0.9933 - recall: 0.8930 - f1_score: 0.9388 - val_loss: 0.2567 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9447 - precision: 0.9919 - recall: 0.8936 - f1_score: 0.9394 - val_loss: 0.2564 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2367 - acc: 0.9447 - precision: 0.9925 - recall: 0.8910 - f1_score: 0.9380 - val_loss: 0.2561 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2364 - acc: 0.9447 - precision: 0.9923 - recall: 0.9001 - f1_score: 0.9426 - val_loss: 0.2559 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9447 - precision: 0.9914 - recall: 0.8860 - f1_score: 0.9333 - val_loss: 0.2556 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2359 - acc: 0.9447 - precision: 0.9913 - recall: 0.8917 - f1_score: 0.9378 - val_loss: 0.2554 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2356 - acc: 0.9447 - precision: 0.9935 - recall: 0.8943 - f1_score: 0.9401 - val_loss: 0.2551 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9447 - precision: 0.9926 - recall: 0.8919 - f1_score: 0.9382 - val_loss: 0.2548 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9447 - precision: 0.9941 - recall: 0.8881 - f1_score: 0.9375 - val_loss: 0.2546 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2348 - acc: 0.9447 - precision: 0.9925 - recall: 0.8933 - f1_score: 0.9396 - val_loss: 0.2543 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2345 - acc: 0.9447 - precision: 0.9934 - recall: 0.8913 - f1_score: 0.9378 - val_loss: 0.2541 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2342 - acc: 0.9447 - precision: 0.9931 - recall: 0.8941 - f1_score: 0.9401 - val_loss: 0.2538 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2340 - acc: 0.9447 - precision: 0.9926 - recall: 0.8929 - f1_score: 0.9392 - val_loss: 0.2536 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9447 - precision: 0.9925 - recall: 0.8924 - f1_score: 0.9389 - val_loss: 0.2533 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2335 - acc: 0.9447 - precision: 0.9931 - recall: 0.8891 - f1_score: 0.9373 - val_loss: 0.2531 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9447 - precision: 0.9926 - recall: 0.8912 - f1_score: 0.9377 - val_loss: 0.2528 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2330 - acc: 0.9447 - precision: 0.9937 - recall: 0.8925 - f1_score: 0.9400 - val_loss: 0.2526 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9447 - precision: 0.9934 - recall: 0.8892 - f1_score: 0.9375 - val_loss: 0.2523 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 960/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2324 - acc: 0.9447 - precision: 0.9937 - recall: 0.8923 - f1_score: 0.9398 - val_loss: 0.2521 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9447 - precision: 0.9929 - recall: 0.8933 - f1_score: 0.9393 - val_loss: 0.2518 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9447 - precision: 0.9941 - recall: 0.8895 - f1_score: 0.9364 - val_loss: 0.2516 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2317 - acc: 0.9447 - precision: 0.9917 - recall: 0.8910 - f1_score: 0.9374 - val_loss: 0.2513 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2314 - acc: 0.9447 - precision: 0.9933 - recall: 0.8941 - f1_score: 0.9393 - val_loss: 0.2511 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2312 - acc: 0.9447 - precision: 0.9925 - recall: 0.8922 - f1_score: 0.9387 - val_loss: 0.2509 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2309 - acc: 0.9447 - precision: 0.9935 - recall: 0.8893 - f1_score: 0.9381 - val_loss: 0.2506 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9447 - precision: 0.9924 - recall: 0.8921 - f1_score: 0.9387 - val_loss: 0.2504 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2304 - acc: 0.9447 - precision: 0.9901 - recall: 0.8907 - f1_score: 0.9373 - val_loss: 0.2501 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2302 - acc: 0.9447 - precision: 0.9911 - recall: 0.8895 - f1_score: 0.9363 - val_loss: 0.2499 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2299 - acc: 0.9447 - precision: 0.9917 - recall: 0.8890 - f1_score: 0.9368 - val_loss: 0.2497 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2048 - acc: 0.9400 - precision: 1.0000 - recall: 0.8889 - f1_score: 0.941 - 0s - loss: 0.2297 - acc: 0.9447 - precision: 0.9915 - recall: 0.8897 - f1_score: 0.9372 - val_loss: 0.2494 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2295 - acc: 0.9447 - precision: 0.9937 - recall: 0.8958 - f1_score: 0.9407 - val_loss: 0.2492 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2292 - acc: 0.9447 - precision: 0.9934 - recall: 0.8919 - f1_score: 0.9390 - val_loss: 0.2490 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2290 - acc: 0.9447 - precision: 0.9926 - recall: 0.8953 - f1_score: 0.9405 - val_loss: 0.2488 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2287 - acc: 0.9447 - precision: 0.9925 - recall: 0.8868 - f1_score: 0.9348 - val_loss: 0.2485 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2285 - acc: 0.9447 - precision: 0.9941 - recall: 0.8907 - f1_score: 0.9374 - val_loss: 0.2483 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2283 - acc: 0.9447 - precision: 0.9925 - recall: 0.8947 - f1_score: 0.9397 - val_loss: 0.2481 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2280 - acc: 0.9447 - precision: 0.9927 - recall: 0.8943 - f1_score: 0.9399 - val_loss: 0.2478 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2278 - acc: 0.9447 - precision: 0.9935 - recall: 0.8894 - f1_score: 0.9374 - val_loss: 0.2476 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2276 - acc: 0.9447 - precision: 0.9941 - recall: 0.8935 - f1_score: 0.9400 - val_loss: 0.2474 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2273 - acc: 0.9447 - precision: 0.9939 - recall: 0.8931 - f1_score: 0.9397 - val_loss: 0.2472 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2271 - acc: 0.9447 - precision: 0.9924 - recall: 0.8927 - f1_score: 0.9388 - val_loss: 0.2469 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2269 - acc: 0.9447 - precision: 0.9933 - recall: 0.8933 - f1_score: 0.9402 - val_loss: 0.2467 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2266 - acc: 0.9447 - precision: 0.9911 - recall: 0.8895 - f1_score: 0.9362 - val_loss: 0.2465 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2264 - acc: 0.9447 - precision: 0.9934 - recall: 0.8906 - f1_score: 0.9383 - val_loss: 0.2463 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2262 - acc: 0.9447 - precision: 0.9931 - recall: 0.8917 - f1_score: 0.9391 - val_loss: 0.2461 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2260 - acc: 0.9447 - precision: 0.9939 - recall: 0.8922 - f1_score: 0.9391 - val_loss: 0.2459 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2257 - acc: 0.9447 - precision: 0.9920 - recall: 0.8942 - f1_score: 0.9387 - val_loss: 0.2456 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2255 - acc: 0.9447 - precision: 0.9933 - recall: 0.8906 - f1_score: 0.9381 - val_loss: 0.2454 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2253 - acc: 0.9447 - precision: 0.9938 - recall: 0.8916 - f1_score: 0.9382 - val_loss: 0.2452 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2251 - acc: 0.9447 - precision: 0.9932 - recall: 0.8918 - f1_score: 0.9374 - val_loss: 0.2450 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2248 - acc: 0.9447 - precision: 0.9926 - recall: 0.8976 - f1_score: 0.9398 - val_loss: 0.2448 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2246 - acc: 0.9447 - precision: 0.9920 - recall: 0.8916 - f1_score: 0.9382 - val_loss: 0.2446 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2244 - acc: 0.9447 - precision: 0.9931 - recall: 0.8945 - f1_score: 0.9399 - val_loss: 0.2443 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2242 - acc: 0.9447 - precision: 0.9935 - recall: 0.8914 - f1_score: 0.9369 - val_loss: 0.2441 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2240 - acc: 0.9447 - precision: 0.9920 - recall: 0.8905 - f1_score: 0.9371 - val_loss: 0.2439 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2237 - acc: 0.9447 - precision: 0.9915 - recall: 0.8915 - f1_score: 0.9375 - val_loss: 0.2437 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2235 - acc: 0.9447 - precision: 0.9921 - recall: 0.8944 - f1_score: 0.9397 - val_loss: 0.2435 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2233 - acc: 0.9447 - precision: 0.9939 - recall: 0.8916 - f1_score: 0.9391 - val_loss: 0.2433 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2231 - acc: 0.9447 - precision: 0.9917 - recall: 0.8917 - f1_score: 0.9381 - val_loss: 0.2431 - val_acc: 0.9304 - val_precision: 0.9883 - val_recall: 0.8849 - val_f1_score: 0.9325\n",
      " 50/158 [========>.....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# NN model\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FP = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return TP / (TP_plus_FP + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FN = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return TP / (TP_plus_FN + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * prec * rec / (prec + rec + K.epsilon())\n",
    "\n",
    "def nn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(NUMBER_OF_NEURONS,\n",
    "                    input_dim=NUMBER_OF_FEATURES,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(REGULARIZATION_LAMBDA)))\n",
    "#     model.add(layers.Dense(NUMBER_OF_NEURONS, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimazier = optimizers.SGD(lr=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimazier,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', precision, recall, f1_score])\n",
    "    return model\n",
    "\n",
    "train_results = {'models': [], 'history': [], 'score': []}\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS)\n",
    "for train_index, validation_index in kf.split(under_sample_dataset):\n",
    "    k_fold_train, k_fold_validation = under_sample_dataset[train_index], under_sample_dataset[validation_index]\n",
    "\n",
    "    x_train = k_fold_train[:,:-1]\n",
    "    y_train = k_fold_train[:,-1:]\n",
    "        \n",
    "    x_validation = k_fold_validation[:,:-1]\n",
    "    y_validation = k_fold_validation[:,-1:]\n",
    "    \n",
    "    model = nn_model()\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), verbose=1, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    score = model.evaluate(x_validation, y_validation, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    train_results['models'].append(model)\n",
    "    train_results['history'].append(history)\n",
    "    train_results['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.248062</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.986328</td>\n",
       "      <td>0.875189</td>\n",
       "      <td>0.927051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.279089</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.972482</td>\n",
       "      <td>0.847515</td>\n",
       "      <td>0.904266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.211614</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.972759</td>\n",
       "      <td>0.918308</td>\n",
       "      <td>0.941496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.211711</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911970</td>\n",
       "      <td>0.953391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.243087</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.932535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Loss  Accuracy  Precision    Recall  F1_score\n",
       "K-fold 1  0.248062  0.930818   0.986328  0.875189  0.927051\n",
       "K-fold 2  0.279089  0.911392   0.972482  0.847515  0.904266\n",
       "K-fold 3  0.211614  0.955696   0.972759  0.918308  0.941496\n",
       "K-fold 4  0.211711  0.955696   1.000000  0.911970  0.953391\n",
       "K-fold 5  0.243087  0.930380   0.988279  0.884887  0.932535"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Loss, Precision, Recall and F1 score in each validation\n",
    "\n",
    "train_results_dict = {'Loss': [i[0] for i in train_results['score']],\n",
    "                      'Accuracy': [i[1] for i in train_results['score']],\n",
    "                      'Precision': [i[2] for i in train_results['score']],\n",
    "                      'Recall': [i[3] for i in train_results['score']],\n",
    "                      'F1_score': [i[4] for i in train_results['score']]}\n",
    "\n",
    "columns = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=train_results_dict, columns=columns, index=indexes)\n",
    "results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc826d970f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc826e0bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0nxF0IID/T/AYgDqeYN5CbzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc826d01358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8192e2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPJAUfyGE8ED/H8O0agHEV4gBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc819166c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves for validation and training data during learning\n",
    "for history in train_results['history']:\n",
    "    show_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION ON TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.981654</td>\n",
       "      <td>0.080817</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>0.148329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.086915</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>0.158537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.982673</td>\n",
       "      <td>0.085206</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>0.155689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.983761</td>\n",
       "      <td>0.090457</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>0.164408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>0.202673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision   Recall  F1_score\n",
       "K-fold 1  0.981654   0.080817  0.90099  0.148329\n",
       "K-fold 2  0.983041   0.086915  0.90099  0.158537\n",
       "K-fold 3  0.982673   0.085206  0.90099  0.155689\n",
       "K-fold 4  0.983761   0.090457  0.90099  0.164408\n",
       "K-fold 5  0.987430   0.114178  0.90099  0.202673"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Precision, Recall and F1 score for test dataset for each model from cross validation\n",
    "\n",
    "test_results = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F1_score': []}\n",
    "confusion_matrixes = []\n",
    "for model in train_results['models']:\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    predicted = np.asarray([np.round(j[0]) for j in predicted])\n",
    "    actual = np.asarray([j[0] for j in y_test])\n",
    "        \n",
    "    TP = np.count_nonzero(predicted * actual)\n",
    "    TN = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    FP = np.count_nonzero(predicted * (actual - 1))\n",
    "    FN = np.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "    confusion_matrix_dict = {'actual 1': [TP, FN], 'actual 0': [FP, TN]}\n",
    "    confusion_matrix = pd.DataFrame(data=confusion_matrix_dict, columns =['actual 1', 'actual 0'], index=['predicted 1', 'predicted 0'])\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = metrics.accuracy_score(actual, predicted)\n",
    "    \n",
    "    test_results['Accuracy'].append(accuracy)\n",
    "    test_results['Precision'].append(precision)\n",
    "    test_results['Recall'].append(recall)\n",
    "    test_results['F1_score'].append(f1)\n",
    "    confusion_matrixes.append(confusion_matrix)\n",
    "    \n",
    "columns = ['Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=test_results, columns=columns, index=indexes)\n",
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejpesko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOjeOyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc81940f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8190c3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc818ffc8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFLE3E9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc818f116a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdIQQghhMUkaQgghLPb/17N4/1AQmIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc818c90470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in train_results['models']:\n",
    "    TPR_array = []\n",
    "    FPR_array = []\n",
    "    for i in range(-50,50,5):\n",
    "        predicted = model.predict(x_test)\n",
    "        predicted = np.asarray([np.round(j[0]+i/100) for j in predicted])\n",
    "        actual = np.asarray([j[0] for j in y_test])\n",
    "\n",
    "        TP = np.count_nonzero(np.multiply(predicted, actual))\n",
    "        TN = np.count_nonzero(np.multiply(predicted - 1, actual - 1))\n",
    "        FP = np.count_nonzero(np.multiply(predicted, actual - 1))\n",
    "        FN = np.count_nonzero(np.multiply(predicted - 1, actual))\n",
    "\n",
    "        TPR_array.append(TP / (TP+FN))\n",
    "        FPR_array.append(FP / (FP+TN))\n",
    "\n",
    "    plot_ROC(TPR_array, FPR_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91      1035\n",
       "predicted 0        10     55826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       956\n",
       "predicted 0        10     55905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       977\n",
       "predicted 0        10     55884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       915\n",
       "predicted 0        10     55946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>56155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       706\n",
       "predicted 0        10     56155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrixes for each valdation\n",
    "for matrix in confusion_matrixes:\n",
    "    display(matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
