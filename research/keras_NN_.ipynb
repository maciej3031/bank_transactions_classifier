{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from keras import regularizers, optimizers, layers, models\n",
    "from IPython.display import display\n",
    "import os\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA PARAMETERS\n",
    "DATASET_NAME = os.path.join(\"..\", \"data\", \"creditcard.csv\")\n",
    "NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET = 400\n",
    "N_SPLITS = 5\n",
    "\n",
    "# NN PARAMETERS\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "NUMBER_OF_NEURONS = 1024\n",
    "REGULARIZATION_LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "dataset = pd.read_csv(DATASET_NAME)\n",
    "dataset = dataset.drop(['Time','Amount'],axis=1)\n",
    "\n",
    "NUMBER_OF_FEATURES = dataset.shape[1] - 1 # Minus 1 because of column: 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEXCAYAAACdwyIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBY+IiFjq/wEs5BITJe0CZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc05156b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for all data\n",
    "count_classes = pd.value_counts(dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset on train_and_validation dataset and test dataset\n",
    "train_and_validation, test = train_test_split(dataset, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Convert test data to numpyarray and split them.\n",
    "test = test.values\n",
    "x_test = test[:,:-1]\n",
    "y_test = test[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create balanced, under sample train and validation dataset \n",
    "fraud_indices = np.array(train_and_validation[train_and_validation.Class == 1].index)\n",
    "normal_indices = np.array(train_and_validation[train_and_validation.Class == 0].index)\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indices, NUMBER_OF_OK_TRANSACTIONS_IN_TRAIN_VALIDATION_DATASET, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "under_sample_dataset = dataset.iloc[under_sample_indices,:]\n",
    "\n",
    "# Shuffle train and validation dataset\n",
    "under_sample_dataset = under_sample_dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgphYWIiJj6P0+koQ8tk9iMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbfe0af198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    400\n",
       "1    391\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot histogram for training and validation dataset\n",
    "count_classes = pd.value_counts(under_sample_dataset['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert training and validation dataset to numpy array\n",
    "under_sample_dataset = under_sample_dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pot loss\n",
    "def show_loss(history):   \n",
    "    x_axis = range(0, EPOCHS)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, history.history['loss'], label='train_loss')\n",
    "    ax.plot(x_axis, history.history['val_loss'], label='val_loss')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Log loss')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.title('loss vs epoch number')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(TPR_array, FPR_array):   \n",
    "    plt.title('ROC')\n",
    "    plt.plot(FPR_array, TPR_array, 'b')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 632 samples, validate on 159 samples\n",
      "Epoch 1/1000\n",
      "632/632 [==============================] - 0s - loss: 6.0015 - acc: 0.6329 - precision: 0.5792 - recall: 0.9345 - f1_score: 0.7110 - val_loss: 5.9917 - val_acc: 0.5975 - val_precision: 0.5416 - val_recall: 0.9627 - val_f1_score: 0.6874\n",
      "Epoch 2/1000\n",
      "632/632 [==============================] - 0s - loss: 5.9384 - acc: 0.6329 - precision: 0.5811 - recall: 0.9528 - f1_score: 0.7198 - val_loss: 5.9449 - val_acc: 0.6101 - val_precision: 0.5504 - val_recall: 0.9627 - val_f1_score: 0.6942\n",
      "Epoch 3/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8934 - acc: 0.6329 - precision: 0.5770 - recall: 0.9538 - f1_score: 0.7148 - val_loss: 5.9050 - val_acc: 0.6226 - val_precision: 0.5596 - val_recall: 0.9627 - val_f1_score: 0.7011\n",
      "Epoch 4/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8540 - acc: 0.6392 - precision: 0.5827 - recall: 0.9537 - f1_score: 0.7198 - val_loss: 5.8681 - val_acc: 0.6289 - val_precision: 0.5642 - val_recall: 0.9627 - val_f1_score: 0.7046\n",
      "Epoch 5/1000\n",
      "632/632 [==============================] - 0s - loss: 5.8175 - acc: 0.6503 - precision: 0.5909 - recall: 0.9554 - f1_score: 0.7262 - val_loss: 5.8328 - val_acc: 0.6289 - val_precision: 0.5642 - val_recall: 0.9627 - val_f1_score: 0.7046\n",
      "Epoch 6/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7826 - acc: 0.6646 - precision: 0.6028 - recall: 0.9535 - f1_score: 0.7364 - val_loss: 5.7986 - val_acc: 0.6415 - val_precision: 0.5731 - val_recall: 0.9627 - val_f1_score: 0.7114\n",
      "Epoch 7/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7487 - acc: 0.6756 - precision: 0.6096 - recall: 0.9491 - f1_score: 0.7398 - val_loss: 5.7651 - val_acc: 0.6604 - val_precision: 0.5866 - val_recall: 0.9748 - val_f1_score: 0.7250\n",
      "Epoch 8/1000\n",
      "632/632 [==============================] - 0s - loss: 5.7156 - acc: 0.6962 - precision: 0.6319 - recall: 0.9502 - f1_score: 0.7570 - val_loss: 5.7322 - val_acc: 0.6918 - val_precision: 0.6089 - val_recall: 0.9748 - val_f1_score: 0.7432\n",
      "Epoch 9/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6832 - acc: 0.7089 - precision: 0.6427 - recall: 0.9466 - f1_score: 0.7632 - val_loss: 5.6998 - val_acc: 0.6981 - val_precision: 0.6130 - val_recall: 0.9748 - val_f1_score: 0.7465\n",
      "Epoch 10/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6512 - acc: 0.7326 - precision: 0.6625 - recall: 0.9465 - f1_score: 0.7766 - val_loss: 5.6679 - val_acc: 0.7170 - val_precision: 0.6307 - val_recall: 0.9748 - val_f1_score: 0.7586\n",
      "Epoch 11/1000\n",
      "632/632 [==============================] - 0s - loss: 5.6197 - acc: 0.7500 - precision: 0.6787 - recall: 0.9436 - f1_score: 0.7873 - val_loss: 5.6363 - val_acc: 0.7233 - val_precision: 0.6350 - val_recall: 0.9748 - val_f1_score: 0.7621\n",
      "Epoch 12/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5886 - acc: 0.7611 - precision: 0.6898 - recall: 0.9485 - f1_score: 0.7968 - val_loss: 5.6051 - val_acc: 0.7484 - val_precision: 0.6613 - val_recall: 0.9627 - val_f1_score: 0.7761\n",
      "Epoch 13/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5578 - acc: 0.7706 - precision: 0.7031 - recall: 0.9397 - f1_score: 0.8017 - val_loss: 5.5742 - val_acc: 0.7610 - val_precision: 0.6717 - val_recall: 0.9627 - val_f1_score: 0.7838\n",
      "Epoch 14/1000\n",
      "632/632 [==============================] - 0s - loss: 5.5273 - acc: 0.7816 - precision: 0.7106 - recall: 0.9342 - f1_score: 0.8059 - val_loss: 5.5435 - val_acc: 0.7673 - val_precision: 0.6790 - val_recall: 0.9627 - val_f1_score: 0.7883\n",
      "Epoch 15/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4971 - acc: 0.7975 - precision: 0.7298 - recall: 0.9357 - f1_score: 0.8192 - val_loss: 5.5131 - val_acc: 0.7736 - val_precision: 0.6867 - val_recall: 0.9627 - val_f1_score: 0.7930\n",
      "Epoch 16/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4672 - acc: 0.8085 - precision: 0.7454 - recall: 0.9360 - f1_score: 0.8285 - val_loss: 5.4831 - val_acc: 0.7862 - val_precision: 0.7004 - val_recall: 0.9627 - val_f1_score: 0.8017\n",
      "Epoch 17/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4375 - acc: 0.8291 - precision: 0.7666 - recall: 0.9335 - f1_score: 0.8410 - val_loss: 5.4532 - val_acc: 0.7987 - val_precision: 0.7119 - val_recall: 0.9627 - val_f1_score: 0.8099\n",
      "Epoch 18/1000\n",
      "632/632 [==============================] - 0s - loss: 5.4081 - acc: 0.8418 - precision: 0.7877 - recall: 0.9298 - f1_score: 0.8505 - val_loss: 5.4237 - val_acc: 0.8113 - val_precision: 0.7255 - val_recall: 0.9627 - val_f1_score: 0.8188\n",
      "Epoch 19/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3790 - acc: 0.8528 - precision: 0.8050 - recall: 0.9340 - f1_score: 0.8618 - val_loss: 5.3944 - val_acc: 0.8176 - val_precision: 0.7335 - val_recall: 0.9627 - val_f1_score: 0.8236\n",
      "Epoch 20/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3501 - acc: 0.8608 - precision: 0.8158 - recall: 0.9285 - f1_score: 0.8668 - val_loss: 5.3653 - val_acc: 0.8302 - val_precision: 0.7534 - val_recall: 0.9507 - val_f1_score: 0.8312\n",
      "Epoch 21/1000\n",
      "632/632 [==============================] - 0s - loss: 5.3214 - acc: 0.8655 - precision: 0.8263 - recall: 0.9281 - f1_score: 0.8720 - val_loss: 5.3365 - val_acc: 0.8365 - val_precision: 0.7620 - val_recall: 0.9507 - val_f1_score: 0.8361\n",
      "Epoch 22/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2930 - acc: 0.8703 - precision: 0.8317 - recall: 0.9294 - f1_score: 0.8765 - val_loss: 5.3078 - val_acc: 0.8553 - val_precision: 0.7880 - val_recall: 0.9507 - val_f1_score: 0.8511\n",
      "Epoch 23/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2647 - acc: 0.8782 - precision: 0.8497 - recall: 0.9260 - f1_score: 0.8821 - val_loss: 5.2794 - val_acc: 0.8679 - val_precision: 0.8006 - val_recall: 0.9507 - val_f1_score: 0.8617\n",
      "Epoch 24/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2367 - acc: 0.8797 - precision: 0.8457 - recall: 0.9240 - f1_score: 0.8812 - val_loss: 5.2512 - val_acc: 0.8742 - val_precision: 0.8099 - val_recall: 0.9507 - val_f1_score: 0.8668\n",
      "Epoch 25/1000\n",
      "632/632 [==============================] - 0s - loss: 5.2089 - acc: 0.8877 - precision: 0.8624 - recall: 0.9261 - f1_score: 0.8902 - val_loss: 5.2233 - val_acc: 0.8742 - val_precision: 0.8099 - val_recall: 0.9507 - val_f1_score: 0.8668\n",
      "Epoch 26/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1813 - acc: 0.8940 - precision: 0.8752 - recall: 0.9229 - f1_score: 0.8968 - val_loss: 5.1955 - val_acc: 0.8868 - val_precision: 0.8302 - val_recall: 0.9507 - val_f1_score: 0.8775\n",
      "Epoch 27/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1539 - acc: 0.8987 - precision: 0.8849 - recall: 0.9183 - f1_score: 0.9003 - val_loss: 5.1679 - val_acc: 0.8805 - val_precision: 0.8113 - val_recall: 0.8940 - val_f1_score: 0.8492\n",
      "Epoch 28/1000\n",
      "632/632 [==============================] - 0s - loss: 5.1267 - acc: 0.9035 - precision: 0.8938 - recall: 0.9117 - f1_score: 0.9015 - val_loss: 5.1406 - val_acc: 0.8805 - val_precision: 0.8183 - val_recall: 0.8815 - val_f1_score: 0.8474\n",
      "Epoch 29/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0997 - acc: 0.9035 - precision: 0.8912 - recall: 0.9122 - f1_score: 0.9003 - val_loss: 5.1135 - val_acc: 0.8805 - val_precision: 0.8183 - val_recall: 0.8815 - val_f1_score: 0.8474\n",
      "Epoch 30/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0729 - acc: 0.9082 - precision: 0.9023 - recall: 0.9102 - f1_score: 0.9050 - val_loss: 5.0865 - val_acc: 0.8868 - val_precision: 0.8291 - val_recall: 0.8815 - val_f1_score: 0.8529\n",
      "Epoch 31/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0463 - acc: 0.9114 - precision: 0.9092 - recall: 0.9107 - f1_score: 0.9091 - val_loss: 5.0598 - val_acc: 0.8994 - val_precision: 0.8522 - val_recall: 0.8815 - val_f1_score: 0.8642\n",
      "Epoch 32/1000\n",
      "632/632 [==============================] - 0s - loss: 5.0198 - acc: 0.9146 - precision: 0.9166 - recall: 0.9110 - f1_score: 0.9128 - val_loss: 5.0332 - val_acc: 0.9119 - val_precision: 0.8773 - val_recall: 0.8815 - val_f1_score: 0.8760\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.9936 - acc: 0.9161 - precision: 0.9194 - recall: 0.9137 - f1_score: 0.9152 - val_loss: 5.0068 - val_acc: 0.9119 - val_precision: 0.8773 - val_recall: 0.8815 - val_f1_score: 0.8760\n",
      "Epoch 34/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9675 - acc: 0.9161 - precision: 0.9244 - recall: 0.9017 - f1_score: 0.9115 - val_loss: 4.9806 - val_acc: 0.9119 - val_precision: 0.8773 - val_recall: 0.8815 - val_f1_score: 0.8760\n",
      "Epoch 35/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9416 - acc: 0.9161 - precision: 0.9316 - recall: 0.9031 - f1_score: 0.9154 - val_loss: 4.9546 - val_acc: 0.9119 - val_precision: 0.8773 - val_recall: 0.8815 - val_f1_score: 0.8760\n",
      "Epoch 36/1000\n",
      "632/632 [==============================] - 0s - loss: 4.9158 - acc: 0.9177 - precision: 0.9326 - recall: 0.9018 - f1_score: 0.9153 - val_loss: 4.9288 - val_acc: 0.9182 - val_precision: 0.8863 - val_recall: 0.8815 - val_f1_score: 0.8813\n",
      "Epoch 37/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8903 - acc: 0.9209 - precision: 0.9366 - recall: 0.9021 - f1_score: 0.9177 - val_loss: 4.9032 - val_acc: 0.9119 - val_precision: 0.8848 - val_recall: 0.8689 - val_f1_score: 0.8749\n",
      "Epoch 38/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8649 - acc: 0.9209 - precision: 0.9385 - recall: 0.9010 - f1_score: 0.9176 - val_loss: 4.8777 - val_acc: 0.9119 - val_precision: 0.8848 - val_recall: 0.8689 - val_f1_score: 0.8749\n",
      "Epoch 39/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8397 - acc: 0.9209 - precision: 0.9387 - recall: 0.9015 - f1_score: 0.9184 - val_loss: 4.8524 - val_acc: 0.9182 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 40/1000\n",
      "632/632 [==============================] - 0s - loss: 4.8147 - acc: 0.9209 - precision: 0.9389 - recall: 0.8969 - f1_score: 0.9160 - val_loss: 4.8273 - val_acc: 0.9182 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 41/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7898 - acc: 0.9241 - precision: 0.9429 - recall: 0.8967 - f1_score: 0.9173 - val_loss: 4.8024 - val_acc: 0.9182 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 42/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7651 - acc: 0.9256 - precision: 0.9508 - recall: 0.8988 - f1_score: 0.9228 - val_loss: 4.7776 - val_acc: 0.9182 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 43/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7406 - acc: 0.9256 - precision: 0.9505 - recall: 0.9008 - f1_score: 0.9236 - val_loss: 4.7530 - val_acc: 0.9182 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 44/1000\n",
      "632/632 [==============================] - 0s - loss: 4.7162 - acc: 0.9272 - precision: 0.9582 - recall: 0.8962 - f1_score: 0.9250 - val_loss: 4.7286 - val_acc: 0.9245 - val_precision: 0.8934 - val_recall: 0.8563 - val_f1_score: 0.8738\n",
      "Epoch 45/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6919 - acc: 0.9272 - precision: 0.9558 - recall: 0.8921 - f1_score: 0.9217 - val_loss: 4.7043 - val_acc: 0.9308 - val_precision: 0.9046 - val_recall: 0.8563 - val_f1_score: 0.8795\n",
      "Epoch 46/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6679 - acc: 0.9288 - precision: 0.9515 - recall: 0.8888 - f1_score: 0.9185 - val_loss: 4.6802 - val_acc: 0.9245 - val_precision: 0.9046 - val_recall: 0.8442 - val_f1_score: 0.8728\n",
      "Epoch 47/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6439 - acc: 0.9304 - precision: 0.9624 - recall: 0.8976 - f1_score: 0.9275 - val_loss: 4.6562 - val_acc: 0.9245 - val_precision: 0.9046 - val_recall: 0.8442 - val_f1_score: 0.8728\n",
      "Epoch 48/1000\n",
      "632/632 [==============================] - 0s - loss: 4.6201 - acc: 0.9304 - precision: 0.9622 - recall: 0.8970 - f1_score: 0.9275 - val_loss: 4.6324 - val_acc: 0.9308 - val_precision: 0.9166 - val_recall: 0.8442 - val_f1_score: 0.8787\n",
      "Epoch 49/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5965 - acc: 0.9304 - precision: 0.9613 - recall: 0.8929 - f1_score: 0.9250 - val_loss: 4.6087 - val_acc: 0.9308 - val_precision: 0.9166 - val_recall: 0.8442 - val_f1_score: 0.8787\n",
      "Epoch 50/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5730 - acc: 0.9304 - precision: 0.9644 - recall: 0.8969 - f1_score: 0.9274 - val_loss: 4.5851 - val_acc: 0.9308 - val_precision: 0.9166 - val_recall: 0.8442 - val_f1_score: 0.8787\n",
      "Epoch 51/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5497 - acc: 0.9320 - precision: 0.9647 - recall: 0.8982 - f1_score: 0.9287 - val_loss: 4.5618 - val_acc: 0.9308 - val_precision: 0.9166 - val_recall: 0.8442 - val_f1_score: 0.8787\n",
      "Epoch 52/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5264 - acc: 0.9351 - precision: 0.9725 - recall: 0.8992 - f1_score: 0.9328 - val_loss: 4.5385 - val_acc: 0.9308 - val_precision: 0.9166 - val_recall: 0.8442 - val_f1_score: 0.8787\n",
      "Epoch 53/1000\n",
      "632/632 [==============================] - 0s - loss: 4.5034 - acc: 0.9351 - precision: 0.9724 - recall: 0.8965 - f1_score: 0.9314 - val_loss: 4.5154 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 54/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4805 - acc: 0.9351 - precision: 0.9701 - recall: 0.8924 - f1_score: 0.9281 - val_loss: 4.4925 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 55/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4577 - acc: 0.9351 - precision: 0.9728 - recall: 0.9020 - f1_score: 0.9338 - val_loss: 4.4697 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 56/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4351 - acc: 0.9351 - precision: 0.9708 - recall: 0.8921 - f1_score: 0.9289 - val_loss: 4.4470 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 57/1000\n",
      "632/632 [==============================] - 0s - loss: 4.4126 - acc: 0.9351 - precision: 0.9718 - recall: 0.8966 - f1_score: 0.9320 - val_loss: 4.4245 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 58/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3902 - acc: 0.9351 - precision: 0.9710 - recall: 0.8920 - f1_score: 0.9291 - val_loss: 4.4022 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 59/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3680 - acc: 0.9351 - precision: 0.9732 - recall: 0.8969 - f1_score: 0.9323 - val_loss: 4.3799 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 60/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3459 - acc: 0.9335 - precision: 0.9745 - recall: 0.8909 - f1_score: 0.9289 - val_loss: 4.3578 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 61/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3239 - acc: 0.9335 - precision: 0.9733 - recall: 0.8922 - f1_score: 0.9300 - val_loss: 4.3358 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 62/1000\n",
      "632/632 [==============================] - 0s - loss: 4.3021 - acc: 0.9335 - precision: 0.9709 - recall: 0.8930 - f1_score: 0.9292 - val_loss: 4.3139 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 63/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2804 - acc: 0.9335 - precision: 0.9730 - recall: 0.8899 - f1_score: 0.9287 - val_loss: 4.2922 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 64/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2588 - acc: 0.9335 - precision: 0.9710 - recall: 0.8919 - f1_score: 0.9286 - val_loss: 4.2706 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 4.2373 - acc: 0.9335 - precision: 0.9734 - recall: 0.8923 - f1_score: 0.9293 - val_loss: 4.2492 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 66/1000\n",
      "632/632 [==============================] - 0s - loss: 4.2160 - acc: 0.9335 - precision: 0.9726 - recall: 0.8892 - f1_score: 0.9268 - val_loss: 4.2279 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 67/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1948 - acc: 0.9335 - precision: 0.9720 - recall: 0.8920 - f1_score: 0.9293 - val_loss: 4.2067 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 68/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1738 - acc: 0.9335 - precision: 0.9707 - recall: 0.8908 - f1_score: 0.9272 - val_loss: 4.1856 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 69/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1528 - acc: 0.9335 - precision: 0.9719 - recall: 0.8927 - f1_score: 0.9298 - val_loss: 4.1647 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 70/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1320 - acc: 0.9320 - precision: 0.9735 - recall: 0.8904 - f1_score: 0.9283 - val_loss: 4.1439 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 71/1000\n",
      "632/632 [==============================] - 0s - loss: 4.1113 - acc: 0.9320 - precision: 0.9740 - recall: 0.8894 - f1_score: 0.9280 - val_loss: 4.1232 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 72/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0907 - acc: 0.9320 - precision: 0.9716 - recall: 0.8897 - f1_score: 0.9278 - val_loss: 4.1026 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 73/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0702 - acc: 0.9320 - precision: 0.9725 - recall: 0.8892 - f1_score: 0.9273 - val_loss: 4.0821 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 74/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0499 - acc: 0.9320 - precision: 0.9692 - recall: 0.8811 - f1_score: 0.9213 - val_loss: 4.0618 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 75/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0297 - acc: 0.9320 - precision: 0.9720 - recall: 0.8892 - f1_score: 0.9281 - val_loss: 4.0416 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 76/1000\n",
      "632/632 [==============================] - 0s - loss: 4.0096 - acc: 0.9320 - precision: 0.9737 - recall: 0.8871 - f1_score: 0.9268 - val_loss: 4.0215 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 77/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9896 - acc: 0.9320 - precision: 0.9756 - recall: 0.8928 - f1_score: 0.9308 - val_loss: 4.0015 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 78/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9697 - acc: 0.9320 - precision: 0.9734 - recall: 0.8903 - f1_score: 0.9281 - val_loss: 3.9816 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 79/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9499 - acc: 0.9335 - precision: 0.9727 - recall: 0.8937 - f1_score: 0.9302 - val_loss: 3.9619 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 80/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9303 - acc: 0.9335 - precision: 0.9700 - recall: 0.8902 - f1_score: 0.9278 - val_loss: 3.9422 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 81/1000\n",
      "632/632 [==============================] - 0s - loss: 3.9107 - acc: 0.9335 - precision: 0.9739 - recall: 0.8901 - f1_score: 0.9285 - val_loss: 3.9227 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 82/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8913 - acc: 0.9335 - precision: 0.9705 - recall: 0.8941 - f1_score: 0.9293 - val_loss: 3.9032 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 83/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8719 - acc: 0.9335 - precision: 0.9737 - recall: 0.8942 - f1_score: 0.9303 - val_loss: 3.8839 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 84/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8527 - acc: 0.9335 - precision: 0.9719 - recall: 0.8908 - f1_score: 0.9280 - val_loss: 3.8647 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 85/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8336 - acc: 0.9335 - precision: 0.9729 - recall: 0.8928 - f1_score: 0.9301 - val_loss: 3.8456 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 86/1000\n",
      "632/632 [==============================] - 0s - loss: 3.8146 - acc: 0.9335 - precision: 0.9727 - recall: 0.8941 - f1_score: 0.9302 - val_loss: 3.8267 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 87/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7957 - acc: 0.9335 - precision: 0.9727 - recall: 0.8918 - f1_score: 0.9295 - val_loss: 3.8078 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 88/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7769 - acc: 0.9335 - precision: 0.9705 - recall: 0.8894 - f1_score: 0.9278 - val_loss: 3.7890 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 89/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 3.7846 - acc: 0.9000 - precision: 0.9583 - recall: 0.8519 - f1_score: 0.902 - 0s - loss: 3.7582 - acc: 0.9335 - precision: 0.9720 - recall: 0.8941 - f1_score: 0.9305 - val_loss: 3.7704 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 90/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7397 - acc: 0.9335 - precision: 0.9735 - recall: 0.8871 - f1_score: 0.9256 - val_loss: 3.7518 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 91/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7212 - acc: 0.9335 - precision: 0.9721 - recall: 0.8921 - f1_score: 0.9283 - val_loss: 3.7334 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 92/1000\n",
      "632/632 [==============================] - 0s - loss: 3.7028 - acc: 0.9335 - precision: 0.9705 - recall: 0.8916 - f1_score: 0.9286 - val_loss: 3.7150 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 93/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6845 - acc: 0.9304 - precision: 0.9723 - recall: 0.8850 - f1_score: 0.9259 - val_loss: 3.6967 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 94/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6664 - acc: 0.9304 - precision: 0.9724 - recall: 0.8851 - f1_score: 0.9258 - val_loss: 3.6786 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 95/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6483 - acc: 0.9304 - precision: 0.9727 - recall: 0.8887 - f1_score: 0.9267 - val_loss: 3.6606 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 96/1000\n",
      "632/632 [==============================] - 0s - loss: 3.6304 - acc: 0.9320 - precision: 0.9728 - recall: 0.8949 - f1_score: 0.9304 - val_loss: 3.6426 - val_acc: 0.9371 - val_precision: 0.9303 - val_recall: 0.8442 - val_f1_score: 0.8848\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.6125 - acc: 0.9320 - precision: 0.9730 - recall: 0.8887 - f1_score: 0.9277 - val_loss: 3.6248 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 98/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5947 - acc: 0.9320 - precision: 0.9732 - recall: 0.8875 - f1_score: 0.9274 - val_loss: 3.6070 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 99/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5771 - acc: 0.9320 - precision: 0.9738 - recall: 0.8885 - f1_score: 0.9261 - val_loss: 3.5894 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 100/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 3.5492 - acc: 0.9600 - precision: 0.9130 - recall: 1.0000 - f1_score: 0.954 - 0s - loss: 3.5595 - acc: 0.9320 - precision: 0.9740 - recall: 0.8920 - f1_score: 0.9299 - val_loss: 3.5719 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 101/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5420 - acc: 0.9320 - precision: 0.9709 - recall: 0.8834 - f1_score: 0.9243 - val_loss: 3.5544 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 102/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5246 - acc: 0.9320 - precision: 0.9738 - recall: 0.8864 - f1_score: 0.9256 - val_loss: 3.5371 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 103/1000\n",
      "632/632 [==============================] - 0s - loss: 3.5074 - acc: 0.9335 - precision: 0.9737 - recall: 0.8879 - f1_score: 0.9276 - val_loss: 3.5198 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 104/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4902 - acc: 0.9335 - precision: 0.9732 - recall: 0.8891 - f1_score: 0.9280 - val_loss: 3.5026 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 105/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4731 - acc: 0.9335 - precision: 0.9743 - recall: 0.8895 - f1_score: 0.9287 - val_loss: 3.4856 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 106/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4561 - acc: 0.9320 - precision: 0.9763 - recall: 0.8845 - f1_score: 0.9267 - val_loss: 3.4686 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 107/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4392 - acc: 0.9320 - precision: 0.9757 - recall: 0.8833 - f1_score: 0.9255 - val_loss: 3.4517 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 108/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4224 - acc: 0.9335 - precision: 0.9768 - recall: 0.8850 - f1_score: 0.9258 - val_loss: 3.4349 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 109/1000\n",
      "632/632 [==============================] - 0s - loss: 3.4056 - acc: 0.9335 - precision: 0.9770 - recall: 0.8868 - f1_score: 0.9273 - val_loss: 3.4182 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 110/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3890 - acc: 0.9335 - precision: 0.9763 - recall: 0.8894 - f1_score: 0.9295 - val_loss: 3.4016 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 111/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3724 - acc: 0.9351 - precision: 0.9808 - recall: 0.8852 - f1_score: 0.9295 - val_loss: 3.3851 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 112/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3560 - acc: 0.9351 - precision: 0.9821 - recall: 0.8849 - f1_score: 0.9295 - val_loss: 3.3687 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 113/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3396 - acc: 0.9351 - precision: 0.9790 - recall: 0.8884 - f1_score: 0.9298 - val_loss: 3.3524 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 114/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3234 - acc: 0.9351 - precision: 0.9778 - recall: 0.8889 - f1_score: 0.9300 - val_loss: 3.3361 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 115/1000\n",
      "632/632 [==============================] - 0s - loss: 3.3072 - acc: 0.9335 - precision: 0.9778 - recall: 0.8870 - f1_score: 0.9286 - val_loss: 3.3200 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 116/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2911 - acc: 0.9351 - precision: 0.9802 - recall: 0.8902 - f1_score: 0.9317 - val_loss: 3.3039 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 117/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 3.2453 - acc: 0.9600 - precision: 0.9583 - recall: 0.9583 - f1_score: 0.958 - 0s - loss: 3.2751 - acc: 0.9351 - precision: 0.9811 - recall: 0.8909 - f1_score: 0.9325 - val_loss: 3.2879 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 118/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2591 - acc: 0.9351 - precision: 0.9799 - recall: 0.8878 - f1_score: 0.9303 - val_loss: 3.2720 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 119/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2433 - acc: 0.9351 - precision: 0.9794 - recall: 0.8888 - f1_score: 0.9303 - val_loss: 3.2562 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 120/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2276 - acc: 0.9351 - precision: 0.9784 - recall: 0.8832 - f1_score: 0.9273 - val_loss: 3.2405 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 121/1000\n",
      "632/632 [==============================] - 0s - loss: 3.2119 - acc: 0.9351 - precision: 0.9798 - recall: 0.8868 - f1_score: 0.9293 - val_loss: 3.2248 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 122/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1963 - acc: 0.9351 - precision: 0.9800 - recall: 0.8889 - f1_score: 0.9318 - val_loss: 3.2093 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 123/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1808 - acc: 0.9351 - precision: 0.9782 - recall: 0.8873 - f1_score: 0.9294 - val_loss: 3.1938 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 124/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1654 - acc: 0.9351 - precision: 0.9791 - recall: 0.8895 - f1_score: 0.9300 - val_loss: 3.1785 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 125/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1501 - acc: 0.9351 - precision: 0.9765 - recall: 0.8881 - f1_score: 0.9290 - val_loss: 3.1632 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 126/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1348 - acc: 0.9351 - precision: 0.9796 - recall: 0.8911 - f1_score: 0.9320 - val_loss: 3.1479 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 127/1000\n",
      "632/632 [==============================] - 0s - loss: 3.1197 - acc: 0.9351 - precision: 0.9776 - recall: 0.8911 - f1_score: 0.9315 - val_loss: 3.1328 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 3.1046 - acc: 0.9351 - precision: 0.9785 - recall: 0.8948 - f1_score: 0.9332 - val_loss: 3.1177 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 129/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0896 - acc: 0.9351 - precision: 0.9775 - recall: 0.8874 - f1_score: 0.9296 - val_loss: 3.1028 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 130/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0746 - acc: 0.9351 - precision: 0.9779 - recall: 0.8905 - f1_score: 0.9310 - val_loss: 3.0879 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 131/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0598 - acc: 0.9351 - precision: 0.9772 - recall: 0.8927 - f1_score: 0.9313 - val_loss: 3.0731 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 132/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0450 - acc: 0.9351 - precision: 0.9793 - recall: 0.8870 - f1_score: 0.9299 - val_loss: 3.0583 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 133/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0303 - acc: 0.9351 - precision: 0.9787 - recall: 0.8893 - f1_score: 0.9295 - val_loss: 3.0437 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 134/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0157 - acc: 0.9351 - precision: 0.9799 - recall: 0.8876 - f1_score: 0.9302 - val_loss: 3.0291 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 135/1000\n",
      "632/632 [==============================] - 0s - loss: 3.0012 - acc: 0.9351 - precision: 0.9783 - recall: 0.8873 - f1_score: 0.9297 - val_loss: 3.0146 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 136/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9868 - acc: 0.9335 - precision: 0.9773 - recall: 0.8873 - f1_score: 0.9292 - val_loss: 3.0002 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 137/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9724 - acc: 0.9335 - precision: 0.9800 - recall: 0.8850 - f1_score: 0.9286 - val_loss: 2.9859 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 138/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9581 - acc: 0.9335 - precision: 0.9786 - recall: 0.8787 - f1_score: 0.9245 - val_loss: 2.9716 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 139/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9439 - acc: 0.9335 - precision: 0.9793 - recall: 0.8905 - f1_score: 0.9303 - val_loss: 2.9574 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 140/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9297 - acc: 0.9335 - precision: 0.9809 - recall: 0.8848 - f1_score: 0.9290 - val_loss: 2.9433 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 141/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9157 - acc: 0.9335 - precision: 0.9795 - recall: 0.8864 - f1_score: 0.9297 - val_loss: 2.9293 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 142/1000\n",
      "632/632 [==============================] - 0s - loss: 2.9017 - acc: 0.9335 - precision: 0.9810 - recall: 0.8871 - f1_score: 0.9309 - val_loss: 2.9153 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 143/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8878 - acc: 0.9335 - precision: 0.9783 - recall: 0.8848 - f1_score: 0.9284 - val_loss: 2.9015 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 144/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8739 - acc: 0.9335 - precision: 0.9775 - recall: 0.8921 - f1_score: 0.9309 - val_loss: 2.8876 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 145/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8601 - acc: 0.9335 - precision: 0.9785 - recall: 0.8850 - f1_score: 0.9286 - val_loss: 2.8739 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 146/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8465 - acc: 0.9335 - precision: 0.9749 - recall: 0.8850 - f1_score: 0.9255 - val_loss: 2.8602 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 147/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8328 - acc: 0.9335 - precision: 0.9787 - recall: 0.8830 - f1_score: 0.9261 - val_loss: 2.8467 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 148/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8193 - acc: 0.9335 - precision: 0.9771 - recall: 0.8855 - f1_score: 0.9281 - val_loss: 2.8331 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 149/1000\n",
      "632/632 [==============================] - 0s - loss: 2.8058 - acc: 0.9335 - precision: 0.9794 - recall: 0.8900 - f1_score: 0.9298 - val_loss: 2.8197 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 150/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7924 - acc: 0.9335 - precision: 0.9777 - recall: 0.8812 - f1_score: 0.9256 - val_loss: 2.8063 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 151/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7791 - acc: 0.9335 - precision: 0.9796 - recall: 0.8867 - f1_score: 0.9296 - val_loss: 2.7930 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 152/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7658 - acc: 0.9335 - precision: 0.9802 - recall: 0.8862 - f1_score: 0.9292 - val_loss: 2.7798 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 153/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7526 - acc: 0.9320 - precision: 0.9755 - recall: 0.8800 - f1_score: 0.9244 - val_loss: 2.7666 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 154/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7395 - acc: 0.9335 - precision: 0.9768 - recall: 0.8853 - f1_score: 0.9278 - val_loss: 2.7535 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 155/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7264 - acc: 0.9320 - precision: 0.9789 - recall: 0.8807 - f1_score: 0.9260 - val_loss: 2.7405 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 156/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7134 - acc: 0.9320 - precision: 0.9788 - recall: 0.8799 - f1_score: 0.9259 - val_loss: 2.7275 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 157/1000\n",
      "632/632 [==============================] - 0s - loss: 2.7005 - acc: 0.9320 - precision: 0.9790 - recall: 0.8830 - f1_score: 0.9275 - val_loss: 2.7146 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 158/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6877 - acc: 0.9320 - precision: 0.9797 - recall: 0.8781 - f1_score: 0.9236 - val_loss: 2.7018 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 159/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6749 - acc: 0.9320 - precision: 0.9788 - recall: 0.8811 - f1_score: 0.9271 - val_loss: 2.6891 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.6622 - acc: 0.9320 - precision: 0.9759 - recall: 0.8770 - f1_score: 0.9231 - val_loss: 2.6764 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 161/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6495 - acc: 0.9320 - precision: 0.9791 - recall: 0.8849 - f1_score: 0.9280 - val_loss: 2.6638 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 162/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6369 - acc: 0.9320 - precision: 0.9796 - recall: 0.8836 - f1_score: 0.9284 - val_loss: 2.6512 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 163/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6244 - acc: 0.9320 - precision: 0.9757 - recall: 0.8844 - f1_score: 0.9265 - val_loss: 2.6388 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 164/1000\n",
      "632/632 [==============================] - 0s - loss: 2.6120 - acc: 0.9320 - precision: 0.9795 - recall: 0.8810 - f1_score: 0.9257 - val_loss: 2.6264 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 165/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5996 - acc: 0.9320 - precision: 0.9774 - recall: 0.8809 - f1_score: 0.9259 - val_loss: 2.6140 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 166/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5873 - acc: 0.9320 - precision: 0.9791 - recall: 0.8823 - f1_score: 0.9259 - val_loss: 2.6017 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 167/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5750 - acc: 0.9320 - precision: 0.9808 - recall: 0.8837 - f1_score: 0.9286 - val_loss: 2.5895 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 168/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5629 - acc: 0.9335 - precision: 0.9801 - recall: 0.8822 - f1_score: 0.9279 - val_loss: 2.5774 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 169/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5507 - acc: 0.9335 - precision: 0.9829 - recall: 0.8836 - f1_score: 0.9298 - val_loss: 2.5653 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 170/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5387 - acc: 0.9335 - precision: 0.9809 - recall: 0.8806 - f1_score: 0.9271 - val_loss: 2.5533 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 171/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5267 - acc: 0.9335 - precision: 0.9797 - recall: 0.8787 - f1_score: 0.9245 - val_loss: 2.5413 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 172/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5147 - acc: 0.9335 - precision: 0.9814 - recall: 0.8794 - f1_score: 0.9269 - val_loss: 2.5294 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 173/1000\n",
      "632/632 [==============================] - 0s - loss: 2.5029 - acc: 0.9335 - precision: 0.9831 - recall: 0.8765 - f1_score: 0.9254 - val_loss: 2.5175 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 174/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4911 - acc: 0.9335 - precision: 0.9816 - recall: 0.8820 - f1_score: 0.9277 - val_loss: 2.5058 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 175/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4793 - acc: 0.9351 - precision: 0.9832 - recall: 0.8854 - f1_score: 0.9310 - val_loss: 2.4941 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 176/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4676 - acc: 0.9351 - precision: 0.9838 - recall: 0.8867 - f1_score: 0.9313 - val_loss: 2.4824 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 177/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4560 - acc: 0.9351 - precision: 0.9828 - recall: 0.8923 - f1_score: 0.9342 - val_loss: 2.4708 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 178/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4444 - acc: 0.9351 - precision: 0.9811 - recall: 0.8886 - f1_score: 0.9316 - val_loss: 2.4593 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 179/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4329 - acc: 0.9351 - precision: 0.9823 - recall: 0.8870 - f1_score: 0.9310 - val_loss: 2.4478 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 180/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4215 - acc: 0.9351 - precision: 0.9812 - recall: 0.8829 - f1_score: 0.9277 - val_loss: 2.4364 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 181/1000\n",
      "632/632 [==============================] - 0s - loss: 2.4101 - acc: 0.9351 - precision: 0.9836 - recall: 0.8862 - f1_score: 0.9313 - val_loss: 2.4251 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 182/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3988 - acc: 0.9351 - precision: 0.9847 - recall: 0.8868 - f1_score: 0.9321 - val_loss: 2.4138 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 183/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3875 - acc: 0.9351 - precision: 0.9834 - recall: 0.8893 - f1_score: 0.9330 - val_loss: 2.4026 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 184/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3763 - acc: 0.9351 - precision: 0.9814 - recall: 0.8855 - f1_score: 0.9301 - val_loss: 2.3914 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 185/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3652 - acc: 0.9367 - precision: 0.9865 - recall: 0.8887 - f1_score: 0.9329 - val_loss: 2.3803 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 186/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3541 - acc: 0.9367 - precision: 0.9860 - recall: 0.8856 - f1_score: 0.9325 - val_loss: 2.3693 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 187/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3431 - acc: 0.9367 - precision: 0.9873 - recall: 0.8849 - f1_score: 0.9322 - val_loss: 2.3583 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 188/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3321 - acc: 0.9367 - precision: 0.9857 - recall: 0.8812 - f1_score: 0.9292 - val_loss: 2.3473 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 189/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3212 - acc: 0.9367 - precision: 0.9852 - recall: 0.8853 - f1_score: 0.9321 - val_loss: 2.3365 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 190/1000\n",
      "632/632 [==============================] - 0s - loss: 2.3104 - acc: 0.9367 - precision: 0.9838 - recall: 0.8884 - f1_score: 0.9320 - val_loss: 2.3256 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 191/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2996 - acc: 0.9367 - precision: 0.9868 - recall: 0.8876 - f1_score: 0.9340 - val_loss: 2.3149 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 2.2888 - acc: 0.9367 - precision: 0.9866 - recall: 0.8828 - f1_score: 0.9308 - val_loss: 2.3042 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 193/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2781 - acc: 0.9367 - precision: 0.9870 - recall: 0.8839 - f1_score: 0.9316 - val_loss: 2.2935 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 194/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2675 - acc: 0.9367 - precision: 0.9849 - recall: 0.8832 - f1_score: 0.9306 - val_loss: 2.2829 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 195/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2569 - acc: 0.9367 - precision: 0.9868 - recall: 0.8854 - f1_score: 0.9320 - val_loss: 2.2724 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 196/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2464 - acc: 0.9367 - precision: 0.9854 - recall: 0.8845 - f1_score: 0.9312 - val_loss: 2.2619 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 197/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2360 - acc: 0.9367 - precision: 0.9869 - recall: 0.8893 - f1_score: 0.9342 - val_loss: 2.2515 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 198/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2256 - acc: 0.9367 - precision: 0.9871 - recall: 0.8885 - f1_score: 0.9344 - val_loss: 2.2411 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 199/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2152 - acc: 0.9367 - precision: 0.9860 - recall: 0.8831 - f1_score: 0.9299 - val_loss: 2.2308 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 200/1000\n",
      "632/632 [==============================] - 0s - loss: 2.2049 - acc: 0.9367 - precision: 0.9850 - recall: 0.8854 - f1_score: 0.9318 - val_loss: 2.2205 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 201/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1947 - acc: 0.9367 - precision: 0.9869 - recall: 0.8864 - f1_score: 0.9321 - val_loss: 2.2103 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 202/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1845 - acc: 0.9367 - precision: 0.9863 - recall: 0.8877 - f1_score: 0.9332 - val_loss: 2.2002 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 203/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1743 - acc: 0.9367 - precision: 0.9866 - recall: 0.8859 - f1_score: 0.9322 - val_loss: 2.1901 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 204/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1643 - acc: 0.9367 - precision: 0.9867 - recall: 0.8881 - f1_score: 0.9337 - val_loss: 2.1800 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 205/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1542 - acc: 0.9367 - precision: 0.9873 - recall: 0.8850 - f1_score: 0.9318 - val_loss: 2.1700 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 206/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1443 - acc: 0.9367 - precision: 0.9859 - recall: 0.8844 - f1_score: 0.9312 - val_loss: 2.1601 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 207/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1343 - acc: 0.9367 - precision: 0.9849 - recall: 0.8829 - f1_score: 0.9305 - val_loss: 2.1502 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 208/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1245 - acc: 0.9367 - precision: 0.9862 - recall: 0.8800 - f1_score: 0.9285 - val_loss: 2.1404 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 209/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1146 - acc: 0.9367 - precision: 0.9863 - recall: 0.8837 - f1_score: 0.9312 - val_loss: 2.1306 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 210/1000\n",
      "632/632 [==============================] - 0s - loss: 2.1049 - acc: 0.9367 - precision: 0.9870 - recall: 0.8852 - f1_score: 0.9326 - val_loss: 2.1208 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 211/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0951 - acc: 0.9367 - precision: 0.9848 - recall: 0.8868 - f1_score: 0.9313 - val_loss: 2.1112 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 212/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0855 - acc: 0.9367 - precision: 0.9866 - recall: 0.8816 - f1_score: 0.9297 - val_loss: 2.1015 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 213/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0759 - acc: 0.9383 - precision: 0.9887 - recall: 0.8875 - f1_score: 0.9341 - val_loss: 2.0919 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 214/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0663 - acc: 0.9367 - precision: 0.9853 - recall: 0.8868 - f1_score: 0.9318 - val_loss: 2.0824 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 215/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0568 - acc: 0.9383 - precision: 0.9901 - recall: 0.8843 - f1_score: 0.9331 - val_loss: 2.0729 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 216/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0473 - acc: 0.9383 - precision: 0.9881 - recall: 0.8845 - f1_score: 0.9324 - val_loss: 2.0635 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 217/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0379 - acc: 0.9383 - precision: 0.9882 - recall: 0.8835 - f1_score: 0.9314 - val_loss: 2.0541 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 218/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0285 - acc: 0.9383 - precision: 0.9894 - recall: 0.8862 - f1_score: 0.9336 - val_loss: 2.0448 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 219/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0192 - acc: 0.9383 - precision: 0.9884 - recall: 0.8845 - f1_score: 0.9327 - val_loss: 2.0355 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 220/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0099 - acc: 0.9383 - precision: 0.9896 - recall: 0.8832 - f1_score: 0.9319 - val_loss: 2.0263 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 221/1000\n",
      "632/632 [==============================] - 0s - loss: 2.0007 - acc: 0.9383 - precision: 0.9907 - recall: 0.8874 - f1_score: 0.9349 - val_loss: 2.0171 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 222/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9915 - acc: 0.9383 - precision: 0.9895 - recall: 0.8856 - f1_score: 0.9330 - val_loss: 2.0079 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 223/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9824 - acc: 0.9383 - precision: 0.9895 - recall: 0.8869 - f1_score: 0.9346 - val_loss: 1.9988 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.9733 - acc: 0.9383 - precision: 0.9899 - recall: 0.8862 - f1_score: 0.9332 - val_loss: 1.9898 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 225/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9642 - acc: 0.9383 - precision: 0.9886 - recall: 0.8874 - f1_score: 0.9339 - val_loss: 1.9808 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 226/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9553 - acc: 0.9383 - precision: 0.9898 - recall: 0.8883 - f1_score: 0.9340 - val_loss: 1.9718 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 227/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9463 - acc: 0.9383 - precision: 0.9886 - recall: 0.8819 - f1_score: 0.9308 - val_loss: 1.9629 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 228/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9374 - acc: 0.9383 - precision: 0.9898 - recall: 0.8858 - f1_score: 0.9339 - val_loss: 1.9541 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 229/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9286 - acc: 0.9383 - precision: 0.9893 - recall: 0.8902 - f1_score: 0.9363 - val_loss: 1.9453 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 230/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9198 - acc: 0.9383 - precision: 0.9898 - recall: 0.8869 - f1_score: 0.9344 - val_loss: 1.9365 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 231/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9110 - acc: 0.9383 - precision: 0.9893 - recall: 0.8855 - f1_score: 0.9337 - val_loss: 1.9278 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 232/1000\n",
      "632/632 [==============================] - 0s - loss: 1.9023 - acc: 0.9383 - precision: 0.9905 - recall: 0.8846 - f1_score: 0.9329 - val_loss: 1.9191 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 233/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8936 - acc: 0.9383 - precision: 0.9901 - recall: 0.8852 - f1_score: 0.9339 - val_loss: 1.9104 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 234/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8850 - acc: 0.9383 - precision: 0.9908 - recall: 0.8879 - f1_score: 0.9354 - val_loss: 1.9019 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 235/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8764 - acc: 0.9383 - precision: 0.9896 - recall: 0.8852 - f1_score: 0.9332 - val_loss: 1.8933 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 236/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8679 - acc: 0.9383 - precision: 0.9895 - recall: 0.8873 - f1_score: 0.9342 - val_loss: 1.8848 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 237/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8594 - acc: 0.9383 - precision: 0.9895 - recall: 0.8887 - f1_score: 0.9351 - val_loss: 1.8764 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 238/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8510 - acc: 0.9383 - precision: 0.9885 - recall: 0.8868 - f1_score: 0.9341 - val_loss: 1.8679 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 239/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8426 - acc: 0.9383 - precision: 0.9900 - recall: 0.8862 - f1_score: 0.9340 - val_loss: 1.8596 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 240/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8342 - acc: 0.9383 - precision: 0.9855 - recall: 0.8856 - f1_score: 0.9313 - val_loss: 1.8513 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 241/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8259 - acc: 0.9383 - precision: 0.9882 - recall: 0.8819 - f1_score: 0.9311 - val_loss: 1.8430 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 242/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8176 - acc: 0.9383 - precision: 0.9901 - recall: 0.8869 - f1_score: 0.9350 - val_loss: 1.8348 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 243/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8094 - acc: 0.9383 - precision: 0.9866 - recall: 0.8865 - f1_score: 0.9327 - val_loss: 1.8266 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 244/1000\n",
      "632/632 [==============================] - 0s - loss: 1.8012 - acc: 0.9383 - precision: 0.9906 - recall: 0.8832 - f1_score: 0.9326 - val_loss: 1.8184 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 245/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7931 - acc: 0.9383 - precision: 0.9895 - recall: 0.8879 - f1_score: 0.9349 - val_loss: 1.8103 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 246/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7850 - acc: 0.9383 - precision: 0.9893 - recall: 0.8840 - f1_score: 0.9327 - val_loss: 1.8022 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 247/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7769 - acc: 0.9383 - precision: 0.9890 - recall: 0.8845 - f1_score: 0.9335 - val_loss: 1.7942 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 248/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7689 - acc: 0.9383 - precision: 0.9890 - recall: 0.8865 - f1_score: 0.9340 - val_loss: 1.7862 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 249/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7609 - acc: 0.9383 - precision: 0.9890 - recall: 0.8863 - f1_score: 0.9334 - val_loss: 1.7783 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 250/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7530 - acc: 0.9383 - precision: 0.9902 - recall: 0.8852 - f1_score: 0.9340 - val_loss: 1.7704 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 251/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7451 - acc: 0.9383 - precision: 0.9891 - recall: 0.8851 - f1_score: 0.9331 - val_loss: 1.7625 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 252/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7372 - acc: 0.9383 - precision: 0.9882 - recall: 0.8884 - f1_score: 0.9342 - val_loss: 1.7547 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 253/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7294 - acc: 0.9383 - precision: 0.9906 - recall: 0.8855 - f1_score: 0.9338 - val_loss: 1.7470 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 254/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7217 - acc: 0.9383 - precision: 0.9907 - recall: 0.8858 - f1_score: 0.9336 - val_loss: 1.7392 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 255/1000\n",
      "632/632 [==============================] - 0s - loss: 1.7139 - acc: 0.9383 - precision: 0.9893 - recall: 0.8831 - f1_score: 0.9323 - val_loss: 1.7315 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.7063 - acc: 0.9383 - precision: 0.9908 - recall: 0.8830 - f1_score: 0.9328 - val_loss: 1.7239 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 257/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6986 - acc: 0.9383 - precision: 0.9893 - recall: 0.8833 - f1_score: 0.9318 - val_loss: 1.7162 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 258/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6910 - acc: 0.9383 - precision: 0.9890 - recall: 0.8847 - f1_score: 0.9329 - val_loss: 1.7087 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 259/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6834 - acc: 0.9383 - precision: 0.9892 - recall: 0.8828 - f1_score: 0.9315 - val_loss: 1.7011 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 260/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6759 - acc: 0.9383 - precision: 0.9898 - recall: 0.8869 - f1_score: 0.9339 - val_loss: 1.6936 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 261/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6684 - acc: 0.9383 - precision: 0.9891 - recall: 0.8878 - f1_score: 0.9348 - val_loss: 1.6862 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 262/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6610 - acc: 0.9383 - precision: 0.9906 - recall: 0.8857 - f1_score: 0.9332 - val_loss: 1.6787 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 263/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6535 - acc: 0.9383 - precision: 0.9895 - recall: 0.8882 - f1_score: 0.9346 - val_loss: 1.6714 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 264/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6462 - acc: 0.9383 - precision: 0.9893 - recall: 0.8855 - f1_score: 0.9335 - val_loss: 1.6640 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 265/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6388 - acc: 0.9383 - precision: 0.9882 - recall: 0.8822 - f1_score: 0.9305 - val_loss: 1.6567 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 266/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6315 - acc: 0.9383 - precision: 0.9894 - recall: 0.8847 - f1_score: 0.9331 - val_loss: 1.6494 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 267/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6243 - acc: 0.9383 - precision: 0.9905 - recall: 0.8877 - f1_score: 0.9346 - val_loss: 1.6422 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 268/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6170 - acc: 0.9383 - precision: 0.9894 - recall: 0.8877 - f1_score: 0.9348 - val_loss: 1.6350 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 269/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6099 - acc: 0.9383 - precision: 0.9859 - recall: 0.8816 - f1_score: 0.9298 - val_loss: 1.6279 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 270/1000\n",
      "632/632 [==============================] - 0s - loss: 1.6027 - acc: 0.9383 - precision: 0.9892 - recall: 0.8838 - f1_score: 0.9324 - val_loss: 1.6208 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 271/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5956 - acc: 0.9383 - precision: 0.9909 - recall: 0.8909 - f1_score: 0.9356 - val_loss: 1.6137 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 272/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5885 - acc: 0.9383 - precision: 0.9902 - recall: 0.8862 - f1_score: 0.9347 - val_loss: 1.6066 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 273/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5815 - acc: 0.9383 - precision: 0.9882 - recall: 0.8800 - f1_score: 0.9299 - val_loss: 1.5996 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 274/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5745 - acc: 0.9383 - precision: 0.9893 - recall: 0.8898 - f1_score: 0.9348 - val_loss: 1.5927 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 275/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5675 - acc: 0.9383 - precision: 0.9884 - recall: 0.8855 - f1_score: 0.9327 - val_loss: 1.5857 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 276/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5606 - acc: 0.9383 - precision: 0.9906 - recall: 0.8840 - f1_score: 0.9336 - val_loss: 1.5788 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 277/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5537 - acc: 0.9383 - precision: 0.9906 - recall: 0.8833 - f1_score: 0.9328 - val_loss: 1.5720 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 278/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5468 - acc: 0.9383 - precision: 0.9891 - recall: 0.8847 - f1_score: 0.9334 - val_loss: 1.5651 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 279/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5400 - acc: 0.9383 - precision: 0.9908 - recall: 0.8848 - f1_score: 0.9332 - val_loss: 1.5583 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 280/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5332 - acc: 0.9383 - precision: 0.9890 - recall: 0.8852 - f1_score: 0.9334 - val_loss: 1.5516 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 281/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5264 - acc: 0.9383 - precision: 0.9897 - recall: 0.8883 - f1_score: 0.9353 - val_loss: 1.5449 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 282/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5197 - acc: 0.9383 - precision: 0.9900 - recall: 0.8843 - f1_score: 0.9325 - val_loss: 1.5382 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 283/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5130 - acc: 0.9383 - precision: 0.9901 - recall: 0.8836 - f1_score: 0.9321 - val_loss: 1.5315 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 284/1000\n",
      "632/632 [==============================] - 0s - loss: 1.5064 - acc: 0.9383 - precision: 0.9873 - recall: 0.8838 - f1_score: 0.9313 - val_loss: 1.5249 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 285/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4998 - acc: 0.9383 - precision: 0.9898 - recall: 0.8851 - f1_score: 0.9330 - val_loss: 1.5183 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 286/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4932 - acc: 0.9383 - precision: 0.9900 - recall: 0.8876 - f1_score: 0.9346 - val_loss: 1.5118 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 287/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4866 - acc: 0.9383 - precision: 0.9884 - recall: 0.8845 - f1_score: 0.9326 - val_loss: 1.5053 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.4801 - acc: 0.9383 - precision: 0.9882 - recall: 0.8810 - f1_score: 0.9299 - val_loss: 1.4988 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 289/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4736 - acc: 0.9383 - precision: 0.9885 - recall: 0.8834 - f1_score: 0.9318 - val_loss: 1.4924 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 290/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4672 - acc: 0.9383 - precision: 0.9905 - recall: 0.8871 - f1_score: 0.9348 - val_loss: 1.4859 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 291/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4608 - acc: 0.9383 - precision: 0.9895 - recall: 0.8840 - f1_score: 0.9327 - val_loss: 1.4796 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 292/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4544 - acc: 0.9383 - precision: 0.9886 - recall: 0.8810 - f1_score: 0.9309 - val_loss: 1.4732 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 293/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4481 - acc: 0.9383 - precision: 0.9898 - recall: 0.8885 - f1_score: 0.9352 - val_loss: 1.4669 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 294/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4417 - acc: 0.9383 - precision: 0.9898 - recall: 0.8844 - f1_score: 0.9328 - val_loss: 1.4606 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 295/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4355 - acc: 0.9383 - precision: 0.9905 - recall: 0.8805 - f1_score: 0.9309 - val_loss: 1.4544 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 296/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4292 - acc: 0.9383 - precision: 0.9893 - recall: 0.8825 - f1_score: 0.9317 - val_loss: 1.4482 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 297/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4230 - acc: 0.9383 - precision: 0.9899 - recall: 0.8866 - f1_score: 0.9334 - val_loss: 1.4420 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 298/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4168 - acc: 0.9383 - precision: 0.9901 - recall: 0.8844 - f1_score: 0.9325 - val_loss: 1.4358 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 299/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4106 - acc: 0.9383 - precision: 0.9873 - recall: 0.8893 - f1_score: 0.9345 - val_loss: 1.4297 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 300/1000\n",
      "632/632 [==============================] - 0s - loss: 1.4045 - acc: 0.9383 - precision: 0.9879 - recall: 0.8836 - f1_score: 0.9314 - val_loss: 1.4236 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 301/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3984 - acc: 0.9383 - precision: 0.9893 - recall: 0.8853 - f1_score: 0.9336 - val_loss: 1.4175 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 302/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3924 - acc: 0.9383 - precision: 0.9893 - recall: 0.8861 - f1_score: 0.9331 - val_loss: 1.4115 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 303/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3863 - acc: 0.9383 - precision: 0.9900 - recall: 0.8877 - f1_score: 0.9344 - val_loss: 1.4055 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 304/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3803 - acc: 0.9383 - precision: 0.9890 - recall: 0.8874 - f1_score: 0.9337 - val_loss: 1.3996 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 305/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3744 - acc: 0.9383 - precision: 0.9913 - recall: 0.8861 - f1_score: 0.9343 - val_loss: 1.3936 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 306/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3684 - acc: 0.9383 - precision: 0.9886 - recall: 0.8885 - f1_score: 0.9347 - val_loss: 1.3877 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 307/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3625 - acc: 0.9383 - precision: 0.9886 - recall: 0.8855 - f1_score: 0.9336 - val_loss: 1.3819 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 308/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3566 - acc: 0.9383 - precision: 0.9900 - recall: 0.8851 - f1_score: 0.9334 - val_loss: 1.3760 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 309/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3508 - acc: 0.9383 - precision: 0.9867 - recall: 0.8810 - f1_score: 0.9294 - val_loss: 1.3702 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 310/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3450 - acc: 0.9383 - precision: 0.9893 - recall: 0.8846 - f1_score: 0.9330 - val_loss: 1.3644 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 311/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3392 - acc: 0.9383 - precision: 0.9895 - recall: 0.8885 - f1_score: 0.9347 - val_loss: 1.3587 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 312/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3334 - acc: 0.9383 - precision: 0.9883 - recall: 0.8893 - f1_score: 0.9354 - val_loss: 1.3529 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 313/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3277 - acc: 0.9383 - precision: 0.9881 - recall: 0.8836 - f1_score: 0.9324 - val_loss: 1.3473 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 314/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3220 - acc: 0.9383 - precision: 0.9901 - recall: 0.8879 - f1_score: 0.9346 - val_loss: 1.3416 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 315/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3163 - acc: 0.9383 - precision: 0.9890 - recall: 0.8841 - f1_score: 0.9324 - val_loss: 1.3360 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 316/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3107 - acc: 0.9383 - precision: 0.9889 - recall: 0.8870 - f1_score: 0.9341 - val_loss: 1.3303 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 317/1000\n",
      "632/632 [==============================] - 0s - loss: 1.3051 - acc: 0.9383 - precision: 0.9883 - recall: 0.8853 - f1_score: 0.9325 - val_loss: 1.3248 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 318/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2995 - acc: 0.9383 - precision: 0.9893 - recall: 0.8851 - f1_score: 0.9336 - val_loss: 1.3192 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 319/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2940 - acc: 0.9383 - precision: 0.9895 - recall: 0.8840 - f1_score: 0.9320 - val_loss: 1.3137 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 320/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.2884 - acc: 0.9383 - precision: 0.9895 - recall: 0.8853 - f1_score: 0.9330 - val_loss: 1.3082 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 321/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2829 - acc: 0.9383 - precision: 0.9911 - recall: 0.8831 - f1_score: 0.9331 - val_loss: 1.3028 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 322/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2775 - acc: 0.9383 - precision: 0.9898 - recall: 0.8870 - f1_score: 0.9334 - val_loss: 1.2973 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 323/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2720 - acc: 0.9383 - precision: 0.9896 - recall: 0.8881 - f1_score: 0.9350 - val_loss: 1.2919 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 324/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2666 - acc: 0.9383 - precision: 0.9877 - recall: 0.8834 - f1_score: 0.9311 - val_loss: 1.2865 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 325/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2612 - acc: 0.9383 - precision: 0.9888 - recall: 0.8905 - f1_score: 0.9361 - val_loss: 1.2812 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 326/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2559 - acc: 0.9383 - precision: 0.9882 - recall: 0.8890 - f1_score: 0.9342 - val_loss: 1.2759 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 327/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2506 - acc: 0.9383 - precision: 0.9886 - recall: 0.8858 - f1_score: 0.9332 - val_loss: 1.2706 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 328/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2453 - acc: 0.9383 - precision: 0.9899 - recall: 0.8871 - f1_score: 0.9349 - val_loss: 1.2653 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 329/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2400 - acc: 0.9383 - precision: 0.9876 - recall: 0.8887 - f1_score: 0.9341 - val_loss: 1.2600 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 330/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2347 - acc: 0.9399 - precision: 0.9902 - recall: 0.8848 - f1_score: 0.9328 - val_loss: 1.2548 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 331/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2295 - acc: 0.9399 - precision: 0.9893 - recall: 0.8887 - f1_score: 0.9354 - val_loss: 1.2496 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 332/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2243 - acc: 0.9399 - precision: 0.9890 - recall: 0.8899 - f1_score: 0.9345 - val_loss: 1.2445 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 333/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2192 - acc: 0.9399 - precision: 0.9893 - recall: 0.8874 - f1_score: 0.9344 - val_loss: 1.2393 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 334/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2140 - acc: 0.9399 - precision: 0.9891 - recall: 0.8875 - f1_score: 0.9335 - val_loss: 1.2342 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 335/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2089 - acc: 0.9399 - precision: 0.9897 - recall: 0.8915 - f1_score: 0.9372 - val_loss: 1.2292 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 336/1000\n",
      "632/632 [==============================] - 0s - loss: 1.2038 - acc: 0.9399 - precision: 0.9909 - recall: 0.8894 - f1_score: 0.9368 - val_loss: 1.2241 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 337/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1987 - acc: 0.9399 - precision: 0.9900 - recall: 0.8877 - f1_score: 0.9346 - val_loss: 1.2191 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 338/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1937 - acc: 0.9399 - precision: 0.9904 - recall: 0.8916 - f1_score: 0.9368 - val_loss: 1.2141 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 339/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1887 - acc: 0.9399 - precision: 0.9899 - recall: 0.8891 - f1_score: 0.9358 - val_loss: 1.2091 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 340/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1837 - acc: 0.9399 - precision: 0.9885 - recall: 0.8891 - f1_score: 0.9350 - val_loss: 1.2042 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 341/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1788 - acc: 0.9399 - precision: 0.9906 - recall: 0.8932 - f1_score: 0.9382 - val_loss: 1.1992 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 342/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1738 - acc: 0.9399 - precision: 0.9880 - recall: 0.8882 - f1_score: 0.9343 - val_loss: 1.1943 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 343/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1689 - acc: 0.9399 - precision: 0.9867 - recall: 0.8827 - f1_score: 0.9308 - val_loss: 1.1895 - val_acc: 0.9308 - val_precision: 0.9303 - val_recall: 0.8321 - val_f1_score: 0.8779\n",
      "Epoch 344/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1640 - acc: 0.9399 - precision: 0.9884 - recall: 0.8882 - f1_score: 0.9345 - val_loss: 1.1846 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 345/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1592 - acc: 0.9399 - precision: 0.9899 - recall: 0.8886 - f1_score: 0.9357 - val_loss: 1.1798 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 346/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1543 - acc: 0.9399 - precision: 0.9896 - recall: 0.8891 - f1_score: 0.9356 - val_loss: 1.1750 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 347/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1495 - acc: 0.9399 - precision: 0.9885 - recall: 0.8874 - f1_score: 0.9343 - val_loss: 1.1702 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 348/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1447 - acc: 0.9399 - precision: 0.9898 - recall: 0.8863 - f1_score: 0.9341 - val_loss: 1.1655 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 349/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1400 - acc: 0.9399 - precision: 0.9904 - recall: 0.8915 - f1_score: 0.9363 - val_loss: 1.1607 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 350/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1352 - acc: 0.9399 - precision: 0.9901 - recall: 0.8857 - f1_score: 0.9326 - val_loss: 1.1560 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 351/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1305 - acc: 0.9399 - precision: 0.9902 - recall: 0.8877 - f1_score: 0.9356 - val_loss: 1.1513 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 1.1259 - acc: 0.9399 - precision: 0.9884 - recall: 0.8897 - f1_score: 0.9357 - val_loss: 1.1467 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 353/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1212 - acc: 0.9399 - precision: 0.9884 - recall: 0.8891 - f1_score: 0.9344 - val_loss: 1.1421 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 354/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1166 - acc: 0.9399 - precision: 0.9900 - recall: 0.8900 - f1_score: 0.9365 - val_loss: 1.1375 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 355/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1119 - acc: 0.9399 - precision: 0.9894 - recall: 0.8891 - f1_score: 0.9348 - val_loss: 1.1329 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 356/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1073 - acc: 0.9399 - precision: 0.9867 - recall: 0.8886 - f1_score: 0.9345 - val_loss: 1.1283 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 357/1000\n",
      "632/632 [==============================] - 0s - loss: 1.1028 - acc: 0.9399 - precision: 0.9895 - recall: 0.8864 - f1_score: 0.9336 - val_loss: 1.1238 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 358/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0982 - acc: 0.9399 - precision: 0.9889 - recall: 0.8889 - f1_score: 0.9355 - val_loss: 1.1193 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 359/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0937 - acc: 0.9399 - precision: 0.9906 - recall: 0.8880 - f1_score: 0.9357 - val_loss: 1.1148 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 360/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0892 - acc: 0.9399 - precision: 0.9899 - recall: 0.8885 - f1_score: 0.9352 - val_loss: 1.1103 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 361/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0847 - acc: 0.9399 - precision: 0.9893 - recall: 0.8871 - f1_score: 0.9349 - val_loss: 1.1059 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 362/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0803 - acc: 0.9399 - precision: 0.9914 - recall: 0.8884 - f1_score: 0.9362 - val_loss: 1.1014 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 363/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0759 - acc: 0.9399 - precision: 0.9898 - recall: 0.8908 - f1_score: 0.9364 - val_loss: 1.0970 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 364/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0714 - acc: 0.9399 - precision: 0.9898 - recall: 0.8880 - f1_score: 0.9352 - val_loss: 1.0927 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 365/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0671 - acc: 0.9399 - precision: 0.9902 - recall: 0.8852 - f1_score: 0.9322 - val_loss: 1.0883 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 366/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0627 - acc: 0.9399 - precision: 0.9911 - recall: 0.8924 - f1_score: 0.9376 - val_loss: 1.0840 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 367/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0584 - acc: 0.9399 - precision: 0.9898 - recall: 0.8894 - f1_score: 0.9353 - val_loss: 1.0797 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 368/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0540 - acc: 0.9399 - precision: 0.9901 - recall: 0.8867 - f1_score: 0.9344 - val_loss: 1.0754 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 369/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0497 - acc: 0.9399 - precision: 0.9895 - recall: 0.8870 - f1_score: 0.9337 - val_loss: 1.0711 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 370/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0455 - acc: 0.9399 - precision: 0.9883 - recall: 0.8905 - f1_score: 0.9362 - val_loss: 1.0669 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 371/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0412 - acc: 0.9399 - precision: 0.9892 - recall: 0.8868 - f1_score: 0.9337 - val_loss: 1.0626 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 372/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0370 - acc: 0.9399 - precision: 0.9898 - recall: 0.8860 - f1_score: 0.9331 - val_loss: 1.0584 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 373/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0328 - acc: 0.9399 - precision: 0.9901 - recall: 0.8861 - f1_score: 0.9337 - val_loss: 1.0543 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 374/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0286 - acc: 0.9399 - precision: 0.9887 - recall: 0.8863 - f1_score: 0.9337 - val_loss: 1.0501 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 375/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0244 - acc: 0.9399 - precision: 0.9897 - recall: 0.8886 - f1_score: 0.9360 - val_loss: 1.0460 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 376/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0203 - acc: 0.9399 - precision: 0.9897 - recall: 0.8909 - f1_score: 0.9366 - val_loss: 1.0419 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 377/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0161 - acc: 0.9399 - precision: 0.9902 - recall: 0.8912 - f1_score: 0.9363 - val_loss: 1.0378 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 378/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0120 - acc: 0.9399 - precision: 0.9893 - recall: 0.8905 - f1_score: 0.9360 - val_loss: 1.0337 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 379/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0080 - acc: 0.9399 - precision: 0.9888 - recall: 0.8902 - f1_score: 0.9350 - val_loss: 1.0296 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 380/1000\n",
      "632/632 [==============================] - 0s - loss: 1.0039 - acc: 0.9399 - precision: 0.9894 - recall: 0.8863 - f1_score: 0.9345 - val_loss: 1.0256 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 381/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9999 - acc: 0.9399 - precision: 0.9909 - recall: 0.8893 - f1_score: 0.9361 - val_loss: 1.0216 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 382/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9958 - acc: 0.9399 - precision: 0.9887 - recall: 0.8882 - f1_score: 0.9350 - val_loss: 1.0176 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 383/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9918 - acc: 0.9399 - precision: 0.9877 - recall: 0.8901 - f1_score: 0.9358 - val_loss: 1.0136 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 384/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.9879 - acc: 0.9399 - precision: 0.9882 - recall: 0.8885 - f1_score: 0.9351 - val_loss: 1.0097 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 385/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9839 - acc: 0.9399 - precision: 0.9892 - recall: 0.8947 - f1_score: 0.9385 - val_loss: 1.0058 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 386/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9800 - acc: 0.9399 - precision: 0.9906 - recall: 0.8895 - f1_score: 0.9368 - val_loss: 1.0019 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 387/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9760 - acc: 0.9399 - precision: 0.9907 - recall: 0.8921 - f1_score: 0.9371 - val_loss: 0.9980 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 388/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9721 - acc: 0.9399 - precision: 0.9892 - recall: 0.8993 - f1_score: 0.9401 - val_loss: 0.9941 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 389/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9683 - acc: 0.9399 - precision: 0.9888 - recall: 0.8858 - f1_score: 0.9329 - val_loss: 0.9902 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 390/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9644 - acc: 0.9399 - precision: 0.9863 - recall: 0.8845 - f1_score: 0.9314 - val_loss: 0.9864 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 391/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9606 - acc: 0.9399 - precision: 0.9899 - recall: 0.8884 - f1_score: 0.9359 - val_loss: 0.9826 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 392/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9567 - acc: 0.9399 - precision: 0.9873 - recall: 0.8854 - f1_score: 0.9329 - val_loss: 0.9788 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 393/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9529 - acc: 0.9399 - precision: 0.9901 - recall: 0.8892 - f1_score: 0.9362 - val_loss: 0.9751 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 394/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9491 - acc: 0.9399 - precision: 0.9911 - recall: 0.8874 - f1_score: 0.9349 - val_loss: 0.9713 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 395/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9454 - acc: 0.9399 - precision: 0.9910 - recall: 0.8866 - f1_score: 0.9334 - val_loss: 0.9676 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 396/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9416 - acc: 0.9399 - precision: 0.9896 - recall: 0.8882 - f1_score: 0.9354 - val_loss: 0.9639 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 397/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9379 - acc: 0.9399 - precision: 0.9902 - recall: 0.8890 - f1_score: 0.9360 - val_loss: 0.9602 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 398/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9342 - acc: 0.9399 - precision: 0.9893 - recall: 0.8891 - f1_score: 0.9358 - val_loss: 0.9565 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 399/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9305 - acc: 0.9399 - precision: 0.9890 - recall: 0.8840 - f1_score: 0.9323 - val_loss: 0.9528 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 400/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9269 - acc: 0.9399 - precision: 0.9845 - recall: 0.8834 - f1_score: 0.9284 - val_loss: 0.9492 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 401/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9232 - acc: 0.9399 - precision: 0.9885 - recall: 0.8871 - f1_score: 0.9344 - val_loss: 0.9456 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 402/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9196 - acc: 0.9399 - precision: 0.9903 - recall: 0.8862 - f1_score: 0.9337 - val_loss: 0.9420 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 403/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9160 - acc: 0.9399 - precision: 0.9906 - recall: 0.8880 - f1_score: 0.9348 - val_loss: 0.9384 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 404/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9124 - acc: 0.9399 - precision: 0.9894 - recall: 0.8934 - f1_score: 0.9380 - val_loss: 0.9348 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 405/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9088 - acc: 0.9399 - precision: 0.9905 - recall: 0.8873 - f1_score: 0.9347 - val_loss: 0.9313 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 406/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9052 - acc: 0.9399 - precision: 0.9902 - recall: 0.8897 - f1_score: 0.9365 - val_loss: 0.9277 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 407/1000\n",
      "632/632 [==============================] - 0s - loss: 0.9017 - acc: 0.9399 - precision: 0.9863 - recall: 0.8833 - f1_score: 0.9315 - val_loss: 0.9242 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 408/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8982 - acc: 0.9399 - precision: 0.9890 - recall: 0.8887 - f1_score: 0.9353 - val_loss: 0.9207 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 409/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8947 - acc: 0.9399 - precision: 0.9904 - recall: 0.8873 - f1_score: 0.9345 - val_loss: 0.9173 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 410/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8912 - acc: 0.9399 - precision: 0.9893 - recall: 0.8897 - f1_score: 0.9355 - val_loss: 0.9138 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 411/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8877 - acc: 0.9399 - precision: 0.9897 - recall: 0.8875 - f1_score: 0.9339 - val_loss: 0.9104 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 412/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8843 - acc: 0.9399 - precision: 0.9906 - recall: 0.8884 - f1_score: 0.9354 - val_loss: 0.9069 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 413/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8808 - acc: 0.9399 - precision: 0.9902 - recall: 0.8886 - f1_score: 0.9350 - val_loss: 0.9035 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 414/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8774 - acc: 0.9399 - precision: 0.9895 - recall: 0.8897 - f1_score: 0.9360 - val_loss: 0.9001 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 415/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8740 - acc: 0.9399 - precision: 0.9892 - recall: 0.8843 - f1_score: 0.9325 - val_loss: 0.8968 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 416/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.8706 - acc: 0.9399 - precision: 0.9890 - recall: 0.8890 - f1_score: 0.9352 - val_loss: 0.8934 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 417/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8673 - acc: 0.9399 - precision: 0.9892 - recall: 0.8903 - f1_score: 0.9361 - val_loss: 0.8901 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 418/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8639 - acc: 0.9399 - precision: 0.9891 - recall: 0.8832 - f1_score: 0.9317 - val_loss: 0.8868 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 419/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8606 - acc: 0.9399 - precision: 0.9905 - recall: 0.8909 - f1_score: 0.9365 - val_loss: 0.8835 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 420/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8573 - acc: 0.9399 - precision: 0.9886 - recall: 0.8873 - f1_score: 0.9341 - val_loss: 0.8802 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 421/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8540 - acc: 0.9415 - precision: 0.9906 - recall: 0.8882 - f1_score: 0.9349 - val_loss: 0.8769 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 422/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8507 - acc: 0.9415 - precision: 0.9898 - recall: 0.8926 - f1_score: 0.9377 - val_loss: 0.8737 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 423/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8474 - acc: 0.9415 - precision: 0.9895 - recall: 0.8905 - f1_score: 0.9367 - val_loss: 0.8704 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 424/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8442 - acc: 0.9415 - precision: 0.9894 - recall: 0.8939 - f1_score: 0.9386 - val_loss: 0.8672 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 425/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8409 - acc: 0.9415 - precision: 0.9886 - recall: 0.8911 - f1_score: 0.9364 - val_loss: 0.8640 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 426/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8377 - acc: 0.9415 - precision: 0.9909 - recall: 0.8918 - f1_score: 0.9380 - val_loss: 0.8608 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 427/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8345 - acc: 0.9415 - precision: 0.9892 - recall: 0.8950 - f1_score: 0.9379 - val_loss: 0.8576 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 428/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8313 - acc: 0.9415 - precision: 0.9899 - recall: 0.8918 - f1_score: 0.9366 - val_loss: 0.8545 - val_acc: 0.9371 - val_precision: 0.9434 - val_recall: 0.8321 - val_f1_score: 0.8840\n",
      "Epoch 429/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8282 - acc: 0.9415 - precision: 0.9896 - recall: 0.8905 - f1_score: 0.9357 - val_loss: 0.8513 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 430/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8250 - acc: 0.9415 - precision: 0.9888 - recall: 0.8919 - f1_score: 0.9367 - val_loss: 0.8482 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 431/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8219 - acc: 0.9415 - precision: 0.9888 - recall: 0.8960 - f1_score: 0.9377 - val_loss: 0.8451 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 432/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8188 - acc: 0.9415 - precision: 0.9888 - recall: 0.8945 - f1_score: 0.9383 - val_loss: 0.8420 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 433/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8157 - acc: 0.9415 - precision: 0.9870 - recall: 0.8890 - f1_score: 0.9348 - val_loss: 0.8390 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 434/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8126 - acc: 0.9415 - precision: 0.9903 - recall: 0.8941 - f1_score: 0.9385 - val_loss: 0.8359 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 435/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8095 - acc: 0.9415 - precision: 0.9900 - recall: 0.8914 - f1_score: 0.9367 - val_loss: 0.8329 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 436/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.8101 - acc: 0.9200 - precision: 0.9615 - recall: 0.8929 - f1_score: 0.925 - 0s - loss: 0.8065 - acc: 0.9415 - precision: 0.9900 - recall: 0.8885 - f1_score: 0.9355 - val_loss: 0.8298 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 437/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8034 - acc: 0.9415 - precision: 0.9892 - recall: 0.8981 - f1_score: 0.9400 - val_loss: 0.8268 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 438/1000\n",
      "632/632 [==============================] - 0s - loss: 0.8004 - acc: 0.9415 - precision: 0.9903 - recall: 0.8925 - f1_score: 0.9376 - val_loss: 0.8238 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 439/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7974 - acc: 0.9415 - precision: 0.9900 - recall: 0.8972 - f1_score: 0.9404 - val_loss: 0.8208 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 440/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7944 - acc: 0.9415 - precision: 0.9887 - recall: 0.8933 - f1_score: 0.9381 - val_loss: 0.8179 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 441/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7914 - acc: 0.9415 - precision: 0.9892 - recall: 0.8890 - f1_score: 0.9354 - val_loss: 0.8149 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 442/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7885 - acc: 0.9415 - precision: 0.9908 - recall: 0.8888 - f1_score: 0.9359 - val_loss: 0.8120 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 443/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7855 - acc: 0.9415 - precision: 0.9869 - recall: 0.8959 - f1_score: 0.9366 - val_loss: 0.8091 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 444/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7826 - acc: 0.9415 - precision: 0.9908 - recall: 0.8868 - f1_score: 0.9341 - val_loss: 0.8062 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 445/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7797 - acc: 0.9415 - precision: 0.9894 - recall: 0.8872 - f1_score: 0.9349 - val_loss: 0.8033 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 446/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7767 - acc: 0.9415 - precision: 0.9903 - recall: 0.8935 - f1_score: 0.9387 - val_loss: 0.8004 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 447/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7739 - acc: 0.9415 - precision: 0.9891 - recall: 0.8944 - f1_score: 0.9383 - val_loss: 0.7975 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.7710 - acc: 0.9415 - precision: 0.9899 - recall: 0.8921 - f1_score: 0.9374 - val_loss: 0.7947 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 449/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7681 - acc: 0.9415 - precision: 0.9906 - recall: 0.8864 - f1_score: 0.9338 - val_loss: 0.7918 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 450/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7653 - acc: 0.9415 - precision: 0.9904 - recall: 0.8910 - f1_score: 0.9363 - val_loss: 0.7890 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 451/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7624 - acc: 0.9415 - precision: 0.9887 - recall: 0.8918 - f1_score: 0.9363 - val_loss: 0.7862 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 452/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7596 - acc: 0.9415 - precision: 0.9897 - recall: 0.8897 - f1_score: 0.9354 - val_loss: 0.7834 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 453/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7568 - acc: 0.9415 - precision: 0.9892 - recall: 0.8895 - f1_score: 0.9348 - val_loss: 0.7807 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 454/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7540 - acc: 0.9415 - precision: 0.9900 - recall: 0.8933 - f1_score: 0.9381 - val_loss: 0.7779 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 455/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7513 - acc: 0.9415 - precision: 0.9894 - recall: 0.8913 - f1_score: 0.9369 - val_loss: 0.7752 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 456/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7485 - acc: 0.9415 - precision: 0.9895 - recall: 0.8886 - f1_score: 0.9352 - val_loss: 0.7724 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 457/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7457 - acc: 0.9415 - precision: 0.9878 - recall: 0.8897 - f1_score: 0.9349 - val_loss: 0.7697 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 458/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7430 - acc: 0.9415 - precision: 0.9883 - recall: 0.8904 - f1_score: 0.9356 - val_loss: 0.7670 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 459/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7403 - acc: 0.9415 - precision: 0.9883 - recall: 0.8887 - f1_score: 0.9336 - val_loss: 0.7643 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 460/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7376 - acc: 0.9415 - precision: 0.9890 - recall: 0.8959 - f1_score: 0.9389 - val_loss: 0.7616 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 461/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7349 - acc: 0.9415 - precision: 0.9884 - recall: 0.8867 - f1_score: 0.9332 - val_loss: 0.7590 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 462/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7322 - acc: 0.9415 - precision: 0.9905 - recall: 0.8853 - f1_score: 0.9330 - val_loss: 0.7563 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 463/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7295 - acc: 0.9415 - precision: 0.9903 - recall: 0.8903 - f1_score: 0.9365 - val_loss: 0.7537 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 464/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7269 - acc: 0.9415 - precision: 0.9886 - recall: 0.8924 - f1_score: 0.9376 - val_loss: 0.7511 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 465/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7242 - acc: 0.9415 - precision: 0.9901 - recall: 0.8921 - f1_score: 0.9370 - val_loss: 0.7485 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 466/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7216 - acc: 0.9415 - precision: 0.9896 - recall: 0.8900 - f1_score: 0.9367 - val_loss: 0.7459 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 467/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7190 - acc: 0.9415 - precision: 0.9890 - recall: 0.8942 - f1_score: 0.9382 - val_loss: 0.7433 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 468/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7164 - acc: 0.9415 - precision: 0.9899 - recall: 0.8904 - f1_score: 0.9354 - val_loss: 0.7407 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 469/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7138 - acc: 0.9415 - precision: 0.9892 - recall: 0.8942 - f1_score: 0.9386 - val_loss: 0.7381 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 470/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7112 - acc: 0.9415 - precision: 0.9892 - recall: 0.8944 - f1_score: 0.9382 - val_loss: 0.7356 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 471/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7087 - acc: 0.9415 - precision: 0.9892 - recall: 0.8876 - f1_score: 0.9347 - val_loss: 0.7330 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 472/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7061 - acc: 0.9415 - precision: 0.9899 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 0.7305 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 473/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7036 - acc: 0.9415 - precision: 0.9901 - recall: 0.8915 - f1_score: 0.9359 - val_loss: 0.7280 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 474/1000\n",
      "632/632 [==============================] - 0s - loss: 0.7011 - acc: 0.9415 - precision: 0.9897 - recall: 0.8938 - f1_score: 0.9381 - val_loss: 0.7255 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 475/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6986 - acc: 0.9415 - precision: 0.9888 - recall: 0.8940 - f1_score: 0.9382 - val_loss: 0.7230 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 476/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6961 - acc: 0.9415 - precision: 0.9901 - recall: 0.8942 - f1_score: 0.9386 - val_loss: 0.7205 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 477/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6936 - acc: 0.9415 - precision: 0.9900 - recall: 0.8912 - f1_score: 0.9364 - val_loss: 0.7181 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 478/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6911 - acc: 0.9415 - precision: 0.9891 - recall: 0.8920 - f1_score: 0.9374 - val_loss: 0.7156 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 479/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6887 - acc: 0.9415 - precision: 0.9893 - recall: 0.8942 - f1_score: 0.9388 - val_loss: 0.7132 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 480/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6862 - acc: 0.9415 - precision: 0.9888 - recall: 0.8884 - f1_score: 0.9351 - val_loss: 0.7108 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 481/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6838 - acc: 0.9415 - precision: 0.9887 - recall: 0.8904 - f1_score: 0.9360 - val_loss: 0.7084 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 482/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6813 - acc: 0.9415 - precision: 0.9895 - recall: 0.8919 - f1_score: 0.9374 - val_loss: 0.7060 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 483/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6789 - acc: 0.9415 - precision: 0.9899 - recall: 0.8937 - f1_score: 0.9381 - val_loss: 0.7036 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 484/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6765 - acc: 0.9415 - precision: 0.9906 - recall: 0.8922 - f1_score: 0.9374 - val_loss: 0.7012 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 485/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6741 - acc: 0.9415 - precision: 0.9906 - recall: 0.8910 - f1_score: 0.9371 - val_loss: 0.6989 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 486/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6718 - acc: 0.9415 - precision: 0.9893 - recall: 0.8881 - f1_score: 0.9350 - val_loss: 0.6965 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 487/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6694 - acc: 0.9415 - precision: 0.9896 - recall: 0.8917 - f1_score: 0.9375 - val_loss: 0.6942 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 488/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6671 - acc: 0.9415 - precision: 0.9892 - recall: 0.8953 - f1_score: 0.9389 - val_loss: 0.6918 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 489/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6647 - acc: 0.9415 - precision: 0.9897 - recall: 0.8941 - f1_score: 0.9390 - val_loss: 0.6895 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 490/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6624 - acc: 0.9415 - precision: 0.9885 - recall: 0.8946 - f1_score: 0.9379 - val_loss: 0.6872 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 491/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6601 - acc: 0.9415 - precision: 0.9888 - recall: 0.8899 - f1_score: 0.9352 - val_loss: 0.6849 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 492/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6578 - acc: 0.9415 - precision: 0.9883 - recall: 0.8946 - f1_score: 0.9379 - val_loss: 0.6826 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 493/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6555 - acc: 0.9415 - precision: 0.9901 - recall: 0.8895 - f1_score: 0.9353 - val_loss: 0.6804 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 494/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6532 - acc: 0.9415 - precision: 0.9915 - recall: 0.8910 - f1_score: 0.9365 - val_loss: 0.6781 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 495/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6509 - acc: 0.9415 - precision: 0.9906 - recall: 0.8944 - f1_score: 0.9384 - val_loss: 0.6759 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 496/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6487 - acc: 0.9415 - precision: 0.9897 - recall: 0.8920 - f1_score: 0.9361 - val_loss: 0.6736 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 497/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6464 - acc: 0.9415 - precision: 0.9906 - recall: 0.8946 - f1_score: 0.9385 - val_loss: 0.6714 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 498/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6442 - acc: 0.9415 - precision: 0.9882 - recall: 0.8910 - f1_score: 0.9362 - val_loss: 0.6692 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 499/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6420 - acc: 0.9415 - precision: 0.9903 - recall: 0.8892 - f1_score: 0.9346 - val_loss: 0.6670 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 500/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6397 - acc: 0.9415 - precision: 0.9890 - recall: 0.8924 - f1_score: 0.9374 - val_loss: 0.6648 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 501/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6375 - acc: 0.9415 - precision: 0.9906 - recall: 0.8907 - f1_score: 0.9368 - val_loss: 0.6626 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 502/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6353 - acc: 0.9415 - precision: 0.9887 - recall: 0.8926 - f1_score: 0.9366 - val_loss: 0.6605 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 503/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6332 - acc: 0.9415 - precision: 0.9902 - recall: 0.8922 - f1_score: 0.9367 - val_loss: 0.6583 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 504/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6310 - acc: 0.9415 - precision: 0.9895 - recall: 0.8911 - f1_score: 0.9363 - val_loss: 0.6562 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 505/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6288 - acc: 0.9415 - precision: 0.9901 - recall: 0.8930 - f1_score: 0.9379 - val_loss: 0.6540 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 506/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6267 - acc: 0.9415 - precision: 0.9884 - recall: 0.8908 - f1_score: 0.9363 - val_loss: 0.6519 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 507/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6245 - acc: 0.9430 - precision: 0.9881 - recall: 0.8944 - f1_score: 0.9385 - val_loss: 0.6498 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 508/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6224 - acc: 0.9415 - precision: 0.9890 - recall: 0.8868 - f1_score: 0.9339 - val_loss: 0.6477 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 509/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6203 - acc: 0.9430 - precision: 0.9894 - recall: 0.8957 - f1_score: 0.9393 - val_loss: 0.6456 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 510/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6182 - acc: 0.9430 - precision: 0.9900 - recall: 0.8952 - f1_score: 0.9394 - val_loss: 0.6435 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 511/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6161 - acc: 0.9430 - precision: 0.9910 - recall: 0.8955 - f1_score: 0.9396 - val_loss: 0.6414 - val_acc: 0.9434 - val_precision: 0.9434 - val_recall: 0.8447 - val_f1_score: 0.8907\n",
      "Epoch 512/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.6140 - acc: 0.9430 - precision: 0.9890 - recall: 0.8942 - f1_score: 0.9385 - val_loss: 0.6394 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 513/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6119 - acc: 0.9430 - precision: 0.9892 - recall: 0.8958 - f1_score: 0.9392 - val_loss: 0.6373 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 514/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6099 - acc: 0.9430 - precision: 0.9906 - recall: 0.8963 - f1_score: 0.9391 - val_loss: 0.6353 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 515/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6078 - acc: 0.9430 - precision: 0.9884 - recall: 0.8952 - f1_score: 0.9380 - val_loss: 0.6332 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 516/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6058 - acc: 0.9430 - precision: 0.9892 - recall: 0.8995 - f1_score: 0.9396 - val_loss: 0.6312 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 517/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6037 - acc: 0.9430 - precision: 0.9888 - recall: 0.8909 - f1_score: 0.9361 - val_loss: 0.6292 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 518/1000\n",
      "632/632 [==============================] - 0s - loss: 0.6017 - acc: 0.9430 - precision: 0.9901 - recall: 0.8932 - f1_score: 0.9379 - val_loss: 0.6272 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 519/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5997 - acc: 0.9430 - precision: 0.9893 - recall: 0.8958 - f1_score: 0.9393 - val_loss: 0.6252 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 520/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5977 - acc: 0.9430 - precision: 0.9905 - recall: 0.8939 - f1_score: 0.9371 - val_loss: 0.6232 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 521/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5957 - acc: 0.9430 - precision: 0.9898 - recall: 0.8926 - f1_score: 0.9372 - val_loss: 0.6213 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 522/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5937 - acc: 0.9430 - precision: 0.9906 - recall: 0.8945 - f1_score: 0.9393 - val_loss: 0.6193 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 523/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5917 - acc: 0.9430 - precision: 0.9872 - recall: 0.8980 - f1_score: 0.9396 - val_loss: 0.6173 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 524/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5898 - acc: 0.9430 - precision: 0.9897 - recall: 0.8934 - f1_score: 0.9383 - val_loss: 0.6154 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 525/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5878 - acc: 0.9430 - precision: 0.9894 - recall: 0.8948 - f1_score: 0.9383 - val_loss: 0.6135 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 526/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5859 - acc: 0.9430 - precision: 0.9905 - recall: 0.8940 - f1_score: 0.9384 - val_loss: 0.6115 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 527/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5839 - acc: 0.9430 - precision: 0.9894 - recall: 0.8953 - f1_score: 0.9390 - val_loss: 0.6096 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 528/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5820 - acc: 0.9430 - precision: 0.9881 - recall: 0.8925 - f1_score: 0.9363 - val_loss: 0.6077 - val_acc: 0.9497 - val_precision: 0.9434 - val_recall: 0.8573 - val_f1_score: 0.8977\n",
      "Epoch 529/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5801 - acc: 0.9430 - precision: 0.9899 - recall: 0.8949 - f1_score: 0.9389 - val_loss: 0.6058 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 530/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5782 - acc: 0.9430 - precision: 0.9892 - recall: 0.8931 - f1_score: 0.9377 - val_loss: 0.6040 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 531/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5763 - acc: 0.9430 - precision: 0.9883 - recall: 0.8934 - f1_score: 0.9368 - val_loss: 0.6021 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 532/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5744 - acc: 0.9430 - precision: 0.9901 - recall: 0.8949 - f1_score: 0.9389 - val_loss: 0.6002 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 533/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5725 - acc: 0.9430 - precision: 0.9889 - recall: 0.8946 - f1_score: 0.9386 - val_loss: 0.5984 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 534/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5707 - acc: 0.9430 - precision: 0.9900 - recall: 0.8970 - f1_score: 0.9393 - val_loss: 0.5965 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 535/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5688 - acc: 0.9430 - precision: 0.9893 - recall: 0.8931 - f1_score: 0.9384 - val_loss: 0.5947 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 536/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5669 - acc: 0.9430 - precision: 0.9897 - recall: 0.8988 - f1_score: 0.9407 - val_loss: 0.5929 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 537/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5651 - acc: 0.9430 - precision: 0.9897 - recall: 0.8956 - f1_score: 0.9392 - val_loss: 0.5910 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 538/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5633 - acc: 0.9430 - precision: 0.9905 - recall: 0.8951 - f1_score: 0.9396 - val_loss: 0.5892 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 539/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5615 - acc: 0.9430 - precision: 0.9889 - recall: 0.8938 - f1_score: 0.9378 - val_loss: 0.5874 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 540/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5596 - acc: 0.9430 - precision: 0.9902 - recall: 0.8957 - f1_score: 0.9400 - val_loss: 0.5856 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 541/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5578 - acc: 0.9430 - precision: 0.9900 - recall: 0.8929 - f1_score: 0.9373 - val_loss: 0.5838 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 542/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5560 - acc: 0.9430 - precision: 0.9885 - recall: 0.8918 - f1_score: 0.9349 - val_loss: 0.5821 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 543/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5542 - acc: 0.9430 - precision: 0.9891 - recall: 0.8982 - f1_score: 0.9409 - val_loss: 0.5803 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.5525 - acc: 0.9430 - precision: 0.9889 - recall: 0.8905 - f1_score: 0.9359 - val_loss: 0.5785 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 545/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5507 - acc: 0.9430 - precision: 0.9870 - recall: 0.8931 - f1_score: 0.9375 - val_loss: 0.5768 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 546/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5489 - acc: 0.9430 - precision: 0.9905 - recall: 0.8954 - f1_score: 0.9396 - val_loss: 0.5750 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 547/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5472 - acc: 0.9430 - precision: 0.9900 - recall: 0.8923 - f1_score: 0.9369 - val_loss: 0.5733 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 548/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5454 - acc: 0.9430 - precision: 0.9886 - recall: 0.8940 - f1_score: 0.9381 - val_loss: 0.5716 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 549/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5437 - acc: 0.9430 - precision: 0.9896 - recall: 0.8983 - f1_score: 0.9404 - val_loss: 0.5699 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 550/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5420 - acc: 0.9430 - precision: 0.9905 - recall: 0.8931 - f1_score: 0.9375 - val_loss: 0.5682 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 551/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5403 - acc: 0.9430 - precision: 0.9893 - recall: 0.8945 - f1_score: 0.9385 - val_loss: 0.5665 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 552/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5385 - acc: 0.9430 - precision: 0.9869 - recall: 0.8992 - f1_score: 0.9397 - val_loss: 0.5648 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 553/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5368 - acc: 0.9430 - precision: 0.9905 - recall: 0.8970 - f1_score: 0.9408 - val_loss: 0.5631 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 554/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5352 - acc: 0.9430 - precision: 0.9873 - recall: 0.8943 - f1_score: 0.9369 - val_loss: 0.5614 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 555/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5335 - acc: 0.9430 - precision: 0.9893 - recall: 0.8980 - f1_score: 0.9405 - val_loss: 0.5598 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 556/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5318 - acc: 0.9430 - precision: 0.9905 - recall: 0.8931 - f1_score: 0.9382 - val_loss: 0.5581 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 557/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5301 - acc: 0.9430 - precision: 0.9900 - recall: 0.8890 - f1_score: 0.9351 - val_loss: 0.5565 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 558/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5285 - acc: 0.9430 - precision: 0.9901 - recall: 0.8957 - f1_score: 0.9389 - val_loss: 0.5548 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 559/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5268 - acc: 0.9430 - precision: 0.9895 - recall: 0.8965 - f1_score: 0.9400 - val_loss: 0.5532 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 560/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5252 - acc: 0.9430 - precision: 0.9905 - recall: 0.8964 - f1_score: 0.9400 - val_loss: 0.5516 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 561/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5235 - acc: 0.9430 - precision: 0.9895 - recall: 0.8957 - f1_score: 0.9395 - val_loss: 0.5500 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 562/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5219 - acc: 0.9430 - precision: 0.9902 - recall: 0.8967 - f1_score: 0.9405 - val_loss: 0.5484 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 563/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5203 - acc: 0.9430 - precision: 0.9891 - recall: 0.8988 - f1_score: 0.9403 - val_loss: 0.5468 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 564/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5187 - acc: 0.9430 - precision: 0.9900 - recall: 0.8974 - f1_score: 0.9396 - val_loss: 0.5452 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 565/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5171 - acc: 0.9430 - precision: 0.9892 - recall: 0.8995 - f1_score: 0.9409 - val_loss: 0.5436 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 566/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5155 - acc: 0.9430 - precision: 0.9895 - recall: 0.8931 - f1_score: 0.9374 - val_loss: 0.5420 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 567/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5139 - acc: 0.9430 - precision: 0.9894 - recall: 0.8932 - f1_score: 0.9383 - val_loss: 0.5405 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 568/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5123 - acc: 0.9430 - precision: 0.9906 - recall: 0.8934 - f1_score: 0.9376 - val_loss: 0.5389 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 569/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5107 - acc: 0.9430 - precision: 0.9883 - recall: 0.8920 - f1_score: 0.9368 - val_loss: 0.5373 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 570/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5092 - acc: 0.9430 - precision: 0.9881 - recall: 0.8913 - f1_score: 0.9363 - val_loss: 0.5358 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 571/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5076 - acc: 0.9430 - precision: 0.9892 - recall: 0.8941 - f1_score: 0.9386 - val_loss: 0.5343 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 572/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5060 - acc: 0.9430 - precision: 0.9890 - recall: 0.8940 - f1_score: 0.9378 - val_loss: 0.5327 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 573/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5045 - acc: 0.9430 - precision: 0.9904 - recall: 0.8949 - f1_score: 0.9386 - val_loss: 0.5312 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 574/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5030 - acc: 0.9430 - precision: 0.9906 - recall: 0.8967 - f1_score: 0.9399 - val_loss: 0.5297 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 575/1000\n",
      "632/632 [==============================] - 0s - loss: 0.5014 - acc: 0.9430 - precision: 0.9892 - recall: 0.8914 - f1_score: 0.9370 - val_loss: 0.5282 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 576/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4999 - acc: 0.9430 - precision: 0.9890 - recall: 0.8932 - f1_score: 0.9374 - val_loss: 0.5267 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 577/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4984 - acc: 0.9430 - precision: 0.9904 - recall: 0.8960 - f1_score: 0.9397 - val_loss: 0.5252 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 578/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4969 - acc: 0.9430 - precision: 0.9888 - recall: 0.8918 - f1_score: 0.9369 - val_loss: 0.5237 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 579/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4954 - acc: 0.9430 - precision: 0.9902 - recall: 0.8994 - f1_score: 0.9418 - val_loss: 0.5223 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 580/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4939 - acc: 0.9430 - precision: 0.9906 - recall: 0.8961 - f1_score: 0.9397 - val_loss: 0.5208 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 581/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4924 - acc: 0.9430 - precision: 0.9902 - recall: 0.8969 - f1_score: 0.9403 - val_loss: 0.5193 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 582/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4910 - acc: 0.9430 - precision: 0.9878 - recall: 0.8920 - f1_score: 0.9368 - val_loss: 0.5179 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 583/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4895 - acc: 0.9430 - precision: 0.9891 - recall: 0.8985 - f1_score: 0.9405 - val_loss: 0.5164 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 584/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4880 - acc: 0.9430 - precision: 0.9902 - recall: 0.8898 - f1_score: 0.9351 - val_loss: 0.5150 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 585/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4866 - acc: 0.9430 - precision: 0.9877 - recall: 0.8922 - f1_score: 0.9373 - val_loss: 0.5135 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 586/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4851 - acc: 0.9430 - precision: 0.9915 - recall: 0.8965 - f1_score: 0.9404 - val_loss: 0.5121 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 587/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4837 - acc: 0.9430 - precision: 0.9893 - recall: 0.8984 - f1_score: 0.9404 - val_loss: 0.5107 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 588/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.4968 - acc: 0.9400 - precision: 1.0000 - recall: 0.8696 - f1_score: 0.930 - 0s - loss: 0.4823 - acc: 0.9430 - precision: 0.9894 - recall: 0.8924 - f1_score: 0.9378 - val_loss: 0.5093 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 589/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4808 - acc: 0.9430 - precision: 0.9898 - recall: 0.8902 - f1_score: 0.9352 - val_loss: 0.5079 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 590/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4794 - acc: 0.9430 - precision: 0.9905 - recall: 0.8970 - f1_score: 0.9398 - val_loss: 0.5065 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 591/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4780 - acc: 0.9430 - precision: 0.9903 - recall: 0.8993 - f1_score: 0.9417 - val_loss: 0.5051 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 592/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4766 - acc: 0.9430 - precision: 0.9897 - recall: 0.8923 - f1_score: 0.9379 - val_loss: 0.5037 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 593/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4752 - acc: 0.9430 - precision: 0.9907 - recall: 0.8949 - f1_score: 0.9400 - val_loss: 0.5023 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 594/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4738 - acc: 0.9430 - precision: 0.9908 - recall: 0.8932 - f1_score: 0.9382 - val_loss: 0.5009 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 595/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4724 - acc: 0.9430 - precision: 0.9888 - recall: 0.8906 - f1_score: 0.9357 - val_loss: 0.4996 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 596/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4710 - acc: 0.9430 - precision: 0.9891 - recall: 0.8946 - f1_score: 0.9388 - val_loss: 0.4982 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 597/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4697 - acc: 0.9430 - precision: 0.9886 - recall: 0.8954 - f1_score: 0.9391 - val_loss: 0.4968 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 598/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4683 - acc: 0.9430 - precision: 0.9901 - recall: 0.8911 - f1_score: 0.9373 - val_loss: 0.4955 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 599/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4669 - acc: 0.9430 - precision: 0.9893 - recall: 0.8959 - f1_score: 0.9387 - val_loss: 0.4942 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 600/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4656 - acc: 0.9430 - precision: 0.9885 - recall: 0.8983 - f1_score: 0.9399 - val_loss: 0.4928 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 601/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4642 - acc: 0.9430 - precision: 0.9888 - recall: 0.8965 - f1_score: 0.9385 - val_loss: 0.4915 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 602/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4629 - acc: 0.9430 - precision: 0.9898 - recall: 0.8950 - f1_score: 0.9391 - val_loss: 0.4902 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 603/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4616 - acc: 0.9430 - precision: 0.9880 - recall: 0.8919 - f1_score: 0.9364 - val_loss: 0.4889 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 604/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4602 - acc: 0.9430 - precision: 0.9887 - recall: 0.8956 - f1_score: 0.9392 - val_loss: 0.4876 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 605/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4589 - acc: 0.9430 - precision: 0.9883 - recall: 0.8985 - f1_score: 0.9402 - val_loss: 0.4863 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 606/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4576 - acc: 0.9430 - precision: 0.9901 - recall: 0.8935 - f1_score: 0.9380 - val_loss: 0.4850 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 607/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4563 - acc: 0.9430 - precision: 0.9892 - recall: 0.8968 - f1_score: 0.9397 - val_loss: 0.4837 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4550 - acc: 0.9430 - precision: 0.9917 - recall: 0.8920 - f1_score: 0.9380 - val_loss: 0.4824 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 609/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4537 - acc: 0.9430 - precision: 0.9901 - recall: 0.8948 - f1_score: 0.9391 - val_loss: 0.4812 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 610/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4524 - acc: 0.9430 - precision: 0.9896 - recall: 0.8937 - f1_score: 0.9383 - val_loss: 0.4799 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 611/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4511 - acc: 0.9430 - precision: 0.9894 - recall: 0.8959 - f1_score: 0.9392 - val_loss: 0.4786 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 612/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4499 - acc: 0.9430 - precision: 0.9887 - recall: 0.8933 - f1_score: 0.9370 - val_loss: 0.4774 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 613/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4486 - acc: 0.9430 - precision: 0.9898 - recall: 0.8976 - f1_score: 0.9400 - val_loss: 0.4761 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 614/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4473 - acc: 0.9430 - precision: 0.9911 - recall: 0.8941 - f1_score: 0.9390 - val_loss: 0.4749 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 615/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4461 - acc: 0.9430 - precision: 0.9890 - recall: 0.8956 - f1_score: 0.9393 - val_loss: 0.4737 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 616/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4448 - acc: 0.9430 - precision: 0.9881 - recall: 0.8955 - f1_score: 0.9384 - val_loss: 0.4724 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 617/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4436 - acc: 0.9446 - precision: 0.9883 - recall: 0.8998 - f1_score: 0.9410 - val_loss: 0.4712 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 618/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4423 - acc: 0.9446 - precision: 0.9899 - recall: 0.9004 - f1_score: 0.9412 - val_loss: 0.4700 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 619/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4411 - acc: 0.9446 - precision: 0.9895 - recall: 0.8967 - f1_score: 0.9401 - val_loss: 0.4688 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 620/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4399 - acc: 0.9446 - precision: 0.9902 - recall: 0.8972 - f1_score: 0.9407 - val_loss: 0.4676 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 621/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4387 - acc: 0.9446 - precision: 0.9889 - recall: 0.8983 - f1_score: 0.9402 - val_loss: 0.4664 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 622/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4375 - acc: 0.9446 - precision: 0.9889 - recall: 0.8991 - f1_score: 0.9403 - val_loss: 0.4652 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 623/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4363 - acc: 0.9446 - precision: 0.9908 - recall: 0.8986 - f1_score: 0.9413 - val_loss: 0.4640 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 624/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4350 - acc: 0.9446 - precision: 0.9892 - recall: 0.8999 - f1_score: 0.9414 - val_loss: 0.4628 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 625/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4338 - acc: 0.9446 - precision: 0.9871 - recall: 0.8975 - f1_score: 0.9399 - val_loss: 0.4616 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 626/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4327 - acc: 0.9446 - precision: 0.9902 - recall: 0.9000 - f1_score: 0.9412 - val_loss: 0.4604 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 627/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4315 - acc: 0.9446 - precision: 0.9892 - recall: 0.8977 - f1_score: 0.9403 - val_loss: 0.4593 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 628/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4303 - acc: 0.9446 - precision: 0.9888 - recall: 0.8988 - f1_score: 0.9411 - val_loss: 0.4581 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 629/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4291 - acc: 0.9446 - precision: 0.9898 - recall: 0.8986 - f1_score: 0.9415 - val_loss: 0.4569 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 630/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4280 - acc: 0.9446 - precision: 0.9894 - recall: 0.8992 - f1_score: 0.9412 - val_loss: 0.4558 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 631/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4268 - acc: 0.9446 - precision: 0.9886 - recall: 0.8993 - f1_score: 0.9407 - val_loss: 0.4546 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 632/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4256 - acc: 0.9446 - precision: 0.9907 - recall: 0.8963 - f1_score: 0.9399 - val_loss: 0.4535 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 633/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4245 - acc: 0.9446 - precision: 0.9896 - recall: 0.8958 - f1_score: 0.9400 - val_loss: 0.4524 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 634/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4233 - acc: 0.9446 - precision: 0.9904 - recall: 0.8984 - f1_score: 0.9411 - val_loss: 0.4512 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 635/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4222 - acc: 0.9446 - precision: 0.9904 - recall: 0.8959 - f1_score: 0.9399 - val_loss: 0.4501 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 636/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4211 - acc: 0.9446 - precision: 0.9896 - recall: 0.9010 - f1_score: 0.9417 - val_loss: 0.4490 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 637/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4199 - acc: 0.9446 - precision: 0.9891 - recall: 0.8965 - f1_score: 0.9396 - val_loss: 0.4479 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 638/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4188 - acc: 0.9446 - precision: 0.9898 - recall: 0.9007 - f1_score: 0.9415 - val_loss: 0.4468 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 639/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4177 - acc: 0.9446 - precision: 0.9885 - recall: 0.8951 - f1_score: 0.9376 - val_loss: 0.4457 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.4166 - acc: 0.9446 - precision: 0.9907 - recall: 0.8962 - f1_score: 0.9400 - val_loss: 0.4446 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 641/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4155 - acc: 0.9446 - precision: 0.9907 - recall: 0.8979 - f1_score: 0.9412 - val_loss: 0.4435 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 642/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4144 - acc: 0.9446 - precision: 0.9897 - recall: 0.8983 - f1_score: 0.9396 - val_loss: 0.4424 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 643/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4133 - acc: 0.9446 - precision: 0.9882 - recall: 0.9006 - f1_score: 0.9411 - val_loss: 0.4413 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 644/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4122 - acc: 0.9446 - precision: 0.9863 - recall: 0.8916 - f1_score: 0.9346 - val_loss: 0.4403 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 645/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4111 - acc: 0.9446 - precision: 0.9896 - recall: 0.8964 - f1_score: 0.9395 - val_loss: 0.4392 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 646/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4100 - acc: 0.9446 - precision: 0.9889 - recall: 0.9022 - f1_score: 0.9420 - val_loss: 0.4381 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 647/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4089 - acc: 0.9446 - precision: 0.9890 - recall: 0.8962 - f1_score: 0.9392 - val_loss: 0.4371 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 648/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4079 - acc: 0.9446 - precision: 0.9917 - recall: 0.8970 - f1_score: 0.9396 - val_loss: 0.4360 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 649/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4068 - acc: 0.9446 - precision: 0.9892 - recall: 0.9027 - f1_score: 0.9432 - val_loss: 0.4350 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 650/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4057 - acc: 0.9446 - precision: 0.9906 - recall: 0.8993 - f1_score: 0.9416 - val_loss: 0.4339 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 651/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4047 - acc: 0.9446 - precision: 0.9891 - recall: 0.8970 - f1_score: 0.9397 - val_loss: 0.4329 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 652/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4036 - acc: 0.9446 - precision: 0.9889 - recall: 0.8973 - f1_score: 0.9400 - val_loss: 0.4318 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 653/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4026 - acc: 0.9446 - precision: 0.9886 - recall: 0.8973 - f1_score: 0.9389 - val_loss: 0.4308 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 654/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4015 - acc: 0.9446 - precision: 0.9884 - recall: 0.9025 - f1_score: 0.9424 - val_loss: 0.4298 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 655/1000\n",
      "632/632 [==============================] - 0s - loss: 0.4005 - acc: 0.9446 - precision: 0.9898 - recall: 0.8978 - f1_score: 0.9401 - val_loss: 0.4288 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 656/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3995 - acc: 0.9446 - precision: 0.9891 - recall: 0.9027 - f1_score: 0.9425 - val_loss: 0.4278 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 657/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3985 - acc: 0.9446 - precision: 0.9893 - recall: 0.8987 - f1_score: 0.9408 - val_loss: 0.4268 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 658/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3974 - acc: 0.9446 - precision: 0.9901 - recall: 0.8960 - f1_score: 0.9394 - val_loss: 0.4258 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 659/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3964 - acc: 0.9446 - precision: 0.9895 - recall: 0.8992 - f1_score: 0.9410 - val_loss: 0.4248 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 660/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3954 - acc: 0.9446 - precision: 0.9892 - recall: 0.8944 - f1_score: 0.9382 - val_loss: 0.4238 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 661/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3944 - acc: 0.9446 - precision: 0.9895 - recall: 0.8952 - f1_score: 0.9379 - val_loss: 0.4228 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 662/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3934 - acc: 0.9446 - precision: 0.9893 - recall: 0.9008 - f1_score: 0.9420 - val_loss: 0.4218 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 663/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3924 - acc: 0.9446 - precision: 0.9903 - recall: 0.9008 - f1_score: 0.9421 - val_loss: 0.4208 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 664/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3914 - acc: 0.9446 - precision: 0.9891 - recall: 0.8958 - f1_score: 0.9386 - val_loss: 0.4198 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 665/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3904 - acc: 0.9446 - precision: 0.9881 - recall: 0.8954 - f1_score: 0.9382 - val_loss: 0.4188 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 666/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3894 - acc: 0.9446 - precision: 0.9903 - recall: 0.9011 - f1_score: 0.9423 - val_loss: 0.4179 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 667/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3885 - acc: 0.9446 - precision: 0.9902 - recall: 0.8983 - f1_score: 0.9403 - val_loss: 0.4169 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 668/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3875 - acc: 0.9446 - precision: 0.9893 - recall: 0.9001 - f1_score: 0.9416 - val_loss: 0.4160 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 669/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3865 - acc: 0.9446 - precision: 0.9899 - recall: 0.8962 - f1_score: 0.9397 - val_loss: 0.4150 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 670/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3856 - acc: 0.9446 - precision: 0.9892 - recall: 0.9004 - f1_score: 0.9417 - val_loss: 0.4141 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 671/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3846 - acc: 0.9446 - precision: 0.9893 - recall: 0.9009 - f1_score: 0.9410 - val_loss: 0.4132 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3836 - acc: 0.9446 - precision: 0.9911 - recall: 0.8979 - f1_score: 0.9410 - val_loss: 0.4122 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 673/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3827 - acc: 0.9446 - precision: 0.9886 - recall: 0.8862 - f1_score: 0.9323 - val_loss: 0.4113 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 674/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3818 - acc: 0.9446 - precision: 0.9895 - recall: 0.9017 - f1_score: 0.9422 - val_loss: 0.4103 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 675/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3808 - acc: 0.9446 - precision: 0.9886 - recall: 0.9055 - f1_score: 0.9433 - val_loss: 0.4094 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 676/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3799 - acc: 0.9446 - precision: 0.9901 - recall: 0.8989 - f1_score: 0.9414 - val_loss: 0.4085 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 677/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3789 - acc: 0.9446 - precision: 0.9904 - recall: 0.8991 - f1_score: 0.9393 - val_loss: 0.4076 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 678/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3780 - acc: 0.9446 - precision: 0.9898 - recall: 0.8974 - f1_score: 0.9403 - val_loss: 0.4067 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 679/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3771 - acc: 0.9446 - precision: 0.9899 - recall: 0.9014 - f1_score: 0.9422 - val_loss: 0.4058 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 680/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3762 - acc: 0.9446 - precision: 0.9890 - recall: 0.9028 - f1_score: 0.9421 - val_loss: 0.4049 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 681/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3753 - acc: 0.9446 - precision: 0.9894 - recall: 0.8984 - f1_score: 0.9407 - val_loss: 0.4040 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 682/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3743 - acc: 0.9446 - precision: 0.9898 - recall: 0.8978 - f1_score: 0.9406 - val_loss: 0.4031 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 683/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3734 - acc: 0.9446 - precision: 0.9901 - recall: 0.8974 - f1_score: 0.9405 - val_loss: 0.4022 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 684/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3725 - acc: 0.9446 - precision: 0.9897 - recall: 0.8976 - f1_score: 0.9400 - val_loss: 0.4013 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 685/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3716 - acc: 0.9446 - precision: 0.9883 - recall: 0.8971 - f1_score: 0.9398 - val_loss: 0.4004 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 686/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3707 - acc: 0.9446 - precision: 0.9896 - recall: 0.8960 - f1_score: 0.9386 - val_loss: 0.3996 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 687/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3699 - acc: 0.9446 - precision: 0.9887 - recall: 0.8957 - f1_score: 0.9393 - val_loss: 0.3987 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 688/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3690 - acc: 0.9446 - precision: 0.9905 - recall: 0.8968 - f1_score: 0.9389 - val_loss: 0.3978 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 689/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3681 - acc: 0.9446 - precision: 0.9891 - recall: 0.9000 - f1_score: 0.9417 - val_loss: 0.3970 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 690/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3672 - acc: 0.9446 - precision: 0.9897 - recall: 0.8976 - f1_score: 0.9402 - val_loss: 0.3961 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 691/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3663 - acc: 0.9446 - precision: 0.9894 - recall: 0.8957 - f1_score: 0.9388 - val_loss: 0.3952 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 692/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3655 - acc: 0.9446 - precision: 0.9894 - recall: 0.8949 - f1_score: 0.9392 - val_loss: 0.3944 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 693/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3646 - acc: 0.9446 - precision: 0.9905 - recall: 0.8979 - f1_score: 0.9407 - val_loss: 0.3935 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 694/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3638 - acc: 0.9446 - precision: 0.9898 - recall: 0.8992 - f1_score: 0.9417 - val_loss: 0.3927 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 695/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3629 - acc: 0.9446 - precision: 0.9897 - recall: 0.8939 - f1_score: 0.9378 - val_loss: 0.3919 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 696/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3620 - acc: 0.9446 - precision: 0.9898 - recall: 0.8980 - f1_score: 0.9409 - val_loss: 0.3910 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 697/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3612 - acc: 0.9446 - precision: 0.9899 - recall: 0.8942 - f1_score: 0.9389 - val_loss: 0.3902 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 698/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3604 - acc: 0.9446 - precision: 0.9890 - recall: 0.8895 - f1_score: 0.9353 - val_loss: 0.3894 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 699/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3595 - acc: 0.9446 - precision: 0.9896 - recall: 0.8985 - f1_score: 0.9405 - val_loss: 0.3885 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 700/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3587 - acc: 0.9446 - precision: 0.9900 - recall: 0.9010 - f1_score: 0.9418 - val_loss: 0.3877 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 701/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3579 - acc: 0.9446 - precision: 0.9888 - recall: 0.8933 - f1_score: 0.9373 - val_loss: 0.3869 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 702/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3570 - acc: 0.9446 - precision: 0.9885 - recall: 0.9026 - f1_score: 0.9417 - val_loss: 0.3861 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 703/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3562 - acc: 0.9446 - precision: 0.9901 - recall: 0.8971 - f1_score: 0.9405 - val_loss: 0.3853 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 704/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3554 - acc: 0.9446 - precision: 0.9904 - recall: 0.9080 - f1_score: 0.9455 - val_loss: 0.3845 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 705/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3546 - acc: 0.9446 - precision: 0.9898 - recall: 0.8974 - f1_score: 0.9410 - val_loss: 0.3837 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 706/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3537 - acc: 0.9446 - precision: 0.9904 - recall: 0.8994 - f1_score: 0.9414 - val_loss: 0.3829 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 707/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3529 - acc: 0.9446 - precision: 0.9879 - recall: 0.8992 - f1_score: 0.9405 - val_loss: 0.3821 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 708/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3521 - acc: 0.9446 - precision: 0.9912 - recall: 0.9008 - f1_score: 0.9423 - val_loss: 0.3813 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 709/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3513 - acc: 0.9446 - precision: 0.9895 - recall: 0.8969 - f1_score: 0.9403 - val_loss: 0.3805 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 710/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3505 - acc: 0.9446 - precision: 0.9888 - recall: 0.8974 - f1_score: 0.9400 - val_loss: 0.3797 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 711/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3497 - acc: 0.9446 - precision: 0.9896 - recall: 0.8963 - f1_score: 0.9397 - val_loss: 0.3789 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 712/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3490 - acc: 0.9446 - precision: 0.9893 - recall: 0.8975 - f1_score: 0.9399 - val_loss: 0.3782 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 713/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3482 - acc: 0.9446 - precision: 0.9887 - recall: 0.8973 - f1_score: 0.9393 - val_loss: 0.3774 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 714/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3474 - acc: 0.9446 - precision: 0.9907 - recall: 0.8966 - f1_score: 0.9392 - val_loss: 0.3766 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 715/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3466 - acc: 0.9446 - precision: 0.9898 - recall: 0.9005 - f1_score: 0.9423 - val_loss: 0.3759 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 716/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3458 - acc: 0.9446 - precision: 0.9902 - recall: 0.8988 - f1_score: 0.9416 - val_loss: 0.3751 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 717/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3451 - acc: 0.9446 - precision: 0.9895 - recall: 0.8964 - f1_score: 0.9392 - val_loss: 0.3744 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 718/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3443 - acc: 0.9446 - precision: 0.9906 - recall: 0.9000 - f1_score: 0.9425 - val_loss: 0.3736 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 719/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3435 - acc: 0.9446 - precision: 0.9896 - recall: 0.8964 - f1_score: 0.9400 - val_loss: 0.3728 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 720/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3428 - acc: 0.9446 - precision: 0.9899 - recall: 0.8978 - f1_score: 0.9403 - val_loss: 0.3721 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 721/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3420 - acc: 0.9446 - precision: 0.9885 - recall: 0.8947 - f1_score: 0.9380 - val_loss: 0.3714 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 722/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3413 - acc: 0.9446 - precision: 0.9897 - recall: 0.9014 - f1_score: 0.9425 - val_loss: 0.3706 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 723/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3405 - acc: 0.9446 - precision: 0.9897 - recall: 0.8992 - f1_score: 0.9415 - val_loss: 0.3699 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 724/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3398 - acc: 0.9446 - precision: 0.9905 - recall: 0.8994 - f1_score: 0.9419 - val_loss: 0.3691 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 725/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3390 - acc: 0.9446 - precision: 0.9903 - recall: 0.9002 - f1_score: 0.9419 - val_loss: 0.3684 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 726/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3383 - acc: 0.9446 - precision: 0.9896 - recall: 0.8946 - f1_score: 0.9380 - val_loss: 0.3677 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 727/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3376 - acc: 0.9446 - precision: 0.9889 - recall: 0.8970 - f1_score: 0.9399 - val_loss: 0.3670 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 728/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3368 - acc: 0.9446 - precision: 0.9883 - recall: 0.8969 - f1_score: 0.9393 - val_loss: 0.3663 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 729/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3361 - acc: 0.9446 - precision: 0.9881 - recall: 0.8988 - f1_score: 0.9405 - val_loss: 0.3655 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 730/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3354 - acc: 0.9446 - precision: 0.9889 - recall: 0.8976 - f1_score: 0.9400 - val_loss: 0.3648 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 731/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3347 - acc: 0.9446 - precision: 0.9893 - recall: 0.8959 - f1_score: 0.9388 - val_loss: 0.3641 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 732/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3339 - acc: 0.9446 - precision: 0.9890 - recall: 0.8965 - f1_score: 0.9397 - val_loss: 0.3634 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 733/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3332 - acc: 0.9446 - precision: 0.9884 - recall: 0.8973 - f1_score: 0.9400 - val_loss: 0.3628 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 734/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3325 - acc: 0.9446 - precision: 0.9903 - recall: 0.9004 - f1_score: 0.9419 - val_loss: 0.3621 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 735/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3318 - acc: 0.9446 - precision: 0.9900 - recall: 0.8984 - f1_score: 0.9414 - val_loss: 0.3614 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 736/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3311 - acc: 0.9446 - precision: 0.9882 - recall: 0.9008 - f1_score: 0.9416 - val_loss: 0.3607 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 737/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3304 - acc: 0.9446 - precision: 0.9895 - recall: 0.8996 - f1_score: 0.9414 - val_loss: 0.3600 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 738/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3297 - acc: 0.9446 - precision: 0.9899 - recall: 0.9009 - f1_score: 0.9425 - val_loss: 0.3593 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 739/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3290 - acc: 0.9446 - precision: 0.9896 - recall: 0.8983 - f1_score: 0.9405 - val_loss: 0.3586 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 740/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3283 - acc: 0.9446 - precision: 0.9868 - recall: 0.8895 - f1_score: 0.9335 - val_loss: 0.3579 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 741/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3276 - acc: 0.9446 - precision: 0.9903 - recall: 0.9002 - f1_score: 0.9419 - val_loss: 0.3573 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 742/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3269 - acc: 0.9446 - precision: 0.9888 - recall: 0.8985 - f1_score: 0.9395 - val_loss: 0.3566 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 743/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3263 - acc: 0.9446 - precision: 0.9885 - recall: 0.8981 - f1_score: 0.9398 - val_loss: 0.3559 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 744/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3256 - acc: 0.9446 - precision: 0.9919 - recall: 0.8961 - f1_score: 0.9393 - val_loss: 0.3553 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 745/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3249 - acc: 0.9446 - precision: 0.9886 - recall: 0.8961 - f1_score: 0.9385 - val_loss: 0.3546 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 746/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3242 - acc: 0.9446 - precision: 0.9904 - recall: 0.8958 - f1_score: 0.9386 - val_loss: 0.3539 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 747/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3236 - acc: 0.9446 - precision: 0.9899 - recall: 0.8966 - f1_score: 0.9393 - val_loss: 0.3533 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 748/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3229 - acc: 0.9446 - precision: 0.9901 - recall: 0.9028 - f1_score: 0.9436 - val_loss: 0.3526 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 749/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3222 - acc: 0.9446 - precision: 0.9894 - recall: 0.8988 - f1_score: 0.9407 - val_loss: 0.3520 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 750/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3216 - acc: 0.9446 - precision: 0.9901 - recall: 0.8991 - f1_score: 0.9420 - val_loss: 0.3513 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 751/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3209 - acc: 0.9446 - precision: 0.9901 - recall: 0.8993 - f1_score: 0.9412 - val_loss: 0.3507 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 752/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3203 - acc: 0.9446 - precision: 0.9896 - recall: 0.8991 - f1_score: 0.9416 - val_loss: 0.3501 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 753/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3196 - acc: 0.9446 - precision: 0.9904 - recall: 0.8970 - f1_score: 0.9406 - val_loss: 0.3494 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 754/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3190 - acc: 0.9446 - precision: 0.9902 - recall: 0.8999 - f1_score: 0.9422 - val_loss: 0.3488 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 755/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3183 - acc: 0.9446 - precision: 0.9885 - recall: 0.9005 - f1_score: 0.9410 - val_loss: 0.3482 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 756/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3177 - acc: 0.9446 - precision: 0.9897 - recall: 0.8978 - f1_score: 0.9405 - val_loss: 0.3475 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 757/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3170 - acc: 0.9446 - precision: 0.9853 - recall: 0.8933 - f1_score: 0.9363 - val_loss: 0.3469 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 758/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3164 - acc: 0.9446 - precision: 0.9898 - recall: 0.9009 - f1_score: 0.9423 - val_loss: 0.3463 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 759/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3158 - acc: 0.9446 - precision: 0.9906 - recall: 0.8980 - f1_score: 0.9403 - val_loss: 0.3457 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 760/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3151 - acc: 0.9446 - precision: 0.9906 - recall: 0.9006 - f1_score: 0.9422 - val_loss: 0.3451 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 761/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3145 - acc: 0.9446 - precision: 0.9889 - recall: 0.8982 - f1_score: 0.9393 - val_loss: 0.3444 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 762/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3139 - acc: 0.9446 - precision: 0.9905 - recall: 0.8978 - f1_score: 0.9411 - val_loss: 0.3438 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 763/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3133 - acc: 0.9446 - precision: 0.9907 - recall: 0.9032 - f1_score: 0.9437 - val_loss: 0.3432 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 764/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3127 - acc: 0.9446 - precision: 0.9893 - recall: 0.8981 - f1_score: 0.9405 - val_loss: 0.3426 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 765/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3120 - acc: 0.9446 - precision: 0.9901 - recall: 0.8991 - f1_score: 0.9414 - val_loss: 0.3420 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 766/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3114 - acc: 0.9446 - precision: 0.9895 - recall: 0.9007 - f1_score: 0.9425 - val_loss: 0.3414 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 767/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3108 - acc: 0.9446 - precision: 0.9902 - recall: 0.9022 - f1_score: 0.9430 - val_loss: 0.3408 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.3102 - acc: 0.9446 - precision: 0.9881 - recall: 0.8952 - f1_score: 0.9387 - val_loss: 0.3402 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 769/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3096 - acc: 0.9446 - precision: 0.9896 - recall: 0.8973 - f1_score: 0.9402 - val_loss: 0.3396 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 770/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3090 - acc: 0.9446 - precision: 0.9909 - recall: 0.8994 - f1_score: 0.9420 - val_loss: 0.3391 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 771/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3084 - acc: 0.9446 - precision: 0.9880 - recall: 0.8948 - f1_score: 0.9387 - val_loss: 0.3385 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 772/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3078 - acc: 0.9446 - precision: 0.9900 - recall: 0.9009 - f1_score: 0.9427 - val_loss: 0.3379 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 773/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3072 - acc: 0.9446 - precision: 0.9900 - recall: 0.9011 - f1_score: 0.9410 - val_loss: 0.3373 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 774/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3066 - acc: 0.9446 - precision: 0.9893 - recall: 0.8970 - f1_score: 0.9401 - val_loss: 0.3367 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 775/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3060 - acc: 0.9446 - precision: 0.9906 - recall: 0.8975 - f1_score: 0.9397 - val_loss: 0.3361 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 776/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3055 - acc: 0.9446 - precision: 0.9908 - recall: 0.9007 - f1_score: 0.9424 - val_loss: 0.3356 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 777/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3049 - acc: 0.9446 - precision: 0.9875 - recall: 0.8970 - f1_score: 0.9386 - val_loss: 0.3350 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 778/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3043 - acc: 0.9446 - precision: 0.9896 - recall: 0.8979 - f1_score: 0.9403 - val_loss: 0.3344 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 779/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3037 - acc: 0.9446 - precision: 0.9903 - recall: 0.8980 - f1_score: 0.9400 - val_loss: 0.3339 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 780/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3031 - acc: 0.9446 - precision: 0.9900 - recall: 0.9007 - f1_score: 0.9422 - val_loss: 0.3333 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 781/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3026 - acc: 0.9446 - precision: 0.9904 - recall: 0.9012 - f1_score: 0.9421 - val_loss: 0.3328 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 782/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3020 - acc: 0.9446 - precision: 0.9893 - recall: 0.8977 - f1_score: 0.9404 - val_loss: 0.3322 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 783/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3014 - acc: 0.9446 - precision: 0.9892 - recall: 0.8952 - f1_score: 0.9382 - val_loss: 0.3317 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 784/1000\n",
      "632/632 [==============================] - 0s - loss: 0.3009 - acc: 0.9446 - precision: 0.9896 - recall: 0.8958 - f1_score: 0.9388 - val_loss: 0.3311 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 785/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.9400 - precision: 1.0000 - recall: 0.8750 - f1_score: 0.933 - 0s - loss: 0.3003 - acc: 0.9446 - precision: 0.9885 - recall: 0.8925 - f1_score: 0.9358 - val_loss: 0.3306 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 786/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2998 - acc: 0.9446 - precision: 0.9908 - recall: 0.8951 - f1_score: 0.9390 - val_loss: 0.3300 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 787/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2992 - acc: 0.9446 - precision: 0.9892 - recall: 0.9028 - f1_score: 0.9427 - val_loss: 0.3295 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 788/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2987 - acc: 0.9446 - precision: 0.9893 - recall: 0.8982 - f1_score: 0.9410 - val_loss: 0.3289 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 789/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2981 - acc: 0.9446 - precision: 0.9903 - recall: 0.8961 - f1_score: 0.9395 - val_loss: 0.3284 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 790/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2976 - acc: 0.9446 - precision: 0.9895 - recall: 0.8978 - f1_score: 0.9396 - val_loss: 0.3278 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 791/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2970 - acc: 0.9446 - precision: 0.9898 - recall: 0.8998 - f1_score: 0.9416 - val_loss: 0.3273 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 792/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2965 - acc: 0.9446 - precision: 0.9883 - recall: 0.8947 - f1_score: 0.9374 - val_loss: 0.3268 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 793/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2959 - acc: 0.9446 - precision: 0.9884 - recall: 0.8978 - f1_score: 0.9397 - val_loss: 0.3262 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 794/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2954 - acc: 0.9446 - precision: 0.9895 - recall: 0.8948 - f1_score: 0.9389 - val_loss: 0.3257 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 795/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2948 - acc: 0.9446 - precision: 0.9906 - recall: 0.8974 - f1_score: 0.9411 - val_loss: 0.3252 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 796/1000\n",
      "632/632 [==============================] - ETA: 0s - loss: 0.3376 - acc: 0.9200 - precision: 1.0000 - recall: 0.8462 - f1_score: 0.916 - 0s - loss: 0.2943 - acc: 0.9446 - precision: 0.9882 - recall: 0.8966 - f1_score: 0.9392 - val_loss: 0.3247 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 797/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2938 - acc: 0.9446 - precision: 0.9885 - recall: 0.8982 - f1_score: 0.9405 - val_loss: 0.3241 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 798/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2933 - acc: 0.9446 - precision: 0.9903 - recall: 0.8984 - f1_score: 0.9403 - val_loss: 0.3236 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 799/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2927 - acc: 0.9446 - precision: 0.9901 - recall: 0.8989 - f1_score: 0.9406 - val_loss: 0.3231 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 800/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2922 - acc: 0.9446 - precision: 0.9900 - recall: 0.8995 - f1_score: 0.9412 - val_loss: 0.3226 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 801/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2917 - acc: 0.9446 - precision: 0.9886 - recall: 0.8969 - f1_score: 0.9395 - val_loss: 0.3221 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 802/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2912 - acc: 0.9446 - precision: 0.9899 - recall: 0.8996 - f1_score: 0.9419 - val_loss: 0.3216 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 803/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2906 - acc: 0.9446 - precision: 0.9902 - recall: 0.8978 - f1_score: 0.9409 - val_loss: 0.3211 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 804/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2901 - acc: 0.9446 - precision: 0.9892 - recall: 0.8988 - f1_score: 0.9402 - val_loss: 0.3206 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 805/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2896 - acc: 0.9446 - precision: 0.9904 - recall: 0.8965 - f1_score: 0.9402 - val_loss: 0.3201 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 806/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2891 - acc: 0.9446 - precision: 0.9864 - recall: 0.8944 - f1_score: 0.9375 - val_loss: 0.3196 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 807/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2886 - acc: 0.9446 - precision: 0.9907 - recall: 0.8971 - f1_score: 0.9407 - val_loss: 0.3191 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 808/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2881 - acc: 0.9446 - precision: 0.9893 - recall: 0.8972 - f1_score: 0.9404 - val_loss: 0.3186 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 809/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2876 - acc: 0.9446 - precision: 0.9891 - recall: 0.8971 - f1_score: 0.9400 - val_loss: 0.3181 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 810/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2871 - acc: 0.9446 - precision: 0.9890 - recall: 0.8987 - f1_score: 0.9402 - val_loss: 0.3176 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 811/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2866 - acc: 0.9446 - precision: 0.9886 - recall: 0.9021 - f1_score: 0.9424 - val_loss: 0.3171 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 812/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2861 - acc: 0.9446 - precision: 0.9898 - recall: 0.9004 - f1_score: 0.9421 - val_loss: 0.3166 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 813/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2856 - acc: 0.9446 - precision: 0.9893 - recall: 0.8996 - f1_score: 0.9414 - val_loss: 0.3161 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 814/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2851 - acc: 0.9446 - precision: 0.9906 - recall: 0.8987 - f1_score: 0.9413 - val_loss: 0.3157 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 815/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2846 - acc: 0.9446 - precision: 0.9901 - recall: 0.8970 - f1_score: 0.9399 - val_loss: 0.3152 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 816/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2841 - acc: 0.9446 - precision: 0.9878 - recall: 0.8966 - f1_score: 0.9394 - val_loss: 0.3147 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 817/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2837 - acc: 0.9446 - precision: 0.9896 - recall: 0.8943 - f1_score: 0.9383 - val_loss: 0.3142 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 818/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2832 - acc: 0.9446 - precision: 0.9888 - recall: 0.8972 - f1_score: 0.9396 - val_loss: 0.3137 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 819/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2827 - acc: 0.9446 - precision: 0.9876 - recall: 0.8932 - f1_score: 0.9357 - val_loss: 0.3133 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 820/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2822 - acc: 0.9446 - precision: 0.9898 - recall: 0.8953 - f1_score: 0.9371 - val_loss: 0.3128 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 821/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2817 - acc: 0.9446 - precision: 0.9889 - recall: 0.8978 - f1_score: 0.9402 - val_loss: 0.3123 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 822/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2813 - acc: 0.9446 - precision: 0.9899 - recall: 0.8987 - f1_score: 0.9410 - val_loss: 0.3118 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 823/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2808 - acc: 0.9446 - precision: 0.9896 - recall: 0.8975 - f1_score: 0.9407 - val_loss: 0.3114 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 824/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2803 - acc: 0.9446 - precision: 0.9895 - recall: 0.8974 - f1_score: 0.9409 - val_loss: 0.3109 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 825/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2799 - acc: 0.9446 - precision: 0.9887 - recall: 0.8977 - f1_score: 0.9405 - val_loss: 0.3105 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 826/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2794 - acc: 0.9446 - precision: 0.9906 - recall: 0.8962 - f1_score: 0.9400 - val_loss: 0.3100 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 827/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2789 - acc: 0.9446 - precision: 0.9893 - recall: 0.8980 - f1_score: 0.9404 - val_loss: 0.3095 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 828/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2785 - acc: 0.9446 - precision: 0.9875 - recall: 0.9010 - f1_score: 0.9406 - val_loss: 0.3091 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 829/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2780 - acc: 0.9446 - precision: 0.9888 - recall: 0.8971 - f1_score: 0.9388 - val_loss: 0.3086 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 830/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2775 - acc: 0.9446 - precision: 0.9898 - recall: 0.8989 - f1_score: 0.9417 - val_loss: 0.3082 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2771 - acc: 0.9446 - precision: 0.9894 - recall: 0.8968 - f1_score: 0.9399 - val_loss: 0.3077 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 832/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2766 - acc: 0.9446 - precision: 0.9891 - recall: 0.9013 - f1_score: 0.9425 - val_loss: 0.3073 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 833/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2762 - acc: 0.9446 - precision: 0.9878 - recall: 0.8950 - f1_score: 0.9381 - val_loss: 0.3068 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 834/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2757 - acc: 0.9446 - precision: 0.9884 - recall: 0.8967 - f1_score: 0.9394 - val_loss: 0.3064 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 835/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2753 - acc: 0.9446 - precision: 0.9906 - recall: 0.8954 - f1_score: 0.9385 - val_loss: 0.3060 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 836/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2749 - acc: 0.9446 - precision: 0.9891 - recall: 0.8954 - f1_score: 0.9387 - val_loss: 0.3055 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 837/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2744 - acc: 0.9446 - precision: 0.9902 - recall: 0.8971 - f1_score: 0.9407 - val_loss: 0.3051 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 838/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2740 - acc: 0.9446 - precision: 0.9898 - recall: 0.8977 - f1_score: 0.9404 - val_loss: 0.3047 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 839/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2735 - acc: 0.9446 - precision: 0.9881 - recall: 0.8967 - f1_score: 0.9396 - val_loss: 0.3042 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 840/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2731 - acc: 0.9446 - precision: 0.9916 - recall: 0.8949 - f1_score: 0.9398 - val_loss: 0.3038 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 841/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2727 - acc: 0.9446 - precision: 0.9909 - recall: 0.8947 - f1_score: 0.9386 - val_loss: 0.3034 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 842/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2722 - acc: 0.9446 - precision: 0.9898 - recall: 0.9012 - f1_score: 0.9415 - val_loss: 0.3029 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 843/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2718 - acc: 0.9446 - precision: 0.9896 - recall: 0.8984 - f1_score: 0.9405 - val_loss: 0.3025 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 844/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2714 - acc: 0.9446 - precision: 0.9898 - recall: 0.8977 - f1_score: 0.9402 - val_loss: 0.3021 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 845/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2709 - acc: 0.9446 - precision: 0.9884 - recall: 0.9006 - f1_score: 0.9410 - val_loss: 0.3017 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 846/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2705 - acc: 0.9446 - precision: 0.9890 - recall: 0.8967 - f1_score: 0.9395 - val_loss: 0.3013 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 847/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2701 - acc: 0.9446 - precision: 0.9899 - recall: 0.9021 - f1_score: 0.9422 - val_loss: 0.3009 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 848/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2697 - acc: 0.9446 - precision: 0.9900 - recall: 0.9019 - f1_score: 0.9432 - val_loss: 0.3004 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 849/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2692 - acc: 0.9446 - precision: 0.9890 - recall: 0.8990 - f1_score: 0.9413 - val_loss: 0.3000 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 850/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2688 - acc: 0.9446 - precision: 0.9908 - recall: 0.9019 - f1_score: 0.9433 - val_loss: 0.2996 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 851/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2684 - acc: 0.9446 - precision: 0.9872 - recall: 0.8942 - f1_score: 0.9365 - val_loss: 0.2992 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 852/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2680 - acc: 0.9446 - precision: 0.9905 - recall: 0.9001 - f1_score: 0.9426 - val_loss: 0.2988 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 853/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2676 - acc: 0.9446 - precision: 0.9891 - recall: 0.8959 - f1_score: 0.9395 - val_loss: 0.2984 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 854/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2672 - acc: 0.9446 - precision: 0.9886 - recall: 0.8970 - f1_score: 0.9395 - val_loss: 0.2980 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 855/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2668 - acc: 0.9446 - precision: 0.9903 - recall: 0.8983 - f1_score: 0.9406 - val_loss: 0.2976 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 856/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2664 - acc: 0.9446 - precision: 0.9892 - recall: 0.8970 - f1_score: 0.9387 - val_loss: 0.2972 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 857/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2660 - acc: 0.9446 - precision: 0.9904 - recall: 0.8977 - f1_score: 0.9405 - val_loss: 0.2968 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 858/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2656 - acc: 0.9446 - precision: 0.9893 - recall: 0.8967 - f1_score: 0.9396 - val_loss: 0.2964 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 859/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2652 - acc: 0.9446 - precision: 0.9901 - recall: 0.8950 - f1_score: 0.9393 - val_loss: 0.2960 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 860/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2648 - acc: 0.9446 - precision: 0.9883 - recall: 0.8954 - f1_score: 0.9380 - val_loss: 0.2956 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 861/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2644 - acc: 0.9446 - precision: 0.9879 - recall: 0.8968 - f1_score: 0.9392 - val_loss: 0.2952 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 862/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2640 - acc: 0.9446 - precision: 0.9903 - recall: 0.8987 - f1_score: 0.9420 - val_loss: 0.2948 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 863/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2636 - acc: 0.9446 - precision: 0.9901 - recall: 0.8995 - f1_score: 0.9409 - val_loss: 0.2945 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 864/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2632 - acc: 0.9446 - precision: 0.9876 - recall: 0.8927 - f1_score: 0.9368 - val_loss: 0.2941 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 865/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2628 - acc: 0.9446 - precision: 0.9896 - recall: 0.9001 - f1_score: 0.9416 - val_loss: 0.2937 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 866/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2624 - acc: 0.9446 - precision: 0.9895 - recall: 0.9014 - f1_score: 0.9420 - val_loss: 0.2933 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 867/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2620 - acc: 0.9446 - precision: 0.9887 - recall: 0.9004 - f1_score: 0.9412 - val_loss: 0.2929 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 868/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2616 - acc: 0.9446 - precision: 0.9881 - recall: 0.8950 - f1_score: 0.9381 - val_loss: 0.2926 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 869/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2613 - acc: 0.9446 - precision: 0.9880 - recall: 0.8980 - f1_score: 0.9403 - val_loss: 0.2922 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 870/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2609 - acc: 0.9446 - precision: 0.9907 - recall: 0.9018 - f1_score: 0.9429 - val_loss: 0.2918 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 871/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2605 - acc: 0.9446 - precision: 0.9905 - recall: 0.8981 - f1_score: 0.9416 - val_loss: 0.2914 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 872/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2601 - acc: 0.9446 - precision: 0.9889 - recall: 0.9026 - f1_score: 0.9427 - val_loss: 0.2911 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 873/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2597 - acc: 0.9446 - precision: 0.9893 - recall: 0.9022 - f1_score: 0.9421 - val_loss: 0.2907 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 874/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2594 - acc: 0.9446 - precision: 0.9893 - recall: 0.8988 - f1_score: 0.9410 - val_loss: 0.2903 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 875/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2590 - acc: 0.9446 - precision: 0.9909 - recall: 0.9005 - f1_score: 0.9427 - val_loss: 0.2899 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 876/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2586 - acc: 0.9446 - precision: 0.9892 - recall: 0.8955 - f1_score: 0.9390 - val_loss: 0.2896 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 877/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2583 - acc: 0.9446 - precision: 0.9902 - recall: 0.8966 - f1_score: 0.9400 - val_loss: 0.2892 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 878/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2579 - acc: 0.9446 - precision: 0.9889 - recall: 0.8988 - f1_score: 0.9406 - val_loss: 0.2888 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 879/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2575 - acc: 0.9446 - precision: 0.9860 - recall: 0.8984 - f1_score: 0.9388 - val_loss: 0.2885 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 880/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2572 - acc: 0.9446 - precision: 0.9905 - recall: 0.9014 - f1_score: 0.9425 - val_loss: 0.2881 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 881/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2568 - acc: 0.9446 - precision: 0.9913 - recall: 0.8957 - f1_score: 0.9402 - val_loss: 0.2878 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 882/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2564 - acc: 0.9446 - precision: 0.9905 - recall: 0.9039 - f1_score: 0.9441 - val_loss: 0.2874 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 883/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2561 - acc: 0.9446 - precision: 0.9898 - recall: 0.8939 - f1_score: 0.9383 - val_loss: 0.2870 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 884/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2557 - acc: 0.9446 - precision: 0.9898 - recall: 0.9016 - f1_score: 0.9419 - val_loss: 0.2867 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 885/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2554 - acc: 0.9446 - precision: 0.9897 - recall: 0.8941 - f1_score: 0.9380 - val_loss: 0.2863 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 886/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2550 - acc: 0.9446 - precision: 0.9891 - recall: 0.9005 - f1_score: 0.9422 - val_loss: 0.2860 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 887/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2547 - acc: 0.9446 - precision: 0.9902 - recall: 0.8992 - f1_score: 0.9419 - val_loss: 0.2857 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 888/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2543 - acc: 0.9446 - precision: 0.9898 - recall: 0.8972 - f1_score: 0.9389 - val_loss: 0.2853 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 889/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2540 - acc: 0.9446 - precision: 0.9896 - recall: 0.8995 - f1_score: 0.9413 - val_loss: 0.2850 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 890/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2536 - acc: 0.9446 - precision: 0.9863 - recall: 0.8972 - f1_score: 0.9384 - val_loss: 0.2846 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 891/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2533 - acc: 0.9446 - precision: 0.9898 - recall: 0.8952 - f1_score: 0.9384 - val_loss: 0.2843 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 892/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2529 - acc: 0.9446 - precision: 0.9878 - recall: 0.8953 - f1_score: 0.9388 - val_loss: 0.2840 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 893/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2526 - acc: 0.9446 - precision: 0.9880 - recall: 0.9019 - f1_score: 0.9422 - val_loss: 0.2836 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 894/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2522 - acc: 0.9446 - precision: 0.9909 - recall: 0.8972 - f1_score: 0.9407 - val_loss: 0.2833 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 895/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2519 - acc: 0.9446 - precision: 0.9903 - recall: 0.8965 - f1_score: 0.9402 - val_loss: 0.2830 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 896/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2516 - acc: 0.9446 - precision: 0.9893 - recall: 0.8940 - f1_score: 0.9380 - val_loss: 0.2826 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 897/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2512 - acc: 0.9446 - precision: 0.9895 - recall: 0.8988 - f1_score: 0.9415 - val_loss: 0.2823 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 898/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2509 - acc: 0.9446 - precision: 0.9891 - recall: 0.9001 - f1_score: 0.9412 - val_loss: 0.2820 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 899/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2505 - acc: 0.9446 - precision: 0.9890 - recall: 0.8968 - f1_score: 0.9396 - val_loss: 0.2816 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 900/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2502 - acc: 0.9446 - precision: 0.9893 - recall: 0.9002 - f1_score: 0.9415 - val_loss: 0.2813 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 901/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2499 - acc: 0.9446 - precision: 0.9901 - recall: 0.9021 - f1_score: 0.9435 - val_loss: 0.2810 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 902/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2495 - acc: 0.9446 - precision: 0.9900 - recall: 0.9005 - f1_score: 0.9420 - val_loss: 0.2806 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 903/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2492 - acc: 0.9446 - precision: 0.9898 - recall: 0.9019 - f1_score: 0.9427 - val_loss: 0.2803 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 904/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2489 - acc: 0.9446 - precision: 0.9885 - recall: 0.8956 - f1_score: 0.9387 - val_loss: 0.2800 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 905/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2486 - acc: 0.9446 - precision: 0.9902 - recall: 0.8968 - f1_score: 0.9401 - val_loss: 0.2797 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 906/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2482 - acc: 0.9446 - precision: 0.9899 - recall: 0.8945 - f1_score: 0.9377 - val_loss: 0.2794 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 907/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2479 - acc: 0.9446 - precision: 0.9904 - recall: 0.8984 - f1_score: 0.9412 - val_loss: 0.2790 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 908/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2476 - acc: 0.9446 - precision: 0.9882 - recall: 0.8994 - f1_score: 0.9408 - val_loss: 0.2787 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 909/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2473 - acc: 0.9446 - precision: 0.9907 - recall: 0.8964 - f1_score: 0.9405 - val_loss: 0.2784 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 910/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2469 - acc: 0.9446 - precision: 0.9901 - recall: 0.8969 - f1_score: 0.9402 - val_loss: 0.2781 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 911/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2466 - acc: 0.9446 - precision: 0.9890 - recall: 0.9021 - f1_score: 0.9428 - val_loss: 0.2778 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 912/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2463 - acc: 0.9446 - precision: 0.9890 - recall: 0.8996 - f1_score: 0.9414 - val_loss: 0.2775 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 913/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2460 - acc: 0.9446 - precision: 0.9885 - recall: 0.8959 - f1_score: 0.9392 - val_loss: 0.2772 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 914/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2457 - acc: 0.9446 - precision: 0.9870 - recall: 0.9022 - f1_score: 0.9413 - val_loss: 0.2769 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 915/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2454 - acc: 0.9446 - precision: 0.9885 - recall: 0.8995 - f1_score: 0.9410 - val_loss: 0.2766 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 916/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2451 - acc: 0.9446 - precision: 0.9872 - recall: 0.8987 - f1_score: 0.9398 - val_loss: 0.2763 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 917/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2448 - acc: 0.9446 - precision: 0.9903 - recall: 0.8982 - f1_score: 0.9410 - val_loss: 0.2760 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 918/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2445 - acc: 0.9446 - precision: 0.9898 - recall: 0.8986 - f1_score: 0.9411 - val_loss: 0.2757 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 919/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2441 - acc: 0.9446 - precision: 0.9904 - recall: 0.8991 - f1_score: 0.9412 - val_loss: 0.2754 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 920/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2438 - acc: 0.9446 - precision: 0.9897 - recall: 0.8986 - f1_score: 0.9400 - val_loss: 0.2751 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 921/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2435 - acc: 0.9446 - precision: 0.9897 - recall: 0.9002 - f1_score: 0.9422 - val_loss: 0.2748 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 922/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2432 - acc: 0.9446 - precision: 0.9902 - recall: 0.8988 - f1_score: 0.9416 - val_loss: 0.2745 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 923/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2429 - acc: 0.9446 - precision: 0.9897 - recall: 0.8996 - f1_score: 0.9416 - val_loss: 0.2742 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 924/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2426 - acc: 0.9446 - precision: 0.9895 - recall: 0.8966 - f1_score: 0.9399 - val_loss: 0.2739 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 925/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2423 - acc: 0.9446 - precision: 0.9890 - recall: 0.8984 - f1_score: 0.9402 - val_loss: 0.2736 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 926/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2420 - acc: 0.9446 - precision: 0.9894 - recall: 0.8997 - f1_score: 0.9420 - val_loss: 0.2733 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 927/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2417 - acc: 0.9446 - precision: 0.9889 - recall: 0.8960 - f1_score: 0.9391 - val_loss: 0.2730 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 928/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2415 - acc: 0.9446 - precision: 0.9906 - recall: 0.9013 - f1_score: 0.9420 - val_loss: 0.2727 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 929/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2412 - acc: 0.9446 - precision: 0.9875 - recall: 0.8963 - f1_score: 0.9386 - val_loss: 0.2724 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 930/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2409 - acc: 0.9446 - precision: 0.9897 - recall: 0.8911 - f1_score: 0.9363 - val_loss: 0.2721 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 931/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2406 - acc: 0.9446 - precision: 0.9902 - recall: 0.9012 - f1_score: 0.9424 - val_loss: 0.2718 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 932/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2403 - acc: 0.9446 - precision: 0.9907 - recall: 0.8952 - f1_score: 0.9384 - val_loss: 0.2715 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 933/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2400 - acc: 0.9446 - precision: 0.9892 - recall: 0.8883 - f1_score: 0.9333 - val_loss: 0.2712 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 934/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2397 - acc: 0.9446 - precision: 0.9908 - recall: 0.8960 - f1_score: 0.9397 - val_loss: 0.2710 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 935/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2394 - acc: 0.9446 - precision: 0.9896 - recall: 0.8991 - f1_score: 0.9411 - val_loss: 0.2707 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 936/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2391 - acc: 0.9446 - precision: 0.9906 - recall: 0.8984 - f1_score: 0.9412 - val_loss: 0.2704 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 937/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2389 - acc: 0.9446 - precision: 0.9896 - recall: 0.8975 - f1_score: 0.9399 - val_loss: 0.2701 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 938/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2386 - acc: 0.9446 - precision: 0.9868 - recall: 0.8958 - f1_score: 0.9384 - val_loss: 0.2698 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 939/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2383 - acc: 0.9446 - precision: 0.9884 - recall: 0.8988 - f1_score: 0.9408 - val_loss: 0.2696 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 940/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2380 - acc: 0.9446 - precision: 0.9888 - recall: 0.8987 - f1_score: 0.9402 - val_loss: 0.2693 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 941/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2378 - acc: 0.9446 - precision: 0.9898 - recall: 0.8982 - f1_score: 0.9410 - val_loss: 0.2690 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 942/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2375 - acc: 0.9446 - precision: 0.9905 - recall: 0.8976 - f1_score: 0.9406 - val_loss: 0.2687 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 943/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2372 - acc: 0.9446 - precision: 0.9892 - recall: 0.8980 - f1_score: 0.9406 - val_loss: 0.2685 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 944/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2369 - acc: 0.9446 - precision: 0.9906 - recall: 0.8973 - f1_score: 0.9403 - val_loss: 0.2682 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 945/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2367 - acc: 0.9446 - precision: 0.9905 - recall: 0.8984 - f1_score: 0.9408 - val_loss: 0.2679 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 946/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2364 - acc: 0.9446 - precision: 0.9892 - recall: 0.8971 - f1_score: 0.9394 - val_loss: 0.2677 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 947/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2361 - acc: 0.9446 - precision: 0.9904 - recall: 0.8984 - f1_score: 0.9415 - val_loss: 0.2674 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 948/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2358 - acc: 0.9446 - precision: 0.9894 - recall: 0.8976 - f1_score: 0.9406 - val_loss: 0.2672 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 949/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2356 - acc: 0.9446 - precision: 0.9899 - recall: 0.8969 - f1_score: 0.9405 - val_loss: 0.2669 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 950/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2353 - acc: 0.9446 - precision: 0.9904 - recall: 0.8988 - f1_score: 0.9416 - val_loss: 0.2666 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 951/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2350 - acc: 0.9446 - precision: 0.9866 - recall: 0.8922 - f1_score: 0.9360 - val_loss: 0.2664 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 952/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2348 - acc: 0.9446 - precision: 0.9905 - recall: 0.8956 - f1_score: 0.9402 - val_loss: 0.2661 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 953/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2345 - acc: 0.9446 - precision: 0.9891 - recall: 0.8990 - f1_score: 0.9410 - val_loss: 0.2658 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 954/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2343 - acc: 0.9446 - precision: 0.9893 - recall: 0.9034 - f1_score: 0.9428 - val_loss: 0.2656 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 955/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2340 - acc: 0.9446 - precision: 0.9892 - recall: 0.8947 - f1_score: 0.9385 - val_loss: 0.2654 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 956/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2337 - acc: 0.9446 - precision: 0.9898 - recall: 0.8939 - f1_score: 0.9362 - val_loss: 0.2651 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 957/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2335 - acc: 0.9446 - precision: 0.9894 - recall: 0.9004 - f1_score: 0.9417 - val_loss: 0.2649 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 958/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2332 - acc: 0.9446 - precision: 0.9891 - recall: 0.8998 - f1_score: 0.9414 - val_loss: 0.2646 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 959/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2330 - acc: 0.9446 - precision: 0.9895 - recall: 0.8968 - f1_score: 0.9403 - val_loss: 0.2643 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 960/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2327 - acc: 0.9446 - precision: 0.9883 - recall: 0.8980 - f1_score: 0.9389 - val_loss: 0.2641 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 961/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2325 - acc: 0.9446 - precision: 0.9907 - recall: 0.8972 - f1_score: 0.9405 - val_loss: 0.2638 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 962/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2322 - acc: 0.9446 - precision: 0.9904 - recall: 0.8952 - f1_score: 0.9393 - val_loss: 0.2636 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 963/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2320 - acc: 0.9446 - precision: 0.9899 - recall: 0.8941 - f1_score: 0.9378 - val_loss: 0.2633 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 964/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2317 - acc: 0.9446 - precision: 0.9886 - recall: 0.8958 - f1_score: 0.9392 - val_loss: 0.2631 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 965/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2315 - acc: 0.9446 - precision: 0.9907 - recall: 0.8977 - f1_score: 0.9411 - val_loss: 0.2628 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 966/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2312 - acc: 0.9446 - precision: 0.9898 - recall: 0.8966 - f1_score: 0.9404 - val_loss: 0.2626 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 967/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2310 - acc: 0.9446 - precision: 0.9910 - recall: 0.9040 - f1_score: 0.9436 - val_loss: 0.2624 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 968/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2307 - acc: 0.9446 - precision: 0.9884 - recall: 0.9011 - f1_score: 0.9420 - val_loss: 0.2621 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 969/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2305 - acc: 0.9446 - precision: 0.9901 - recall: 0.8958 - f1_score: 0.9383 - val_loss: 0.2619 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 970/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2302 - acc: 0.9446 - precision: 0.9906 - recall: 0.8973 - f1_score: 0.9411 - val_loss: 0.2616 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 971/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2300 - acc: 0.9446 - precision: 0.9885 - recall: 0.8983 - f1_score: 0.9405 - val_loss: 0.2614 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 972/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2297 - acc: 0.9446 - precision: 0.9896 - recall: 0.8963 - f1_score: 0.9397 - val_loss: 0.2611 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 973/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2295 - acc: 0.9446 - precision: 0.9902 - recall: 0.9002 - f1_score: 0.9417 - val_loss: 0.2609 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 974/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2293 - acc: 0.9446 - precision: 0.9883 - recall: 0.9004 - f1_score: 0.9406 - val_loss: 0.2607 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 975/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2290 - acc: 0.9446 - precision: 0.9900 - recall: 0.9004 - f1_score: 0.9415 - val_loss: 0.2604 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 976/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2288 - acc: 0.9446 - precision: 0.9890 - recall: 0.8964 - f1_score: 0.9395 - val_loss: 0.2602 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 977/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2285 - acc: 0.9446 - precision: 0.9900 - recall: 0.9006 - f1_score: 0.9426 - val_loss: 0.2600 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 978/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2283 - acc: 0.9446 - precision: 0.9890 - recall: 0.8985 - f1_score: 0.9401 - val_loss: 0.2597 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 979/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2281 - acc: 0.9446 - precision: 0.9892 - recall: 0.9004 - f1_score: 0.9422 - val_loss: 0.2595 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 980/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2278 - acc: 0.9446 - precision: 0.9895 - recall: 0.8996 - f1_score: 0.9414 - val_loss: 0.2593 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 981/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2276 - acc: 0.9446 - precision: 0.9869 - recall: 0.8956 - f1_score: 0.9380 - val_loss: 0.2590 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 982/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2274 - acc: 0.9446 - precision: 0.9895 - recall: 0.9002 - f1_score: 0.9422 - val_loss: 0.2588 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 983/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2271 - acc: 0.9446 - precision: 0.9900 - recall: 0.8937 - f1_score: 0.9374 - val_loss: 0.2586 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 984/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2269 - acc: 0.9446 - precision: 0.9898 - recall: 0.8963 - f1_score: 0.9399 - val_loss: 0.2583 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 985/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2267 - acc: 0.9446 - precision: 0.9897 - recall: 0.9012 - f1_score: 0.9422 - val_loss: 0.2581 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 986/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2265 - acc: 0.9446 - precision: 0.9894 - recall: 0.8993 - f1_score: 0.9411 - val_loss: 0.2579 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 987/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2262 - acc: 0.9446 - precision: 0.9909 - recall: 0.8976 - f1_score: 0.9410 - val_loss: 0.2577 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 988/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2260 - acc: 0.9446 - precision: 0.9895 - recall: 0.9003 - f1_score: 0.9410 - val_loss: 0.2575 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 989/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2258 - acc: 0.9446 - precision: 0.9889 - recall: 0.8994 - f1_score: 0.9415 - val_loss: 0.2573 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 990/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2256 - acc: 0.9446 - precision: 0.9915 - recall: 0.8967 - f1_score: 0.9406 - val_loss: 0.2570 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s - loss: 0.2253 - acc: 0.9446 - precision: 0.9899 - recall: 0.8968 - f1_score: 0.9401 - val_loss: 0.2568 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 992/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2251 - acc: 0.9446 - precision: 0.9894 - recall: 0.8959 - f1_score: 0.9388 - val_loss: 0.2566 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 993/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2249 - acc: 0.9446 - precision: 0.9909 - recall: 0.8956 - f1_score: 0.9392 - val_loss: 0.2564 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 994/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2247 - acc: 0.9446 - precision: 0.9888 - recall: 0.8969 - f1_score: 0.9392 - val_loss: 0.2561 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 995/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2245 - acc: 0.9446 - precision: 0.9903 - recall: 0.9039 - f1_score: 0.9437 - val_loss: 0.2559 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 996/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2242 - acc: 0.9446 - precision: 0.9897 - recall: 0.9018 - f1_score: 0.9429 - val_loss: 0.2557 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 997/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2240 - acc: 0.9446 - precision: 0.9883 - recall: 0.9004 - f1_score: 0.9418 - val_loss: 0.2555 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 998/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2238 - acc: 0.9446 - precision: 0.9896 - recall: 0.9000 - f1_score: 0.9413 - val_loss: 0.2553 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 999/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2236 - acc: 0.9446 - precision: 0.9911 - recall: 0.9001 - f1_score: 0.9424 - val_loss: 0.2551 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      "Epoch 1000/1000\n",
      "632/632 [==============================] - 0s - loss: 0.2234 - acc: 0.9446 - precision: 0.9905 - recall: 0.8998 - f1_score: 0.9418 - val_loss: 0.2549 - val_acc: 0.9434 - val_precision: 0.9303 - val_recall: 0.8573 - val_f1_score: 0.8915\n",
      " 50/159 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.1512 - acc: 0.4455 - precision: 0.4085 - recall: 0.5116 - f1_score: 0.4445 - val_loss: 5.9888 - val_acc: 0.6519 - val_precision: 0.6088 - val_recall: 0.9533 - val_f1_score: 0.7373\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9638 - acc: 0.6209 - precision: 0.5666 - recall: 0.9602 - f1_score: 0.7100 - val_loss: 5.9018 - val_acc: 0.6519 - val_precision: 0.6030 - val_recall: 0.9760 - val_f1_score: 0.7414\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8968 - acc: 0.6288 - precision: 0.5679 - recall: 0.9914 - f1_score: 0.7187 - val_loss: 5.8497 - val_acc: 0.6392 - val_precision: 0.5936 - val_recall: 0.9760 - val_f1_score: 0.7346\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8490 - acc: 0.6382 - precision: 0.5737 - recall: 0.9917 - f1_score: 0.7260 - val_loss: 5.8072 - val_acc: 0.6392 - val_precision: 0.5936 - val_recall: 0.9760 - val_f1_score: 0.7346\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8077 - acc: 0.6493 - precision: 0.5809 - recall: 0.9962 - f1_score: 0.7315 - val_loss: 5.7694 - val_acc: 0.6582 - val_precision: 0.6074 - val_recall: 0.9760 - val_f1_score: 0.7449\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7696 - acc: 0.6635 - precision: 0.5914 - recall: 0.9972 - f1_score: 0.7390 - val_loss: 5.7338 - val_acc: 0.6899 - val_precision: 0.6321 - val_recall: 0.9760 - val_f1_score: 0.7623\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7334 - acc: 0.6793 - precision: 0.6019 - recall: 0.9949 - f1_score: 0.7437 - val_loss: 5.6997 - val_acc: 0.7215 - val_precision: 0.6588 - val_recall: 0.9760 - val_f1_score: 0.7814\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6986 - acc: 0.7062 - precision: 0.6262 - recall: 0.9947 - f1_score: 0.7648 - val_loss: 5.6668 - val_acc: 0.7342 - val_precision: 0.6734 - val_recall: 0.9533 - val_f1_score: 0.7853\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6646 - acc: 0.7172 - precision: 0.6345 - recall: 0.9882 - f1_score: 0.7675 - val_loss: 5.6346 - val_acc: 0.7532 - val_precision: 0.6897 - val_recall: 0.9533 - val_f1_score: 0.7975\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6313 - acc: 0.7441 - precision: 0.6597 - recall: 0.9879 - f1_score: 0.7880 - val_loss: 5.6031 - val_acc: 0.7848 - val_precision: 0.7204 - val_recall: 0.9533 - val_f1_score: 0.8185\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5987 - acc: 0.7583 - precision: 0.6721 - recall: 0.9833 - f1_score: 0.7959 - val_loss: 5.5721 - val_acc: 0.7975 - val_precision: 0.7338 - val_recall: 0.9533 - val_f1_score: 0.8274\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 5.5658 - acc: 0.8200 - precision: 0.7500 - recall: 1.0000 - f1_score: 0.857 - 0s - loss: 5.5666 - acc: 0.7804 - precision: 0.6975 - recall: 0.9776 - f1_score: 0.8123 - val_loss: 5.5416 - val_acc: 0.7848 - val_precision: 0.7333 - val_recall: 0.9161 - val_f1_score: 0.8129\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5349 - acc: 0.7978 - precision: 0.7140 - recall: 0.9768 - f1_score: 0.8226 - val_loss: 5.5115 - val_acc: 0.8101 - val_precision: 0.7646 - val_recall: 0.9161 - val_f1_score: 0.8308\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5036 - acc: 0.8152 - precision: 0.7285 - recall: 0.9782 - f1_score: 0.8302 - val_loss: 5.4817 - val_acc: 0.8101 - val_precision: 0.7646 - val_recall: 0.9161 - val_f1_score: 0.8308\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4727 - acc: 0.8278 - precision: 0.7512 - recall: 0.9670 - f1_score: 0.8443 - val_loss: 5.4522 - val_acc: 0.8291 - val_precision: 0.7917 - val_recall: 0.9161 - val_f1_score: 0.8457\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4421 - acc: 0.8373 - precision: 0.7702 - recall: 0.9514 - f1_score: 0.8468 - val_loss: 5.4231 - val_acc: 0.8354 - val_precision: 0.7985 - val_recall: 0.9161 - val_f1_score: 0.8503\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4118 - acc: 0.8531 - precision: 0.7887 - recall: 0.9509 - f1_score: 0.8594 - val_loss: 5.3942 - val_acc: 0.8734 - val_precision: 0.8501 - val_recall: 0.9161 - val_f1_score: 0.8796\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3818 - acc: 0.8689 - precision: 0.8078 - recall: 0.9520 - f1_score: 0.8714 - val_loss: 5.3656 - val_acc: 0.8797 - val_precision: 0.8701 - val_recall: 0.9065 - val_f1_score: 0.8856\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3522 - acc: 0.8799 - precision: 0.8362 - recall: 0.9453 - f1_score: 0.8840 - val_loss: 5.3373 - val_acc: 0.8924 - val_precision: 0.8903 - val_recall: 0.9065 - val_f1_score: 0.8971\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3228 - acc: 0.8910 - precision: 0.8473 - recall: 0.9400 - f1_score: 0.8901 - val_loss: 5.3092 - val_acc: 0.8924 - val_precision: 0.8903 - val_recall: 0.9065 - val_f1_score: 0.8971\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2937 - acc: 0.9005 - precision: 0.8674 - recall: 0.9456 - f1_score: 0.9013 - val_loss: 5.2814 - val_acc: 0.8924 - val_precision: 0.8903 - val_recall: 0.9065 - val_f1_score: 0.8971\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2648 - acc: 0.9115 - precision: 0.8818 - recall: 0.9443 - f1_score: 0.9107 - val_loss: 5.2537 - val_acc: 0.8987 - val_precision: 0.9005 - val_recall: 0.9065 - val_f1_score: 0.9027\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.2362 - acc: 0.9131 - precision: 0.8901 - recall: 0.9434 - f1_score: 0.9141 - val_loss: 5.2263 - val_acc: 0.9051 - val_precision: 0.9131 - val_recall: 0.9065 - val_f1_score: 0.9089\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2079 - acc: 0.9226 - precision: 0.8986 - recall: 0.9342 - f1_score: 0.9146 - val_loss: 5.1991 - val_acc: 0.9051 - val_precision: 0.9131 - val_recall: 0.9065 - val_f1_score: 0.9089\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1798 - acc: 0.9258 - precision: 0.9111 - recall: 0.9357 - f1_score: 0.9216 - val_loss: 5.1722 - val_acc: 0.8987 - val_precision: 0.9124 - val_recall: 0.8969 - val_f1_score: 0.9034\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1519 - acc: 0.9289 - precision: 0.9173 - recall: 0.9372 - f1_score: 0.9255 - val_loss: 5.1454 - val_acc: 0.9051 - val_precision: 0.9239 - val_recall: 0.8969 - val_f1_score: 0.9095\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1242 - acc: 0.9305 - precision: 0.9230 - recall: 0.9299 - f1_score: 0.9255 - val_loss: 5.1189 - val_acc: 0.9114 - val_precision: 0.9341 - val_recall: 0.8969 - val_f1_score: 0.9140\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0968 - acc: 0.9305 - precision: 0.9311 - recall: 0.9284 - f1_score: 0.9280 - val_loss: 5.0925 - val_acc: 0.9177 - val_precision: 0.9450 - val_recall: 0.8969 - val_f1_score: 0.9187\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0696 - acc: 0.9305 - precision: 0.9388 - recall: 0.9225 - f1_score: 0.9295 - val_loss: 5.0663 - val_acc: 0.9241 - val_precision: 0.9575 - val_recall: 0.8969 - val_f1_score: 0.9251\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0426 - acc: 0.9336 - precision: 0.9411 - recall: 0.9216 - f1_score: 0.9294 - val_loss: 5.0403 - val_acc: 0.9241 - val_precision: 0.9575 - val_recall: 0.8969 - val_f1_score: 0.9251\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0158 - acc: 0.9352 - precision: 0.9423 - recall: 0.9205 - f1_score: 0.9289 - val_loss: 5.0145 - val_acc: 0.9241 - val_precision: 0.9575 - val_recall: 0.8969 - val_f1_score: 0.9251\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9892 - acc: 0.9336 - precision: 0.9449 - recall: 0.9203 - f1_score: 0.9313 - val_loss: 4.9888 - val_acc: 0.9241 - val_precision: 0.9575 - val_recall: 0.8969 - val_f1_score: 0.9251\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9628 - acc: 0.9336 - precision: 0.9399 - recall: 0.9184 - f1_score: 0.9274 - val_loss: 4.9633 - val_acc: 0.9304 - val_precision: 0.9712 - val_recall: 0.8969 - val_f1_score: 0.9318\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9366 - acc: 0.9384 - precision: 0.9494 - recall: 0.9193 - f1_score: 0.9331 - val_loss: 4.9381 - val_acc: 0.9304 - val_precision: 0.9712 - val_recall: 0.8969 - val_f1_score: 0.9318\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9106 - acc: 0.9384 - precision: 0.9527 - recall: 0.9183 - f1_score: 0.9339 - val_loss: 4.9129 - val_acc: 0.9304 - val_precision: 0.9712 - val_recall: 0.8969 - val_f1_score: 0.9318\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8848 - acc: 0.9400 - precision: 0.9571 - recall: 0.9250 - f1_score: 0.9396 - val_loss: 4.8880 - val_acc: 0.9304 - val_precision: 0.9712 - val_recall: 0.8969 - val_f1_score: 0.9318\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8591 - acc: 0.9415 - precision: 0.9589 - recall: 0.9161 - f1_score: 0.9363 - val_loss: 4.8632 - val_acc: 0.9304 - val_precision: 0.9712 - val_recall: 0.8969 - val_f1_score: 0.9318\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8337 - acc: 0.9415 - precision: 0.9584 - recall: 0.9211 - f1_score: 0.9372 - val_loss: 4.8386 - val_acc: 0.9241 - val_precision: 0.9705 - val_recall: 0.8837 - val_f1_score: 0.9245\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8083 - acc: 0.9431 - precision: 0.9658 - recall: 0.9133 - f1_score: 0.9383 - val_loss: 4.8141 - val_acc: 0.9241 - val_precision: 0.9705 - val_recall: 0.8837 - val_f1_score: 0.9245\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7832 - acc: 0.9431 - precision: 0.9650 - recall: 0.9145 - f1_score: 0.9383 - val_loss: 4.7898 - val_acc: 0.9177 - val_precision: 0.9705 - val_recall: 0.8741 - val_f1_score: 0.9188\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7583 - acc: 0.9431 - precision: 0.9651 - recall: 0.9126 - f1_score: 0.9370 - val_loss: 4.7657 - val_acc: 0.9177 - val_precision: 0.9705 - val_recall: 0.8741 - val_f1_score: 0.9188\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7336 - acc: 0.9447 - precision: 0.9695 - recall: 0.9134 - f1_score: 0.9390 - val_loss: 4.7417 - val_acc: 0.9177 - val_precision: 0.9705 - val_recall: 0.8741 - val_f1_score: 0.9188\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7090 - acc: 0.9447 - precision: 0.9701 - recall: 0.9168 - f1_score: 0.9416 - val_loss: 4.7178 - val_acc: 0.9177 - val_precision: 0.9705 - val_recall: 0.8741 - val_f1_score: 0.9188\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6845 - acc: 0.9463 - precision: 0.9710 - recall: 0.9173 - f1_score: 0.9428 - val_loss: 4.6941 - val_acc: 0.9114 - val_precision: 0.9699 - val_recall: 0.8610 - val_f1_score: 0.9111\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6603 - acc: 0.9463 - precision: 0.9729 - recall: 0.9142 - f1_score: 0.9415 - val_loss: 4.6706 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6362 - acc: 0.9463 - precision: 0.9791 - recall: 0.9100 - f1_score: 0.9412 - val_loss: 4.6472 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6122 - acc: 0.9463 - precision: 0.9756 - recall: 0.9116 - f1_score: 0.9412 - val_loss: 4.6239 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5884 - acc: 0.9479 - precision: 0.9799 - recall: 0.9152 - f1_score: 0.9455 - val_loss: 4.6008 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5648 - acc: 0.9479 - precision: 0.9811 - recall: 0.9142 - f1_score: 0.9448 - val_loss: 4.5778 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5413 - acc: 0.9479 - precision: 0.9793 - recall: 0.9128 - f1_score: 0.9434 - val_loss: 4.5550 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5180 - acc: 0.9479 - precision: 0.9779 - recall: 0.9110 - f1_score: 0.9423 - val_loss: 4.5323 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4948 - acc: 0.9479 - precision: 0.9795 - recall: 0.9121 - f1_score: 0.9439 - val_loss: 4.5097 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4718 - acc: 0.9479 - precision: 0.9799 - recall: 0.9104 - f1_score: 0.9420 - val_loss: 4.4873 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4489 - acc: 0.9479 - precision: 0.9790 - recall: 0.9142 - f1_score: 0.9444 - val_loss: 4.4650 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.4262 - acc: 0.9479 - precision: 0.9790 - recall: 0.9139 - f1_score: 0.9447 - val_loss: 4.4429 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4036 - acc: 0.9479 - precision: 0.9802 - recall: 0.9127 - f1_score: 0.9443 - val_loss: 4.4208 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3811 - acc: 0.9479 - precision: 0.9778 - recall: 0.9113 - f1_score: 0.9425 - val_loss: 4.3989 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3588 - acc: 0.9479 - precision: 0.9771 - recall: 0.9077 - f1_score: 0.9401 - val_loss: 4.3772 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3366 - acc: 0.9479 - precision: 0.9809 - recall: 0.9118 - f1_score: 0.9441 - val_loss: 4.3555 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3145 - acc: 0.9479 - precision: 0.9796 - recall: 0.9120 - f1_score: 0.9439 - val_loss: 4.3340 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2926 - acc: 0.9463 - precision: 0.9794 - recall: 0.9080 - f1_score: 0.9420 - val_loss: 4.3126 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2709 - acc: 0.9447 - precision: 0.9805 - recall: 0.9071 - f1_score: 0.9416 - val_loss: 4.2914 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2492 - acc: 0.9447 - precision: 0.9806 - recall: 0.9051 - f1_score: 0.9392 - val_loss: 4.2702 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2277 - acc: 0.9447 - precision: 0.9790 - recall: 0.9059 - f1_score: 0.9401 - val_loss: 4.2492 - val_acc: 0.9051 - val_precision: 0.9691 - val_recall: 0.8466 - val_f1_score: 0.9031\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2063 - acc: 0.9447 - precision: 0.9804 - recall: 0.9057 - f1_score: 0.9403 - val_loss: 4.2283 - val_acc: 0.8987 - val_precision: 0.9683 - val_recall: 0.8322 - val_f1_score: 0.8946\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1851 - acc: 0.9447 - precision: 0.9794 - recall: 0.9064 - f1_score: 0.9404 - val_loss: 4.2075 - val_acc: 0.8987 - val_precision: 0.9683 - val_recall: 0.8322 - val_f1_score: 0.8946\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1639 - acc: 0.9447 - precision: 0.9774 - recall: 0.9056 - f1_score: 0.9394 - val_loss: 4.1869 - val_acc: 0.8987 - val_precision: 0.9683 - val_recall: 0.8322 - val_f1_score: 0.8946\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1429 - acc: 0.9447 - precision: 0.9791 - recall: 0.9062 - f1_score: 0.9402 - val_loss: 4.1663 - val_acc: 0.8987 - val_precision: 0.9683 - val_recall: 0.8322 - val_f1_score: 0.8946\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1221 - acc: 0.9447 - precision: 0.9777 - recall: 0.9080 - f1_score: 0.9399 - val_loss: 4.1459 - val_acc: 0.8987 - val_precision: 0.9683 - val_recall: 0.8322 - val_f1_score: 0.8946\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1013 - acc: 0.9447 - precision: 0.9792 - recall: 0.9066 - f1_score: 0.9400 - val_loss: 4.1256 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0807 - acc: 0.9447 - precision: 0.9786 - recall: 0.9036 - f1_score: 0.9384 - val_loss: 4.1054 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0601 - acc: 0.9447 - precision: 0.9800 - recall: 0.9068 - f1_score: 0.9409 - val_loss: 4.0853 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0397 - acc: 0.9447 - precision: 0.9771 - recall: 0.9018 - f1_score: 0.9371 - val_loss: 4.0653 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0195 - acc: 0.9447 - precision: 0.9797 - recall: 0.9101 - f1_score: 0.9424 - val_loss: 4.0454 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9993 - acc: 0.9447 - precision: 0.9796 - recall: 0.9080 - f1_score: 0.9412 - val_loss: 4.0257 - val_acc: 0.8924 - val_precision: 0.9673 - val_recall: 0.8178 - val_f1_score: 0.8857\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9793 - acc: 0.9447 - precision: 0.9800 - recall: 0.9087 - f1_score: 0.9421 - val_loss: 4.0061 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 3.9535 - acc: 0.9000 - precision: 1.0000 - recall: 0.8276 - f1_score: 0.905 - 0s - loss: 3.9594 - acc: 0.9447 - precision: 0.9795 - recall: 0.9097 - f1_score: 0.9425 - val_loss: 3.9866 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9396 - acc: 0.9447 - precision: 0.9791 - recall: 0.9078 - f1_score: 0.9407 - val_loss: 3.9671 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9199 - acc: 0.9447 - precision: 0.9777 - recall: 0.9046 - f1_score: 0.9386 - val_loss: 3.9478 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9003 - acc: 0.9447 - precision: 0.9805 - recall: 0.9059 - f1_score: 0.9404 - val_loss: 3.9286 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8808 - acc: 0.9447 - precision: 0.9785 - recall: 0.9057 - f1_score: 0.9396 - val_loss: 3.9095 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8615 - acc: 0.9447 - precision: 0.9798 - recall: 0.9073 - f1_score: 0.9412 - val_loss: 3.8905 - val_acc: 0.8861 - val_precision: 0.9673 - val_recall: 0.8082 - val_f1_score: 0.8798\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8422 - acc: 0.9447 - precision: 0.9765 - recall: 0.9066 - f1_score: 0.9388 - val_loss: 3.8717 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8231 - acc: 0.9447 - precision: 0.9806 - recall: 0.8980 - f1_score: 0.9353 - val_loss: 3.8529 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8040 - acc: 0.9447 - precision: 0.9783 - recall: 0.9072 - f1_score: 0.9402 - val_loss: 3.8342 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7851 - acc: 0.9447 - precision: 0.9773 - recall: 0.9087 - f1_score: 0.9408 - val_loss: 3.8157 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.7663 - acc: 0.9447 - precision: 0.9783 - recall: 0.9036 - f1_score: 0.9383 - val_loss: 3.7972 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7476 - acc: 0.9431 - precision: 0.9774 - recall: 0.8974 - f1_score: 0.9347 - val_loss: 3.7788 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7290 - acc: 0.9431 - precision: 0.9810 - recall: 0.8996 - f1_score: 0.9375 - val_loss: 3.7605 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7105 - acc: 0.9431 - precision: 0.9799 - recall: 0.9042 - f1_score: 0.9392 - val_loss: 3.7424 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6921 - acc: 0.9431 - precision: 0.9779 - recall: 0.9037 - f1_score: 0.9381 - val_loss: 3.7243 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6738 - acc: 0.9431 - precision: 0.9814 - recall: 0.9040 - f1_score: 0.9398 - val_loss: 3.7064 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6556 - acc: 0.9431 - precision: 0.9781 - recall: 0.9004 - f1_score: 0.9369 - val_loss: 3.6885 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6376 - acc: 0.9431 - precision: 0.9813 - recall: 0.9008 - f1_score: 0.9372 - val_loss: 3.6707 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6196 - acc: 0.9431 - precision: 0.9778 - recall: 0.9001 - f1_score: 0.9368 - val_loss: 3.6531 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6017 - acc: 0.9431 - precision: 0.9780 - recall: 0.9019 - f1_score: 0.9376 - val_loss: 3.6355 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5839 - acc: 0.9431 - precision: 0.9793 - recall: 0.9034 - f1_score: 0.9386 - val_loss: 3.6180 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5663 - acc: 0.9431 - precision: 0.9815 - recall: 0.8999 - f1_score: 0.9385 - val_loss: 3.6006 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5487 - acc: 0.9431 - precision: 0.9774 - recall: 0.9018 - f1_score: 0.9372 - val_loss: 3.5833 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5312 - acc: 0.9431 - precision: 0.9777 - recall: 0.9017 - f1_score: 0.9371 - val_loss: 3.5661 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5138 - acc: 0.9431 - precision: 0.9799 - recall: 0.9070 - f1_score: 0.9409 - val_loss: 3.5490 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4965 - acc: 0.9431 - precision: 0.9774 - recall: 0.9005 - f1_score: 0.9360 - val_loss: 3.5320 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4793 - acc: 0.9431 - precision: 0.9781 - recall: 0.9002 - f1_score: 0.9363 - val_loss: 3.5151 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4622 - acc: 0.9431 - precision: 0.9787 - recall: 0.9016 - f1_score: 0.9375 - val_loss: 3.4983 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4452 - acc: 0.9431 - precision: 0.9792 - recall: 0.9010 - f1_score: 0.9375 - val_loss: 3.4815 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4283 - acc: 0.9431 - precision: 0.9800 - recall: 0.9052 - f1_score: 0.9395 - val_loss: 3.4649 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4115 - acc: 0.9431 - precision: 0.9781 - recall: 0.9057 - f1_score: 0.9396 - val_loss: 3.4483 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3948 - acc: 0.9431 - precision: 0.9790 - recall: 0.9053 - f1_score: 0.9395 - val_loss: 3.4318 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3781 - acc: 0.9431 - precision: 0.9789 - recall: 0.9034 - f1_score: 0.9384 - val_loss: 3.4154 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3616 - acc: 0.9431 - precision: 0.9794 - recall: 0.9014 - f1_score: 0.9377 - val_loss: 3.3991 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3451 - acc: 0.9431 - precision: 0.9806 - recall: 0.9065 - f1_score: 0.9408 - val_loss: 3.3829 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3288 - acc: 0.9431 - precision: 0.9771 - recall: 0.8995 - f1_score: 0.9360 - val_loss: 3.3668 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3125 - acc: 0.9431 - precision: 0.9780 - recall: 0.9040 - f1_score: 0.9383 - val_loss: 3.3508 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2963 - acc: 0.9431 - precision: 0.9795 - recall: 0.9011 - f1_score: 0.9372 - val_loss: 3.3348 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2802 - acc: 0.9431 - precision: 0.9799 - recall: 0.9051 - f1_score: 0.9397 - val_loss: 3.3190 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2642 - acc: 0.9431 - precision: 0.9792 - recall: 0.9015 - f1_score: 0.9375 - val_loss: 3.3032 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2483 - acc: 0.9431 - precision: 0.9778 - recall: 0.9078 - f1_score: 0.9401 - val_loss: 3.2875 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2325 - acc: 0.9431 - precision: 0.9807 - recall: 0.9051 - f1_score: 0.9399 - val_loss: 3.2719 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.2168 - acc: 0.9431 - precision: 0.9785 - recall: 0.9019 - f1_score: 0.9377 - val_loss: 3.2564 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2011 - acc: 0.9431 - precision: 0.9799 - recall: 0.9022 - f1_score: 0.9377 - val_loss: 3.2409 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1855 - acc: 0.9431 - precision: 0.9774 - recall: 0.9002 - f1_score: 0.9362 - val_loss: 3.2255 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1700 - acc: 0.9431 - precision: 0.9790 - recall: 0.9001 - f1_score: 0.9368 - val_loss: 3.2102 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 3.1547 - acc: 0.9450 - precision: 0.9822 - recall: 0.9007 - f1_score: 0.938 - 0s - loss: 3.1546 - acc: 0.9431 - precision: 0.9802 - recall: 0.9004 - f1_score: 0.9377 - val_loss: 3.1950 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 3.1509 - acc: 0.9400 - precision: 0.9524 - recall: 0.9091 - f1_score: 0.930 - 0s - loss: 3.1393 - acc: 0.9431 - precision: 0.9785 - recall: 0.8988 - f1_score: 0.9360 - val_loss: 3.1799 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1240 - acc: 0.9431 - precision: 0.9770 - recall: 0.8986 - f1_score: 0.9344 - val_loss: 3.1649 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8082 - val_f1_score: 0.8867\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1089 - acc: 0.9431 - precision: 0.9805 - recall: 0.9027 - f1_score: 0.9390 - val_loss: 3.1499 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0938 - acc: 0.9431 - precision: 0.9781 - recall: 0.9053 - f1_score: 0.9396 - val_loss: 3.1350 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0788 - acc: 0.9431 - precision: 0.9795 - recall: 0.9049 - f1_score: 0.9399 - val_loss: 3.1202 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0639 - acc: 0.9431 - precision: 0.9782 - recall: 0.9009 - f1_score: 0.9365 - val_loss: 3.1055 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0491 - acc: 0.9431 - precision: 0.9778 - recall: 0.9045 - f1_score: 0.9389 - val_loss: 3.0908 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0343 - acc: 0.9431 - precision: 0.9806 - recall: 0.8968 - f1_score: 0.9355 - val_loss: 3.0762 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0196 - acc: 0.9431 - precision: 0.9801 - recall: 0.9028 - f1_score: 0.9386 - val_loss: 3.0618 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0050 - acc: 0.9415 - precision: 0.9788 - recall: 0.8980 - f1_score: 0.9362 - val_loss: 3.0474 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9905 - acc: 0.9415 - precision: 0.9770 - recall: 0.9027 - f1_score: 0.9372 - val_loss: 3.0330 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9761 - acc: 0.9415 - precision: 0.9796 - recall: 0.8998 - f1_score: 0.9369 - val_loss: 3.0187 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9617 - acc: 0.9415 - precision: 0.9784 - recall: 0.8998 - f1_score: 0.9370 - val_loss: 3.0045 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9474 - acc: 0.9415 - precision: 0.9781 - recall: 0.9017 - f1_score: 0.9367 - val_loss: 2.9904 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9332 - acc: 0.9415 - precision: 0.9797 - recall: 0.9011 - f1_score: 0.9382 - val_loss: 2.9764 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9191 - acc: 0.9415 - precision: 0.9796 - recall: 0.9008 - f1_score: 0.9369 - val_loss: 2.9624 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9050 - acc: 0.9415 - precision: 0.9775 - recall: 0.8982 - f1_score: 0.9340 - val_loss: 2.9486 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8910 - acc: 0.9415 - precision: 0.9803 - recall: 0.9031 - f1_score: 0.9386 - val_loss: 2.9347 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8771 - acc: 0.9415 - precision: 0.9792 - recall: 0.8953 - f1_score: 0.9340 - val_loss: 2.9210 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8633 - acc: 0.9415 - precision: 0.9785 - recall: 0.9022 - f1_score: 0.9377 - val_loss: 2.9073 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8495 - acc: 0.9415 - precision: 0.9796 - recall: 0.9012 - f1_score: 0.9381 - val_loss: 2.8937 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8359 - acc: 0.9415 - precision: 0.9795 - recall: 0.9001 - f1_score: 0.9357 - val_loss: 2.8802 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8222 - acc: 0.9415 - precision: 0.9789 - recall: 0.8968 - f1_score: 0.9348 - val_loss: 2.8667 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8087 - acc: 0.9415 - precision: 0.9795 - recall: 0.9020 - f1_score: 0.9381 - val_loss: 2.8533 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7952 - acc: 0.9415 - precision: 0.9795 - recall: 0.8962 - f1_score: 0.9350 - val_loss: 2.8400 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7818 - acc: 0.9415 - precision: 0.9790 - recall: 0.9012 - f1_score: 0.9375 - val_loss: 2.8268 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.7685 - acc: 0.9415 - precision: 0.9796 - recall: 0.9026 - f1_score: 0.9389 - val_loss: 2.8136 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7553 - acc: 0.9415 - precision: 0.9794 - recall: 0.9027 - f1_score: 0.9385 - val_loss: 2.8005 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7421 - acc: 0.9415 - precision: 0.9781 - recall: 0.9004 - f1_score: 0.9356 - val_loss: 2.7874 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7290 - acc: 0.9415 - precision: 0.9773 - recall: 0.8998 - f1_score: 0.9363 - val_loss: 2.7745 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7159 - acc: 0.9415 - precision: 0.9795 - recall: 0.9016 - f1_score: 0.9381 - val_loss: 2.7616 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7030 - acc: 0.9415 - precision: 0.9792 - recall: 0.8998 - f1_score: 0.9364 - val_loss: 2.7487 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6900 - acc: 0.9415 - precision: 0.9789 - recall: 0.8973 - f1_score: 0.9348 - val_loss: 2.7360 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6772 - acc: 0.9415 - precision: 0.9801 - recall: 0.8991 - f1_score: 0.9369 - val_loss: 2.7233 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6644 - acc: 0.9415 - precision: 0.9792 - recall: 0.8993 - f1_score: 0.9365 - val_loss: 2.7106 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6517 - acc: 0.9415 - precision: 0.9806 - recall: 0.9011 - f1_score: 0.9376 - val_loss: 2.6981 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6391 - acc: 0.9415 - precision: 0.9791 - recall: 0.9010 - f1_score: 0.9378 - val_loss: 2.6856 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6265 - acc: 0.9415 - precision: 0.9796 - recall: 0.9047 - f1_score: 0.9397 - val_loss: 2.6731 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6140 - acc: 0.9415 - precision: 0.9781 - recall: 0.8969 - f1_score: 0.9343 - val_loss: 2.6607 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6016 - acc: 0.9415 - precision: 0.9794 - recall: 0.9053 - f1_score: 0.9394 - val_loss: 2.6484 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5892 - acc: 0.9415 - precision: 0.9800 - recall: 0.8995 - f1_score: 0.9371 - val_loss: 2.6362 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5769 - acc: 0.9415 - precision: 0.9797 - recall: 0.8968 - f1_score: 0.9352 - val_loss: 2.6240 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5647 - acc: 0.9415 - precision: 0.9792 - recall: 0.8999 - f1_score: 0.9371 - val_loss: 2.6119 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5525 - acc: 0.9415 - precision: 0.9770 - recall: 0.8976 - f1_score: 0.9354 - val_loss: 2.5998 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5404 - acc: 0.9415 - precision: 0.9789 - recall: 0.8978 - f1_score: 0.9358 - val_loss: 2.5878 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5283 - acc: 0.9415 - precision: 0.9786 - recall: 0.9021 - f1_score: 0.9380 - val_loss: 2.5759 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5164 - acc: 0.9415 - precision: 0.9782 - recall: 0.9013 - f1_score: 0.9374 - val_loss: 2.5640 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5044 - acc: 0.9415 - precision: 0.9800 - recall: 0.8986 - f1_score: 0.9358 - val_loss: 2.5522 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4926 - acc: 0.9415 - precision: 0.9801 - recall: 0.9002 - f1_score: 0.9374 - val_loss: 2.5405 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4808 - acc: 0.9415 - precision: 0.9766 - recall: 0.9013 - f1_score: 0.9363 - val_loss: 2.5288 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4691 - acc: 0.9415 - precision: 0.9783 - recall: 0.9022 - f1_score: 0.9376 - val_loss: 2.5172 - val_acc: 0.8861 - val_precision: 0.9849 - val_recall: 0.7986 - val_f1_score: 0.8806\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4574 - acc: 0.9415 - precision: 0.9781 - recall: 0.8999 - f1_score: 0.9366 - val_loss: 2.5056 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4458 - acc: 0.9415 - precision: 0.9795 - recall: 0.9038 - f1_score: 0.9382 - val_loss: 2.4941 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4342 - acc: 0.9415 - precision: 0.9782 - recall: 0.8991 - f1_score: 0.9361 - val_loss: 2.4827 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4228 - acc: 0.9415 - precision: 0.9778 - recall: 0.8998 - f1_score: 0.9363 - val_loss: 2.4713 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4113 - acc: 0.9415 - precision: 0.9784 - recall: 0.8952 - f1_score: 0.9336 - val_loss: 2.4600 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4000 - acc: 0.9415 - precision: 0.9764 - recall: 0.8959 - f1_score: 0.9333 - val_loss: 2.4487 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3887 - acc: 0.9415 - precision: 0.9796 - recall: 0.8999 - f1_score: 0.9372 - val_loss: 2.4375 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 182/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.3774 - acc: 0.9415 - precision: 0.9788 - recall: 0.8994 - f1_score: 0.9356 - val_loss: 2.4263 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3662 - acc: 0.9415 - precision: 0.9807 - recall: 0.8982 - f1_score: 0.9349 - val_loss: 2.4153 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3551 - acc: 0.9415 - precision: 0.9798 - recall: 0.8987 - f1_score: 0.9363 - val_loss: 2.4042 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3440 - acc: 0.9415 - precision: 0.9789 - recall: 0.9057 - f1_score: 0.9394 - val_loss: 2.3933 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3330 - acc: 0.9415 - precision: 0.9758 - recall: 0.9019 - f1_score: 0.9355 - val_loss: 2.3823 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3220 - acc: 0.9415 - precision: 0.9796 - recall: 0.8983 - f1_score: 0.9363 - val_loss: 2.3715 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3112 - acc: 0.9415 - precision: 0.9796 - recall: 0.8986 - f1_score: 0.9371 - val_loss: 2.3607 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3003 - acc: 0.9415 - precision: 0.9788 - recall: 0.8991 - f1_score: 0.9364 - val_loss: 2.3499 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2895 - acc: 0.9415 - precision: 0.9803 - recall: 0.8977 - f1_score: 0.9359 - val_loss: 2.3392 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2788 - acc: 0.9415 - precision: 0.9784 - recall: 0.8994 - f1_score: 0.9362 - val_loss: 2.3286 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2681 - acc: 0.9415 - precision: 0.9764 - recall: 0.9028 - f1_score: 0.9370 - val_loss: 2.3180 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2575 - acc: 0.9415 - precision: 0.9760 - recall: 0.9040 - f1_score: 0.9360 - val_loss: 2.3075 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2470 - acc: 0.9415 - precision: 0.9799 - recall: 0.8975 - f1_score: 0.9359 - val_loss: 2.2970 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2365 - acc: 0.9415 - precision: 0.9777 - recall: 0.8994 - f1_score: 0.9355 - val_loss: 2.2866 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2260 - acc: 0.9415 - precision: 0.9802 - recall: 0.8956 - f1_score: 0.9346 - val_loss: 2.2763 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2156 - acc: 0.9415 - precision: 0.9773 - recall: 0.9043 - f1_score: 0.9376 - val_loss: 2.2660 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2053 - acc: 0.9415 - precision: 0.9796 - recall: 0.9035 - f1_score: 0.9387 - val_loss: 2.2557 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1950 - acc: 0.9415 - precision: 0.9801 - recall: 0.8978 - f1_score: 0.9363 - val_loss: 2.2455 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1847 - acc: 0.9415 - precision: 0.9789 - recall: 0.8902 - f1_score: 0.9305 - val_loss: 2.2354 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1746 - acc: 0.9415 - precision: 0.9783 - recall: 0.9013 - f1_score: 0.9369 - val_loss: 2.2253 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1644 - acc: 0.9415 - precision: 0.9794 - recall: 0.8996 - f1_score: 0.9365 - val_loss: 2.2152 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1544 - acc: 0.9415 - precision: 0.9785 - recall: 0.9001 - f1_score: 0.9362 - val_loss: 2.2052 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1444 - acc: 0.9415 - precision: 0.9797 - recall: 0.8989 - f1_score: 0.9367 - val_loss: 2.1953 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1344 - acc: 0.9415 - precision: 0.9783 - recall: 0.8987 - f1_score: 0.9358 - val_loss: 2.1854 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1245 - acc: 0.9415 - precision: 0.9803 - recall: 0.8996 - f1_score: 0.9378 - val_loss: 2.1756 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1146 - acc: 0.9415 - precision: 0.9797 - recall: 0.9002 - f1_score: 0.9369 - val_loss: 2.1658 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1048 - acc: 0.9415 - precision: 0.9784 - recall: 0.9033 - f1_score: 0.9377 - val_loss: 2.1561 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0950 - acc: 0.9415 - precision: 0.9794 - recall: 0.8950 - f1_score: 0.9329 - val_loss: 2.1464 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0853 - acc: 0.9415 - precision: 0.9795 - recall: 0.9011 - f1_score: 0.9379 - val_loss: 2.1367 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0757 - acc: 0.9415 - precision: 0.9776 - recall: 0.8990 - f1_score: 0.9357 - val_loss: 2.1272 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0661 - acc: 0.9415 - precision: 0.9799 - recall: 0.8961 - f1_score: 0.9350 - val_loss: 2.1176 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0565 - acc: 0.9415 - precision: 0.9795 - recall: 0.8971 - f1_score: 0.9347 - val_loss: 2.1081 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.0470 - acc: 0.9415 - precision: 0.9801 - recall: 0.8992 - f1_score: 0.9363 - val_loss: 2.0987 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0375 - acc: 0.9415 - precision: 0.9787 - recall: 0.8979 - f1_score: 0.9356 - val_loss: 2.0893 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0281 - acc: 0.9415 - precision: 0.9792 - recall: 0.8990 - f1_score: 0.9362 - val_loss: 2.0800 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0188 - acc: 0.9415 - precision: 0.9790 - recall: 0.9013 - f1_score: 0.9378 - val_loss: 2.0707 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0095 - acc: 0.9415 - precision: 0.9787 - recall: 0.8975 - f1_score: 0.9360 - val_loss: 2.0615 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0002 - acc: 0.9415 - precision: 0.9742 - recall: 0.8996 - f1_score: 0.9346 - val_loss: 2.0523 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9910 - acc: 0.9415 - precision: 0.9773 - recall: 0.8963 - f1_score: 0.9341 - val_loss: 2.0431 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9818 - acc: 0.9415 - precision: 0.9781 - recall: 0.8999 - f1_score: 0.9362 - val_loss: 2.0340 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9727 - acc: 0.9415 - precision: 0.9772 - recall: 0.8998 - f1_score: 0.9358 - val_loss: 2.0250 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9636 - acc: 0.9415 - precision: 0.9792 - recall: 0.8994 - f1_score: 0.9363 - val_loss: 2.0160 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9546 - acc: 0.9431 - precision: 0.9792 - recall: 0.9067 - f1_score: 0.9397 - val_loss: 2.0070 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9456 - acc: 0.9431 - precision: 0.9798 - recall: 0.8989 - f1_score: 0.9364 - val_loss: 1.9981 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9367 - acc: 0.9431 - precision: 0.9797 - recall: 0.9066 - f1_score: 0.9396 - val_loss: 1.9893 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9278 - acc: 0.9431 - precision: 0.9791 - recall: 0.9002 - f1_score: 0.9367 - val_loss: 1.9805 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9190 - acc: 0.9431 - precision: 0.9786 - recall: 0.8978 - f1_score: 0.9345 - val_loss: 1.9717 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9102 - acc: 0.9431 - precision: 0.9810 - recall: 0.8991 - f1_score: 0.9364 - val_loss: 1.9630 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9015 - acc: 0.9431 - precision: 0.9786 - recall: 0.9035 - f1_score: 0.9391 - val_loss: 1.9543 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8928 - acc: 0.9431 - precision: 0.9815 - recall: 0.9019 - f1_score: 0.9393 - val_loss: 1.9456 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8841 - acc: 0.9431 - precision: 0.9796 - recall: 0.8982 - f1_score: 0.9358 - val_loss: 1.9371 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8755 - acc: 0.9431 - precision: 0.9785 - recall: 0.9028 - f1_score: 0.9381 - val_loss: 1.9285 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8669 - acc: 0.9431 - precision: 0.9808 - recall: 0.9028 - f1_score: 0.9393 - val_loss: 1.9200 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8584 - acc: 0.9431 - precision: 0.9790 - recall: 0.9029 - f1_score: 0.9390 - val_loss: 1.9115 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8499 - acc: 0.9431 - precision: 0.9799 - recall: 0.8999 - f1_score: 0.9373 - val_loss: 1.9031 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8415 - acc: 0.9431 - precision: 0.9776 - recall: 0.9035 - f1_score: 0.9378 - val_loss: 1.8948 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8331 - acc: 0.9431 - precision: 0.9786 - recall: 0.9045 - f1_score: 0.9387 - val_loss: 1.8864 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8248 - acc: 0.9431 - precision: 0.9785 - recall: 0.9019 - f1_score: 0.9371 - val_loss: 1.8781 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8165 - acc: 0.9431 - precision: 0.9795 - recall: 0.9030 - f1_score: 0.9387 - val_loss: 1.8699 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8082 - acc: 0.9431 - precision: 0.9796 - recall: 0.9008 - f1_score: 0.9367 - val_loss: 1.8617 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8000 - acc: 0.9431 - precision: 0.9763 - recall: 0.8978 - f1_score: 0.9347 - val_loss: 1.8536 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7918 - acc: 0.9431 - precision: 0.9789 - recall: 0.9030 - f1_score: 0.9385 - val_loss: 1.8454 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7837 - acc: 0.9431 - precision: 0.9772 - recall: 0.9033 - f1_score: 0.9374 - val_loss: 1.8374 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7756 - acc: 0.9431 - precision: 0.9775 - recall: 0.8983 - f1_score: 0.9345 - val_loss: 1.8293 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 246/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.7676 - acc: 0.9431 - precision: 0.9796 - recall: 0.9028 - f1_score: 0.9386 - val_loss: 1.8213 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7595 - acc: 0.9431 - precision: 0.9783 - recall: 0.9021 - f1_score: 0.9374 - val_loss: 1.8134 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7516 - acc: 0.9431 - precision: 0.9798 - recall: 0.9081 - f1_score: 0.9413 - val_loss: 1.8055 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7437 - acc: 0.9431 - precision: 0.9783 - recall: 0.9042 - f1_score: 0.9390 - val_loss: 1.7976 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7358 - acc: 0.9431 - precision: 0.9799 - recall: 0.9026 - f1_score: 0.9380 - val_loss: 1.7898 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7279 - acc: 0.9431 - precision: 0.9788 - recall: 0.9029 - f1_score: 0.9389 - val_loss: 1.7820 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7201 - acc: 0.9431 - precision: 0.9807 - recall: 0.9053 - f1_score: 0.9397 - val_loss: 1.7743 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7124 - acc: 0.9431 - precision: 0.9774 - recall: 0.9025 - f1_score: 0.9372 - val_loss: 1.7666 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7047 - acc: 0.9431 - precision: 0.9785 - recall: 0.8993 - f1_score: 0.9357 - val_loss: 1.7589 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6970 - acc: 0.9431 - precision: 0.9798 - recall: 0.9013 - f1_score: 0.9369 - val_loss: 1.7512 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6893 - acc: 0.9431 - precision: 0.9809 - recall: 0.9011 - f1_score: 0.9386 - val_loss: 1.7437 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6817 - acc: 0.9431 - precision: 0.9802 - recall: 0.8997 - f1_score: 0.9361 - val_loss: 1.7361 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6742 - acc: 0.9431 - precision: 0.9787 - recall: 0.8997 - f1_score: 0.9364 - val_loss: 1.7286 - val_acc: 0.8924 - val_precision: 0.9849 - val_recall: 0.8130 - val_f1_score: 0.8895\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6667 - acc: 0.9431 - precision: 0.9769 - recall: 0.9051 - f1_score: 0.9384 - val_loss: 1.7211 - val_acc: 0.8987 - val_precision: 0.9849 - val_recall: 0.8274 - val_f1_score: 0.8980\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6592 - acc: 0.9431 - precision: 0.9775 - recall: 0.8991 - f1_score: 0.9359 - val_loss: 1.7137 - val_acc: 0.8987 - val_precision: 0.9849 - val_recall: 0.8274 - val_f1_score: 0.8980\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6517 - acc: 0.9431 - precision: 0.9798 - recall: 0.9005 - f1_score: 0.9373 - val_loss: 1.7063 - val_acc: 0.8987 - val_precision: 0.9849 - val_recall: 0.8274 - val_f1_score: 0.8980\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6443 - acc: 0.9431 - precision: 0.9789 - recall: 0.9027 - f1_score: 0.9382 - val_loss: 1.6989 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6370 - acc: 0.9415 - precision: 0.9780 - recall: 0.9004 - f1_score: 0.9365 - val_loss: 1.6916 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6296 - acc: 0.9415 - precision: 0.9801 - recall: 0.8993 - f1_score: 0.9375 - val_loss: 1.6843 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6223 - acc: 0.9415 - precision: 0.9786 - recall: 0.9014 - f1_score: 0.9372 - val_loss: 1.6771 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6151 - acc: 0.9415 - precision: 0.9768 - recall: 0.8968 - f1_score: 0.9349 - val_loss: 1.6699 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6079 - acc: 0.9415 - precision: 0.9802 - recall: 0.9012 - f1_score: 0.9375 - val_loss: 1.6627 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6007 - acc: 0.9415 - precision: 0.9795 - recall: 0.8978 - f1_score: 0.9354 - val_loss: 1.6556 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5935 - acc: 0.9415 - precision: 0.9771 - recall: 0.8994 - f1_score: 0.9355 - val_loss: 1.6485 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5864 - acc: 0.9415 - precision: 0.9791 - recall: 0.9024 - f1_score: 0.9382 - val_loss: 1.6414 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5794 - acc: 0.9415 - precision: 0.9783 - recall: 0.8953 - f1_score: 0.9332 - val_loss: 1.6344 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5723 - acc: 0.9415 - precision: 0.9791 - recall: 0.8987 - f1_score: 0.9360 - val_loss: 1.6274 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5653 - acc: 0.9415 - precision: 0.9801 - recall: 0.8958 - f1_score: 0.9355 - val_loss: 1.6205 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5584 - acc: 0.9415 - precision: 0.9799 - recall: 0.8974 - f1_score: 0.9356 - val_loss: 1.6135 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5515 - acc: 0.9415 - precision: 0.9826 - recall: 0.9004 - f1_score: 0.9387 - val_loss: 1.6067 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5446 - acc: 0.9415 - precision: 0.9773 - recall: 0.8986 - f1_score: 0.9352 - val_loss: 1.5998 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5377 - acc: 0.9415 - precision: 0.9797 - recall: 0.8987 - f1_score: 0.9363 - val_loss: 1.5930 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.5309 - acc: 0.9415 - precision: 0.9776 - recall: 0.8995 - f1_score: 0.9360 - val_loss: 1.5862 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5241 - acc: 0.9415 - precision: 0.9778 - recall: 0.8986 - f1_score: 0.9353 - val_loss: 1.5795 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5174 - acc: 0.9415 - precision: 0.9780 - recall: 0.9013 - f1_score: 0.9370 - val_loss: 1.5728 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5107 - acc: 0.9415 - precision: 0.9783 - recall: 0.8981 - f1_score: 0.9359 - val_loss: 1.5661 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5040 - acc: 0.9415 - precision: 0.9775 - recall: 0.8998 - f1_score: 0.9355 - val_loss: 1.5595 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4974 - acc: 0.9415 - precision: 0.9813 - recall: 0.8976 - f1_score: 0.9357 - val_loss: 1.5529 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4907 - acc: 0.9415 - precision: 0.9784 - recall: 0.8968 - f1_score: 0.9350 - val_loss: 1.5463 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4842 - acc: 0.9415 - precision: 0.9812 - recall: 0.8976 - f1_score: 0.9359 - val_loss: 1.5398 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4776 - acc: 0.9415 - precision: 0.9785 - recall: 0.9005 - f1_score: 0.9369 - val_loss: 1.5333 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4711 - acc: 0.9415 - precision: 0.9778 - recall: 0.8970 - f1_score: 0.9339 - val_loss: 1.5268 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4647 - acc: 0.9415 - precision: 0.9774 - recall: 0.8931 - f1_score: 0.9325 - val_loss: 1.5204 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4582 - acc: 0.9415 - precision: 0.9796 - recall: 0.8992 - f1_score: 0.9365 - val_loss: 1.5140 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4518 - acc: 0.9415 - precision: 0.9794 - recall: 0.9014 - f1_score: 0.9377 - val_loss: 1.5076 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4454 - acc: 0.9415 - precision: 0.9775 - recall: 0.8985 - f1_score: 0.9353 - val_loss: 1.5012 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4391 - acc: 0.9415 - precision: 0.9763 - recall: 0.8996 - f1_score: 0.9354 - val_loss: 1.4949 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4328 - acc: 0.9415 - precision: 0.9805 - recall: 0.9010 - f1_score: 0.9379 - val_loss: 1.4887 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4265 - acc: 0.9415 - precision: 0.9783 - recall: 0.8948 - f1_score: 0.9334 - val_loss: 1.4824 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4203 - acc: 0.9415 - precision: 0.9797 - recall: 0.9002 - f1_score: 0.9374 - val_loss: 1.4762 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4141 - acc: 0.9415 - precision: 0.9789 - recall: 0.9046 - f1_score: 0.9395 - val_loss: 1.4700 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4079 - acc: 0.9415 - precision: 0.9774 - recall: 0.9013 - f1_score: 0.9368 - val_loss: 1.4639 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4017 - acc: 0.9415 - precision: 0.9796 - recall: 0.9003 - f1_score: 0.9371 - val_loss: 1.4578 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3956 - acc: 0.9415 - precision: 0.9787 - recall: 0.9014 - f1_score: 0.9366 - val_loss: 1.4517 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3895 - acc: 0.9415 - precision: 0.9805 - recall: 0.8983 - f1_score: 0.9357 - val_loss: 1.4457 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3835 - acc: 0.9415 - precision: 0.9796 - recall: 0.9001 - f1_score: 0.9372 - val_loss: 1.4396 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3774 - acc: 0.9415 - precision: 0.9790 - recall: 0.8998 - f1_score: 0.9367 - val_loss: 1.4337 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3715 - acc: 0.9431 - precision: 0.9803 - recall: 0.9041 - f1_score: 0.9393 - val_loss: 1.4277 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3655 - acc: 0.9431 - precision: 0.9788 - recall: 0.9044 - f1_score: 0.9393 - val_loss: 1.4218 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3596 - acc: 0.9431 - precision: 0.9784 - recall: 0.9037 - f1_score: 0.9385 - val_loss: 1.4159 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3537 - acc: 0.9431 - precision: 0.9785 - recall: 0.8992 - f1_score: 0.9353 - val_loss: 1.4100 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3478 - acc: 0.9431 - precision: 0.9802 - recall: 0.9033 - f1_score: 0.9384 - val_loss: 1.4042 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3420 - acc: 0.9431 - precision: 0.9779 - recall: 0.9001 - f1_score: 0.9365 - val_loss: 1.3984 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3361 - acc: 0.9431 - precision: 0.9803 - recall: 0.9022 - f1_score: 0.9380 - val_loss: 1.3926 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 310/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3304 - acc: 0.9431 - precision: 0.9785 - recall: 0.8992 - f1_score: 0.9351 - val_loss: 1.3868 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3246 - acc: 0.9431 - precision: 0.9775 - recall: 0.9065 - f1_score: 0.9396 - val_loss: 1.3811 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3189 - acc: 0.9431 - precision: 0.9790 - recall: 0.9018 - f1_score: 0.9376 - val_loss: 1.3754 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3132 - acc: 0.9431 - precision: 0.9789 - recall: 0.9070 - f1_score: 0.9409 - val_loss: 1.3698 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3075 - acc: 0.9431 - precision: 0.9775 - recall: 0.9009 - f1_score: 0.9365 - val_loss: 1.3641 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3019 - acc: 0.9431 - precision: 0.9785 - recall: 0.8997 - f1_score: 0.9368 - val_loss: 1.3586 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2963 - acc: 0.9431 - precision: 0.9795 - recall: 0.8996 - f1_score: 0.9368 - val_loss: 1.3530 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2907 - acc: 0.9431 - precision: 0.9801 - recall: 0.9023 - f1_score: 0.9374 - val_loss: 1.3474 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2852 - acc: 0.9431 - precision: 0.9777 - recall: 0.9045 - f1_score: 0.9380 - val_loss: 1.3419 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2797 - acc: 0.9431 - precision: 0.9795 - recall: 0.8991 - f1_score: 0.9359 - val_loss: 1.3364 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2742 - acc: 0.9431 - precision: 0.9790 - recall: 0.9033 - f1_score: 0.9379 - val_loss: 1.3310 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2687 - acc: 0.9431 - precision: 0.9806 - recall: 0.9041 - f1_score: 0.9395 - val_loss: 1.3256 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2633 - acc: 0.9431 - precision: 0.9789 - recall: 0.9017 - f1_score: 0.9376 - val_loss: 1.3202 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2579 - acc: 0.9431 - precision: 0.9807 - recall: 0.8997 - f1_score: 0.9376 - val_loss: 1.3148 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2525 - acc: 0.9431 - precision: 0.9777 - recall: 0.9049 - f1_score: 0.9389 - val_loss: 1.3094 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2472 - acc: 0.9431 - precision: 0.9796 - recall: 0.9019 - f1_score: 0.9379 - val_loss: 1.3041 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2419 - acc: 0.9431 - precision: 0.9761 - recall: 0.9032 - f1_score: 0.9372 - val_loss: 1.2988 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2366 - acc: 0.9431 - precision: 0.9794 - recall: 0.8990 - f1_score: 0.9363 - val_loss: 1.2935 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2313 - acc: 0.9431 - precision: 0.9780 - recall: 0.8996 - f1_score: 0.9358 - val_loss: 1.2883 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2260 - acc: 0.9431 - precision: 0.9799 - recall: 0.9068 - f1_score: 0.9409 - val_loss: 1.2831 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2208 - acc: 0.9431 - precision: 0.9789 - recall: 0.9037 - f1_score: 0.9384 - val_loss: 1.2779 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2156 - acc: 0.9431 - precision: 0.9793 - recall: 0.9011 - f1_score: 0.9374 - val_loss: 1.2728 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2105 - acc: 0.9431 - precision: 0.9803 - recall: 0.9052 - f1_score: 0.9392 - val_loss: 1.2676 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2053 - acc: 0.9431 - precision: 0.9795 - recall: 0.9029 - f1_score: 0.9386 - val_loss: 1.2625 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2002 - acc: 0.9431 - precision: 0.9802 - recall: 0.9039 - f1_score: 0.9397 - val_loss: 1.2575 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1952 - acc: 0.9431 - precision: 0.9787 - recall: 0.9033 - f1_score: 0.9390 - val_loss: 1.2524 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1901 - acc: 0.9431 - precision: 0.9788 - recall: 0.9058 - f1_score: 0.9396 - val_loss: 1.2474 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1851 - acc: 0.9431 - precision: 0.9799 - recall: 0.9014 - f1_score: 0.9379 - val_loss: 1.2424 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1801 - acc: 0.9431 - precision: 0.9774 - recall: 0.9016 - f1_score: 0.9374 - val_loss: 1.2374 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1751 - acc: 0.9431 - precision: 0.9773 - recall: 0.8976 - f1_score: 0.9348 - val_loss: 1.2325 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1701 - acc: 0.9431 - precision: 0.9800 - recall: 0.9033 - f1_score: 0.9389 - val_loss: 1.2275 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.1696 - acc: 0.9440 - precision: 0.9865 - recall: 0.8922 - f1_score: 0.934 - 0s - loss: 1.1652 - acc: 0.9431 - precision: 0.9796 - recall: 0.9006 - f1_score: 0.9364 - val_loss: 1.2226 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 342/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1603 - acc: 0.9431 - precision: 0.9782 - recall: 0.9022 - f1_score: 0.9378 - val_loss: 1.2177 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1554 - acc: 0.9431 - precision: 0.9776 - recall: 0.9065 - f1_score: 0.9393 - val_loss: 1.2129 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1506 - acc: 0.9431 - precision: 0.9788 - recall: 0.9054 - f1_score: 0.9400 - val_loss: 1.2081 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1457 - acc: 0.9431 - precision: 0.9791 - recall: 0.9041 - f1_score: 0.9394 - val_loss: 1.2033 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1409 - acc: 0.9431 - precision: 0.9794 - recall: 0.9032 - f1_score: 0.9385 - val_loss: 1.1985 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1362 - acc: 0.9431 - precision: 0.9761 - recall: 0.8990 - f1_score: 0.9351 - val_loss: 1.1937 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1314 - acc: 0.9431 - precision: 0.9790 - recall: 0.8982 - f1_score: 0.9352 - val_loss: 1.1890 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1267 - acc: 0.9431 - precision: 0.9794 - recall: 0.9016 - f1_score: 0.9377 - val_loss: 1.1843 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1220 - acc: 0.9431 - precision: 0.9779 - recall: 0.9037 - f1_score: 0.9388 - val_loss: 1.1796 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1173 - acc: 0.9431 - precision: 0.9775 - recall: 0.9022 - f1_score: 0.9376 - val_loss: 1.1750 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1126 - acc: 0.9431 - precision: 0.9784 - recall: 0.8998 - f1_score: 0.9361 - val_loss: 1.1704 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1080 - acc: 0.9431 - precision: 0.9779 - recall: 0.9056 - f1_score: 0.9384 - val_loss: 1.1658 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1034 - acc: 0.9431 - precision: 0.9777 - recall: 0.9024 - f1_score: 0.9378 - val_loss: 1.1612 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0988 - acc: 0.9431 - precision: 0.9782 - recall: 0.9045 - f1_score: 0.9383 - val_loss: 1.1566 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0943 - acc: 0.9431 - precision: 0.9809 - recall: 0.9057 - f1_score: 0.9403 - val_loss: 1.1521 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0897 - acc: 0.9431 - precision: 0.9774 - recall: 0.9005 - f1_score: 0.9362 - val_loss: 1.1476 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0852 - acc: 0.9431 - precision: 0.9775 - recall: 0.8976 - f1_score: 0.9346 - val_loss: 1.1431 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0807 - acc: 0.9431 - precision: 0.9776 - recall: 0.9030 - f1_score: 0.9376 - val_loss: 1.1386 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0762 - acc: 0.9431 - precision: 0.9805 - recall: 0.9032 - f1_score: 0.9389 - val_loss: 1.1342 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0718 - acc: 0.9431 - precision: 0.9774 - recall: 0.9000 - f1_score: 0.9366 - val_loss: 1.1297 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0674 - acc: 0.9431 - precision: 0.9794 - recall: 0.9071 - f1_score: 0.9394 - val_loss: 1.1253 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0630 - acc: 0.9431 - precision: 0.9793 - recall: 0.9066 - f1_score: 0.9401 - val_loss: 1.1210 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0586 - acc: 0.9431 - precision: 0.9800 - recall: 0.9071 - f1_score: 0.9413 - val_loss: 1.1166 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0542 - acc: 0.9431 - precision: 0.9796 - recall: 0.9053 - f1_score: 0.9400 - val_loss: 1.1123 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0499 - acc: 0.9431 - precision: 0.9793 - recall: 0.8965 - f1_score: 0.9350 - val_loss: 1.1080 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0456 - acc: 0.9431 - precision: 0.9792 - recall: 0.9057 - f1_score: 0.9390 - val_loss: 1.1037 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0413 - acc: 0.9431 - precision: 0.9795 - recall: 0.9033 - f1_score: 0.9381 - val_loss: 1.0994 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0370 - acc: 0.9431 - precision: 0.9798 - recall: 0.8976 - f1_score: 0.9356 - val_loss: 1.0952 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0328 - acc: 0.9431 - precision: 0.9769 - recall: 0.9016 - f1_score: 0.9370 - val_loss: 1.0909 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0285 - acc: 0.9431 - precision: 0.9781 - recall: 0.9018 - f1_score: 0.9370 - val_loss: 1.0867 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0243 - acc: 0.9431 - precision: 0.9823 - recall: 0.9061 - f1_score: 0.9409 - val_loss: 1.0825 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0201 - acc: 0.9431 - precision: 0.9792 - recall: 0.9058 - f1_score: 0.9394 - val_loss: 1.0784 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0160 - acc: 0.9431 - precision: 0.9767 - recall: 0.9035 - f1_score: 0.9382 - val_loss: 1.0742 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0118 - acc: 0.9447 - precision: 0.9840 - recall: 0.9003 - f1_score: 0.9388 - val_loss: 1.0701 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0077 - acc: 0.9431 - precision: 0.9769 - recall: 0.8986 - f1_score: 0.9352 - val_loss: 1.0660 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0036 - acc: 0.9447 - precision: 0.9821 - recall: 0.9022 - f1_score: 0.9395 - val_loss: 1.0620 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9995 - acc: 0.9447 - precision: 0.9819 - recall: 0.9028 - f1_score: 0.9396 - val_loss: 1.0579 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9955 - acc: 0.9447 - precision: 0.9814 - recall: 0.9029 - f1_score: 0.9398 - val_loss: 1.0539 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9915 - acc: 0.9447 - precision: 0.9824 - recall: 0.9043 - f1_score: 0.9392 - val_loss: 1.0498 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9874 - acc: 0.9447 - precision: 0.9843 - recall: 0.9090 - f1_score: 0.9437 - val_loss: 1.0459 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9834 - acc: 0.9447 - precision: 0.9810 - recall: 0.9006 - f1_score: 0.9383 - val_loss: 1.0419 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9795 - acc: 0.9447 - precision: 0.9824 - recall: 0.9062 - f1_score: 0.9415 - val_loss: 1.0379 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9755 - acc: 0.9447 - precision: 0.9827 - recall: 0.9031 - f1_score: 0.9405 - val_loss: 1.0340 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9716 - acc: 0.9447 - precision: 0.9826 - recall: 0.9014 - f1_score: 0.9387 - val_loss: 1.0301 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9677 - acc: 0.9447 - precision: 0.9842 - recall: 0.9053 - f1_score: 0.9412 - val_loss: 1.0262 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9638 - acc: 0.9447 - precision: 0.9831 - recall: 0.9064 - f1_score: 0.9424 - val_loss: 1.0223 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9599 - acc: 0.9447 - precision: 0.9829 - recall: 0.9023 - f1_score: 0.9403 - val_loss: 1.0185 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9560 - acc: 0.9447 - precision: 0.9827 - recall: 0.9052 - f1_score: 0.9406 - val_loss: 1.0146 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9522 - acc: 0.9447 - precision: 0.9838 - recall: 0.9048 - f1_score: 0.9416 - val_loss: 1.0108 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9484 - acc: 0.9447 - precision: 0.9836 - recall: 0.9041 - f1_score: 0.9409 - val_loss: 1.0070 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9446 - acc: 0.9447 - precision: 0.9821 - recall: 0.9050 - f1_score: 0.9408 - val_loss: 1.0032 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9408 - acc: 0.9447 - precision: 0.9821 - recall: 0.9030 - f1_score: 0.9395 - val_loss: 0.9995 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9371 - acc: 0.9447 - precision: 0.9821 - recall: 0.9054 - f1_score: 0.9410 - val_loss: 0.9957 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9333 - acc: 0.9447 - precision: 0.9822 - recall: 0.9016 - f1_score: 0.9391 - val_loss: 0.9920 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9296 - acc: 0.9447 - precision: 0.9809 - recall: 0.9038 - f1_score: 0.9385 - val_loss: 0.9883 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9259 - acc: 0.9447 - precision: 0.9842 - recall: 0.8996 - f1_score: 0.9384 - val_loss: 0.9847 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9222 - acc: 0.9447 - precision: 0.9828 - recall: 0.8990 - f1_score: 0.9381 - val_loss: 0.9810 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9186 - acc: 0.9447 - precision: 0.9817 - recall: 0.9018 - f1_score: 0.9393 - val_loss: 0.9774 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9149 - acc: 0.9447 - precision: 0.9824 - recall: 0.9056 - f1_score: 0.9414 - val_loss: 0.9737 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9113 - acc: 0.9447 - precision: 0.9811 - recall: 0.9026 - f1_score: 0.9393 - val_loss: 0.9701 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9077 - acc: 0.9447 - precision: 0.9798 - recall: 0.8986 - f1_score: 0.9372 - val_loss: 0.9665 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9041 - acc: 0.9447 - precision: 0.9819 - recall: 0.9013 - f1_score: 0.9390 - val_loss: 0.9630 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9005 - acc: 0.9447 - precision: 0.9812 - recall: 0.9027 - f1_score: 0.9397 - val_loss: 0.9594 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8970 - acc: 0.9447 - precision: 0.9826 - recall: 0.9032 - f1_score: 0.9404 - val_loss: 0.9559 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 406/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8934 - acc: 0.9447 - precision: 0.9823 - recall: 0.9072 - f1_score: 0.9424 - val_loss: 0.9524 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8899 - acc: 0.9447 - precision: 0.9845 - recall: 0.9019 - f1_score: 0.9399 - val_loss: 0.9489 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8864 - acc: 0.9447 - precision: 0.9838 - recall: 0.9014 - f1_score: 0.9392 - val_loss: 0.9454 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8829 - acc: 0.9447 - precision: 0.9834 - recall: 0.9077 - f1_score: 0.9431 - val_loss: 0.9419 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8795 - acc: 0.9447 - precision: 0.9835 - recall: 0.9046 - f1_score: 0.9403 - val_loss: 0.9385 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8760 - acc: 0.9447 - precision: 0.9829 - recall: 0.9081 - f1_score: 0.9423 - val_loss: 0.9350 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8726 - acc: 0.9447 - precision: 0.9835 - recall: 0.9070 - f1_score: 0.9415 - val_loss: 0.9317 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8692 - acc: 0.9447 - precision: 0.9822 - recall: 0.9029 - f1_score: 0.9394 - val_loss: 0.9283 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8658 - acc: 0.9447 - precision: 0.9840 - recall: 0.9080 - f1_score: 0.9431 - val_loss: 0.9249 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8624 - acc: 0.9447 - precision: 0.9818 - recall: 0.9019 - f1_score: 0.9393 - val_loss: 0.9215 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8590 - acc: 0.9447 - precision: 0.9825 - recall: 0.9031 - f1_score: 0.9406 - val_loss: 0.9182 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8557 - acc: 0.9447 - precision: 0.9834 - recall: 0.9052 - f1_score: 0.9413 - val_loss: 0.9149 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8524 - acc: 0.9447 - precision: 0.9840 - recall: 0.9058 - f1_score: 0.9411 - val_loss: 0.9115 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8491 - acc: 0.9447 - precision: 0.9826 - recall: 0.8985 - f1_score: 0.9378 - val_loss: 0.9083 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8458 - acc: 0.9447 - precision: 0.9828 - recall: 0.9039 - f1_score: 0.9406 - val_loss: 0.9050 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8425 - acc: 0.9447 - precision: 0.9816 - recall: 0.9020 - f1_score: 0.9389 - val_loss: 0.9017 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8392 - acc: 0.9447 - precision: 0.9807 - recall: 0.9062 - f1_score: 0.9404 - val_loss: 0.8985 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8360 - acc: 0.9447 - precision: 0.9812 - recall: 0.9038 - f1_score: 0.9392 - val_loss: 0.8953 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8328 - acc: 0.9447 - precision: 0.9793 - recall: 0.8998 - f1_score: 0.9372 - val_loss: 0.8921 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8295 - acc: 0.9447 - precision: 0.9848 - recall: 0.9030 - f1_score: 0.9416 - val_loss: 0.8889 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8263 - acc: 0.9447 - precision: 0.9834 - recall: 0.9005 - f1_score: 0.9394 - val_loss: 0.8857 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8232 - acc: 0.9447 - precision: 0.9827 - recall: 0.8984 - f1_score: 0.9376 - val_loss: 0.8825 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8200 - acc: 0.9447 - precision: 0.9833 - recall: 0.9037 - f1_score: 0.9412 - val_loss: 0.8794 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8169 - acc: 0.9447 - precision: 0.9813 - recall: 0.9063 - f1_score: 0.9412 - val_loss: 0.8763 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8137 - acc: 0.9447 - precision: 0.9829 - recall: 0.9054 - f1_score: 0.9418 - val_loss: 0.8732 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8106 - acc: 0.9447 - precision: 0.9810 - recall: 0.9050 - f1_score: 0.9405 - val_loss: 0.8701 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8075 - acc: 0.9447 - precision: 0.9845 - recall: 0.9023 - f1_score: 0.9409 - val_loss: 0.8670 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8044 - acc: 0.9447 - precision: 0.9831 - recall: 0.8984 - f1_score: 0.9373 - val_loss: 0.8639 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8014 - acc: 0.9447 - precision: 0.9795 - recall: 0.9020 - f1_score: 0.9383 - val_loss: 0.8609 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7983 - acc: 0.9447 - precision: 0.9822 - recall: 0.9024 - f1_score: 0.9400 - val_loss: 0.8578 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7953 - acc: 0.9447 - precision: 0.9814 - recall: 0.9060 - f1_score: 0.9404 - val_loss: 0.8548 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7922 - acc: 0.9447 - precision: 0.9821 - recall: 0.9038 - f1_score: 0.9399 - val_loss: 0.8518 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 438/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7892 - acc: 0.9447 - precision: 0.9803 - recall: 0.9029 - f1_score: 0.9385 - val_loss: 0.8488 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.7824 - acc: 0.9460 - precision: 0.9832 - recall: 0.9123 - f1_score: 0.944 - 0s - loss: 0.7863 - acc: 0.9447 - precision: 0.9818 - recall: 0.9064 - f1_score: 0.9405 - val_loss: 0.8459 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7833 - acc: 0.9447 - precision: 0.9824 - recall: 0.9032 - f1_score: 0.9404 - val_loss: 0.8429 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7803 - acc: 0.9447 - precision: 0.9838 - recall: 0.9001 - f1_score: 0.9390 - val_loss: 0.8399 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7774 - acc: 0.9447 - precision: 0.9812 - recall: 0.8990 - f1_score: 0.9373 - val_loss: 0.8370 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7744 - acc: 0.9447 - precision: 0.9815 - recall: 0.9028 - f1_score: 0.9398 - val_loss: 0.8341 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7715 - acc: 0.9447 - precision: 0.9816 - recall: 0.9047 - f1_score: 0.9403 - val_loss: 0.8312 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7686 - acc: 0.9447 - precision: 0.9816 - recall: 0.9042 - f1_score: 0.9400 - val_loss: 0.8283 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7657 - acc: 0.9447 - precision: 0.9840 - recall: 0.9062 - f1_score: 0.9422 - val_loss: 0.8255 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7629 - acc: 0.9447 - precision: 0.9839 - recall: 0.9036 - f1_score: 0.9400 - val_loss: 0.8226 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7600 - acc: 0.9447 - precision: 0.9817 - recall: 0.9018 - f1_score: 0.9391 - val_loss: 0.8198 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7572 - acc: 0.9447 - precision: 0.9821 - recall: 0.9035 - f1_score: 0.9399 - val_loss: 0.8170 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7543 - acc: 0.9447 - precision: 0.9827 - recall: 0.8996 - f1_score: 0.9372 - val_loss: 0.8141 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7515 - acc: 0.9447 - precision: 0.9836 - recall: 0.9030 - f1_score: 0.9412 - val_loss: 0.8113 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7487 - acc: 0.9447 - precision: 0.9817 - recall: 0.9032 - f1_score: 0.9402 - val_loss: 0.8086 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7459 - acc: 0.9447 - precision: 0.9842 - recall: 0.9073 - f1_score: 0.9424 - val_loss: 0.8058 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7431 - acc: 0.9447 - precision: 0.9843 - recall: 0.9032 - f1_score: 0.9408 - val_loss: 0.8030 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7404 - acc: 0.9447 - precision: 0.9837 - recall: 0.9025 - f1_score: 0.9393 - val_loss: 0.8003 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7376 - acc: 0.9447 - precision: 0.9834 - recall: 0.8994 - f1_score: 0.9389 - val_loss: 0.7976 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7349 - acc: 0.9447 - precision: 0.9837 - recall: 0.9005 - f1_score: 0.9395 - val_loss: 0.7949 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7322 - acc: 0.9447 - precision: 0.9829 - recall: 0.8983 - f1_score: 0.9373 - val_loss: 0.7922 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7295 - acc: 0.9447 - precision: 0.9840 - recall: 0.9011 - f1_score: 0.9386 - val_loss: 0.7895 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7268 - acc: 0.9447 - precision: 0.9820 - recall: 0.9002 - f1_score: 0.9379 - val_loss: 0.7868 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7241 - acc: 0.9447 - precision: 0.9838 - recall: 0.8992 - f1_score: 0.9383 - val_loss: 0.7841 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7215 - acc: 0.9447 - precision: 0.9836 - recall: 0.9009 - f1_score: 0.9388 - val_loss: 0.7815 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7188 - acc: 0.9447 - precision: 0.9812 - recall: 0.9036 - f1_score: 0.9396 - val_loss: 0.7789 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7162 - acc: 0.9447 - precision: 0.9817 - recall: 0.9008 - f1_score: 0.9386 - val_loss: 0.7763 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7135 - acc: 0.9447 - precision: 0.9812 - recall: 0.9044 - f1_score: 0.9401 - val_loss: 0.7737 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7109 - acc: 0.9447 - precision: 0.9816 - recall: 0.9017 - f1_score: 0.9386 - val_loss: 0.7711 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7083 - acc: 0.9447 - precision: 0.9831 - recall: 0.9047 - f1_score: 0.9413 - val_loss: 0.7685 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7057 - acc: 0.9447 - precision: 0.9804 - recall: 0.9039 - f1_score: 0.9401 - val_loss: 0.7659 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7032 - acc: 0.9447 - precision: 0.9829 - recall: 0.9019 - f1_score: 0.9400 - val_loss: 0.7634 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7006 - acc: 0.9447 - precision: 0.9829 - recall: 0.9030 - f1_score: 0.9404 - val_loss: 0.7608 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6981 - acc: 0.9447 - precision: 0.9816 - recall: 0.9030 - f1_score: 0.9396 - val_loss: 0.7583 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6955 - acc: 0.9447 - precision: 0.9838 - recall: 0.9029 - f1_score: 0.9408 - val_loss: 0.7558 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6930 - acc: 0.9447 - precision: 0.9818 - recall: 0.9065 - f1_score: 0.9418 - val_loss: 0.7533 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6905 - acc: 0.9447 - precision: 0.9827 - recall: 0.9005 - f1_score: 0.9381 - val_loss: 0.7508 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6880 - acc: 0.9447 - precision: 0.9825 - recall: 0.9022 - f1_score: 0.9393 - val_loss: 0.7483 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6855 - acc: 0.9447 - precision: 0.9833 - recall: 0.9003 - f1_score: 0.9394 - val_loss: 0.7458 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6831 - acc: 0.9447 - precision: 0.9830 - recall: 0.9054 - f1_score: 0.9414 - val_loss: 0.7434 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6806 - acc: 0.9447 - precision: 0.9806 - recall: 0.9064 - f1_score: 0.9408 - val_loss: 0.7410 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6782 - acc: 0.9447 - precision: 0.9808 - recall: 0.9044 - f1_score: 0.9385 - val_loss: 0.7385 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6757 - acc: 0.9447 - precision: 0.9827 - recall: 0.9003 - f1_score: 0.9391 - val_loss: 0.7361 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6733 - acc: 0.9447 - precision: 0.9808 - recall: 0.9013 - f1_score: 0.9388 - val_loss: 0.7337 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6709 - acc: 0.9447 - precision: 0.9824 - recall: 0.9023 - f1_score: 0.9402 - val_loss: 0.7313 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6685 - acc: 0.9447 - precision: 0.9825 - recall: 0.9041 - f1_score: 0.9414 - val_loss: 0.7289 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6661 - acc: 0.9447 - precision: 0.9806 - recall: 0.9016 - f1_score: 0.9386 - val_loss: 0.7266 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6637 - acc: 0.9447 - precision: 0.9828 - recall: 0.9004 - f1_score: 0.9391 - val_loss: 0.7242 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6614 - acc: 0.9447 - precision: 0.9829 - recall: 0.9038 - f1_score: 0.9410 - val_loss: 0.7219 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6590 - acc: 0.9447 - precision: 0.9818 - recall: 0.9051 - f1_score: 0.9406 - val_loss: 0.7195 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6567 - acc: 0.9447 - precision: 0.9824 - recall: 0.9038 - f1_score: 0.9406 - val_loss: 0.7172 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6543 - acc: 0.9447 - precision: 0.9813 - recall: 0.9020 - f1_score: 0.9387 - val_loss: 0.7149 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6520 - acc: 0.9447 - precision: 0.9811 - recall: 0.9049 - f1_score: 0.9406 - val_loss: 0.7126 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6497 - acc: 0.9447 - precision: 0.9793 - recall: 0.9002 - f1_score: 0.9367 - val_loss: 0.7103 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6474 - acc: 0.9447 - precision: 0.9823 - recall: 0.9011 - f1_score: 0.9389 - val_loss: 0.7080 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6451 - acc: 0.9447 - precision: 0.9825 - recall: 0.9044 - f1_score: 0.9409 - val_loss: 0.7058 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6429 - acc: 0.9447 - precision: 0.9862 - recall: 0.9052 - f1_score: 0.9420 - val_loss: 0.7035 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6406 - acc: 0.9447 - precision: 0.9805 - recall: 0.9051 - f1_score: 0.9394 - val_loss: 0.7013 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6384 - acc: 0.9447 - precision: 0.9835 - recall: 0.9033 - f1_score: 0.9408 - val_loss: 0.6991 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6361 - acc: 0.9447 - precision: 0.9838 - recall: 0.9026 - f1_score: 0.9403 - val_loss: 0.6968 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6339 - acc: 0.9447 - precision: 0.9826 - recall: 0.9081 - f1_score: 0.9427 - val_loss: 0.6946 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6317 - acc: 0.9447 - precision: 0.9816 - recall: 0.9024 - f1_score: 0.9393 - val_loss: 0.6924 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6295 - acc: 0.9447 - precision: 0.9824 - recall: 0.9006 - f1_score: 0.9375 - val_loss: 0.6902 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6273 - acc: 0.9447 - precision: 0.9835 - recall: 0.9004 - f1_score: 0.9394 - val_loss: 0.6881 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6251 - acc: 0.9447 - precision: 0.9810 - recall: 0.9059 - f1_score: 0.9411 - val_loss: 0.6859 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6229 - acc: 0.9447 - precision: 0.9815 - recall: 0.9036 - f1_score: 0.9405 - val_loss: 0.6838 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6208 - acc: 0.9447 - precision: 0.9823 - recall: 0.9031 - f1_score: 0.9405 - val_loss: 0.6816 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6186 - acc: 0.9447 - precision: 0.9838 - recall: 0.9020 - f1_score: 0.9397 - val_loss: 0.6795 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6165 - acc: 0.9447 - precision: 0.9815 - recall: 0.9060 - f1_score: 0.9402 - val_loss: 0.6774 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6144 - acc: 0.9447 - precision: 0.9829 - recall: 0.9025 - f1_score: 0.9396 - val_loss: 0.6753 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6123 - acc: 0.9447 - precision: 0.9817 - recall: 0.8982 - f1_score: 0.9369 - val_loss: 0.6732 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6102 - acc: 0.9447 - precision: 0.9802 - recall: 0.9064 - f1_score: 0.9406 - val_loss: 0.6711 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6081 - acc: 0.9447 - precision: 0.9841 - recall: 0.9022 - f1_score: 0.9405 - val_loss: 0.6690 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6060 - acc: 0.9447 - precision: 0.9828 - recall: 0.9025 - f1_score: 0.9390 - val_loss: 0.6669 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6039 - acc: 0.9447 - precision: 0.9812 - recall: 0.9018 - f1_score: 0.9386 - val_loss: 0.6649 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6018 - acc: 0.9447 - precision: 0.9790 - recall: 0.9012 - f1_score: 0.9376 - val_loss: 0.6628 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5998 - acc: 0.9447 - precision: 0.9812 - recall: 0.9021 - f1_score: 0.9390 - val_loss: 0.6608 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5977 - acc: 0.9447 - precision: 0.9846 - recall: 0.9044 - f1_score: 0.9403 - val_loss: 0.6588 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5957 - acc: 0.9447 - precision: 0.9820 - recall: 0.9046 - f1_score: 0.9404 - val_loss: 0.6567 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5937 - acc: 0.9447 - precision: 0.9820 - recall: 0.9060 - f1_score: 0.9408 - val_loss: 0.6547 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5917 - acc: 0.9447 - precision: 0.9834 - recall: 0.9059 - f1_score: 0.9411 - val_loss: 0.6527 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5897 - acc: 0.9447 - precision: 0.9829 - recall: 0.9053 - f1_score: 0.9414 - val_loss: 0.6508 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5877 - acc: 0.9447 - precision: 0.9819 - recall: 0.9008 - f1_score: 0.9383 - val_loss: 0.6488 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5857 - acc: 0.9447 - precision: 0.9809 - recall: 0.9009 - f1_score: 0.9369 - val_loss: 0.6468 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5837 - acc: 0.9447 - precision: 0.9823 - recall: 0.9034 - f1_score: 0.9404 - val_loss: 0.6449 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5817 - acc: 0.9463 - precision: 0.9856 - recall: 0.9009 - f1_score: 0.9409 - val_loss: 0.6429 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5798 - acc: 0.9463 - precision: 0.9863 - recall: 0.9004 - f1_score: 0.9398 - val_loss: 0.6410 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5778 - acc: 0.9463 - precision: 0.9846 - recall: 0.9038 - f1_score: 0.9417 - val_loss: 0.6391 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5759 - acc: 0.9463 - precision: 0.9850 - recall: 0.9049 - f1_score: 0.9420 - val_loss: 0.6372 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5740 - acc: 0.9463 - precision: 0.9871 - recall: 0.9041 - f1_score: 0.9420 - val_loss: 0.6353 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5721 - acc: 0.9463 - precision: 0.9880 - recall: 0.9004 - f1_score: 0.9413 - val_loss: 0.6334 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5702 - acc: 0.9463 - precision: 0.9859 - recall: 0.8997 - f1_score: 0.9393 - val_loss: 0.6315 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5683 - acc: 0.9463 - precision: 0.9870 - recall: 0.8993 - f1_score: 0.9392 - val_loss: 0.6296 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5664 - acc: 0.9463 - precision: 0.9861 - recall: 0.9031 - f1_score: 0.9419 - val_loss: 0.6277 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5645 - acc: 0.9463 - precision: 0.9874 - recall: 0.9024 - f1_score: 0.9423 - val_loss: 0.6259 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5626 - acc: 0.9463 - precision: 0.9856 - recall: 0.8999 - f1_score: 0.9401 - val_loss: 0.6240 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 534/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5607 - acc: 0.9463 - precision: 0.9865 - recall: 0.9027 - f1_score: 0.9421 - val_loss: 0.6222 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5589 - acc: 0.9463 - precision: 0.9870 - recall: 0.9058 - f1_score: 0.9423 - val_loss: 0.6203 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5571 - acc: 0.9463 - precision: 0.9849 - recall: 0.8992 - f1_score: 0.9381 - val_loss: 0.6185 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5552 - acc: 0.9463 - precision: 0.9860 - recall: 0.9049 - f1_score: 0.9417 - val_loss: 0.6167 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5534 - acc: 0.9463 - precision: 0.9866 - recall: 0.9028 - f1_score: 0.9415 - val_loss: 0.6149 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5516 - acc: 0.9463 - precision: 0.9850 - recall: 0.8979 - f1_score: 0.9379 - val_loss: 0.6131 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5498 - acc: 0.9463 - precision: 0.9849 - recall: 0.9030 - f1_score: 0.9408 - val_loss: 0.6113 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5480 - acc: 0.9463 - precision: 0.9863 - recall: 0.9002 - f1_score: 0.9406 - val_loss: 0.6095 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5462 - acc: 0.9463 - precision: 0.9865 - recall: 0.9010 - f1_score: 0.9411 - val_loss: 0.6078 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5444 - acc: 0.9463 - precision: 0.9835 - recall: 0.9016 - f1_score: 0.9399 - val_loss: 0.6060 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5426 - acc: 0.9463 - precision: 0.9859 - recall: 0.9070 - f1_score: 0.9435 - val_loss: 0.6043 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5409 - acc: 0.9463 - precision: 0.9850 - recall: 0.8986 - f1_score: 0.9388 - val_loss: 0.6025 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5391 - acc: 0.9463 - precision: 0.9860 - recall: 0.9047 - f1_score: 0.9430 - val_loss: 0.6008 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5374 - acc: 0.9463 - precision: 0.9855 - recall: 0.9041 - f1_score: 0.9413 - val_loss: 0.5990 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5356 - acc: 0.9463 - precision: 0.9852 - recall: 0.9015 - f1_score: 0.9408 - val_loss: 0.5973 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5339 - acc: 0.9463 - precision: 0.9859 - recall: 0.9058 - f1_score: 0.9428 - val_loss: 0.5956 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5322 - acc: 0.9463 - precision: 0.9859 - recall: 0.9052 - f1_score: 0.9426 - val_loss: 0.5939 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5305 - acc: 0.9463 - precision: 0.9850 - recall: 0.9053 - f1_score: 0.9419 - val_loss: 0.5922 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5288 - acc: 0.9463 - precision: 0.9861 - recall: 0.9043 - f1_score: 0.9431 - val_loss: 0.5906 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5271 - acc: 0.9463 - precision: 0.9836 - recall: 0.9032 - f1_score: 0.9412 - val_loss: 0.5889 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5254 - acc: 0.9463 - precision: 0.9855 - recall: 0.9035 - f1_score: 0.9414 - val_loss: 0.5872 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5237 - acc: 0.9463 - precision: 0.9857 - recall: 0.9075 - f1_score: 0.9439 - val_loss: 0.5856 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5221 - acc: 0.9463 - precision: 0.9869 - recall: 0.9037 - f1_score: 0.9427 - val_loss: 0.5839 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5204 - acc: 0.9463 - precision: 0.9877 - recall: 0.9019 - f1_score: 0.9417 - val_loss: 0.5823 - val_acc: 0.9051 - val_precision: 1.0000 - val_recall: 0.8274 - val_f1_score: 0.9044\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5187 - acc: 0.9463 - precision: 0.9842 - recall: 0.9037 - f1_score: 0.9409 - val_loss: 0.5806 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5171 - acc: 0.9463 - precision: 0.9875 - recall: 0.9017 - f1_score: 0.9408 - val_loss: 0.5790 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5155 - acc: 0.9463 - precision: 0.9846 - recall: 0.9013 - f1_score: 0.9398 - val_loss: 0.5774 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5138 - acc: 0.9463 - precision: 0.9848 - recall: 0.8999 - f1_score: 0.9398 - val_loss: 0.5758 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5122 - acc: 0.9463 - precision: 0.9869 - recall: 0.9055 - f1_score: 0.9434 - val_loss: 0.5742 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5106 - acc: 0.9463 - precision: 0.9876 - recall: 0.9034 - f1_score: 0.9430 - val_loss: 0.5726 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5090 - acc: 0.9463 - precision: 0.9867 - recall: 0.9045 - f1_score: 0.9429 - val_loss: 0.5710 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5074 - acc: 0.9463 - precision: 0.9845 - recall: 0.9016 - f1_score: 0.9400 - val_loss: 0.5694 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5058 - acc: 0.9463 - precision: 0.9865 - recall: 0.9014 - f1_score: 0.9407 - val_loss: 0.5679 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5042 - acc: 0.9463 - precision: 0.9861 - recall: 0.9016 - f1_score: 0.9414 - val_loss: 0.5663 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5026 - acc: 0.9463 - precision: 0.9836 - recall: 0.8990 - f1_score: 0.9392 - val_loss: 0.5647 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5011 - acc: 0.9463 - precision: 0.9871 - recall: 0.9064 - f1_score: 0.9429 - val_loss: 0.5632 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4995 - acc: 0.9463 - precision: 0.9855 - recall: 0.9041 - f1_score: 0.9421 - val_loss: 0.5616 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4980 - acc: 0.9463 - precision: 0.9862 - recall: 0.9008 - f1_score: 0.9399 - val_loss: 0.5601 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4964 - acc: 0.9463 - precision: 0.9861 - recall: 0.9044 - f1_score: 0.9428 - val_loss: 0.5586 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4949 - acc: 0.9463 - precision: 0.9856 - recall: 0.9065 - f1_score: 0.9438 - val_loss: 0.5571 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4934 - acc: 0.9463 - precision: 0.9852 - recall: 0.9057 - f1_score: 0.9429 - val_loss: 0.5556 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4918 - acc: 0.9463 - precision: 0.9868 - recall: 0.9025 - f1_score: 0.9421 - val_loss: 0.5541 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4903 - acc: 0.9463 - precision: 0.9870 - recall: 0.9027 - f1_score: 0.9424 - val_loss: 0.5526 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4888 - acc: 0.9463 - precision: 0.9861 - recall: 0.9044 - f1_score: 0.9425 - val_loss: 0.5511 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4873 - acc: 0.9463 - precision: 0.9850 - recall: 0.9008 - f1_score: 0.9404 - val_loss: 0.5496 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4858 - acc: 0.9463 - precision: 0.9866 - recall: 0.9014 - f1_score: 0.9412 - val_loss: 0.5481 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4843 - acc: 0.9463 - precision: 0.9869 - recall: 0.9097 - f1_score: 0.9446 - val_loss: 0.5467 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4829 - acc: 0.9463 - precision: 0.9865 - recall: 0.9051 - f1_score: 0.9428 - val_loss: 0.5452 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4814 - acc: 0.9463 - precision: 0.9848 - recall: 0.9008 - f1_score: 0.9406 - val_loss: 0.5437 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4799 - acc: 0.9463 - precision: 0.9867 - recall: 0.9008 - f1_score: 0.9400 - val_loss: 0.5423 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4785 - acc: 0.9463 - precision: 0.9862 - recall: 0.9058 - f1_score: 0.9432 - val_loss: 0.5409 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4770 - acc: 0.9463 - precision: 0.9862 - recall: 0.9060 - f1_score: 0.9437 - val_loss: 0.5395 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4756 - acc: 0.9463 - precision: 0.9870 - recall: 0.8979 - f1_score: 0.9388 - val_loss: 0.5380 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4741 - acc: 0.9463 - precision: 0.9861 - recall: 0.9032 - f1_score: 0.9407 - val_loss: 0.5366 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4727 - acc: 0.9463 - precision: 0.9869 - recall: 0.9017 - f1_score: 0.9409 - val_loss: 0.5352 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4713 - acc: 0.9463 - precision: 0.9863 - recall: 0.8997 - f1_score: 0.9387 - val_loss: 0.5338 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4699 - acc: 0.9463 - precision: 0.9854 - recall: 0.9019 - f1_score: 0.9409 - val_loss: 0.5324 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4685 - acc: 0.9463 - precision: 0.9861 - recall: 0.9047 - f1_score: 0.9430 - val_loss: 0.5310 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4671 - acc: 0.9463 - precision: 0.9858 - recall: 0.9024 - f1_score: 0.9415 - val_loss: 0.5296 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4657 - acc: 0.9463 - precision: 0.9853 - recall: 0.9014 - f1_score: 0.9407 - val_loss: 0.5283 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4643 - acc: 0.9463 - precision: 0.9830 - recall: 0.9006 - f1_score: 0.9393 - val_loss: 0.5269 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4629 - acc: 0.9463 - precision: 0.9865 - recall: 0.8995 - f1_score: 0.9400 - val_loss: 0.5256 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4615 - acc: 0.9463 - precision: 0.9850 - recall: 0.9007 - f1_score: 0.9401 - val_loss: 0.5242 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4602 - acc: 0.9463 - precision: 0.9860 - recall: 0.9035 - f1_score: 0.9425 - val_loss: 0.5229 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4588 - acc: 0.9463 - precision: 0.9856 - recall: 0.9050 - f1_score: 0.9420 - val_loss: 0.5215 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4575 - acc: 0.9463 - precision: 0.9837 - recall: 0.9028 - f1_score: 0.9407 - val_loss: 0.5202 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4561 - acc: 0.9463 - precision: 0.9823 - recall: 0.8967 - f1_score: 0.9363 - val_loss: 0.5188 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4548 - acc: 0.9463 - precision: 0.9855 - recall: 0.9026 - f1_score: 0.9411 - val_loss: 0.5175 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4534 - acc: 0.9463 - precision: 0.9870 - recall: 0.8963 - f1_score: 0.9376 - val_loss: 0.5162 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4521 - acc: 0.9463 - precision: 0.9868 - recall: 0.9004 - f1_score: 0.9404 - val_loss: 0.5149 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4508 - acc: 0.9463 - precision: 0.9851 - recall: 0.9020 - f1_score: 0.9407 - val_loss: 0.5136 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4495 - acc: 0.9463 - precision: 0.9854 - recall: 0.8955 - f1_score: 0.9361 - val_loss: 0.5123 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4482 - acc: 0.9463 - precision: 0.9853 - recall: 0.8998 - f1_score: 0.9382 - val_loss: 0.5110 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4469 - acc: 0.9463 - precision: 0.9864 - recall: 0.9028 - f1_score: 0.9417 - val_loss: 0.5097 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4456 - acc: 0.9463 - precision: 0.9852 - recall: 0.9001 - f1_score: 0.9401 - val_loss: 0.5085 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4443 - acc: 0.9463 - precision: 0.9871 - recall: 0.9026 - f1_score: 0.9412 - val_loss: 0.5072 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4430 - acc: 0.9463 - precision: 0.9858 - recall: 0.9035 - f1_score: 0.9421 - val_loss: 0.5059 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4417 - acc: 0.9463 - precision: 0.9880 - recall: 0.9039 - f1_score: 0.9428 - val_loss: 0.5047 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4405 - acc: 0.9463 - precision: 0.9846 - recall: 0.9027 - f1_score: 0.9409 - val_loss: 0.5034 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4392 - acc: 0.9463 - precision: 0.9863 - recall: 0.9032 - f1_score: 0.9417 - val_loss: 0.5022 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4379 - acc: 0.9463 - precision: 0.9876 - recall: 0.9001 - f1_score: 0.9404 - val_loss: 0.5010 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4367 - acc: 0.9463 - precision: 0.9872 - recall: 0.9018 - f1_score: 0.9417 - val_loss: 0.4997 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4354 - acc: 0.9463 - precision: 0.9862 - recall: 0.9029 - f1_score: 0.9419 - val_loss: 0.4985 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4342 - acc: 0.9463 - precision: 0.9848 - recall: 0.9025 - f1_score: 0.9410 - val_loss: 0.4973 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4330 - acc: 0.9463 - precision: 0.9835 - recall: 0.8995 - f1_score: 0.9388 - val_loss: 0.4961 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4317 - acc: 0.9463 - precision: 0.9870 - recall: 0.9018 - f1_score: 0.9407 - val_loss: 0.4949 - val_acc: 0.9114 - val_precision: 1.0000 - val_recall: 0.8406 - val_f1_score: 0.9121\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4305 - acc: 0.9463 - precision: 0.9850 - recall: 0.8999 - f1_score: 0.9393 - val_loss: 0.4937 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4293 - acc: 0.9463 - precision: 0.9839 - recall: 0.9012 - f1_score: 0.9399 - val_loss: 0.4925 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4281 - acc: 0.9463 - precision: 0.9852 - recall: 0.9051 - f1_score: 0.9426 - val_loss: 0.4913 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4269 - acc: 0.9463 - precision: 0.9856 - recall: 0.9029 - f1_score: 0.9412 - val_loss: 0.4901 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4257 - acc: 0.9463 - precision: 0.9865 - recall: 0.9036 - f1_score: 0.9423 - val_loss: 0.4889 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4245 - acc: 0.9463 - precision: 0.9869 - recall: 0.9064 - f1_score: 0.9440 - val_loss: 0.4878 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4233 - acc: 0.9463 - precision: 0.9856 - recall: 0.9026 - f1_score: 0.9411 - val_loss: 0.4866 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4221 - acc: 0.9463 - precision: 0.9857 - recall: 0.9067 - f1_score: 0.9438 - val_loss: 0.4855 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4209 - acc: 0.9463 - precision: 0.9858 - recall: 0.9026 - f1_score: 0.9419 - val_loss: 0.4843 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4198 - acc: 0.9463 - precision: 0.9848 - recall: 0.9031 - f1_score: 0.9415 - val_loss: 0.4832 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 630/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4186 - acc: 0.9463 - precision: 0.9857 - recall: 0.9024 - f1_score: 0.9405 - val_loss: 0.4820 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4174 - acc: 0.9463 - precision: 0.9818 - recall: 0.9033 - f1_score: 0.9396 - val_loss: 0.4809 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4163 - acc: 0.9463 - precision: 0.9865 - recall: 0.9041 - f1_score: 0.9425 - val_loss: 0.4798 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4151 - acc: 0.9463 - precision: 0.9864 - recall: 0.9018 - f1_score: 0.9413 - val_loss: 0.4786 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4140 - acc: 0.9463 - precision: 0.9836 - recall: 0.8999 - f1_score: 0.9388 - val_loss: 0.4775 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4129 - acc: 0.9463 - precision: 0.9865 - recall: 0.9016 - f1_score: 0.9411 - val_loss: 0.4764 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4117 - acc: 0.9463 - precision: 0.9858 - recall: 0.9108 - f1_score: 0.9453 - val_loss: 0.4753 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4106 - acc: 0.9463 - precision: 0.9870 - recall: 0.8998 - f1_score: 0.9405 - val_loss: 0.4742 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4095 - acc: 0.9463 - precision: 0.9862 - recall: 0.9014 - f1_score: 0.9396 - val_loss: 0.4731 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4084 - acc: 0.9463 - precision: 0.9844 - recall: 0.9038 - f1_score: 0.9419 - val_loss: 0.4720 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4073 - acc: 0.9463 - precision: 0.9869 - recall: 0.9018 - f1_score: 0.9415 - val_loss: 0.4709 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4061 - acc: 0.9463 - precision: 0.9834 - recall: 0.9037 - f1_score: 0.9412 - val_loss: 0.4698 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4050 - acc: 0.9463 - precision: 0.9834 - recall: 0.9007 - f1_score: 0.9390 - val_loss: 0.4687 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4039 - acc: 0.9463 - precision: 0.9861 - recall: 0.8971 - f1_score: 0.9381 - val_loss: 0.4677 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4029 - acc: 0.9463 - precision: 0.9869 - recall: 0.9055 - f1_score: 0.9426 - val_loss: 0.4666 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4018 - acc: 0.9463 - precision: 0.9861 - recall: 0.9004 - f1_score: 0.9407 - val_loss: 0.4655 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4007 - acc: 0.9463 - precision: 0.9853 - recall: 0.9024 - f1_score: 0.9407 - val_loss: 0.4645 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3996 - acc: 0.9463 - precision: 0.9830 - recall: 0.8991 - f1_score: 0.9373 - val_loss: 0.4634 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3985 - acc: 0.9463 - precision: 0.9873 - recall: 0.9007 - f1_score: 0.9404 - val_loss: 0.4624 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3975 - acc: 0.9463 - precision: 0.9864 - recall: 0.9015 - f1_score: 0.9409 - val_loss: 0.4614 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3964 - acc: 0.9463 - precision: 0.9875 - recall: 0.8998 - f1_score: 0.9390 - val_loss: 0.4603 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3954 - acc: 0.9463 - precision: 0.9863 - recall: 0.9032 - f1_score: 0.9406 - val_loss: 0.4593 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3943 - acc: 0.9463 - precision: 0.9860 - recall: 0.9020 - f1_score: 0.9413 - val_loss: 0.4583 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3933 - acc: 0.9463 - precision: 0.9857 - recall: 0.9001 - f1_score: 0.9396 - val_loss: 0.4573 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3922 - acc: 0.9463 - precision: 0.9852 - recall: 0.9013 - f1_score: 0.9405 - val_loss: 0.4562 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3912 - acc: 0.9463 - precision: 0.9869 - recall: 0.9023 - f1_score: 0.9409 - val_loss: 0.4552 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3902 - acc: 0.9463 - precision: 0.9876 - recall: 0.9005 - f1_score: 0.9402 - val_loss: 0.4542 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3892 - acc: 0.9463 - precision: 0.9866 - recall: 0.9074 - f1_score: 0.9432 - val_loss: 0.4532 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9463 - precision: 0.9865 - recall: 0.9041 - f1_score: 0.9424 - val_loss: 0.4522 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3871 - acc: 0.9463 - precision: 0.9840 - recall: 0.9031 - f1_score: 0.9406 - val_loss: 0.4513 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3861 - acc: 0.9463 - precision: 0.9840 - recall: 0.9021 - f1_score: 0.9406 - val_loss: 0.4503 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3851 - acc: 0.9463 - precision: 0.9855 - recall: 0.8974 - f1_score: 0.9372 - val_loss: 0.4493 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3841 - acc: 0.9463 - precision: 0.9858 - recall: 0.8988 - f1_score: 0.9379 - val_loss: 0.4483 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3831 - acc: 0.9463 - precision: 0.9855 - recall: 0.8999 - f1_score: 0.9384 - val_loss: 0.4473 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3821 - acc: 0.9463 - precision: 0.9847 - recall: 0.8994 - f1_score: 0.9393 - val_loss: 0.4464 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3811 - acc: 0.9463 - precision: 0.9856 - recall: 0.9020 - f1_score: 0.9406 - val_loss: 0.4454 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3802 - acc: 0.9463 - precision: 0.9867 - recall: 0.9019 - f1_score: 0.9414 - val_loss: 0.4445 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3792 - acc: 0.9463 - precision: 0.9853 - recall: 0.8980 - f1_score: 0.9382 - val_loss: 0.4435 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3782 - acc: 0.9463 - precision: 0.9853 - recall: 0.9051 - f1_score: 0.9418 - val_loss: 0.4426 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3772 - acc: 0.9463 - precision: 0.9847 - recall: 0.9037 - f1_score: 0.9409 - val_loss: 0.4416 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3763 - acc: 0.9463 - precision: 0.9856 - recall: 0.9018 - f1_score: 0.9402 - val_loss: 0.4407 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3753 - acc: 0.9463 - precision: 0.9850 - recall: 0.9013 - f1_score: 0.9399 - val_loss: 0.4398 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3744 - acc: 0.9463 - precision: 0.9807 - recall: 0.8968 - f1_score: 0.9365 - val_loss: 0.4388 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3734 - acc: 0.9463 - precision: 0.9852 - recall: 0.9050 - f1_score: 0.9428 - val_loss: 0.4379 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3725 - acc: 0.9463 - precision: 0.9851 - recall: 0.9013 - f1_score: 0.9406 - val_loss: 0.4370 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3715 - acc: 0.9463 - precision: 0.9827 - recall: 0.8988 - f1_score: 0.9381 - val_loss: 0.4361 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3706 - acc: 0.9463 - precision: 0.9849 - recall: 0.9039 - f1_score: 0.9419 - val_loss: 0.4351 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3697 - acc: 0.9463 - precision: 0.9868 - recall: 0.9015 - f1_score: 0.9403 - val_loss: 0.4342 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3687 - acc: 0.9463 - precision: 0.9853 - recall: 0.9034 - f1_score: 0.9414 - val_loss: 0.4333 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3678 - acc: 0.9463 - precision: 0.9846 - recall: 0.9044 - f1_score: 0.9418 - val_loss: 0.4324 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3669 - acc: 0.9463 - precision: 0.9873 - recall: 0.9019 - f1_score: 0.9409 - val_loss: 0.4315 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3660 - acc: 0.9463 - precision: 0.9830 - recall: 0.8951 - f1_score: 0.9357 - val_loss: 0.4307 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3651 - acc: 0.9463 - precision: 0.9841 - recall: 0.9012 - f1_score: 0.9394 - val_loss: 0.4298 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3642 - acc: 0.9463 - precision: 0.9860 - recall: 0.9048 - f1_score: 0.9429 - val_loss: 0.4289 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3633 - acc: 0.9463 - precision: 0.9883 - recall: 0.9000 - f1_score: 0.9400 - val_loss: 0.4280 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3624 - acc: 0.9463 - precision: 0.9863 - recall: 0.9020 - f1_score: 0.9407 - val_loss: 0.4271 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3615 - acc: 0.9463 - precision: 0.9875 - recall: 0.9029 - f1_score: 0.9416 - val_loss: 0.4263 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3606 - acc: 0.9463 - precision: 0.9858 - recall: 0.9003 - f1_score: 0.9393 - val_loss: 0.4254 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3597 - acc: 0.9463 - precision: 0.9874 - recall: 0.8992 - f1_score: 0.9398 - val_loss: 0.4246 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3588 - acc: 0.9463 - precision: 0.9857 - recall: 0.9063 - f1_score: 0.9428 - val_loss: 0.4237 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3579 - acc: 0.9463 - precision: 0.9863 - recall: 0.9041 - f1_score: 0.9423 - val_loss: 0.4229 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3571 - acc: 0.9463 - precision: 0.9855 - recall: 0.9055 - f1_score: 0.9422 - val_loss: 0.4220 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3562 - acc: 0.9463 - precision: 0.9865 - recall: 0.9013 - f1_score: 0.9402 - val_loss: 0.4212 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3553 - acc: 0.9463 - precision: 0.9873 - recall: 0.9030 - f1_score: 0.9420 - val_loss: 0.4203 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 694/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3545 - acc: 0.9463 - precision: 0.9859 - recall: 0.9029 - f1_score: 0.9421 - val_loss: 0.4195 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3536 - acc: 0.9463 - precision: 0.9840 - recall: 0.9027 - f1_score: 0.9409 - val_loss: 0.4187 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3528 - acc: 0.9463 - precision: 0.9869 - recall: 0.9032 - f1_score: 0.9426 - val_loss: 0.4178 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3519 - acc: 0.9463 - precision: 0.9850 - recall: 0.9018 - f1_score: 0.9395 - val_loss: 0.4170 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3511 - acc: 0.9463 - precision: 0.9877 - recall: 0.9024 - f1_score: 0.9420 - val_loss: 0.4162 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3502 - acc: 0.9463 - precision: 0.9871 - recall: 0.9062 - f1_score: 0.9438 - val_loss: 0.4154 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3494 - acc: 0.9463 - precision: 0.9851 - recall: 0.9047 - f1_score: 0.9420 - val_loss: 0.4146 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3486 - acc: 0.9463 - precision: 0.9841 - recall: 0.9029 - f1_score: 0.9412 - val_loss: 0.4138 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3477 - acc: 0.9463 - precision: 0.9847 - recall: 0.8998 - f1_score: 0.9389 - val_loss: 0.4130 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3469 - acc: 0.9463 - precision: 0.9854 - recall: 0.8976 - f1_score: 0.9379 - val_loss: 0.4122 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3461 - acc: 0.9463 - precision: 0.9865 - recall: 0.9043 - f1_score: 0.9425 - val_loss: 0.4114 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3453 - acc: 0.9463 - precision: 0.9877 - recall: 0.9065 - f1_score: 0.9443 - val_loss: 0.4106 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3445 - acc: 0.9463 - precision: 0.9848 - recall: 0.9000 - f1_score: 0.9399 - val_loss: 0.4098 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3437 - acc: 0.9463 - precision: 0.9845 - recall: 0.9047 - f1_score: 0.9425 - val_loss: 0.4090 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3429 - acc: 0.9463 - precision: 0.9821 - recall: 0.8993 - f1_score: 0.9379 - val_loss: 0.4082 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3421 - acc: 0.9463 - precision: 0.9859 - recall: 0.9021 - f1_score: 0.9410 - val_loss: 0.4074 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3413 - acc: 0.9463 - precision: 0.9875 - recall: 0.9055 - f1_score: 0.9437 - val_loss: 0.4067 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3405 - acc: 0.9463 - precision: 0.9877 - recall: 0.9048 - f1_score: 0.9424 - val_loss: 0.4059 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3397 - acc: 0.9463 - precision: 0.9864 - recall: 0.9031 - f1_score: 0.9415 - val_loss: 0.4051 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3389 - acc: 0.9463 - precision: 0.9857 - recall: 0.9035 - f1_score: 0.9418 - val_loss: 0.4044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3381 - acc: 0.9463 - precision: 0.9865 - recall: 0.8999 - f1_score: 0.9399 - val_loss: 0.4036 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3373 - acc: 0.9463 - precision: 0.9857 - recall: 0.9044 - f1_score: 0.9412 - val_loss: 0.4029 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3366 - acc: 0.9463 - precision: 0.9856 - recall: 0.9029 - f1_score: 0.9416 - val_loss: 0.4021 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3358 - acc: 0.9463 - precision: 0.9830 - recall: 0.8975 - f1_score: 0.9375 - val_loss: 0.4014 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3350 - acc: 0.9463 - precision: 0.9845 - recall: 0.9036 - f1_score: 0.9414 - val_loss: 0.4006 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3342 - acc: 0.9463 - precision: 0.9865 - recall: 0.9037 - f1_score: 0.9423 - val_loss: 0.3999 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3335 - acc: 0.9463 - precision: 0.9852 - recall: 0.9031 - f1_score: 0.9408 - val_loss: 0.3992 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3327 - acc: 0.9463 - precision: 0.9860 - recall: 0.9006 - f1_score: 0.9392 - val_loss: 0.3984 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3320 - acc: 0.9463 - precision: 0.9866 - recall: 0.9015 - f1_score: 0.9412 - val_loss: 0.3977 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3312 - acc: 0.9463 - precision: 0.9870 - recall: 0.9034 - f1_score: 0.9422 - val_loss: 0.3970 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3305 - acc: 0.9463 - precision: 0.9858 - recall: 0.9004 - f1_score: 0.9405 - val_loss: 0.3963 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3297 - acc: 0.9463 - precision: 0.9855 - recall: 0.9019 - f1_score: 0.9411 - val_loss: 0.3956 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3290 - acc: 0.9463 - precision: 0.9858 - recall: 0.9022 - f1_score: 0.9402 - val_loss: 0.3949 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3283 - acc: 0.9463 - precision: 0.9846 - recall: 0.9008 - f1_score: 0.9403 - val_loss: 0.3941 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3275 - acc: 0.9463 - precision: 0.9858 - recall: 0.8989 - f1_score: 0.9391 - val_loss: 0.3934 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3268 - acc: 0.9463 - precision: 0.9859 - recall: 0.8981 - f1_score: 0.9385 - val_loss: 0.3927 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3261 - acc: 0.9463 - precision: 0.9838 - recall: 0.9040 - f1_score: 0.9418 - val_loss: 0.3920 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3253 - acc: 0.9463 - precision: 0.9867 - recall: 0.9019 - f1_score: 0.9405 - val_loss: 0.3913 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3246 - acc: 0.9463 - precision: 0.9849 - recall: 0.9055 - f1_score: 0.9428 - val_loss: 0.3906 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3239 - acc: 0.9463 - precision: 0.9873 - recall: 0.9046 - f1_score: 0.9429 - val_loss: 0.3900 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3232 - acc: 0.9463 - precision: 0.9852 - recall: 0.8971 - f1_score: 0.9380 - val_loss: 0.3893 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3225 - acc: 0.9463 - precision: 0.9863 - recall: 0.9024 - f1_score: 0.9419 - val_loss: 0.3886 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3218 - acc: 0.9463 - precision: 0.9854 - recall: 0.9056 - f1_score: 0.9429 - val_loss: 0.3879 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3211 - acc: 0.9463 - precision: 0.9849 - recall: 0.9017 - f1_score: 0.9405 - val_loss: 0.3872 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3204 - acc: 0.9463 - precision: 0.9838 - recall: 0.9040 - f1_score: 0.9414 - val_loss: 0.3866 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3197 - acc: 0.9463 - precision: 0.9865 - recall: 0.9022 - f1_score: 0.9416 - val_loss: 0.3859 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3190 - acc: 0.9463 - precision: 0.9857 - recall: 0.9034 - f1_score: 0.9423 - val_loss: 0.3852 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3183 - acc: 0.9463 - precision: 0.9845 - recall: 0.9010 - f1_score: 0.9398 - val_loss: 0.3846 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3176 - acc: 0.9463 - precision: 0.9864 - recall: 0.9047 - f1_score: 0.9415 - val_loss: 0.3839 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3169 - acc: 0.9463 - precision: 0.9854 - recall: 0.9020 - f1_score: 0.9404 - val_loss: 0.3833 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3162 - acc: 0.9463 - precision: 0.9863 - recall: 0.9029 - f1_score: 0.9417 - val_loss: 0.3826 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3156 - acc: 0.9463 - precision: 0.9865 - recall: 0.9023 - f1_score: 0.9419 - val_loss: 0.3820 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3149 - acc: 0.9463 - precision: 0.9861 - recall: 0.9025 - f1_score: 0.9409 - val_loss: 0.3813 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3142 - acc: 0.9463 - precision: 0.9857 - recall: 0.9033 - f1_score: 0.9420 - val_loss: 0.3807 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3136 - acc: 0.9463 - precision: 0.9848 - recall: 0.9032 - f1_score: 0.9414 - val_loss: 0.3800 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3129 - acc: 0.9463 - precision: 0.9849 - recall: 0.8996 - f1_score: 0.9388 - val_loss: 0.3794 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3122 - acc: 0.9463 - precision: 0.9847 - recall: 0.9023 - f1_score: 0.9399 - val_loss: 0.3788 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3116 - acc: 0.9463 - precision: 0.9847 - recall: 0.9035 - f1_score: 0.9416 - val_loss: 0.3781 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3843 - acc: 0.9200 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.913 - 0s - loss: 0.3109 - acc: 0.9463 - precision: 0.9858 - recall: 0.9039 - f1_score: 0.9420 - val_loss: 0.3775 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3103 - acc: 0.9463 - precision: 0.9859 - recall: 0.9038 - f1_score: 0.9418 - val_loss: 0.3769 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3096 - acc: 0.9463 - precision: 0.9883 - recall: 0.9018 - f1_score: 0.9417 - val_loss: 0.3763 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3090 - acc: 0.9463 - precision: 0.9856 - recall: 0.9044 - f1_score: 0.9421 - val_loss: 0.3756 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3083 - acc: 0.9463 - precision: 0.9875 - recall: 0.9027 - f1_score: 0.9425 - val_loss: 0.3750 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3077 - acc: 0.9463 - precision: 0.9845 - recall: 0.9035 - f1_score: 0.9419 - val_loss: 0.3744 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 758/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3070 - acc: 0.9463 - precision: 0.9858 - recall: 0.9039 - f1_score: 0.9424 - val_loss: 0.3738 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3064 - acc: 0.9463 - precision: 0.9857 - recall: 0.9045 - f1_score: 0.9414 - val_loss: 0.3732 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9463 - precision: 0.9858 - recall: 0.9052 - f1_score: 0.9428 - val_loss: 0.3726 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3051 - acc: 0.9463 - precision: 0.9864 - recall: 0.9024 - f1_score: 0.9416 - val_loss: 0.3720 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3045 - acc: 0.9463 - precision: 0.9852 - recall: 0.9006 - f1_score: 0.9389 - val_loss: 0.3714 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3039 - acc: 0.9463 - precision: 0.9860 - recall: 0.9066 - f1_score: 0.9441 - val_loss: 0.3708 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3033 - acc: 0.9463 - precision: 0.9888 - recall: 0.9010 - f1_score: 0.9418 - val_loss: 0.3702 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3026 - acc: 0.9463 - precision: 0.9843 - recall: 0.8998 - f1_score: 0.9396 - val_loss: 0.3696 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3020 - acc: 0.9463 - precision: 0.9849 - recall: 0.9015 - f1_score: 0.9403 - val_loss: 0.3690 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3014 - acc: 0.9463 - precision: 0.9842 - recall: 0.8995 - f1_score: 0.9385 - val_loss: 0.3684 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3008 - acc: 0.9463 - precision: 0.9859 - recall: 0.9012 - f1_score: 0.9410 - val_loss: 0.3679 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3002 - acc: 0.9463 - precision: 0.9855 - recall: 0.9045 - f1_score: 0.9405 - val_loss: 0.3673 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2996 - acc: 0.9463 - precision: 0.9878 - recall: 0.9003 - f1_score: 0.9411 - val_loss: 0.3667 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2990 - acc: 0.9463 - precision: 0.9835 - recall: 0.9022 - f1_score: 0.9401 - val_loss: 0.3661 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2984 - acc: 0.9463 - precision: 0.9854 - recall: 0.9064 - f1_score: 0.9428 - val_loss: 0.3656 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9463 - precision: 0.9868 - recall: 0.9010 - f1_score: 0.9411 - val_loss: 0.3650 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2972 - acc: 0.9463 - precision: 0.9858 - recall: 0.9036 - f1_score: 0.9417 - val_loss: 0.3644 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2966 - acc: 0.9463 - precision: 0.9854 - recall: 0.9045 - f1_score: 0.9419 - val_loss: 0.3639 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2960 - acc: 0.9463 - precision: 0.9875 - recall: 0.8970 - f1_score: 0.9386 - val_loss: 0.3633 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2954 - acc: 0.9463 - precision: 0.9856 - recall: 0.8994 - f1_score: 0.9393 - val_loss: 0.3628 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2949 - acc: 0.9463 - precision: 0.9848 - recall: 0.9038 - f1_score: 0.9413 - val_loss: 0.3622 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2943 - acc: 0.9463 - precision: 0.9872 - recall: 0.9050 - f1_score: 0.9429 - val_loss: 0.3616 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2937 - acc: 0.9463 - precision: 0.9853 - recall: 0.9034 - f1_score: 0.9417 - val_loss: 0.3611 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2931 - acc: 0.9463 - precision: 0.9861 - recall: 0.9033 - f1_score: 0.9420 - val_loss: 0.3605 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2925 - acc: 0.9463 - precision: 0.9854 - recall: 0.8984 - f1_score: 0.9383 - val_loss: 0.3600 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2920 - acc: 0.9463 - precision: 0.9841 - recall: 0.9058 - f1_score: 0.9419 - val_loss: 0.3595 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2914 - acc: 0.9463 - precision: 0.9847 - recall: 0.9034 - f1_score: 0.9409 - val_loss: 0.3589 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2908 - acc: 0.9463 - precision: 0.9869 - recall: 0.9035 - f1_score: 0.9420 - val_loss: 0.3584 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2903 - acc: 0.9463 - precision: 0.9874 - recall: 0.9031 - f1_score: 0.9410 - val_loss: 0.3578 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2897 - acc: 0.9463 - precision: 0.9860 - recall: 0.9045 - f1_score: 0.9428 - val_loss: 0.3573 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2892 - acc: 0.9463 - precision: 0.9868 - recall: 0.9047 - f1_score: 0.9433 - val_loss: 0.3568 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2886 - acc: 0.9463 - precision: 0.9853 - recall: 0.9055 - f1_score: 0.9426 - val_loss: 0.3563 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 790/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2881 - acc: 0.9463 - precision: 0.9851 - recall: 0.9041 - f1_score: 0.9425 - val_loss: 0.3557 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2875 - acc: 0.9463 - precision: 0.9858 - recall: 0.9044 - f1_score: 0.9407 - val_loss: 0.3552 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2870 - acc: 0.9463 - precision: 0.9871 - recall: 0.9014 - f1_score: 0.9416 - val_loss: 0.3547 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2864 - acc: 0.9463 - precision: 0.9862 - recall: 0.9032 - f1_score: 0.9421 - val_loss: 0.3542 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2859 - acc: 0.9463 - precision: 0.9865 - recall: 0.9069 - f1_score: 0.9440 - val_loss: 0.3537 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2853 - acc: 0.9463 - precision: 0.9853 - recall: 0.9011 - f1_score: 0.9397 - val_loss: 0.3532 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9463 - precision: 0.9867 - recall: 0.9016 - f1_score: 0.9418 - val_loss: 0.3527 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9463 - precision: 0.9852 - recall: 0.9006 - f1_score: 0.9398 - val_loss: 0.3522 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2837 - acc: 0.9463 - precision: 0.9856 - recall: 0.9062 - f1_score: 0.9421 - val_loss: 0.3516 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2832 - acc: 0.9463 - precision: 0.9853 - recall: 0.8999 - f1_score: 0.9400 - val_loss: 0.3511 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2827 - acc: 0.9463 - precision: 0.9855 - recall: 0.9012 - f1_score: 0.9398 - val_loss: 0.3507 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2821 - acc: 0.9463 - precision: 0.9851 - recall: 0.9047 - f1_score: 0.9428 - val_loss: 0.3502 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2816 - acc: 0.9463 - precision: 0.9837 - recall: 0.9056 - f1_score: 0.9415 - val_loss: 0.3497 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2811 - acc: 0.9463 - precision: 0.9830 - recall: 0.9009 - f1_score: 0.9394 - val_loss: 0.3492 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2806 - acc: 0.9463 - precision: 0.9849 - recall: 0.9046 - f1_score: 0.9420 - val_loss: 0.3487 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2801 - acc: 0.9463 - precision: 0.9867 - recall: 0.9054 - f1_score: 0.9428 - val_loss: 0.3482 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2795 - acc: 0.9463 - precision: 0.9857 - recall: 0.9038 - f1_score: 0.9426 - val_loss: 0.3477 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2790 - acc: 0.9463 - precision: 0.9859 - recall: 0.9025 - f1_score: 0.9410 - val_loss: 0.3472 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2785 - acc: 0.9463 - precision: 0.9862 - recall: 0.9002 - f1_score: 0.9406 - val_loss: 0.3467 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2780 - acc: 0.9463 - precision: 0.9870 - recall: 0.9019 - f1_score: 0.9417 - val_loss: 0.3463 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2775 - acc: 0.9463 - precision: 0.9859 - recall: 0.9034 - f1_score: 0.9421 - val_loss: 0.3458 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2770 - acc: 0.9463 - precision: 0.9858 - recall: 0.9010 - f1_score: 0.9400 - val_loss: 0.3453 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2765 - acc: 0.9463 - precision: 0.9875 - recall: 0.9041 - f1_score: 0.9420 - val_loss: 0.3449 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9463 - precision: 0.9863 - recall: 0.9038 - f1_score: 0.9420 - val_loss: 0.3444 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2755 - acc: 0.9463 - precision: 0.9869 - recall: 0.9029 - f1_score: 0.9420 - val_loss: 0.3439 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2750 - acc: 0.9463 - precision: 0.9848 - recall: 0.9015 - f1_score: 0.9403 - val_loss: 0.3435 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2745 - acc: 0.9463 - precision: 0.9852 - recall: 0.9016 - f1_score: 0.9404 - val_loss: 0.3430 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9463 - precision: 0.9854 - recall: 0.9006 - f1_score: 0.9391 - val_loss: 0.3425 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2736 - acc: 0.9463 - precision: 0.9859 - recall: 0.9008 - f1_score: 0.9409 - val_loss: 0.3421 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2731 - acc: 0.9463 - precision: 0.9835 - recall: 0.9023 - f1_score: 0.9403 - val_loss: 0.3416 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2726 - acc: 0.9463 - precision: 0.9869 - recall: 0.9043 - f1_score: 0.9417 - val_loss: 0.3412 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9463 - precision: 0.9862 - recall: 0.9020 - f1_score: 0.9411 - val_loss: 0.3407 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 822/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2716 - acc: 0.9463 - precision: 0.9854 - recall: 0.8998 - f1_score: 0.9393 - val_loss: 0.3403 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2712 - acc: 0.9463 - precision: 0.9854 - recall: 0.9016 - f1_score: 0.9406 - val_loss: 0.3398 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2707 - acc: 0.9463 - precision: 0.9863 - recall: 0.9043 - f1_score: 0.9424 - val_loss: 0.3394 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2702 - acc: 0.9463 - precision: 0.9858 - recall: 0.9059 - f1_score: 0.9433 - val_loss: 0.3390 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9463 - precision: 0.9856 - recall: 0.9021 - f1_score: 0.9414 - val_loss: 0.3385 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9463 - precision: 0.9863 - recall: 0.9054 - f1_score: 0.9417 - val_loss: 0.3381 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2688 - acc: 0.9463 - precision: 0.9866 - recall: 0.9027 - f1_score: 0.9423 - val_loss: 0.3376 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2683 - acc: 0.9463 - precision: 0.9858 - recall: 0.8993 - f1_score: 0.9386 - val_loss: 0.3372 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2679 - acc: 0.9463 - precision: 0.9862 - recall: 0.8981 - f1_score: 0.9395 - val_loss: 0.3368 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2674 - acc: 0.9463 - precision: 0.9851 - recall: 0.9005 - f1_score: 0.9395 - val_loss: 0.3364 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2670 - acc: 0.9463 - precision: 0.9837 - recall: 0.8996 - f1_score: 0.9395 - val_loss: 0.3359 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2665 - acc: 0.9463 - precision: 0.9863 - recall: 0.9040 - f1_score: 0.9425 - val_loss: 0.3355 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2661 - acc: 0.9463 - precision: 0.9839 - recall: 0.9040 - f1_score: 0.9416 - val_loss: 0.3351 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2656 - acc: 0.9463 - precision: 0.9877 - recall: 0.9030 - f1_score: 0.9421 - val_loss: 0.3347 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9463 - precision: 0.9858 - recall: 0.9065 - f1_score: 0.9427 - val_loss: 0.3343 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2647 - acc: 0.9463 - precision: 0.9860 - recall: 0.9022 - f1_score: 0.9413 - val_loss: 0.3338 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2643 - acc: 0.9463 - precision: 0.9868 - recall: 0.9035 - f1_score: 0.9424 - val_loss: 0.3334 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2638 - acc: 0.9463 - precision: 0.9880 - recall: 0.9028 - f1_score: 0.9429 - val_loss: 0.3330 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2634 - acc: 0.9463 - precision: 0.9859 - recall: 0.8991 - f1_score: 0.9391 - val_loss: 0.3326 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2629 - acc: 0.9463 - precision: 0.9851 - recall: 0.8978 - f1_score: 0.9382 - val_loss: 0.3322 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2625 - acc: 0.9463 - precision: 0.9868 - recall: 0.9013 - f1_score: 0.9409 - val_loss: 0.3318 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2621 - acc: 0.9463 - precision: 0.9860 - recall: 0.9012 - f1_score: 0.9412 - val_loss: 0.3314 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2617 - acc: 0.9463 - precision: 0.9847 - recall: 0.9041 - f1_score: 0.9417 - val_loss: 0.3310 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2612 - acc: 0.9463 - precision: 0.9844 - recall: 0.8985 - f1_score: 0.9385 - val_loss: 0.3306 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2608 - acc: 0.9463 - precision: 0.9862 - recall: 0.9021 - f1_score: 0.9416 - val_loss: 0.3302 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2604 - acc: 0.9463 - precision: 0.9851 - recall: 0.9040 - f1_score: 0.9415 - val_loss: 0.3298 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2599 - acc: 0.9463 - precision: 0.9861 - recall: 0.9024 - f1_score: 0.9418 - val_loss: 0.3294 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2595 - acc: 0.9463 - precision: 0.9852 - recall: 0.9069 - f1_score: 0.9430 - val_loss: 0.3290 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2591 - acc: 0.9463 - precision: 0.9855 - recall: 0.9007 - f1_score: 0.9407 - val_loss: 0.3286 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2587 - acc: 0.9463 - precision: 0.9863 - recall: 0.9004 - f1_score: 0.9403 - val_loss: 0.3282 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2582 - acc: 0.9463 - precision: 0.9862 - recall: 0.9038 - f1_score: 0.9425 - val_loss: 0.3278 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9463 - precision: 0.9869 - recall: 0.9028 - f1_score: 0.9418 - val_loss: 0.3275 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 854/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2574 - acc: 0.9463 - precision: 0.9859 - recall: 0.9029 - f1_score: 0.9418 - val_loss: 0.3271 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2570 - acc: 0.9463 - precision: 0.9862 - recall: 0.9042 - f1_score: 0.9426 - val_loss: 0.3267 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2566 - acc: 0.9463 - precision: 0.9861 - recall: 0.9042 - f1_score: 0.9422 - val_loss: 0.3263 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2562 - acc: 0.9463 - precision: 0.9861 - recall: 0.9050 - f1_score: 0.9431 - val_loss: 0.3259 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2558 - acc: 0.9463 - precision: 0.9868 - recall: 0.9058 - f1_score: 0.9440 - val_loss: 0.3256 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2554 - acc: 0.9463 - precision: 0.9851 - recall: 0.9029 - f1_score: 0.9417 - val_loss: 0.3252 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2550 - acc: 0.9463 - precision: 0.9857 - recall: 0.9021 - f1_score: 0.9411 - val_loss: 0.3248 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2546 - acc: 0.9463 - precision: 0.9857 - recall: 0.8985 - f1_score: 0.9393 - val_loss: 0.3244 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2542 - acc: 0.9463 - precision: 0.9866 - recall: 0.9061 - f1_score: 0.9436 - val_loss: 0.3241 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2538 - acc: 0.9463 - precision: 0.9859 - recall: 0.9023 - f1_score: 0.9412 - val_loss: 0.3237 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2534 - acc: 0.9463 - precision: 0.9868 - recall: 0.9000 - f1_score: 0.9400 - val_loss: 0.3233 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2530 - acc: 0.9463 - precision: 0.9864 - recall: 0.9029 - f1_score: 0.9411 - val_loss: 0.3230 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9463 - precision: 0.9861 - recall: 0.9016 - f1_score: 0.9407 - val_loss: 0.3226 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2522 - acc: 0.9463 - precision: 0.9849 - recall: 0.9037 - f1_score: 0.9412 - val_loss: 0.3223 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2518 - acc: 0.9463 - precision: 0.9871 - recall: 0.9005 - f1_score: 0.9402 - val_loss: 0.3219 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2514 - acc: 0.9463 - precision: 0.9863 - recall: 0.9059 - f1_score: 0.9430 - val_loss: 0.3216 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2510 - acc: 0.9463 - precision: 0.9855 - recall: 0.9005 - f1_score: 0.9401 - val_loss: 0.3212 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2507 - acc: 0.9463 - precision: 0.9858 - recall: 0.9003 - f1_score: 0.9399 - val_loss: 0.3208 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9463 - precision: 0.9865 - recall: 0.9025 - f1_score: 0.9417 - val_loss: 0.3205 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2499 - acc: 0.9463 - precision: 0.9857 - recall: 0.9015 - f1_score: 0.9411 - val_loss: 0.3201 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2495 - acc: 0.9463 - precision: 0.9856 - recall: 0.9003 - f1_score: 0.9401 - val_loss: 0.3198 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2491 - acc: 0.9463 - precision: 0.9864 - recall: 0.9020 - f1_score: 0.9417 - val_loss: 0.3194 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2488 - acc: 0.9463 - precision: 0.9869 - recall: 0.9075 - f1_score: 0.9437 - val_loss: 0.3191 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9463 - precision: 0.9865 - recall: 0.9033 - f1_score: 0.9422 - val_loss: 0.3188 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2480 - acc: 0.9463 - precision: 0.9864 - recall: 0.9021 - f1_score: 0.9417 - val_loss: 0.3184 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2476 - acc: 0.9463 - precision: 0.9875 - recall: 0.9009 - f1_score: 0.9409 - val_loss: 0.3181 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2473 - acc: 0.9463 - precision: 0.9864 - recall: 0.9044 - f1_score: 0.9431 - val_loss: 0.3177 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2469 - acc: 0.9463 - precision: 0.9851 - recall: 0.9033 - f1_score: 0.9418 - val_loss: 0.3174 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2465 - acc: 0.9463 - precision: 0.9857 - recall: 0.9032 - f1_score: 0.9424 - val_loss: 0.3171 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2462 - acc: 0.9463 - precision: 0.9843 - recall: 0.9024 - f1_score: 0.9408 - val_loss: 0.3167 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2458 - acc: 0.9463 - precision: 0.9860 - recall: 0.9026 - f1_score: 0.9411 - val_loss: 0.3164 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2455 - acc: 0.9463 - precision: 0.9837 - recall: 0.8986 - f1_score: 0.9372 - val_loss: 0.3161 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2451 - acc: 0.9463 - precision: 0.9868 - recall: 0.9069 - f1_score: 0.9441 - val_loss: 0.3157 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2447 - acc: 0.9463 - precision: 0.9852 - recall: 0.8982 - f1_score: 0.9392 - val_loss: 0.3154 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2444 - acc: 0.9463 - precision: 0.9858 - recall: 0.9048 - f1_score: 0.9426 - val_loss: 0.3151 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2440 - acc: 0.9463 - precision: 0.9852 - recall: 0.9032 - f1_score: 0.9414 - val_loss: 0.3148 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2437 - acc: 0.9463 - precision: 0.9865 - recall: 0.9053 - f1_score: 0.9429 - val_loss: 0.3144 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2433 - acc: 0.9463 - precision: 0.9866 - recall: 0.9054 - f1_score: 0.9432 - val_loss: 0.3141 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2430 - acc: 0.9463 - precision: 0.9867 - recall: 0.9039 - f1_score: 0.9420 - val_loss: 0.3138 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9463 - precision: 0.9856 - recall: 0.9010 - f1_score: 0.9402 - val_loss: 0.3135 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9463 - precision: 0.9879 - recall: 0.9040 - f1_score: 0.9426 - val_loss: 0.3132 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2419 - acc: 0.9463 - precision: 0.9855 - recall: 0.9030 - f1_score: 0.9417 - val_loss: 0.3128 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2416 - acc: 0.9463 - precision: 0.9882 - recall: 0.9020 - f1_score: 0.9422 - val_loss: 0.3125 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2412 - acc: 0.9463 - precision: 0.9866 - recall: 0.9015 - f1_score: 0.9410 - val_loss: 0.3122 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9463 - precision: 0.9860 - recall: 0.9037 - f1_score: 0.9422 - val_loss: 0.3119 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9463 - precision: 0.9839 - recall: 0.8997 - f1_score: 0.9394 - val_loss: 0.3116 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9463 - precision: 0.9850 - recall: 0.9030 - f1_score: 0.9413 - val_loss: 0.3113 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9463 - precision: 0.9862 - recall: 0.9054 - f1_score: 0.9424 - val_loss: 0.3110 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2396 - acc: 0.9463 - precision: 0.9851 - recall: 0.9004 - f1_score: 0.9402 - val_loss: 0.3107 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9463 - precision: 0.9851 - recall: 0.9073 - f1_score: 0.9435 - val_loss: 0.3104 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9463 - precision: 0.9856 - recall: 0.9022 - f1_score: 0.9410 - val_loss: 0.3101 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9463 - precision: 0.9852 - recall: 0.9043 - f1_score: 0.9408 - val_loss: 0.3098 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2382 - acc: 0.9463 - precision: 0.9855 - recall: 0.9048 - f1_score: 0.9421 - val_loss: 0.3095 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2379 - acc: 0.9463 - precision: 0.9860 - recall: 0.8999 - f1_score: 0.9397 - val_loss: 0.3092 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2376 - acc: 0.9463 - precision: 0.9865 - recall: 0.8984 - f1_score: 0.9382 - val_loss: 0.3089 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2373 - acc: 0.9463 - precision: 0.9864 - recall: 0.9044 - f1_score: 0.9425 - val_loss: 0.3086 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9200 - precision: 1.0000 - recall: 0.8788 - f1_score: 0.935 - 0s - loss: 0.2369 - acc: 0.9463 - precision: 0.9867 - recall: 0.9030 - f1_score: 0.9411 - val_loss: 0.3083 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2366 - acc: 0.9463 - precision: 0.9857 - recall: 0.9027 - f1_score: 0.9407 - val_loss: 0.3080 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2363 - acc: 0.9463 - precision: 0.9862 - recall: 0.9042 - f1_score: 0.9428 - val_loss: 0.3077 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9463 - precision: 0.9851 - recall: 0.9063 - f1_score: 0.9433 - val_loss: 0.3074 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2356 - acc: 0.9463 - precision: 0.9872 - recall: 0.9079 - f1_score: 0.9449 - val_loss: 0.3072 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9463 - precision: 0.9838 - recall: 0.9018 - f1_score: 0.9403 - val_loss: 0.3069 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9463 - precision: 0.9866 - recall: 0.9014 - f1_score: 0.9415 - val_loss: 0.3066 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2347 - acc: 0.9463 - precision: 0.9849 - recall: 0.9005 - f1_score: 0.9402 - val_loss: 0.3063 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9463 - precision: 0.9866 - recall: 0.8979 - f1_score: 0.9380 - val_loss: 0.3060 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9463 - precision: 0.9869 - recall: 0.9010 - f1_score: 0.9413 - val_loss: 0.3057 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2338 - acc: 0.9463 - precision: 0.9870 - recall: 0.9024 - f1_score: 0.9403 - val_loss: 0.3055 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2335 - acc: 0.9463 - precision: 0.9850 - recall: 0.9078 - f1_score: 0.9430 - val_loss: 0.3052 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9463 - precision: 0.9868 - recall: 0.9050 - f1_score: 0.9432 - val_loss: 0.3049 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2328 - acc: 0.9463 - precision: 0.9864 - recall: 0.9023 - f1_score: 0.9416 - val_loss: 0.3046 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9463 - precision: 0.9847 - recall: 0.9016 - f1_score: 0.9403 - val_loss: 0.3044 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9463 - precision: 0.9888 - recall: 0.9056 - f1_score: 0.9434 - val_loss: 0.3041 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9463 - precision: 0.9850 - recall: 0.9015 - f1_score: 0.9407 - val_loss: 0.3038 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2316 - acc: 0.9463 - precision: 0.9863 - recall: 0.8985 - f1_score: 0.9383 - val_loss: 0.3035 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2313 - acc: 0.9463 - precision: 0.9856 - recall: 0.9017 - f1_score: 0.9408 - val_loss: 0.3032 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9463 - precision: 0.9845 - recall: 0.9042 - f1_score: 0.9414 - val_loss: 0.3030 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2307 - acc: 0.9463 - precision: 0.9870 - recall: 0.9027 - f1_score: 0.9419 - val_loss: 0.3027 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2304 - acc: 0.9463 - precision: 0.9858 - recall: 0.9038 - f1_score: 0.9421 - val_loss: 0.3024 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2302 - acc: 0.9463 - precision: 0.9854 - recall: 0.9091 - f1_score: 0.9441 - val_loss: 0.3022 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2299 - acc: 0.9463 - precision: 0.9858 - recall: 0.9001 - f1_score: 0.9392 - val_loss: 0.3019 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2296 - acc: 0.9463 - precision: 0.9874 - recall: 0.9029 - f1_score: 0.9427 - val_loss: 0.3017 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2293 - acc: 0.9463 - precision: 0.9854 - recall: 0.9026 - f1_score: 0.9411 - val_loss: 0.3014 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2290 - acc: 0.9463 - precision: 0.9861 - recall: 0.9022 - f1_score: 0.9407 - val_loss: 0.3011 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2287 - acc: 0.9463 - precision: 0.9861 - recall: 0.9027 - f1_score: 0.9410 - val_loss: 0.3009 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2284 - acc: 0.9463 - precision: 0.9831 - recall: 0.8986 - f1_score: 0.9380 - val_loss: 0.3006 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2281 - acc: 0.9463 - precision: 0.9868 - recall: 0.9047 - f1_score: 0.9434 - val_loss: 0.3004 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2278 - acc: 0.9463 - precision: 0.9872 - recall: 0.8990 - f1_score: 0.9386 - val_loss: 0.3001 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2276 - acc: 0.9463 - precision: 0.9864 - recall: 0.9013 - f1_score: 0.9411 - val_loss: 0.2999 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2273 - acc: 0.9463 - precision: 0.9838 - recall: 0.9048 - f1_score: 0.9419 - val_loss: 0.2996 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2270 - acc: 0.9463 - precision: 0.9860 - recall: 0.9026 - f1_score: 0.9415 - val_loss: 0.2994 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2267 - acc: 0.9463 - precision: 0.9854 - recall: 0.8994 - f1_score: 0.9396 - val_loss: 0.2991 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2264 - acc: 0.9463 - precision: 0.9872 - recall: 0.9061 - f1_score: 0.9444 - val_loss: 0.2989 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2262 - acc: 0.9463 - precision: 0.9863 - recall: 0.8980 - f1_score: 0.9386 - val_loss: 0.2986 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2259 - acc: 0.9463 - precision: 0.9862 - recall: 0.9003 - f1_score: 0.9401 - val_loss: 0.2984 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2256 - acc: 0.9463 - precision: 0.9847 - recall: 0.8988 - f1_score: 0.9387 - val_loss: 0.2981 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2253 - acc: 0.9463 - precision: 0.9876 - recall: 0.9007 - f1_score: 0.9401 - val_loss: 0.2979 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2251 - acc: 0.9463 - precision: 0.9870 - recall: 0.8994 - f1_score: 0.9399 - val_loss: 0.2977 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2248 - acc: 0.9463 - precision: 0.9867 - recall: 0.9002 - f1_score: 0.9404 - val_loss: 0.2974 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2245 - acc: 0.9463 - precision: 0.9852 - recall: 0.9048 - f1_score: 0.9424 - val_loss: 0.2972 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2243 - acc: 0.9463 - precision: 0.9852 - recall: 0.9015 - f1_score: 0.9404 - val_loss: 0.2969 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2240 - acc: 0.9463 - precision: 0.9873 - recall: 0.9060 - f1_score: 0.9434 - val_loss: 0.2967 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2237 - acc: 0.9463 - precision: 0.9864 - recall: 0.9041 - f1_score: 0.9421 - val_loss: 0.2965 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2235 - acc: 0.9463 - precision: 0.9835 - recall: 0.9004 - f1_score: 0.9393 - val_loss: 0.2962 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2232 - acc: 0.9463 - precision: 0.9858 - recall: 0.9039 - f1_score: 0.9421 - val_loss: 0.2960 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2229 - acc: 0.9463 - precision: 0.9861 - recall: 0.8996 - f1_score: 0.9400 - val_loss: 0.2958 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2227 - acc: 0.9463 - precision: 0.9849 - recall: 0.9032 - f1_score: 0.9413 - val_loss: 0.2956 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2224 - acc: 0.9463 - precision: 0.9844 - recall: 0.9030 - f1_score: 0.9414 - val_loss: 0.2953 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2221 - acc: 0.9463 - precision: 0.9861 - recall: 0.9028 - f1_score: 0.9415 - val_loss: 0.2951 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2219 - acc: 0.9463 - precision: 0.9865 - recall: 0.9003 - f1_score: 0.9400 - val_loss: 0.2949 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2216 - acc: 0.9463 - precision: 0.9867 - recall: 0.9037 - f1_score: 0.9420 - val_loss: 0.2947 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2214 - acc: 0.9463 - precision: 0.9862 - recall: 0.9023 - f1_score: 0.9414 - val_loss: 0.2944 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2211 - acc: 0.9463 - precision: 0.9869 - recall: 0.9027 - f1_score: 0.9420 - val_loss: 0.2942 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2209 - acc: 0.9463 - precision: 0.9842 - recall: 0.9037 - f1_score: 0.9409 - val_loss: 0.2940 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2206 - acc: 0.9463 - precision: 0.9840 - recall: 0.9013 - f1_score: 0.9400 - val_loss: 0.2938 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2204 - acc: 0.9463 - precision: 0.9858 - recall: 0.9026 - f1_score: 0.9414 - val_loss: 0.2935 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2201 - acc: 0.9463 - precision: 0.9853 - recall: 0.9064 - f1_score: 0.9432 - val_loss: 0.2933 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2199 - acc: 0.9463 - precision: 0.9872 - recall: 0.9047 - f1_score: 0.9430 - val_loss: 0.2931 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2196 - acc: 0.9463 - precision: 0.9857 - recall: 0.9029 - f1_score: 0.9414 - val_loss: 0.2929 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2194 - acc: 0.9463 - precision: 0.9870 - recall: 0.9022 - f1_score: 0.9409 - val_loss: 0.2927 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2191 - acc: 0.9463 - precision: 0.9856 - recall: 0.9010 - f1_score: 0.9400 - val_loss: 0.2924 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2189 - acc: 0.9463 - precision: 0.9876 - recall: 0.9038 - f1_score: 0.9424 - val_loss: 0.2922 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2186 - acc: 0.9463 - precision: 0.9879 - recall: 0.9014 - f1_score: 0.9410 - val_loss: 0.2920 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2184 - acc: 0.9463 - precision: 0.9860 - recall: 0.9051 - f1_score: 0.9433 - val_loss: 0.2918 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2181 - acc: 0.9463 - precision: 0.9873 - recall: 0.9019 - f1_score: 0.9421 - val_loss: 0.2916 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2179 - acc: 0.9463 - precision: 0.9861 - recall: 0.9058 - f1_score: 0.9425 - val_loss: 0.2914 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2177 - acc: 0.9463 - precision: 0.9853 - recall: 0.9067 - f1_score: 0.9432 - val_loss: 0.2912 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2174 - acc: 0.9463 - precision: 0.9855 - recall: 0.9010 - f1_score: 0.9410 - val_loss: 0.2910 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2172 - acc: 0.9463 - precision: 0.9863 - recall: 0.9036 - f1_score: 0.9420 - val_loss: 0.2908 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 982/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2170 - acc: 0.9463 - precision: 0.9851 - recall: 0.9061 - f1_score: 0.9423 - val_loss: 0.2906 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2167 - acc: 0.9463 - precision: 0.9850 - recall: 0.8999 - f1_score: 0.9399 - val_loss: 0.2904 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2165 - acc: 0.9463 - precision: 0.9866 - recall: 0.9056 - f1_score: 0.9432 - val_loss: 0.2902 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2163 - acc: 0.9463 - precision: 0.9860 - recall: 0.8984 - f1_score: 0.9385 - val_loss: 0.2900 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2160 - acc: 0.9463 - precision: 0.9861 - recall: 0.9017 - f1_score: 0.9409 - val_loss: 0.2898 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2158 - acc: 0.9463 - precision: 0.9839 - recall: 0.9072 - f1_score: 0.9424 - val_loss: 0.2896 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2156 - acc: 0.9463 - precision: 0.9863 - recall: 0.9021 - f1_score: 0.9411 - val_loss: 0.2894 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2153 - acc: 0.9463 - precision: 0.9866 - recall: 0.9033 - f1_score: 0.9425 - val_loss: 0.2892 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2151 - acc: 0.9463 - precision: 0.9859 - recall: 0.9011 - f1_score: 0.9396 - val_loss: 0.2890 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2149 - acc: 0.9463 - precision: 0.9869 - recall: 0.9013 - f1_score: 0.9406 - val_loss: 0.2888 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2146 - acc: 0.9463 - precision: 0.9857 - recall: 0.9069 - f1_score: 0.9427 - val_loss: 0.2886 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2144 - acc: 0.9463 - precision: 0.9847 - recall: 0.9048 - f1_score: 0.9418 - val_loss: 0.2884 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2142 - acc: 0.9463 - precision: 0.9860 - recall: 0.9005 - f1_score: 0.9393 - val_loss: 0.2882 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2140 - acc: 0.9463 - precision: 0.9858 - recall: 0.9033 - f1_score: 0.9415 - val_loss: 0.2880 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2137 - acc: 0.9463 - precision: 0.9868 - recall: 0.9022 - f1_score: 0.9416 - val_loss: 0.2878 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2135 - acc: 0.9463 - precision: 0.9870 - recall: 0.9015 - f1_score: 0.9410 - val_loss: 0.2876 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2133 - acc: 0.9463 - precision: 0.9849 - recall: 0.9002 - f1_score: 0.9395 - val_loss: 0.2875 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2131 - acc: 0.9463 - precision: 0.9882 - recall: 0.9000 - f1_score: 0.9407 - val_loss: 0.2873 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2144 - acc: 0.9467 - precision: 0.9886 - recall: 0.9019 - f1_score: 0.942 - 0s - loss: 0.2129 - acc: 0.9463 - precision: 0.9864 - recall: 0.9043 - f1_score: 0.9423 - val_loss: 0.2871 - val_acc: 0.9177 - val_precision: 1.0000 - val_recall: 0.8550 - val_f1_score: 0.9202\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 6.0724 - acc: 0.5150 - precision: 0.4893 - recall: 0.7276 - f1_score: 0.5795 - val_loss: 5.9733 - val_acc: 0.6392 - val_precision: 0.5951 - val_recall: 0.9036 - val_f1_score: 0.7171\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9477 - acc: 0.6130 - precision: 0.5625 - recall: 0.9596 - f1_score: 0.7066 - val_loss: 5.9058 - val_acc: 0.6392 - val_precision: 0.5951 - val_recall: 0.9036 - val_f1_score: 0.7171\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8913 - acc: 0.6161 - precision: 0.5653 - recall: 0.9619 - f1_score: 0.7063 - val_loss: 5.8581 - val_acc: 0.6456 - val_precision: 0.5946 - val_recall: 0.9387 - val_f1_score: 0.7274\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8472 - acc: 0.6193 - precision: 0.5671 - recall: 0.9633 - f1_score: 0.7086 - val_loss: 5.8169 - val_acc: 0.6456 - val_precision: 0.5946 - val_recall: 0.9387 - val_f1_score: 0.7274\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8078 - acc: 0.6224 - precision: 0.5670 - recall: 0.9626 - f1_score: 0.7095 - val_loss: 5.7794 - val_acc: 0.6519 - val_precision: 0.5993 - val_recall: 0.9387 - val_f1_score: 0.7312\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7710 - acc: 0.6351 - precision: 0.5780 - recall: 0.9666 - f1_score: 0.7163 - val_loss: 5.7436 - val_acc: 0.6709 - val_precision: 0.6139 - val_recall: 0.9387 - val_f1_score: 0.7420\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7358 - acc: 0.6414 - precision: 0.5829 - recall: 0.9664 - f1_score: 0.7229 - val_loss: 5.7092 - val_acc: 0.6899 - val_precision: 0.6296 - val_recall: 0.9387 - val_f1_score: 0.7530\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7016 - acc: 0.6667 - precision: 0.6010 - recall: 0.9639 - f1_score: 0.7358 - val_loss: 5.6757 - val_acc: 0.7152 - val_precision: 0.6520 - val_recall: 0.9387 - val_f1_score: 0.7686\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6682 - acc: 0.6761 - precision: 0.6072 - recall: 0.9652 - f1_score: 0.7427 - val_loss: 5.6430 - val_acc: 0.7215 - val_precision: 0.6576 - val_recall: 0.9387 - val_f1_score: 0.7727\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6355 - acc: 0.6919 - precision: 0.6185 - recall: 0.9625 - f1_score: 0.7508 - val_loss: 5.6108 - val_acc: 0.7342 - val_precision: 0.6701 - val_recall: 0.9387 - val_f1_score: 0.7813\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6033 - acc: 0.7014 - precision: 0.6271 - recall: 0.9627 - f1_score: 0.7575 - val_loss: 5.5791 - val_acc: 0.7405 - val_precision: 0.6793 - val_recall: 0.9270 - val_f1_score: 0.7830\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5715 - acc: 0.7188 - precision: 0.6436 - recall: 0.9606 - f1_score: 0.7676 - val_loss: 5.5479 - val_acc: 0.7595 - val_precision: 0.7002 - val_recall: 0.9270 - val_f1_score: 0.7959\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5401 - acc: 0.7299 - precision: 0.6561 - recall: 0.9570 - f1_score: 0.7753 - val_loss: 5.5170 - val_acc: 0.7595 - val_precision: 0.7002 - val_recall: 0.9270 - val_f1_score: 0.7959\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.5091 - acc: 0.7457 - precision: 0.6674 - recall: 0.9562 - f1_score: 0.7849 - val_loss: 5.4865 - val_acc: 0.7722 - val_precision: 0.7146 - val_recall: 0.9270 - val_f1_score: 0.8045\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4785 - acc: 0.7567 - precision: 0.6820 - recall: 0.9605 - f1_score: 0.7947 - val_loss: 5.4564 - val_acc: 0.7848 - val_precision: 0.7298 - val_recall: 0.9270 - val_f1_score: 0.8140\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4482 - acc: 0.7678 - precision: 0.6911 - recall: 0.9596 - f1_score: 0.8007 - val_loss: 5.4265 - val_acc: 0.7975 - val_precision: 0.7431 - val_recall: 0.9270 - val_f1_score: 0.8221\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4182 - acc: 0.7867 - precision: 0.7089 - recall: 0.9557 - f1_score: 0.8099 - val_loss: 5.3970 - val_acc: 0.8165 - val_precision: 0.7650 - val_recall: 0.9270 - val_f1_score: 0.8354\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3885 - acc: 0.7946 - precision: 0.7157 - recall: 0.9554 - f1_score: 0.8143 - val_loss: 5.3677 - val_acc: 0.8165 - val_precision: 0.7650 - val_recall: 0.9270 - val_f1_score: 0.8354\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3591 - acc: 0.8073 - precision: 0.7291 - recall: 0.9568 - f1_score: 0.8263 - val_loss: 5.3387 - val_acc: 0.8228 - val_precision: 0.7745 - val_recall: 0.9270 - val_f1_score: 0.8405\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3299 - acc: 0.8199 - precision: 0.7448 - recall: 0.9572 - f1_score: 0.8360 - val_loss: 5.3099 - val_acc: 0.8291 - val_precision: 0.7816 - val_recall: 0.9270 - val_f1_score: 0.8453\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3010 - acc: 0.8199 - precision: 0.7489 - recall: 0.9515 - f1_score: 0.8366 - val_loss: 5.2814 - val_acc: 0.8354 - val_precision: 0.7884 - val_recall: 0.9270 - val_f1_score: 0.8498\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2723 - acc: 0.8373 - precision: 0.7766 - recall: 0.9517 - f1_score: 0.8521 - val_loss: 5.2531 - val_acc: 0.8481 - val_precision: 0.8057 - val_recall: 0.9270 - val_f1_score: 0.8591\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2439 - acc: 0.8499 - precision: 0.7919 - recall: 0.9428 - f1_score: 0.8597 - val_loss: 5.2250 - val_acc: 0.8544 - val_precision: 0.8133 - val_recall: 0.9270 - val_f1_score: 0.8641\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 5.1291 - acc: 0.9600 - precision: 0.9412 - recall: 1.0000 - f1_score: 0.969 - 0s - loss: 5.2157 - acc: 0.8610 - precision: 0.8035 - recall: 0.9441 - f1_score: 0.8665 - val_loss: 5.1972 - val_acc: 0.8734 - val_precision: 0.8398 - val_recall: 0.9270 - val_f1_score: 0.8804\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1877 - acc: 0.8657 - precision: 0.8206 - recall: 0.9347 - f1_score: 0.8722 - val_loss: 5.1696 - val_acc: 0.8797 - val_precision: 0.8494 - val_recall: 0.9270 - val_f1_score: 0.8853\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1600 - acc: 0.8641 - precision: 0.8197 - recall: 0.9282 - f1_score: 0.8692 - val_loss: 5.1422 - val_acc: 0.8924 - val_precision: 0.8699 - val_recall: 0.9270 - val_f1_score: 0.8958\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1325 - acc: 0.8752 - precision: 0.8371 - recall: 0.9307 - f1_score: 0.8788 - val_loss: 5.1150 - val_acc: 0.9051 - val_precision: 0.8920 - val_recall: 0.9270 - val_f1_score: 0.9066\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1052 - acc: 0.8784 - precision: 0.8391 - recall: 0.9235 - f1_score: 0.8782 - val_loss: 5.0881 - val_acc: 0.8987 - val_precision: 0.8915 - val_recall: 0.9153 - val_f1_score: 0.9004\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0780 - acc: 0.8878 - precision: 0.8639 - recall: 0.9231 - f1_score: 0.8894 - val_loss: 5.0613 - val_acc: 0.8987 - val_precision: 0.8915 - val_recall: 0.9153 - val_f1_score: 0.9004\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0511 - acc: 0.8989 - precision: 0.8801 - recall: 0.9251 - f1_score: 0.9003 - val_loss: 5.0347 - val_acc: 0.8987 - val_precision: 0.8915 - val_recall: 0.9153 - val_f1_score: 0.9004\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0245 - acc: 0.9068 - precision: 0.8924 - recall: 0.9190 - f1_score: 0.9040 - val_loss: 5.0083 - val_acc: 0.8987 - val_precision: 0.8915 - val_recall: 0.9153 - val_f1_score: 0.9004\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9980 - acc: 0.9100 - precision: 0.8966 - recall: 0.9119 - f1_score: 0.9030 - val_loss: 4.9821 - val_acc: 0.9051 - val_precision: 0.9018 - val_recall: 0.9153 - val_f1_score: 0.9063\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9716 - acc: 0.9100 - precision: 0.9035 - recall: 0.9161 - f1_score: 0.9078 - val_loss: 4.9561 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9455 - acc: 0.9179 - precision: 0.9175 - recall: 0.9111 - f1_score: 0.9135 - val_loss: 4.9303 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9196 - acc: 0.9210 - precision: 0.9338 - recall: 0.9086 - f1_score: 0.9200 - val_loss: 4.9046 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8938 - acc: 0.9258 - precision: 0.9402 - recall: 0.9101 - f1_score: 0.9228 - val_loss: 4.8791 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8682 - acc: 0.9258 - precision: 0.9418 - recall: 0.9077 - f1_score: 0.9231 - val_loss: 4.8538 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8428 - acc: 0.9273 - precision: 0.9438 - recall: 0.9079 - f1_score: 0.9243 - val_loss: 4.8287 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8176 - acc: 0.9289 - precision: 0.9480 - recall: 0.9073 - f1_score: 0.9262 - val_loss: 4.8038 - val_acc: 0.8987 - val_precision: 0.9013 - val_recall: 0.9036 - val_f1_score: 0.8999\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7925 - acc: 0.9321 - precision: 0.9516 - recall: 0.9080 - f1_score: 0.9271 - val_loss: 4.7790 - val_acc: 0.9114 - val_precision: 0.9225 - val_recall: 0.9036 - val_f1_score: 0.9116\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7676 - acc: 0.9352 - precision: 0.9587 - recall: 0.9070 - f1_score: 0.9314 - val_loss: 4.7544 - val_acc: 0.9114 - val_precision: 0.9225 - val_recall: 0.9036 - val_f1_score: 0.9116\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7429 - acc: 0.9384 - precision: 0.9741 - recall: 0.9036 - f1_score: 0.9361 - val_loss: 4.7299 - val_acc: 0.9114 - val_precision: 0.9225 - val_recall: 0.9036 - val_f1_score: 0.9116\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7183 - acc: 0.9431 - precision: 0.9830 - recall: 0.8996 - f1_score: 0.9386 - val_loss: 4.7056 - val_acc: 0.9177 - val_precision: 0.9345 - val_recall: 0.9036 - val_f1_score: 0.9180\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6940 - acc: 0.9431 - precision: 0.9831 - recall: 0.8974 - f1_score: 0.9367 - val_loss: 4.6815 - val_acc: 0.9241 - val_precision: 0.9466 - val_recall: 0.9036 - val_f1_score: 0.9235\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6697 - acc: 0.9415 - precision: 0.9819 - recall: 0.8968 - f1_score: 0.9364 - val_loss: 4.6575 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.6456 - acc: 0.9415 - precision: 0.9819 - recall: 0.8982 - f1_score: 0.9367 - val_loss: 4.6336 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6217 - acc: 0.9415 - precision: 0.9817 - recall: 0.8986 - f1_score: 0.9373 - val_loss: 4.6100 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5979 - acc: 0.9415 - precision: 0.9816 - recall: 0.9029 - f1_score: 0.9392 - val_loss: 4.5864 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5743 - acc: 0.9415 - precision: 0.9821 - recall: 0.8955 - f1_score: 0.9355 - val_loss: 4.5630 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5508 - acc: 0.9400 - precision: 0.9824 - recall: 0.8934 - f1_score: 0.9351 - val_loss: 4.5398 - val_acc: 0.9177 - val_precision: 0.9461 - val_recall: 0.8919 - val_f1_score: 0.9166\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5275 - acc: 0.9400 - precision: 0.9809 - recall: 0.8917 - f1_score: 0.9329 - val_loss: 4.5167 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5043 - acc: 0.9400 - precision: 0.9836 - recall: 0.8984 - f1_score: 0.9380 - val_loss: 4.4938 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4813 - acc: 0.9400 - precision: 0.9821 - recall: 0.8968 - f1_score: 0.9357 - val_loss: 4.4710 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4584 - acc: 0.9400 - precision: 0.9834 - recall: 0.8933 - f1_score: 0.9347 - val_loss: 4.4483 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4356 - acc: 0.9400 - precision: 0.9828 - recall: 0.8953 - f1_score: 0.9361 - val_loss: 4.4258 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4131 - acc: 0.9400 - precision: 0.9824 - recall: 0.8941 - f1_score: 0.9349 - val_loss: 4.4034 - val_acc: 0.9241 - val_precision: 0.9587 - val_recall: 0.8919 - val_f1_score: 0.9223\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3906 - acc: 0.9400 - precision: 0.9831 - recall: 0.8971 - f1_score: 0.9373 - val_loss: 4.3812 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3683 - acc: 0.9400 - precision: 0.9828 - recall: 0.8965 - f1_score: 0.9362 - val_loss: 4.3591 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3461 - acc: 0.9400 - precision: 0.9835 - recall: 0.8928 - f1_score: 0.9346 - val_loss: 4.3371 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3240 - acc: 0.9400 - precision: 0.9817 - recall: 0.8920 - f1_score: 0.9342 - val_loss: 4.3153 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3021 - acc: 0.9400 - precision: 0.9826 - recall: 0.8980 - f1_score: 0.9349 - val_loss: 4.2936 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2803 - acc: 0.9400 - precision: 0.9817 - recall: 0.8897 - f1_score: 0.9314 - val_loss: 4.2720 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2587 - acc: 0.9400 - precision: 0.9838 - recall: 0.9002 - f1_score: 0.9389 - val_loss: 4.2505 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2371 - acc: 0.9400 - precision: 0.9834 - recall: 0.8963 - f1_score: 0.9361 - val_loss: 4.2292 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2157 - acc: 0.9400 - precision: 0.9812 - recall: 0.8940 - f1_score: 0.9347 - val_loss: 4.2080 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1945 - acc: 0.9400 - precision: 0.9790 - recall: 0.8922 - f1_score: 0.9327 - val_loss: 4.1870 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1733 - acc: 0.9400 - precision: 0.9833 - recall: 0.8932 - f1_score: 0.9345 - val_loss: 4.1660 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1523 - acc: 0.9415 - precision: 0.9850 - recall: 0.8973 - f1_score: 0.9377 - val_loss: 4.1452 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1314 - acc: 0.9415 - precision: 0.9846 - recall: 0.8918 - f1_score: 0.9352 - val_loss: 4.1245 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1106 - acc: 0.9400 - precision: 0.9867 - recall: 0.8906 - f1_score: 0.9346 - val_loss: 4.1039 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0900 - acc: 0.9400 - precision: 0.9859 - recall: 0.8919 - f1_score: 0.9357 - val_loss: 4.0835 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0695 - acc: 0.9400 - precision: 0.9859 - recall: 0.8926 - f1_score: 0.9354 - val_loss: 4.0631 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0490 - acc: 0.9400 - precision: 0.9849 - recall: 0.8942 - f1_score: 0.9365 - val_loss: 4.0429 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0288 - acc: 0.9384 - precision: 0.9841 - recall: 0.8872 - f1_score: 0.9318 - val_loss: 4.0228 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0086 - acc: 0.9384 - precision: 0.9879 - recall: 0.8905 - f1_score: 0.9356 - val_loss: 4.0029 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9885 - acc: 0.9384 - precision: 0.9869 - recall: 0.8868 - f1_score: 0.9330 - val_loss: 3.9830 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9686 - acc: 0.9384 - precision: 0.9859 - recall: 0.8870 - f1_score: 0.9323 - val_loss: 3.9632 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.9488 - acc: 0.9384 - precision: 0.9862 - recall: 0.8864 - f1_score: 0.9329 - val_loss: 3.9436 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9291 - acc: 0.9384 - precision: 0.9837 - recall: 0.8879 - f1_score: 0.9319 - val_loss: 3.9241 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9094 - acc: 0.9368 - precision: 0.9847 - recall: 0.8871 - f1_score: 0.9312 - val_loss: 3.9047 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8900 - acc: 0.9368 - precision: 0.9850 - recall: 0.8824 - f1_score: 0.9305 - val_loss: 3.8854 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8706 - acc: 0.9368 - precision: 0.9844 - recall: 0.8790 - f1_score: 0.9282 - val_loss: 3.8662 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8513 - acc: 0.9368 - precision: 0.9846 - recall: 0.8849 - f1_score: 0.9307 - val_loss: 3.8471 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8321 - acc: 0.9368 - precision: 0.9864 - recall: 0.8841 - f1_score: 0.9319 - val_loss: 3.8281 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8131 - acc: 0.9368 - precision: 0.9856 - recall: 0.8842 - f1_score: 0.9316 - val_loss: 3.8092 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7942 - acc: 0.9368 - precision: 0.9842 - recall: 0.8821 - f1_score: 0.9292 - val_loss: 3.7904 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7753 - acc: 0.9368 - precision: 0.9855 - recall: 0.8836 - f1_score: 0.9292 - val_loss: 3.7718 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7566 - acc: 0.9368 - precision: 0.9875 - recall: 0.8754 - f1_score: 0.9256 - val_loss: 3.7532 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7380 - acc: 0.9368 - precision: 0.9831 - recall: 0.8822 - f1_score: 0.9291 - val_loss: 3.7348 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7194 - acc: 0.9368 - precision: 0.9860 - recall: 0.8858 - f1_score: 0.9309 - val_loss: 3.7164 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7011 - acc: 0.9368 - precision: 0.9858 - recall: 0.8826 - f1_score: 0.9302 - val_loss: 3.6982 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6827 - acc: 0.9368 - precision: 0.9838 - recall: 0.8838 - f1_score: 0.9304 - val_loss: 3.6801 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6645 - acc: 0.9384 - precision: 0.9874 - recall: 0.8865 - f1_score: 0.9334 - val_loss: 3.6620 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6464 - acc: 0.9384 - precision: 0.9846 - recall: 0.8838 - f1_score: 0.9294 - val_loss: 3.6441 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6284 - acc: 0.9384 - precision: 0.9872 - recall: 0.8873 - f1_score: 0.9333 - val_loss: 3.6262 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6105 - acc: 0.9384 - precision: 0.9864 - recall: 0.8855 - f1_score: 0.9321 - val_loss: 3.6085 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5927 - acc: 0.9384 - precision: 0.9870 - recall: 0.8899 - f1_score: 0.9340 - val_loss: 3.5909 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5750 - acc: 0.9384 - precision: 0.9865 - recall: 0.8875 - f1_score: 0.9329 - val_loss: 3.5733 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5574 - acc: 0.9384 - precision: 0.9862 - recall: 0.8877 - f1_score: 0.9336 - val_loss: 3.5559 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5399 - acc: 0.9384 - precision: 0.9866 - recall: 0.8882 - f1_score: 0.9343 - val_loss: 3.5385 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5225 - acc: 0.9384 - precision: 0.9876 - recall: 0.8851 - f1_score: 0.9314 - val_loss: 3.5213 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5052 - acc: 0.9384 - precision: 0.9826 - recall: 0.8852 - f1_score: 0.9308 - val_loss: 3.5041 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4880 - acc: 0.9384 - precision: 0.9853 - recall: 0.8886 - f1_score: 0.9336 - val_loss: 3.4871 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4709 - acc: 0.9384 - precision: 0.9860 - recall: 0.8900 - f1_score: 0.9338 - val_loss: 3.4701 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4538 - acc: 0.9384 - precision: 0.9864 - recall: 0.8926 - f1_score: 0.9362 - val_loss: 3.4533 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4369 - acc: 0.9384 - precision: 0.9846 - recall: 0.8863 - f1_score: 0.9318 - val_loss: 3.4365 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4201 - acc: 0.9384 - precision: 0.9848 - recall: 0.8856 - f1_score: 0.9317 - val_loss: 3.4198 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4033 - acc: 0.9384 - precision: 0.9845 - recall: 0.8881 - f1_score: 0.9327 - val_loss: 3.4032 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3866 - acc: 0.9384 - precision: 0.9867 - recall: 0.8862 - f1_score: 0.9330 - val_loss: 3.3867 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.3701 - acc: 0.9384 - precision: 0.9854 - recall: 0.8875 - f1_score: 0.9313 - val_loss: 3.3703 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3536 - acc: 0.9384 - precision: 0.9840 - recall: 0.8907 - f1_score: 0.9336 - val_loss: 3.3539 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3372 - acc: 0.9384 - precision: 0.9851 - recall: 0.8878 - f1_score: 0.9328 - val_loss: 3.3377 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3209 - acc: 0.9384 - precision: 0.9864 - recall: 0.8862 - f1_score: 0.9322 - val_loss: 3.3216 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3047 - acc: 0.9384 - precision: 0.9862 - recall: 0.8874 - f1_score: 0.9328 - val_loss: 3.3055 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2886 - acc: 0.9384 - precision: 0.9875 - recall: 0.8865 - f1_score: 0.9331 - val_loss: 3.2895 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2726 - acc: 0.9384 - precision: 0.9856 - recall: 0.8907 - f1_score: 0.9337 - val_loss: 3.2736 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2566 - acc: 0.9384 - precision: 0.9850 - recall: 0.8882 - f1_score: 0.9330 - val_loss: 3.2578 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2408 - acc: 0.9384 - precision: 0.9852 - recall: 0.8885 - f1_score: 0.9334 - val_loss: 3.2421 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2250 - acc: 0.9384 - precision: 0.9852 - recall: 0.8905 - f1_score: 0.9336 - val_loss: 3.2265 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2093 - acc: 0.9384 - precision: 0.9867 - recall: 0.8848 - f1_score: 0.9315 - val_loss: 3.2110 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1937 - acc: 0.9384 - precision: 0.9861 - recall: 0.8876 - f1_score: 0.9327 - val_loss: 3.1955 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1782 - acc: 0.9384 - precision: 0.9869 - recall: 0.8845 - f1_score: 0.9311 - val_loss: 3.1801 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1628 - acc: 0.9384 - precision: 0.9853 - recall: 0.8870 - f1_score: 0.9328 - val_loss: 3.1648 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1474 - acc: 0.9384 - precision: 0.9862 - recall: 0.8935 - f1_score: 0.9357 - val_loss: 3.1496 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1322 - acc: 0.9384 - precision: 0.9857 - recall: 0.8860 - f1_score: 0.9322 - val_loss: 3.1345 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1170 - acc: 0.9384 - precision: 0.9875 - recall: 0.8866 - f1_score: 0.9311 - val_loss: 3.1194 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1019 - acc: 0.9384 - precision: 0.9864 - recall: 0.8862 - f1_score: 0.9314 - val_loss: 3.1045 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0869 - acc: 0.9384 - precision: 0.9870 - recall: 0.8868 - f1_score: 0.9326 - val_loss: 3.0896 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0720 - acc: 0.9384 - precision: 0.9854 - recall: 0.8873 - f1_score: 0.9327 - val_loss: 3.0748 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0571 - acc: 0.9384 - precision: 0.9842 - recall: 0.8964 - f1_score: 0.9356 - val_loss: 3.0601 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0423 - acc: 0.9384 - precision: 0.9859 - recall: 0.8861 - f1_score: 0.9308 - val_loss: 3.0454 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0276 - acc: 0.9384 - precision: 0.9863 - recall: 0.8859 - f1_score: 0.9319 - val_loss: 3.0308 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0130 - acc: 0.9384 - precision: 0.9870 - recall: 0.8863 - f1_score: 0.9329 - val_loss: 3.0164 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9985 - acc: 0.9384 - precision: 0.9860 - recall: 0.8899 - f1_score: 0.9346 - val_loss: 3.0019 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9840 - acc: 0.9384 - precision: 0.9858 - recall: 0.8848 - f1_score: 0.9316 - val_loss: 2.9876 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9696 - acc: 0.9400 - precision: 0.9828 - recall: 0.8913 - f1_score: 0.9338 - val_loss: 2.9734 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9553 - acc: 0.9400 - precision: 0.9865 - recall: 0.8902 - f1_score: 0.9339 - val_loss: 2.9592 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9411 - acc: 0.9400 - precision: 0.9835 - recall: 0.8913 - f1_score: 0.9335 - val_loss: 2.9451 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9269 - acc: 0.9400 - precision: 0.9870 - recall: 0.8902 - f1_score: 0.9355 - val_loss: 2.9310 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.9117 - acc: 0.9383 - precision: 0.9853 - recall: 0.8917 - f1_score: 0.935 - 0s - loss: 2.9129 - acc: 0.9400 - precision: 0.9860 - recall: 0.8941 - f1_score: 0.9370 - val_loss: 2.9171 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8988 - acc: 0.9400 - precision: 0.9855 - recall: 0.8885 - f1_score: 0.9336 - val_loss: 2.9032 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.8849 - acc: 0.9400 - precision: 0.9833 - recall: 0.8850 - f1_score: 0.9303 - val_loss: 2.8894 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8711 - acc: 0.9400 - precision: 0.9841 - recall: 0.8888 - f1_score: 0.9335 - val_loss: 2.8757 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8573 - acc: 0.9415 - precision: 0.9870 - recall: 0.8903 - f1_score: 0.9349 - val_loss: 2.8620 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8436 - acc: 0.9400 - precision: 0.9852 - recall: 0.8923 - f1_score: 0.9351 - val_loss: 2.8484 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8300 - acc: 0.9400 - precision: 0.9861 - recall: 0.8941 - f1_score: 0.9359 - val_loss: 2.8349 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8164 - acc: 0.9415 - precision: 0.9846 - recall: 0.8891 - f1_score: 0.9336 - val_loss: 2.8215 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8029 - acc: 0.9415 - precision: 0.9861 - recall: 0.8943 - f1_score: 0.9370 - val_loss: 2.8081 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7895 - acc: 0.9415 - precision: 0.9869 - recall: 0.8926 - f1_score: 0.9361 - val_loss: 2.7948 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7762 - acc: 0.9415 - precision: 0.9849 - recall: 0.8911 - f1_score: 0.9354 - val_loss: 2.7816 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7629 - acc: 0.9415 - precision: 0.9854 - recall: 0.8959 - f1_score: 0.9372 - val_loss: 2.7684 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7497 - acc: 0.9415 - precision: 0.9853 - recall: 0.8913 - f1_score: 0.9353 - val_loss: 2.7553 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7366 - acc: 0.9415 - precision: 0.9864 - recall: 0.8938 - f1_score: 0.9365 - val_loss: 2.7423 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7235 - acc: 0.9415 - precision: 0.9837 - recall: 0.8909 - f1_score: 0.9337 - val_loss: 2.7294 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7105 - acc: 0.9415 - precision: 0.9866 - recall: 0.8964 - f1_score: 0.9386 - val_loss: 2.7165 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6976 - acc: 0.9415 - precision: 0.9865 - recall: 0.8903 - f1_score: 0.9339 - val_loss: 2.7037 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6847 - acc: 0.9415 - precision: 0.9867 - recall: 0.8938 - f1_score: 0.9363 - val_loss: 2.6910 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6719 - acc: 0.9415 - precision: 0.9875 - recall: 0.8934 - f1_score: 0.9371 - val_loss: 2.6783 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6592 - acc: 0.9415 - precision: 0.9838 - recall: 0.8882 - f1_score: 0.9322 - val_loss: 2.6657 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6466 - acc: 0.9415 - precision: 0.9873 - recall: 0.8972 - f1_score: 0.9392 - val_loss: 2.6531 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6340 - acc: 0.9415 - precision: 0.9854 - recall: 0.8908 - f1_score: 0.9347 - val_loss: 2.6406 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6215 - acc: 0.9415 - precision: 0.9860 - recall: 0.8907 - f1_score: 0.9335 - val_loss: 2.6282 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6090 - acc: 0.9415 - precision: 0.9867 - recall: 0.8983 - f1_score: 0.9390 - val_loss: 2.6159 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5966 - acc: 0.9415 - precision: 0.9862 - recall: 0.8893 - f1_score: 0.9331 - val_loss: 2.6036 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5843 - acc: 0.9415 - precision: 0.9849 - recall: 0.8936 - f1_score: 0.9358 - val_loss: 2.5914 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5721 - acc: 0.9415 - precision: 0.9852 - recall: 0.8895 - f1_score: 0.9329 - val_loss: 2.5792 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5599 - acc: 0.9415 - precision: 0.9843 - recall: 0.8906 - f1_score: 0.9344 - val_loss: 2.5672 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5477 - acc: 0.9415 - precision: 0.9863 - recall: 0.8957 - f1_score: 0.9381 - val_loss: 2.5551 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5357 - acc: 0.9415 - precision: 0.9846 - recall: 0.8934 - f1_score: 0.9355 - val_loss: 2.5432 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5237 - acc: 0.9415 - precision: 0.9846 - recall: 0.8933 - f1_score: 0.9360 - val_loss: 2.5313 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5118 - acc: 0.9415 - precision: 0.9855 - recall: 0.8936 - f1_score: 0.9359 - val_loss: 2.5195 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4999 - acc: 0.9415 - precision: 0.9866 - recall: 0.8942 - f1_score: 0.9365 - val_loss: 2.5077 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4881 - acc: 0.9415 - precision: 0.9844 - recall: 0.8940 - f1_score: 0.9364 - val_loss: 2.4960 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.4763 - acc: 0.9415 - precision: 0.9833 - recall: 0.8972 - f1_score: 0.9375 - val_loss: 2.4843 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4646 - acc: 0.9415 - precision: 0.9855 - recall: 0.8981 - f1_score: 0.9385 - val_loss: 2.4727 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4530 - acc: 0.9415 - precision: 0.9862 - recall: 0.8969 - f1_score: 0.9390 - val_loss: 2.4612 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4415 - acc: 0.9415 - precision: 0.9859 - recall: 0.8961 - f1_score: 0.9381 - val_loss: 2.4498 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4300 - acc: 0.9415 - precision: 0.9867 - recall: 0.8911 - f1_score: 0.9346 - val_loss: 2.4384 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4185 - acc: 0.9415 - precision: 0.9865 - recall: 0.8924 - f1_score: 0.9360 - val_loss: 2.4270 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4071 - acc: 0.9415 - precision: 0.9882 - recall: 0.8917 - f1_score: 0.9359 - val_loss: 2.4157 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3958 - acc: 0.9415 - precision: 0.9868 - recall: 0.8936 - f1_score: 0.9368 - val_loss: 2.4045 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3846 - acc: 0.9415 - precision: 0.9854 - recall: 0.8929 - f1_score: 0.9358 - val_loss: 2.3933 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3734 - acc: 0.9415 - precision: 0.9855 - recall: 0.8947 - f1_score: 0.9369 - val_loss: 2.3822 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3622 - acc: 0.9415 - precision: 0.9859 - recall: 0.8910 - f1_score: 0.9351 - val_loss: 2.3712 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3511 - acc: 0.9415 - precision: 0.9859 - recall: 0.8957 - f1_score: 0.9374 - val_loss: 2.3602 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3401 - acc: 0.9415 - precision: 0.9861 - recall: 0.8920 - f1_score: 0.9358 - val_loss: 2.3493 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3292 - acc: 0.9415 - precision: 0.9852 - recall: 0.8954 - f1_score: 0.9372 - val_loss: 2.3384 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3183 - acc: 0.9415 - precision: 0.9852 - recall: 0.8919 - f1_score: 0.9352 - val_loss: 2.3276 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3074 - acc: 0.9415 - precision: 0.9863 - recall: 0.8969 - f1_score: 0.9369 - val_loss: 2.3168 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2966 - acc: 0.9415 - precision: 0.9869 - recall: 0.8936 - f1_score: 0.9370 - val_loss: 2.3061 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2859 - acc: 0.9415 - precision: 0.9841 - recall: 0.8947 - f1_score: 0.9365 - val_loss: 2.2955 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2752 - acc: 0.9415 - precision: 0.9849 - recall: 0.8976 - f1_score: 0.9383 - val_loss: 2.2849 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2646 - acc: 0.9415 - precision: 0.9833 - recall: 0.8928 - f1_score: 0.9346 - val_loss: 2.2743 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2540 - acc: 0.9415 - precision: 0.9844 - recall: 0.8915 - f1_score: 0.9350 - val_loss: 2.2639 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2435 - acc: 0.9415 - precision: 0.9847 - recall: 0.8903 - f1_score: 0.9340 - val_loss: 2.2534 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2330 - acc: 0.9415 - precision: 0.9849 - recall: 0.8952 - f1_score: 0.9360 - val_loss: 2.2431 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2226 - acc: 0.9415 - precision: 0.9864 - recall: 0.8959 - f1_score: 0.9376 - val_loss: 2.2328 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2123 - acc: 0.9415 - precision: 0.9853 - recall: 0.8917 - f1_score: 0.9353 - val_loss: 2.2225 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2020 - acc: 0.9415 - precision: 0.9874 - recall: 0.8930 - f1_score: 0.9368 - val_loss: 2.2123 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1917 - acc: 0.9415 - precision: 0.9866 - recall: 0.8923 - f1_score: 0.9361 - val_loss: 2.2021 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1815 - acc: 0.9415 - precision: 0.9857 - recall: 0.8952 - f1_score: 0.9369 - val_loss: 2.1920 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1714 - acc: 0.9415 - precision: 0.9860 - recall: 0.8972 - f1_score: 0.9384 - val_loss: 2.1820 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1613 - acc: 0.9415 - precision: 0.9852 - recall: 0.8920 - f1_score: 0.9352 - val_loss: 2.1720 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1513 - acc: 0.9415 - precision: 0.9863 - recall: 0.8928 - f1_score: 0.9363 - val_loss: 2.1620 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1413 - acc: 0.9415 - precision: 0.9863 - recall: 0.8953 - f1_score: 0.9375 - val_loss: 2.1521 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 206/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.1314 - acc: 0.9415 - precision: 0.9845 - recall: 0.8959 - f1_score: 0.9373 - val_loss: 2.1423 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1215 - acc: 0.9415 - precision: 0.9860 - recall: 0.8939 - f1_score: 0.9367 - val_loss: 2.1325 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1117 - acc: 0.9415 - precision: 0.9864 - recall: 0.8941 - f1_score: 0.9357 - val_loss: 2.1228 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1020 - acc: 0.9415 - precision: 0.9861 - recall: 0.8965 - f1_score: 0.9382 - val_loss: 2.1131 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0922 - acc: 0.9415 - precision: 0.9871 - recall: 0.8962 - f1_score: 0.9371 - val_loss: 2.1035 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0826 - acc: 0.9415 - precision: 0.9838 - recall: 0.8927 - f1_score: 0.9351 - val_loss: 2.0939 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0729 - acc: 0.9415 - precision: 0.9870 - recall: 0.8939 - f1_score: 0.9374 - val_loss: 2.0843 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0634 - acc: 0.9415 - precision: 0.9867 - recall: 0.8949 - f1_score: 0.9371 - val_loss: 2.0748 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0539 - acc: 0.9415 - precision: 0.9870 - recall: 0.8972 - f1_score: 0.9389 - val_loss: 2.0654 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0444 - acc: 0.9415 - precision: 0.9857 - recall: 0.8942 - f1_score: 0.9370 - val_loss: 2.0560 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0350 - acc: 0.9415 - precision: 0.9870 - recall: 0.8939 - f1_score: 0.9366 - val_loss: 2.0467 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0256 - acc: 0.9415 - precision: 0.9870 - recall: 0.8958 - f1_score: 0.9382 - val_loss: 2.0374 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0163 - acc: 0.9415 - precision: 0.9863 - recall: 0.8904 - f1_score: 0.9339 - val_loss: 2.0281 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0070 - acc: 0.9431 - precision: 0.9891 - recall: 0.8944 - f1_score: 0.9382 - val_loss: 2.0190 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9978 - acc: 0.9431 - precision: 0.9878 - recall: 0.8930 - f1_score: 0.9373 - val_loss: 2.0098 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9886 - acc: 0.9415 - precision: 0.9854 - recall: 0.8945 - f1_score: 0.9373 - val_loss: 2.0007 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9795 - acc: 0.9431 - precision: 0.9901 - recall: 0.8889 - f1_score: 0.9356 - val_loss: 1.9917 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9704 - acc: 0.9431 - precision: 0.9902 - recall: 0.8991 - f1_score: 0.9411 - val_loss: 1.9827 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9614 - acc: 0.9431 - precision: 0.9893 - recall: 0.8914 - f1_score: 0.9367 - val_loss: 1.9737 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9524 - acc: 0.9431 - precision: 0.9891 - recall: 0.8992 - f1_score: 0.9397 - val_loss: 1.9648 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9435 - acc: 0.9431 - precision: 0.9886 - recall: 0.8935 - f1_score: 0.9366 - val_loss: 1.9559 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9346 - acc: 0.9431 - precision: 0.9887 - recall: 0.8924 - f1_score: 0.9369 - val_loss: 1.9471 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9257 - acc: 0.9431 - precision: 0.9896 - recall: 0.8951 - f1_score: 0.9391 - val_loss: 1.9383 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9169 - acc: 0.9447 - precision: 0.9936 - recall: 0.8897 - f1_score: 0.9371 - val_loss: 1.9296 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9082 - acc: 0.9431 - precision: 0.9882 - recall: 0.8928 - f1_score: 0.9370 - val_loss: 1.9209 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8995 - acc: 0.9447 - precision: 0.9934 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 1.9123 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8908 - acc: 0.9447 - precision: 0.9917 - recall: 0.8926 - f1_score: 0.9379 - val_loss: 1.9037 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8822 - acc: 0.9447 - precision: 0.9934 - recall: 0.8926 - f1_score: 0.9393 - val_loss: 1.8952 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8736 - acc: 0.9463 - precision: 0.9967 - recall: 0.8900 - f1_score: 0.9374 - val_loss: 1.8867 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8651 - acc: 0.9463 - precision: 0.9964 - recall: 0.8930 - f1_score: 0.9413 - val_loss: 1.8782 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8566 - acc: 0.9463 - precision: 0.9958 - recall: 0.8929 - f1_score: 0.9410 - val_loss: 1.8698 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8482 - acc: 0.9463 - precision: 0.9967 - recall: 0.8941 - f1_score: 0.9419 - val_loss: 1.8614 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.8398 - acc: 0.9463 - precision: 0.9973 - recall: 0.8960 - f1_score: 0.9423 - val_loss: 1.8531 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8315 - acc: 0.9463 - precision: 0.9966 - recall: 0.8956 - f1_score: 0.9426 - val_loss: 1.8448 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8231 - acc: 0.9463 - precision: 0.9973 - recall: 0.8908 - f1_score: 0.9401 - val_loss: 1.8365 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8149 - acc: 0.9463 - precision: 0.9970 - recall: 0.8940 - f1_score: 0.9421 - val_loss: 1.8284 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8067 - acc: 0.9463 - precision: 0.9964 - recall: 0.8921 - f1_score: 0.9407 - val_loss: 1.8202 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7985 - acc: 0.9463 - precision: 0.9968 - recall: 0.8950 - f1_score: 0.9419 - val_loss: 1.8121 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7903 - acc: 0.9463 - precision: 0.9961 - recall: 0.8959 - f1_score: 0.9408 - val_loss: 1.8040 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7822 - acc: 0.9463 - precision: 0.9961 - recall: 0.8953 - f1_score: 0.9418 - val_loss: 1.7960 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7742 - acc: 0.9463 - precision: 0.9954 - recall: 0.8951 - f1_score: 0.9410 - val_loss: 1.7880 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7662 - acc: 0.9463 - precision: 0.9972 - recall: 0.8951 - f1_score: 0.9421 - val_loss: 1.7800 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7582 - acc: 0.9463 - precision: 0.9969 - recall: 0.8947 - f1_score: 0.9420 - val_loss: 1.7721 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7503 - acc: 0.9463 - precision: 0.9968 - recall: 0.8959 - f1_score: 0.9428 - val_loss: 1.7643 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7424 - acc: 0.9463 - precision: 0.9964 - recall: 0.8925 - f1_score: 0.9408 - val_loss: 1.7565 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7346 - acc: 0.9463 - precision: 0.9964 - recall: 0.8974 - f1_score: 0.9422 - val_loss: 1.7487 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7268 - acc: 0.9463 - precision: 0.9968 - recall: 0.8931 - f1_score: 0.9412 - val_loss: 1.7409 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7190 - acc: 0.9463 - precision: 0.9966 - recall: 0.8950 - f1_score: 0.9418 - val_loss: 1.7332 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7113 - acc: 0.9463 - precision: 0.9962 - recall: 0.8944 - f1_score: 0.9420 - val_loss: 1.7256 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7036 - acc: 0.9463 - precision: 0.9964 - recall: 0.8893 - f1_score: 0.9380 - val_loss: 1.7180 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6959 - acc: 0.9463 - precision: 0.9967 - recall: 0.8920 - f1_score: 0.9405 - val_loss: 1.7104 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6883 - acc: 0.9463 - precision: 0.9962 - recall: 0.8968 - f1_score: 0.9430 - val_loss: 1.7028 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6808 - acc: 0.9463 - precision: 0.9966 - recall: 0.8890 - f1_score: 0.9384 - val_loss: 1.6953 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6732 - acc: 0.9463 - precision: 0.9975 - recall: 0.8911 - f1_score: 0.9397 - val_loss: 1.6879 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6658 - acc: 0.9463 - precision: 0.9972 - recall: 0.8932 - f1_score: 0.9414 - val_loss: 1.6804 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6583 - acc: 0.9463 - precision: 0.9961 - recall: 0.8925 - f1_score: 0.9395 - val_loss: 1.6731 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6509 - acc: 0.9463 - precision: 0.9971 - recall: 0.8968 - f1_score: 0.9434 - val_loss: 1.6657 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6435 - acc: 0.9463 - precision: 0.9966 - recall: 0.8928 - f1_score: 0.9409 - val_loss: 1.6584 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6362 - acc: 0.9463 - precision: 0.9958 - recall: 0.8941 - f1_score: 0.9413 - val_loss: 1.6511 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6289 - acc: 0.9463 - precision: 0.9975 - recall: 0.8933 - f1_score: 0.9411 - val_loss: 1.6439 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6216 - acc: 0.9463 - precision: 0.9964 - recall: 0.8950 - f1_score: 0.9423 - val_loss: 1.6367 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6144 - acc: 0.9463 - precision: 0.9958 - recall: 0.8924 - f1_score: 0.9405 - val_loss: 1.6295 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6072 - acc: 0.9463 - precision: 0.9961 - recall: 0.8942 - f1_score: 0.9415 - val_loss: 1.6224 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6001 - acc: 0.9463 - precision: 0.9964 - recall: 0.8953 - f1_score: 0.9424 - val_loss: 1.6153 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.5930 - acc: 0.9463 - precision: 0.9966 - recall: 0.8952 - f1_score: 0.9423 - val_loss: 1.6082 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5859 - acc: 0.9463 - precision: 0.9965 - recall: 0.8958 - f1_score: 0.9431 - val_loss: 1.6012 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5789 - acc: 0.9463 - precision: 0.9954 - recall: 0.8914 - f1_score: 0.9390 - val_loss: 1.5942 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5719 - acc: 0.9463 - precision: 0.9966 - recall: 0.8954 - f1_score: 0.9426 - val_loss: 1.5873 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5649 - acc: 0.9463 - precision: 0.9960 - recall: 0.8906 - f1_score: 0.9385 - val_loss: 1.5804 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5580 - acc: 0.9463 - precision: 0.9970 - recall: 0.8940 - f1_score: 0.9411 - val_loss: 1.5735 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5511 - acc: 0.9463 - precision: 0.9967 - recall: 0.8921 - f1_score: 0.9401 - val_loss: 1.5667 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5443 - acc: 0.9463 - precision: 0.9956 - recall: 0.8924 - f1_score: 0.9404 - val_loss: 1.5599 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5374 - acc: 0.9463 - precision: 0.9967 - recall: 0.8957 - f1_score: 0.9410 - val_loss: 1.5531 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5306 - acc: 0.9463 - precision: 0.9962 - recall: 0.8996 - f1_score: 0.9445 - val_loss: 1.5464 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5239 - acc: 0.9463 - precision: 0.9961 - recall: 0.8938 - f1_score: 0.9414 - val_loss: 1.5397 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5172 - acc: 0.9463 - precision: 0.9967 - recall: 0.8930 - f1_score: 0.9401 - val_loss: 1.5330 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5105 - acc: 0.9463 - precision: 0.9964 - recall: 0.8870 - f1_score: 0.9375 - val_loss: 1.5264 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5039 - acc: 0.9463 - precision: 0.9966 - recall: 0.8936 - f1_score: 0.9410 - val_loss: 1.5198 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4972 - acc: 0.9463 - precision: 0.9971 - recall: 0.8933 - f1_score: 0.9411 - val_loss: 1.5132 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4907 - acc: 0.9463 - precision: 0.9966 - recall: 0.8965 - f1_score: 0.9434 - val_loss: 1.5067 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4841 - acc: 0.9463 - precision: 0.9954 - recall: 0.8887 - f1_score: 0.9379 - val_loss: 1.5002 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4776 - acc: 0.9463 - precision: 0.9961 - recall: 0.8955 - f1_score: 0.9422 - val_loss: 1.4938 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4712 - acc: 0.9463 - precision: 0.9966 - recall: 0.8950 - f1_score: 0.9421 - val_loss: 1.4873 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4647 - acc: 0.9463 - precision: 0.9964 - recall: 0.8925 - f1_score: 0.9405 - val_loss: 1.4810 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4583 - acc: 0.9463 - precision: 0.9956 - recall: 0.8930 - f1_score: 0.9403 - val_loss: 1.4746 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4519 - acc: 0.9463 - precision: 0.9964 - recall: 0.8953 - f1_score: 0.9424 - val_loss: 1.4683 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4456 - acc: 0.9463 - precision: 0.9961 - recall: 0.8914 - f1_score: 0.9397 - val_loss: 1.4620 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4393 - acc: 0.9463 - precision: 0.9967 - recall: 0.8976 - f1_score: 0.9433 - val_loss: 1.4557 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4330 - acc: 0.9463 - precision: 0.9961 - recall: 0.8936 - f1_score: 0.9415 - val_loss: 1.4495 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4267 - acc: 0.9463 - precision: 0.9972 - recall: 0.8886 - f1_score: 0.9386 - val_loss: 1.4433 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4205 - acc: 0.9463 - precision: 0.9962 - recall: 0.8964 - f1_score: 0.9429 - val_loss: 1.4371 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4144 - acc: 0.9463 - precision: 0.9954 - recall: 0.8922 - f1_score: 0.9398 - val_loss: 1.4310 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4082 - acc: 0.9463 - precision: 0.9967 - recall: 0.8939 - f1_score: 0.9406 - val_loss: 1.4249 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4021 - acc: 0.9463 - precision: 0.9968 - recall: 0.8946 - f1_score: 0.9415 - val_loss: 1.4188 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3960 - acc: 0.9463 - precision: 0.9956 - recall: 0.8962 - f1_score: 0.9414 - val_loss: 1.4128 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3900 - acc: 0.9463 - precision: 0.9971 - recall: 0.8936 - f1_score: 0.9414 - val_loss: 1.4068 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.3839 - acc: 0.9463 - precision: 0.9974 - recall: 0.8970 - f1_score: 0.9429 - val_loss: 1.4008 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3779 - acc: 0.9463 - precision: 0.9958 - recall: 0.8938 - f1_score: 0.9411 - val_loss: 1.3949 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3720 - acc: 0.9463 - precision: 0.9962 - recall: 0.8938 - f1_score: 0.9414 - val_loss: 1.3889 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3660 - acc: 0.9463 - precision: 0.9967 - recall: 0.8927 - f1_score: 0.9405 - val_loss: 1.3831 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3601 - acc: 0.9463 - precision: 0.9954 - recall: 0.8928 - f1_score: 0.9403 - val_loss: 1.3772 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3543 - acc: 0.9463 - precision: 0.9958 - recall: 0.8957 - f1_score: 0.9422 - val_loss: 1.3714 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3484 - acc: 0.9463 - precision: 0.9962 - recall: 0.8933 - f1_score: 0.9416 - val_loss: 1.3656 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3426 - acc: 0.9463 - precision: 0.9972 - recall: 0.8942 - f1_score: 0.9415 - val_loss: 1.3598 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3368 - acc: 0.9463 - precision: 0.9962 - recall: 0.8945 - f1_score: 0.9418 - val_loss: 1.3541 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3311 - acc: 0.9463 - precision: 0.9962 - recall: 0.8926 - f1_score: 0.9404 - val_loss: 1.3484 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3254 - acc: 0.9463 - precision: 0.9965 - recall: 0.8953 - f1_score: 0.9420 - val_loss: 1.3427 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3197 - acc: 0.9463 - precision: 0.9969 - recall: 0.8921 - f1_score: 0.9400 - val_loss: 1.3371 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3140 - acc: 0.9463 - precision: 0.9953 - recall: 0.8919 - f1_score: 0.9400 - val_loss: 1.3314 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3084 - acc: 0.9463 - precision: 0.9964 - recall: 0.8941 - f1_score: 0.9419 - val_loss: 1.3258 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3028 - acc: 0.9463 - precision: 0.9962 - recall: 0.8914 - f1_score: 0.9403 - val_loss: 1.3203 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2972 - acc: 0.9463 - precision: 0.9973 - recall: 0.8963 - f1_score: 0.9426 - val_loss: 1.3148 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2917 - acc: 0.9463 - precision: 0.9961 - recall: 0.8946 - f1_score: 0.9423 - val_loss: 1.3093 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2861 - acc: 0.9463 - precision: 0.9970 - recall: 0.8935 - f1_score: 0.9417 - val_loss: 1.3038 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2807 - acc: 0.9463 - precision: 0.9968 - recall: 0.8934 - f1_score: 0.9412 - val_loss: 1.2983 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2752 - acc: 0.9463 - precision: 0.9962 - recall: 0.8951 - f1_score: 0.9420 - val_loss: 1.2929 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2698 - acc: 0.9463 - precision: 0.9958 - recall: 0.8897 - f1_score: 0.9387 - val_loss: 1.2875 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2644 - acc: 0.9463 - precision: 0.9953 - recall: 0.8960 - f1_score: 0.9418 - val_loss: 1.2822 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2590 - acc: 0.9463 - precision: 0.9971 - recall: 0.8958 - f1_score: 0.9425 - val_loss: 1.2768 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2536 - acc: 0.9463 - precision: 0.9961 - recall: 0.8938 - f1_score: 0.9416 - val_loss: 1.2715 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2483 - acc: 0.9463 - precision: 0.9967 - recall: 0.8976 - f1_score: 0.9432 - val_loss: 1.2662 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2430 - acc: 0.9463 - precision: 0.9968 - recall: 0.8971 - f1_score: 0.9430 - val_loss: 1.2610 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2377 - acc: 0.9463 - precision: 0.9969 - recall: 0.8949 - f1_score: 0.9423 - val_loss: 1.2558 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2325 - acc: 0.9447 - precision: 0.9912 - recall: 0.8912 - f1_score: 0.9377 - val_loss: 1.2506 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2273 - acc: 0.9463 - precision: 0.9947 - recall: 0.8922 - f1_score: 0.9397 - val_loss: 1.2454 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2221 - acc: 0.9463 - precision: 0.9964 - recall: 0.8934 - f1_score: 0.9415 - val_loss: 1.2402 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2169 - acc: 0.9463 - precision: 0.9972 - recall: 0.8929 - f1_score: 0.9415 - val_loss: 1.2351 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2118 - acc: 0.9463 - precision: 0.9970 - recall: 0.8976 - f1_score: 0.9436 - val_loss: 1.2300 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2067 - acc: 0.9447 - precision: 0.9919 - recall: 0.8958 - f1_score: 0.9405 - val_loss: 1.2250 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2016 - acc: 0.9463 - precision: 0.9962 - recall: 0.8957 - f1_score: 0.9418 - val_loss: 1.2199 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1966 - acc: 0.9463 - precision: 0.9961 - recall: 0.8895 - f1_score: 0.9378 - val_loss: 1.2149 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1915 - acc: 0.9463 - precision: 0.9970 - recall: 0.8909 - f1_score: 0.9399 - val_loss: 1.2099 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1865 - acc: 0.9463 - precision: 0.9954 - recall: 0.8913 - f1_score: 0.9392 - val_loss: 1.2049 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1815 - acc: 0.9463 - precision: 0.9967 - recall: 0.8876 - f1_score: 0.9380 - val_loss: 1.2000 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1766 - acc: 0.9463 - precision: 0.9967 - recall: 0.8933 - f1_score: 0.9407 - val_loss: 1.1951 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1717 - acc: 0.9463 - precision: 0.9970 - recall: 0.8937 - f1_score: 0.9414 - val_loss: 1.1902 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1668 - acc: 0.9463 - precision: 0.9958 - recall: 0.8933 - f1_score: 0.9415 - val_loss: 1.1853 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1619 - acc: 0.9447 - precision: 0.9926 - recall: 0.8995 - f1_score: 0.9427 - val_loss: 1.1805 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1570 - acc: 0.9447 - precision: 0.9931 - recall: 0.8947 - f1_score: 0.9399 - val_loss: 1.1757 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1522 - acc: 0.9463 - precision: 0.9967 - recall: 0.8912 - f1_score: 0.9392 - val_loss: 1.1709 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1474 - acc: 0.9463 - precision: 0.9947 - recall: 0.8972 - f1_score: 0.9423 - val_loss: 1.1661 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1426 - acc: 0.9463 - precision: 0.9961 - recall: 0.8952 - f1_score: 0.9413 - val_loss: 1.1614 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1379 - acc: 0.9463 - precision: 0.9966 - recall: 0.8953 - f1_score: 0.9423 - val_loss: 1.1567 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1331 - acc: 0.9463 - precision: 0.9966 - recall: 0.8963 - f1_score: 0.9426 - val_loss: 1.1520 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1284 - acc: 0.9463 - precision: 0.9970 - recall: 0.8971 - f1_score: 0.9438 - val_loss: 1.1473 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1238 - acc: 0.9463 - precision: 0.9967 - recall: 0.8967 - f1_score: 0.9431 - val_loss: 1.1427 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1191 - acc: 0.9447 - precision: 0.9926 - recall: 0.8927 - f1_score: 0.9384 - val_loss: 1.1381 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1145 - acc: 0.9447 - precision: 0.9934 - recall: 0.8910 - f1_score: 0.9381 - val_loss: 1.1335 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1099 - acc: 0.9463 - precision: 0.9962 - recall: 0.8948 - f1_score: 0.9420 - val_loss: 1.1289 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1053 - acc: 0.9463 - precision: 0.9958 - recall: 0.8920 - f1_score: 0.9399 - val_loss: 1.1243 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1007 - acc: 0.9447 - precision: 0.9926 - recall: 0.8955 - f1_score: 0.9401 - val_loss: 1.1198 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0962 - acc: 0.9447 - precision: 0.9932 - recall: 0.8950 - f1_score: 0.9404 - val_loss: 1.1153 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0917 - acc: 0.9447 - precision: 0.9942 - recall: 0.8907 - f1_score: 0.9384 - val_loss: 1.1108 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0872 - acc: 0.9463 - precision: 0.9954 - recall: 0.8909 - f1_score: 0.9393 - val_loss: 1.1064 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0827 - acc: 0.9463 - precision: 0.9958 - recall: 0.8921 - f1_score: 0.9397 - val_loss: 1.1019 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0783 - acc: 0.9463 - precision: 0.9968 - recall: 0.8919 - f1_score: 0.9407 - val_loss: 1.0975 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0738 - acc: 0.9447 - precision: 0.9928 - recall: 0.8936 - f1_score: 0.9402 - val_loss: 1.0931 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0694 - acc: 0.9447 - precision: 0.9943 - recall: 0.8942 - f1_score: 0.9389 - val_loss: 1.0888 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0651 - acc: 0.9447 - precision: 0.9929 - recall: 0.8961 - f1_score: 0.9397 - val_loss: 1.0844 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0607 - acc: 0.9447 - precision: 0.9926 - recall: 0.8923 - f1_score: 0.9390 - val_loss: 1.0801 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.0564 - acc: 0.9463 - precision: 0.9972 - recall: 0.8930 - f1_score: 0.9413 - val_loss: 1.0758 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0521 - acc: 0.9463 - precision: 0.9969 - recall: 0.8876 - f1_score: 0.9368 - val_loss: 1.0715 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0478 - acc: 0.9463 - precision: 0.9966 - recall: 0.8951 - f1_score: 0.9425 - val_loss: 1.0673 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0435 - acc: 0.9447 - precision: 0.9928 - recall: 0.8935 - f1_score: 0.9398 - val_loss: 1.0630 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0392 - acc: 0.9447 - precision: 0.9931 - recall: 0.8906 - f1_score: 0.9381 - val_loss: 1.0588 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0350 - acc: 0.9463 - precision: 0.9962 - recall: 0.8907 - f1_score: 0.9392 - val_loss: 1.0546 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0308 - acc: 0.9463 - precision: 0.9970 - recall: 0.8944 - f1_score: 0.9425 - val_loss: 1.0505 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0266 - acc: 0.9447 - precision: 0.9920 - recall: 0.8923 - f1_score: 0.9389 - val_loss: 1.0463 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0225 - acc: 0.9447 - precision: 0.9925 - recall: 0.8959 - f1_score: 0.9412 - val_loss: 1.0422 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0183 - acc: 0.9463 - precision: 0.9962 - recall: 0.8922 - f1_score: 0.9398 - val_loss: 1.0381 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0142 - acc: 0.9447 - precision: 0.9919 - recall: 0.8961 - f1_score: 0.9407 - val_loss: 1.0340 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0101 - acc: 0.9463 - precision: 0.9951 - recall: 0.8960 - f1_score: 0.9417 - val_loss: 1.0299 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0060 - acc: 0.9447 - precision: 0.9926 - recall: 0.8933 - f1_score: 0.9395 - val_loss: 1.0259 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0020 - acc: 0.9447 - precision: 0.9934 - recall: 0.8924 - f1_score: 0.9391 - val_loss: 1.0218 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9979 - acc: 0.9447 - precision: 0.9937 - recall: 0.8958 - f1_score: 0.9407 - val_loss: 1.0178 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9939 - acc: 0.9463 - precision: 0.9973 - recall: 0.8946 - f1_score: 0.9421 - val_loss: 1.0139 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9899 - acc: 0.9447 - precision: 0.9919 - recall: 0.8947 - f1_score: 0.9399 - val_loss: 1.0099 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9860 - acc: 0.9463 - precision: 0.9958 - recall: 0.8943 - f1_score: 0.9412 - val_loss: 1.0059 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9820 - acc: 0.9447 - precision: 0.9935 - recall: 0.8954 - f1_score: 0.9401 - val_loss: 1.0020 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9781 - acc: 0.9447 - precision: 0.9924 - recall: 0.8924 - f1_score: 0.9390 - val_loss: 0.9981 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9741 - acc: 0.9447 - precision: 0.9918 - recall: 0.8894 - f1_score: 0.9366 - val_loss: 0.9942 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9703 - acc: 0.9447 - precision: 0.9926 - recall: 0.8940 - f1_score: 0.9399 - val_loss: 0.9904 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9664 - acc: 0.9447 - precision: 0.9937 - recall: 0.8939 - f1_score: 0.9400 - val_loss: 0.9865 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9625 - acc: 0.9463 - precision: 0.9964 - recall: 0.8937 - f1_score: 0.9414 - val_loss: 0.9827 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9587 - acc: 0.9447 - precision: 0.9935 - recall: 0.8943 - f1_score: 0.9404 - val_loss: 0.9789 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9549 - acc: 0.9447 - precision: 0.9925 - recall: 0.8916 - f1_score: 0.9386 - val_loss: 0.9751 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9511 - acc: 0.9447 - precision: 0.9932 - recall: 0.8913 - f1_score: 0.9379 - val_loss: 0.9714 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9473 - acc: 0.9447 - precision: 0.9921 - recall: 0.8916 - f1_score: 0.9381 - val_loss: 0.9676 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9435 - acc: 0.9447 - precision: 0.9931 - recall: 0.8920 - f1_score: 0.9386 - val_loss: 0.9639 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9398 - acc: 0.9447 - precision: 0.9929 - recall: 0.8964 - f1_score: 0.9412 - val_loss: 0.9602 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9361 - acc: 0.9447 - precision: 0.9926 - recall: 0.8941 - f1_score: 0.9399 - val_loss: 0.9565 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9324 - acc: 0.9447 - precision: 0.9941 - recall: 0.8925 - f1_score: 0.9389 - val_loss: 0.9528 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9287 - acc: 0.9447 - precision: 0.9933 - recall: 0.8948 - f1_score: 0.9404 - val_loss: 0.9492 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9250 - acc: 0.9447 - precision: 0.9919 - recall: 0.8970 - f1_score: 0.9410 - val_loss: 0.9455 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9214 - acc: 0.9447 - precision: 0.9929 - recall: 0.8983 - f1_score: 0.9425 - val_loss: 0.9419 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9178 - acc: 0.9447 - precision: 0.9928 - recall: 0.8932 - f1_score: 0.9385 - val_loss: 0.9383 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9142 - acc: 0.9447 - precision: 0.9926 - recall: 0.8970 - f1_score: 0.9418 - val_loss: 0.9347 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9106 - acc: 0.9447 - precision: 0.9935 - recall: 0.8973 - f1_score: 0.9416 - val_loss: 0.9312 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9070 - acc: 0.9447 - precision: 0.9922 - recall: 0.8926 - f1_score: 0.9389 - val_loss: 0.9276 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9034 - acc: 0.9447 - precision: 0.9918 - recall: 0.8974 - f1_score: 0.9411 - val_loss: 0.9241 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8999 - acc: 0.9447 - precision: 0.9933 - recall: 0.8896 - f1_score: 0.9371 - val_loss: 0.9206 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8964 - acc: 0.9447 - precision: 0.9918 - recall: 0.8905 - f1_score: 0.9370 - val_loss: 0.9171 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8929 - acc: 0.9447 - precision: 0.9913 - recall: 0.8933 - f1_score: 0.9389 - val_loss: 0.9136 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8894 - acc: 0.9447 - precision: 0.9937 - recall: 0.8957 - f1_score: 0.9407 - val_loss: 0.9102 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8859 - acc: 0.9447 - precision: 0.9936 - recall: 0.8944 - f1_score: 0.9401 - val_loss: 0.9068 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8825 - acc: 0.9447 - precision: 0.9921 - recall: 0.8969 - f1_score: 0.9410 - val_loss: 0.9033 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8791 - acc: 0.9447 - precision: 0.9922 - recall: 0.8935 - f1_score: 0.9395 - val_loss: 0.8999 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8756 - acc: 0.9447 - precision: 0.9934 - recall: 0.8937 - f1_score: 0.9400 - val_loss: 0.8966 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8723 - acc: 0.9447 - precision: 0.9931 - recall: 0.8950 - f1_score: 0.9404 - val_loss: 0.8932 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8689 - acc: 0.9447 - precision: 0.9938 - recall: 0.8902 - f1_score: 0.9376 - val_loss: 0.8898 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8655 - acc: 0.9447 - precision: 0.9930 - recall: 0.8946 - f1_score: 0.9399 - val_loss: 0.8865 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8622 - acc: 0.9463 - precision: 0.9972 - recall: 0.8917 - f1_score: 0.9403 - val_loss: 0.8832 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8588 - acc: 0.9447 - precision: 0.9923 - recall: 0.8945 - f1_score: 0.9394 - val_loss: 0.8799 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8555 - acc: 0.9447 - precision: 0.9919 - recall: 0.8922 - f1_score: 0.9382 - val_loss: 0.8766 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8522 - acc: 0.9447 - precision: 0.9929 - recall: 0.8948 - f1_score: 0.9404 - val_loss: 0.8734 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8490 - acc: 0.9447 - precision: 0.9921 - recall: 0.8945 - f1_score: 0.9403 - val_loss: 0.8701 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8457 - acc: 0.9447 - precision: 0.9937 - recall: 0.8943 - f1_score: 0.9401 - val_loss: 0.8669 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8425 - acc: 0.9447 - precision: 0.9931 - recall: 0.8936 - f1_score: 0.9402 - val_loss: 0.8637 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8392 - acc: 0.9447 - precision: 0.9921 - recall: 0.8936 - f1_score: 0.9390 - val_loss: 0.8605 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8360 - acc: 0.9447 - precision: 0.9933 - recall: 0.8973 - f1_score: 0.9413 - val_loss: 0.8573 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8328 - acc: 0.9447 - precision: 0.9934 - recall: 0.8950 - f1_score: 0.9409 - val_loss: 0.8541 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8296 - acc: 0.9447 - precision: 0.9931 - recall: 0.8922 - f1_score: 0.9390 - val_loss: 0.8510 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8265 - acc: 0.9447 - precision: 0.9939 - recall: 0.8915 - f1_score: 0.9386 - val_loss: 0.8478 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8233 - acc: 0.9447 - precision: 0.9923 - recall: 0.8948 - f1_score: 0.9399 - val_loss: 0.8447 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 430/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8202 - acc: 0.9447 - precision: 0.9939 - recall: 0.8934 - f1_score: 0.9396 - val_loss: 0.8416 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8171 - acc: 0.9447 - precision: 0.9929 - recall: 0.8958 - f1_score: 0.9406 - val_loss: 0.8385 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8140 - acc: 0.9447 - precision: 0.9926 - recall: 0.8963 - f1_score: 0.9410 - val_loss: 0.8354 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8109 - acc: 0.9447 - precision: 0.9926 - recall: 0.8939 - f1_score: 0.9398 - val_loss: 0.8324 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8078 - acc: 0.9447 - precision: 0.9919 - recall: 0.8918 - f1_score: 0.9379 - val_loss: 0.8293 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8048 - acc: 0.9447 - precision: 0.9928 - recall: 0.8944 - f1_score: 0.9398 - val_loss: 0.8263 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8018 - acc: 0.9447 - precision: 0.9931 - recall: 0.8931 - f1_score: 0.9399 - val_loss: 0.8233 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7987 - acc: 0.9447 - precision: 0.9921 - recall: 0.8953 - f1_score: 0.9408 - val_loss: 0.8203 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7957 - acc: 0.9447 - precision: 0.9926 - recall: 0.8974 - f1_score: 0.9418 - val_loss: 0.8173 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7927 - acc: 0.9463 - precision: 0.9968 - recall: 0.8965 - f1_score: 0.9427 - val_loss: 0.8143 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7898 - acc: 0.9463 - precision: 0.9954 - recall: 0.8930 - f1_score: 0.9408 - val_loss: 0.8114 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7868 - acc: 0.9463 - precision: 0.9956 - recall: 0.8908 - f1_score: 0.9386 - val_loss: 0.8085 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7839 - acc: 0.9463 - precision: 0.9961 - recall: 0.8976 - f1_score: 0.9432 - val_loss: 0.8055 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7809 - acc: 0.9447 - precision: 0.9933 - recall: 0.8938 - f1_score: 0.9389 - val_loss: 0.8026 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7780 - acc: 0.9447 - precision: 0.9933 - recall: 0.8922 - f1_score: 0.9393 - val_loss: 0.7997 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7751 - acc: 0.9447 - precision: 0.9940 - recall: 0.8973 - f1_score: 0.9409 - val_loss: 0.7969 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7722 - acc: 0.9447 - precision: 0.9928 - recall: 0.8934 - f1_score: 0.9399 - val_loss: 0.7940 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7693 - acc: 0.9463 - precision: 0.9967 - recall: 0.8962 - f1_score: 0.9425 - val_loss: 0.7912 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7665 - acc: 0.9447 - precision: 0.9936 - recall: 0.8932 - f1_score: 0.9395 - val_loss: 0.7883 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7636 - acc: 0.9463 - precision: 0.9966 - recall: 0.8932 - f1_score: 0.9417 - val_loss: 0.7855 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7608 - acc: 0.9463 - precision: 0.9967 - recall: 0.8952 - f1_score: 0.9421 - val_loss: 0.7827 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7580 - acc: 0.9463 - precision: 0.9958 - recall: 0.8948 - f1_score: 0.9414 - val_loss: 0.7799 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7552 - acc: 0.9479 - precision: 0.9975 - recall: 0.8935 - f1_score: 0.9411 - val_loss: 0.7771 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7524 - acc: 0.9463 - precision: 0.9929 - recall: 0.9005 - f1_score: 0.9424 - val_loss: 0.7744 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7496 - acc: 0.9463 - precision: 0.9964 - recall: 0.8909 - f1_score: 0.9395 - val_loss: 0.7716 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7469 - acc: 0.9479 - precision: 0.9968 - recall: 0.8948 - f1_score: 0.9421 - val_loss: 0.7689 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7441 - acc: 0.9463 - precision: 0.9935 - recall: 0.8975 - f1_score: 0.9420 - val_loss: 0.7662 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7414 - acc: 0.9479 - precision: 0.9970 - recall: 0.8994 - f1_score: 0.9450 - val_loss: 0.7635 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7387 - acc: 0.9463 - precision: 0.9915 - recall: 0.8962 - f1_score: 0.9405 - val_loss: 0.7608 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7360 - acc: 0.9479 - precision: 0.9961 - recall: 0.8991 - f1_score: 0.9441 - val_loss: 0.7581 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7333 - acc: 0.9463 - precision: 0.9938 - recall: 0.9000 - f1_score: 0.9437 - val_loss: 0.7554 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7306 - acc: 0.9479 - precision: 0.9967 - recall: 0.8998 - f1_score: 0.9450 - val_loss: 0.7528 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7279 - acc: 0.9479 - precision: 0.9964 - recall: 0.8964 - f1_score: 0.9423 - val_loss: 0.7501 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7253 - acc: 0.9479 - precision: 0.9962 - recall: 0.8976 - f1_score: 0.9430 - val_loss: 0.7475 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7227 - acc: 0.9479 - precision: 0.9962 - recall: 0.8964 - f1_score: 0.9426 - val_loss: 0.7449 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7200 - acc: 0.9463 - precision: 0.9906 - recall: 0.8949 - f1_score: 0.9396 - val_loss: 0.7423 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7174 - acc: 0.9479 - precision: 0.9968 - recall: 0.8941 - f1_score: 0.9413 - val_loss: 0.7397 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7148 - acc: 0.9479 - precision: 0.9966 - recall: 0.8981 - f1_score: 0.9437 - val_loss: 0.7371 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7122 - acc: 0.9479 - precision: 0.9962 - recall: 0.8976 - f1_score: 0.9426 - val_loss: 0.7346 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7097 - acc: 0.9479 - precision: 0.9962 - recall: 0.8954 - f1_score: 0.9421 - val_loss: 0.7320 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7071 - acc: 0.9479 - precision: 0.9964 - recall: 0.8956 - f1_score: 0.9424 - val_loss: 0.7295 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7046 - acc: 0.9479 - precision: 0.9970 - recall: 0.8995 - f1_score: 0.9448 - val_loss: 0.7269 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7020 - acc: 0.9479 - precision: 0.9970 - recall: 0.8958 - f1_score: 0.9427 - val_loss: 0.7244 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6995 - acc: 0.9479 - precision: 0.9966 - recall: 0.8972 - f1_score: 0.9430 - val_loss: 0.7219 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6970 - acc: 0.9479 - precision: 0.9961 - recall: 0.8939 - f1_score: 0.9412 - val_loss: 0.7194 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6945 - acc: 0.9479 - precision: 0.9966 - recall: 0.8984 - f1_score: 0.9445 - val_loss: 0.7170 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6920 - acc: 0.9479 - precision: 0.9961 - recall: 0.8972 - f1_score: 0.9434 - val_loss: 0.7145 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6896 - acc: 0.9479 - precision: 0.9966 - recall: 0.8997 - f1_score: 0.9449 - val_loss: 0.7121 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6871 - acc: 0.9479 - precision: 0.9964 - recall: 0.8964 - f1_score: 0.9424 - val_loss: 0.7096 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6846 - acc: 0.9479 - precision: 0.9974 - recall: 0.8966 - f1_score: 0.9424 - val_loss: 0.7072 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6822 - acc: 0.9479 - precision: 0.9958 - recall: 0.8972 - f1_score: 0.9428 - val_loss: 0.7048 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6798 - acc: 0.9479 - precision: 0.9966 - recall: 0.8977 - f1_score: 0.9438 - val_loss: 0.7024 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6774 - acc: 0.9479 - precision: 0.9964 - recall: 0.8983 - f1_score: 0.9439 - val_loss: 0.7000 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6750 - acc: 0.9479 - precision: 0.9968 - recall: 0.9025 - f1_score: 0.9459 - val_loss: 0.6976 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6726 - acc: 0.9479 - precision: 0.9972 - recall: 0.8984 - f1_score: 0.9442 - val_loss: 0.6953 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6702 - acc: 0.9479 - precision: 0.9970 - recall: 0.8957 - f1_score: 0.9424 - val_loss: 0.6929 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6679 - acc: 0.9479 - precision: 0.9956 - recall: 0.8987 - f1_score: 0.9435 - val_loss: 0.6906 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6655 - acc: 0.9479 - precision: 0.9974 - recall: 0.8947 - f1_score: 0.9422 - val_loss: 0.6883 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6632 - acc: 0.9479 - precision: 0.9956 - recall: 0.8975 - f1_score: 0.9430 - val_loss: 0.6860 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6608 - acc: 0.9479 - precision: 0.9956 - recall: 0.8912 - f1_score: 0.9395 - val_loss: 0.6837 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6585 - acc: 0.9479 - precision: 0.9970 - recall: 0.8969 - f1_score: 0.9423 - val_loss: 0.6814 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6562 - acc: 0.9479 - precision: 0.9956 - recall: 0.8999 - f1_score: 0.9437 - val_loss: 0.6791 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6539 - acc: 0.9479 - precision: 0.9961 - recall: 0.8969 - f1_score: 0.9430 - val_loss: 0.6768 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6517 - acc: 0.9479 - precision: 0.9970 - recall: 0.8901 - f1_score: 0.9387 - val_loss: 0.6746 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6494 - acc: 0.9479 - precision: 0.9967 - recall: 0.9041 - f1_score: 0.9467 - val_loss: 0.6723 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6471 - acc: 0.9479 - precision: 0.9964 - recall: 0.9002 - f1_score: 0.9446 - val_loss: 0.6701 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6449 - acc: 0.9479 - precision: 0.9972 - recall: 0.9000 - f1_score: 0.9455 - val_loss: 0.6678 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6427 - acc: 0.9479 - precision: 0.9970 - recall: 0.8953 - f1_score: 0.9424 - val_loss: 0.6656 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6404 - acc: 0.9479 - precision: 0.9967 - recall: 0.8993 - f1_score: 0.9445 - val_loss: 0.6634 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6382 - acc: 0.9479 - precision: 0.9962 - recall: 0.8960 - f1_score: 0.9424 - val_loss: 0.6612 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6360 - acc: 0.9479 - precision: 0.9966 - recall: 0.8963 - f1_score: 0.9427 - val_loss: 0.6590 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6338 - acc: 0.9479 - precision: 0.9975 - recall: 0.8941 - f1_score: 0.9419 - val_loss: 0.6569 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6316 - acc: 0.9479 - precision: 0.9971 - recall: 0.8964 - f1_score: 0.9434 - val_loss: 0.6547 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6295 - acc: 0.9479 - precision: 0.9974 - recall: 0.8935 - f1_score: 0.9417 - val_loss: 0.6526 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6273 - acc: 0.9479 - precision: 0.9961 - recall: 0.8996 - f1_score: 0.9441 - val_loss: 0.6504 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6252 - acc: 0.9479 - precision: 0.9968 - recall: 0.8949 - f1_score: 0.9425 - val_loss: 0.6483 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6230 - acc: 0.9479 - precision: 0.9966 - recall: 0.8973 - f1_score: 0.9435 - val_loss: 0.6462 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6209 - acc: 0.9479 - precision: 0.9970 - recall: 0.8967 - f1_score: 0.9433 - val_loss: 0.6441 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6188 - acc: 0.9479 - precision: 0.9965 - recall: 0.8987 - f1_score: 0.9445 - val_loss: 0.6420 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6167 - acc: 0.9479 - precision: 0.9968 - recall: 0.8957 - f1_score: 0.9420 - val_loss: 0.6399 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6146 - acc: 0.9479 - precision: 0.9956 - recall: 0.8967 - f1_score: 0.9418 - val_loss: 0.6378 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6125 - acc: 0.9479 - precision: 0.9962 - recall: 0.8962 - f1_score: 0.9428 - val_loss: 0.6358 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6104 - acc: 0.9479 - precision: 0.9970 - recall: 0.8956 - f1_score: 0.9422 - val_loss: 0.6337 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6084 - acc: 0.9479 - precision: 0.9970 - recall: 0.8962 - f1_score: 0.9433 - val_loss: 0.6317 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6063 - acc: 0.9479 - precision: 0.9956 - recall: 0.8916 - f1_score: 0.9394 - val_loss: 0.6296 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6043 - acc: 0.9479 - precision: 0.9966 - recall: 0.8986 - f1_score: 0.9446 - val_loss: 0.6276 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6022 - acc: 0.9479 - precision: 0.9962 - recall: 0.8979 - f1_score: 0.9436 - val_loss: 0.6256 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6002 - acc: 0.9479 - precision: 0.9970 - recall: 0.8948 - f1_score: 0.9415 - val_loss: 0.6236 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5982 - acc: 0.9479 - precision: 0.9962 - recall: 0.8969 - f1_score: 0.9431 - val_loss: 0.6216 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5962 - acc: 0.9479 - precision: 0.9967 - recall: 0.8991 - f1_score: 0.9443 - val_loss: 0.6196 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5942 - acc: 0.9479 - precision: 0.9966 - recall: 0.8984 - f1_score: 0.9445 - val_loss: 0.6176 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5922 - acc: 0.9479 - precision: 0.9962 - recall: 0.8991 - f1_score: 0.9438 - val_loss: 0.6157 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5902 - acc: 0.9479 - precision: 0.9962 - recall: 0.8942 - f1_score: 0.9417 - val_loss: 0.6137 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5883 - acc: 0.9479 - precision: 0.9964 - recall: 0.8948 - f1_score: 0.9413 - val_loss: 0.6118 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5863 - acc: 0.9479 - precision: 0.9964 - recall: 0.8965 - f1_score: 0.9421 - val_loss: 0.6098 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5844 - acc: 0.9479 - precision: 0.9973 - recall: 0.9013 - f1_score: 0.9456 - val_loss: 0.6079 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5824 - acc: 0.9494 - precision: 0.9970 - recall: 0.9044 - f1_score: 0.9474 - val_loss: 0.6060 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5805 - acc: 0.9494 - precision: 0.9958 - recall: 0.8993 - f1_score: 0.9440 - val_loss: 0.6041 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5786 - acc: 0.9494 - precision: 0.9971 - recall: 0.8989 - f1_score: 0.9437 - val_loss: 0.6022 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5767 - acc: 0.9494 - precision: 0.9968 - recall: 0.9025 - f1_score: 0.9464 - val_loss: 0.6003 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5748 - acc: 0.9479 - precision: 0.9972 - recall: 0.9011 - f1_score: 0.9455 - val_loss: 0.5984 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5729 - acc: 0.9494 - precision: 0.9972 - recall: 0.9002 - f1_score: 0.9444 - val_loss: 0.5966 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5710 - acc: 0.9494 - precision: 0.9967 - recall: 0.8996 - f1_score: 0.9447 - val_loss: 0.5947 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5692 - acc: 0.9494 - precision: 0.9962 - recall: 0.9034 - f1_score: 0.9467 - val_loss: 0.5929 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5673 - acc: 0.9494 - precision: 0.9954 - recall: 0.9022 - f1_score: 0.9458 - val_loss: 0.5910 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5655 - acc: 0.9494 - precision: 0.9972 - recall: 0.9050 - f1_score: 0.9479 - val_loss: 0.5892 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5636 - acc: 0.9494 - precision: 0.9966 - recall: 0.9016 - f1_score: 0.9453 - val_loss: 0.5874 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5618 - acc: 0.9494 - precision: 0.9968 - recall: 0.8995 - f1_score: 0.9446 - val_loss: 0.5856 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5600 - acc: 0.9494 - precision: 0.9962 - recall: 0.9012 - f1_score: 0.9450 - val_loss: 0.5838 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5582 - acc: 0.9494 - precision: 0.9968 - recall: 0.8974 - f1_score: 0.9420 - val_loss: 0.5820 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5563 - acc: 0.9494 - precision: 0.9962 - recall: 0.9008 - f1_score: 0.9454 - val_loss: 0.5802 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5545 - acc: 0.9494 - precision: 0.9962 - recall: 0.8978 - f1_score: 0.9427 - val_loss: 0.5784 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5528 - acc: 0.9494 - precision: 0.9971 - recall: 0.9015 - f1_score: 0.9462 - val_loss: 0.5766 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5510 - acc: 0.9494 - precision: 0.9958 - recall: 0.9011 - f1_score: 0.9453 - val_loss: 0.5749 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5492 - acc: 0.9494 - precision: 0.9958 - recall: 0.9015 - f1_score: 0.9448 - val_loss: 0.5731 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5474 - acc: 0.9494 - precision: 0.9951 - recall: 0.8946 - f1_score: 0.9394 - val_loss: 0.5714 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5457 - acc: 0.9494 - precision: 0.9966 - recall: 0.8976 - f1_score: 0.9438 - val_loss: 0.5697 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5440 - acc: 0.9494 - precision: 0.9971 - recall: 0.9001 - f1_score: 0.9453 - val_loss: 0.5679 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5422 - acc: 0.9494 - precision: 0.9968 - recall: 0.9029 - f1_score: 0.9459 - val_loss: 0.5662 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5405 - acc: 0.9494 - precision: 0.9970 - recall: 0.9019 - f1_score: 0.9463 - val_loss: 0.5645 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5388 - acc: 0.9494 - precision: 0.9961 - recall: 0.9016 - f1_score: 0.9455 - val_loss: 0.5628 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5371 - acc: 0.9494 - precision: 0.9961 - recall: 0.9039 - f1_score: 0.9468 - val_loss: 0.5611 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5354 - acc: 0.9494 - precision: 0.9966 - recall: 0.9019 - f1_score: 0.9460 - val_loss: 0.5594 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5337 - acc: 0.9494 - precision: 0.9968 - recall: 0.9024 - f1_score: 0.9455 - val_loss: 0.5578 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5320 - acc: 0.9494 - precision: 0.9970 - recall: 0.8987 - f1_score: 0.9446 - val_loss: 0.5561 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5303 - acc: 0.9494 - precision: 0.9963 - recall: 0.9024 - f1_score: 0.9462 - val_loss: 0.5544 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5287 - acc: 0.9494 - precision: 0.9947 - recall: 0.8989 - f1_score: 0.9435 - val_loss: 0.5528 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5270 - acc: 0.9494 - precision: 0.9967 - recall: 0.9032 - f1_score: 0.9464 - val_loss: 0.5511 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 558/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5253 - acc: 0.9494 - precision: 0.9964 - recall: 0.8985 - f1_score: 0.9437 - val_loss: 0.5495 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5237 - acc: 0.9494 - precision: 0.9964 - recall: 0.8991 - f1_score: 0.9440 - val_loss: 0.5479 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5221 - acc: 0.9494 - precision: 0.9962 - recall: 0.8999 - f1_score: 0.9449 - val_loss: 0.5463 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5204 - acc: 0.9494 - precision: 0.9967 - recall: 0.8992 - f1_score: 0.9446 - val_loss: 0.5447 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5188 - acc: 0.9494 - precision: 0.9973 - recall: 0.8986 - f1_score: 0.9444 - val_loss: 0.5431 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5172 - acc: 0.9494 - precision: 0.9970 - recall: 0.8885 - f1_score: 0.9365 - val_loss: 0.5415 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5156 - acc: 0.9494 - precision: 0.9962 - recall: 0.9008 - f1_score: 0.9454 - val_loss: 0.5399 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5140 - acc: 0.9494 - precision: 0.9961 - recall: 0.9005 - f1_score: 0.9451 - val_loss: 0.5383 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5124 - acc: 0.9494 - precision: 0.9968 - recall: 0.9003 - f1_score: 0.9452 - val_loss: 0.5367 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5108 - acc: 0.9494 - precision: 0.9962 - recall: 0.9030 - f1_score: 0.9462 - val_loss: 0.5352 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5093 - acc: 0.9494 - precision: 0.9967 - recall: 0.8995 - f1_score: 0.9449 - val_loss: 0.5336 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5077 - acc: 0.9494 - precision: 0.9962 - recall: 0.9047 - f1_score: 0.9472 - val_loss: 0.5321 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5062 - acc: 0.9494 - precision: 0.9964 - recall: 0.8971 - f1_score: 0.9414 - val_loss: 0.5305 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5046 - acc: 0.9494 - precision: 0.9966 - recall: 0.9026 - f1_score: 0.9465 - val_loss: 0.5290 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5031 - acc: 0.9494 - precision: 0.9966 - recall: 0.9029 - f1_score: 0.9465 - val_loss: 0.5275 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5015 - acc: 0.9494 - precision: 0.9971 - recall: 0.9001 - f1_score: 0.9456 - val_loss: 0.5260 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5000 - acc: 0.9494 - precision: 0.9964 - recall: 0.8996 - f1_score: 0.9430 - val_loss: 0.5245 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4985 - acc: 0.9494 - precision: 0.9964 - recall: 0.9021 - f1_score: 0.9461 - val_loss: 0.5230 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4970 - acc: 0.9494 - precision: 0.9956 - recall: 0.9017 - f1_score: 0.9458 - val_loss: 0.5215 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4955 - acc: 0.9494 - precision: 0.9958 - recall: 0.8994 - f1_score: 0.9446 - val_loss: 0.5200 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4940 - acc: 0.9494 - precision: 0.9947 - recall: 0.9045 - f1_score: 0.9467 - val_loss: 0.5185 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4925 - acc: 0.9494 - precision: 0.9968 - recall: 0.9010 - f1_score: 0.9452 - val_loss: 0.5171 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4910 - acc: 0.9494 - precision: 0.9968 - recall: 0.8958 - f1_score: 0.9420 - val_loss: 0.5156 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4895 - acc: 0.9494 - precision: 0.9962 - recall: 0.8976 - f1_score: 0.9435 - val_loss: 0.5141 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4881 - acc: 0.9494 - precision: 0.9956 - recall: 0.8964 - f1_score: 0.9419 - val_loss: 0.5127 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4866 - acc: 0.9494 - precision: 0.9966 - recall: 0.9020 - f1_score: 0.9450 - val_loss: 0.5112 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4851 - acc: 0.9494 - precision: 0.9969 - recall: 0.9025 - f1_score: 0.9462 - val_loss: 0.5098 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4837 - acc: 0.9494 - precision: 0.9954 - recall: 0.8986 - f1_score: 0.9431 - val_loss: 0.5084 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4823 - acc: 0.9494 - precision: 0.9965 - recall: 0.9020 - f1_score: 0.9460 - val_loss: 0.5070 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4808 - acc: 0.9494 - precision: 0.9954 - recall: 0.9039 - f1_score: 0.9461 - val_loss: 0.5055 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4794 - acc: 0.9494 - precision: 0.9964 - recall: 0.9024 - f1_score: 0.9464 - val_loss: 0.5041 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4780 - acc: 0.9494 - precision: 0.9961 - recall: 0.9027 - f1_score: 0.9459 - val_loss: 0.5027 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4766 - acc: 0.9494 - precision: 0.9958 - recall: 0.8968 - f1_score: 0.9430 - val_loss: 0.5013 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4752 - acc: 0.9494 - precision: 0.9961 - recall: 0.9004 - f1_score: 0.9456 - val_loss: 0.4999 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4738 - acc: 0.9494 - precision: 0.9970 - recall: 0.9009 - f1_score: 0.9454 - val_loss: 0.4986 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4724 - acc: 0.9494 - precision: 0.9966 - recall: 0.8994 - f1_score: 0.9441 - val_loss: 0.4972 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4710 - acc: 0.9494 - precision: 0.9962 - recall: 0.9016 - f1_score: 0.9453 - val_loss: 0.4958 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4696 - acc: 0.9494 - precision: 0.9967 - recall: 0.8984 - f1_score: 0.9445 - val_loss: 0.4945 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4683 - acc: 0.9494 - precision: 0.9970 - recall: 0.9058 - f1_score: 0.9484 - val_loss: 0.4931 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4669 - acc: 0.9494 - precision: 0.9962 - recall: 0.8988 - f1_score: 0.9440 - val_loss: 0.4918 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4655 - acc: 0.9494 - precision: 0.9968 - recall: 0.9022 - f1_score: 0.9460 - val_loss: 0.4904 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4642 - acc: 0.9494 - precision: 0.9967 - recall: 0.9062 - f1_score: 0.9480 - val_loss: 0.4891 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4628 - acc: 0.9494 - precision: 0.9961 - recall: 0.9015 - f1_score: 0.9455 - val_loss: 0.4878 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4615 - acc: 0.9494 - precision: 0.9958 - recall: 0.9007 - f1_score: 0.9449 - val_loss: 0.4864 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4602 - acc: 0.9494 - precision: 0.9962 - recall: 0.8978 - f1_score: 0.9431 - val_loss: 0.4851 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4588 - acc: 0.9494 - precision: 0.9971 - recall: 0.9064 - f1_score: 0.9485 - val_loss: 0.4838 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4575 - acc: 0.9494 - precision: 0.9956 - recall: 0.9042 - f1_score: 0.9456 - val_loss: 0.4825 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4562 - acc: 0.9494 - precision: 0.9966 - recall: 0.8976 - f1_score: 0.9438 - val_loss: 0.4812 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4549 - acc: 0.9494 - precision: 0.9961 - recall: 0.9001 - f1_score: 0.9452 - val_loss: 0.4799 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4536 - acc: 0.9494 - precision: 0.9975 - recall: 0.9014 - f1_score: 0.9457 - val_loss: 0.4787 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4523 - acc: 0.9494 - precision: 0.9962 - recall: 0.9002 - f1_score: 0.9452 - val_loss: 0.4774 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4510 - acc: 0.9494 - precision: 0.9962 - recall: 0.9058 - f1_score: 0.9477 - val_loss: 0.4761 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4498 - acc: 0.9494 - precision: 0.9954 - recall: 0.9030 - f1_score: 0.9453 - val_loss: 0.4748 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4485 - acc: 0.9494 - precision: 0.9964 - recall: 0.9005 - f1_score: 0.9452 - val_loss: 0.4736 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4472 - acc: 0.9494 - precision: 0.9967 - recall: 0.9023 - f1_score: 0.9460 - val_loss: 0.4723 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4459 - acc: 0.9494 - precision: 0.9954 - recall: 0.9010 - f1_score: 0.9452 - val_loss: 0.4711 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4447 - acc: 0.9494 - precision: 0.9972 - recall: 0.9052 - f1_score: 0.9483 - val_loss: 0.4698 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4434 - acc: 0.9494 - precision: 0.9966 - recall: 0.9004 - f1_score: 0.9452 - val_loss: 0.4686 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4422 - acc: 0.9494 - precision: 0.9968 - recall: 0.9015 - f1_score: 0.9458 - val_loss: 0.4674 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4410 - acc: 0.9494 - precision: 0.9970 - recall: 0.9035 - f1_score: 0.9472 - val_loss: 0.4661 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4397 - acc: 0.9494 - precision: 0.9962 - recall: 0.9031 - f1_score: 0.9462 - val_loss: 0.4649 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4385 - acc: 0.9494 - precision: 0.9968 - recall: 0.9020 - f1_score: 0.9467 - val_loss: 0.4637 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4373 - acc: 0.9494 - precision: 0.9966 - recall: 0.9022 - f1_score: 0.9453 - val_loss: 0.4625 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4361 - acc: 0.9494 - precision: 0.9971 - recall: 0.8983 - f1_score: 0.9436 - val_loss: 0.4613 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 622/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4349 - acc: 0.9494 - precision: 0.9968 - recall: 0.8979 - f1_score: 0.9436 - val_loss: 0.4601 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4337 - acc: 0.9494 - precision: 0.9967 - recall: 0.9007 - f1_score: 0.9449 - val_loss: 0.4589 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4325 - acc: 0.9494 - precision: 0.9965 - recall: 0.9005 - f1_score: 0.9448 - val_loss: 0.4578 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4313 - acc: 0.9494 - precision: 0.9971 - recall: 0.9030 - f1_score: 0.9474 - val_loss: 0.4566 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4301 - acc: 0.9494 - precision: 0.9970 - recall: 0.9010 - f1_score: 0.9456 - val_loss: 0.4554 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4289 - acc: 0.9494 - precision: 0.9958 - recall: 0.9017 - f1_score: 0.9451 - val_loss: 0.4543 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4277 - acc: 0.9494 - precision: 0.9967 - recall: 0.9016 - f1_score: 0.9454 - val_loss: 0.4531 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4266 - acc: 0.9494 - precision: 0.9962 - recall: 0.9009 - f1_score: 0.9449 - val_loss: 0.4519 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4254 - acc: 0.9494 - precision: 0.9962 - recall: 0.9005 - f1_score: 0.9445 - val_loss: 0.4508 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4242 - acc: 0.9494 - precision: 0.9970 - recall: 0.8976 - f1_score: 0.9437 - val_loss: 0.4496 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4231 - acc: 0.9494 - precision: 0.9961 - recall: 0.8990 - f1_score: 0.9441 - val_loss: 0.4485 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4220 - acc: 0.9494 - precision: 0.9963 - recall: 0.9020 - f1_score: 0.9454 - val_loss: 0.4474 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4208 - acc: 0.9494 - precision: 0.9971 - recall: 0.9004 - f1_score: 0.9456 - val_loss: 0.4463 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4197 - acc: 0.9494 - precision: 0.9967 - recall: 0.9015 - f1_score: 0.9461 - val_loss: 0.4451 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4185 - acc: 0.9494 - precision: 0.9968 - recall: 0.8998 - f1_score: 0.9450 - val_loss: 0.4440 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4174 - acc: 0.9494 - precision: 0.9968 - recall: 0.8998 - f1_score: 0.9454 - val_loss: 0.4429 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4163 - acc: 0.9494 - precision: 0.9956 - recall: 0.8999 - f1_score: 0.9442 - val_loss: 0.4418 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4152 - acc: 0.9494 - precision: 0.9958 - recall: 0.9012 - f1_score: 0.9459 - val_loss: 0.4407 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4141 - acc: 0.9494 - precision: 0.9953 - recall: 0.9001 - f1_score: 0.9446 - val_loss: 0.4396 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4130 - acc: 0.9494 - precision: 0.9968 - recall: 0.8986 - f1_score: 0.9444 - val_loss: 0.4385 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4119 - acc: 0.9494 - precision: 0.9972 - recall: 0.9010 - f1_score: 0.9458 - val_loss: 0.4375 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4108 - acc: 0.9494 - precision: 0.9966 - recall: 0.9034 - f1_score: 0.9466 - val_loss: 0.4364 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4097 - acc: 0.9494 - precision: 0.9964 - recall: 0.9017 - f1_score: 0.9457 - val_loss: 0.4353 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4086 - acc: 0.9494 - precision: 0.9968 - recall: 0.8985 - f1_score: 0.9442 - val_loss: 0.4342 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4076 - acc: 0.9494 - precision: 0.9966 - recall: 0.9004 - f1_score: 0.9452 - val_loss: 0.4332 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4065 - acc: 0.9494 - precision: 0.9961 - recall: 0.9006 - f1_score: 0.9451 - val_loss: 0.4321 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4054 - acc: 0.9494 - precision: 0.9961 - recall: 0.8970 - f1_score: 0.9427 - val_loss: 0.4311 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4044 - acc: 0.9494 - precision: 0.9962 - recall: 0.9012 - f1_score: 0.9453 - val_loss: 0.4300 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4033 - acc: 0.9494 - precision: 0.9964 - recall: 0.8999 - f1_score: 0.9436 - val_loss: 0.4290 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4022 - acc: 0.9494 - precision: 0.9971 - recall: 0.8993 - f1_score: 0.9447 - val_loss: 0.4279 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4012 - acc: 0.9494 - precision: 0.9968 - recall: 0.8988 - f1_score: 0.9439 - val_loss: 0.4269 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4002 - acc: 0.9494 - precision: 0.9958 - recall: 0.8982 - f1_score: 0.9434 - val_loss: 0.4259 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 654/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3991 - acc: 0.9494 - precision: 0.9968 - recall: 0.9000 - f1_score: 0.9451 - val_loss: 0.4249 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3981 - acc: 0.9494 - precision: 0.9971 - recall: 0.9024 - f1_score: 0.9469 - val_loss: 0.4239 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3971 - acc: 0.9494 - precision: 0.9974 - recall: 0.9017 - f1_score: 0.9461 - val_loss: 0.4228 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3960 - acc: 0.9494 - precision: 0.9964 - recall: 0.9032 - f1_score: 0.9464 - val_loss: 0.4218 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3950 - acc: 0.9494 - precision: 0.9961 - recall: 0.9004 - f1_score: 0.9450 - val_loss: 0.4208 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3940 - acc: 0.9494 - precision: 0.9970 - recall: 0.8997 - f1_score: 0.9452 - val_loss: 0.4198 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3930 - acc: 0.9494 - precision: 0.9967 - recall: 0.8981 - f1_score: 0.9441 - val_loss: 0.4189 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3920 - acc: 0.9494 - precision: 0.9965 - recall: 0.9014 - f1_score: 0.9454 - val_loss: 0.4179 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3910 - acc: 0.9494 - precision: 0.9966 - recall: 0.8973 - f1_score: 0.9422 - val_loss: 0.4169 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3900 - acc: 0.9494 - precision: 0.9962 - recall: 0.9022 - f1_score: 0.9452 - val_loss: 0.4159 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3890 - acc: 0.9494 - precision: 0.9962 - recall: 0.8992 - f1_score: 0.9441 - val_loss: 0.4149 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9494 - precision: 0.9961 - recall: 0.9056 - f1_score: 0.9473 - val_loss: 0.4140 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3871 - acc: 0.9494 - precision: 0.9968 - recall: 0.8973 - f1_score: 0.9430 - val_loss: 0.4130 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3861 - acc: 0.9494 - precision: 0.9944 - recall: 0.8990 - f1_score: 0.9434 - val_loss: 0.4121 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3851 - acc: 0.9494 - precision: 0.9971 - recall: 0.9008 - f1_score: 0.9457 - val_loss: 0.4111 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3842 - acc: 0.9494 - precision: 0.9964 - recall: 0.8976 - f1_score: 0.9431 - val_loss: 0.4101 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3832 - acc: 0.9494 - precision: 0.9967 - recall: 0.8997 - f1_score: 0.9446 - val_loss: 0.4092 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3823 - acc: 0.9494 - precision: 0.9972 - recall: 0.9027 - f1_score: 0.9470 - val_loss: 0.4083 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3813 - acc: 0.9494 - precision: 0.9964 - recall: 0.9014 - f1_score: 0.9455 - val_loss: 0.4073 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3804 - acc: 0.9494 - precision: 0.9971 - recall: 0.8986 - f1_score: 0.9448 - val_loss: 0.4064 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3794 - acc: 0.9494 - precision: 0.9975 - recall: 0.8931 - f1_score: 0.9403 - val_loss: 0.4055 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3785 - acc: 0.9494 - precision: 0.9964 - recall: 0.9013 - f1_score: 0.9456 - val_loss: 0.4046 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3775 - acc: 0.9494 - precision: 0.9968 - recall: 0.9029 - f1_score: 0.9467 - val_loss: 0.4036 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3766 - acc: 0.9494 - precision: 0.9967 - recall: 0.8995 - f1_score: 0.9446 - val_loss: 0.4027 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3757 - acc: 0.9494 - precision: 0.9966 - recall: 0.8985 - f1_score: 0.9446 - val_loss: 0.4018 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3748 - acc: 0.9494 - precision: 0.9954 - recall: 0.9013 - f1_score: 0.9450 - val_loss: 0.4009 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3739 - acc: 0.9494 - precision: 0.9956 - recall: 0.8975 - f1_score: 0.9435 - val_loss: 0.4000 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3730 - acc: 0.9494 - precision: 0.9966 - recall: 0.9038 - f1_score: 0.9466 - val_loss: 0.3991 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3720 - acc: 0.9494 - precision: 0.9970 - recall: 0.9059 - f1_score: 0.9482 - val_loss: 0.3982 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3711 - acc: 0.9494 - precision: 0.9964 - recall: 0.9028 - f1_score: 0.9465 - val_loss: 0.3973 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3702 - acc: 0.9494 - precision: 0.9971 - recall: 0.8951 - f1_score: 0.9422 - val_loss: 0.3964 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3694 - acc: 0.9494 - precision: 0.9968 - recall: 0.8956 - f1_score: 0.9419 - val_loss: 0.3956 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3685 - acc: 0.9494 - precision: 0.9947 - recall: 0.9006 - f1_score: 0.9441 - val_loss: 0.3947 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3676 - acc: 0.9494 - precision: 0.9951 - recall: 0.8994 - f1_score: 0.9432 - val_loss: 0.3938 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3667 - acc: 0.9494 - precision: 0.9944 - recall: 0.8961 - f1_score: 0.9418 - val_loss: 0.3930 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3658 - acc: 0.9494 - precision: 0.9975 - recall: 0.8997 - f1_score: 0.9454 - val_loss: 0.3921 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3650 - acc: 0.9494 - precision: 0.9964 - recall: 0.9004 - f1_score: 0.9452 - val_loss: 0.3912 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3641 - acc: 0.9494 - precision: 0.9958 - recall: 0.9000 - f1_score: 0.9445 - val_loss: 0.3904 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3632 - acc: 0.9494 - precision: 0.9967 - recall: 0.9003 - f1_score: 0.9453 - val_loss: 0.3895 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3624 - acc: 0.9494 - precision: 0.9964 - recall: 0.8974 - f1_score: 0.9429 - val_loss: 0.3887 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3615 - acc: 0.9494 - precision: 0.9951 - recall: 0.9037 - f1_score: 0.9460 - val_loss: 0.3878 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3607 - acc: 0.9494 - precision: 0.9958 - recall: 0.9031 - f1_score: 0.9460 - val_loss: 0.3870 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3598 - acc: 0.9494 - precision: 0.9962 - recall: 0.9031 - f1_score: 0.9466 - val_loss: 0.3862 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3590 - acc: 0.9494 - precision: 0.9964 - recall: 0.9014 - f1_score: 0.9452 - val_loss: 0.3853 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3581 - acc: 0.9494 - precision: 0.9962 - recall: 0.9043 - f1_score: 0.9474 - val_loss: 0.3845 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3573 - acc: 0.9494 - precision: 0.9964 - recall: 0.8997 - f1_score: 0.9449 - val_loss: 0.3837 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3565 - acc: 0.9494 - precision: 0.9969 - recall: 0.9037 - f1_score: 0.9468 - val_loss: 0.3829 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3556 - acc: 0.9494 - precision: 0.9967 - recall: 0.9013 - f1_score: 0.9458 - val_loss: 0.3820 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3548 - acc: 0.9494 - precision: 0.9970 - recall: 0.8944 - f1_score: 0.9411 - val_loss: 0.3812 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3540 - acc: 0.9494 - precision: 0.9970 - recall: 0.9022 - f1_score: 0.9468 - val_loss: 0.3804 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3532 - acc: 0.9494 - precision: 0.9968 - recall: 0.9001 - f1_score: 0.9448 - val_loss: 0.3796 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3524 - acc: 0.9494 - precision: 0.9970 - recall: 0.9027 - f1_score: 0.9470 - val_loss: 0.3788 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3515 - acc: 0.9494 - precision: 0.9967 - recall: 0.9103 - f1_score: 0.9500 - val_loss: 0.3780 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3507 - acc: 0.9494 - precision: 0.9958 - recall: 0.9033 - f1_score: 0.9459 - val_loss: 0.3772 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3499 - acc: 0.9494 - precision: 0.9971 - recall: 0.9013 - f1_score: 0.9461 - val_loss: 0.3764 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3491 - acc: 0.9494 - precision: 0.9961 - recall: 0.9002 - f1_score: 0.9445 - val_loss: 0.3757 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3483 - acc: 0.9494 - precision: 0.9965 - recall: 0.8981 - f1_score: 0.9438 - val_loss: 0.3749 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3476 - acc: 0.9494 - precision: 0.9967 - recall: 0.9020 - f1_score: 0.9460 - val_loss: 0.3741 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3468 - acc: 0.9494 - precision: 0.9939 - recall: 0.8977 - f1_score: 0.9421 - val_loss: 0.3733 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3460 - acc: 0.9494 - precision: 0.9962 - recall: 0.9018 - f1_score: 0.9456 - val_loss: 0.3726 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3452 - acc: 0.9494 - precision: 0.9965 - recall: 0.8974 - f1_score: 0.9432 - val_loss: 0.3718 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3444 - acc: 0.9494 - precision: 0.9975 - recall: 0.8956 - f1_score: 0.9418 - val_loss: 0.3710 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3437 - acc: 0.9494 - precision: 0.9968 - recall: 0.9008 - f1_score: 0.9459 - val_loss: 0.3703 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3429 - acc: 0.9494 - precision: 0.9956 - recall: 0.8943 - f1_score: 0.9409 - val_loss: 0.3695 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3421 - acc: 0.9494 - precision: 0.9962 - recall: 0.8994 - f1_score: 0.9448 - val_loss: 0.3688 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3414 - acc: 0.9494 - precision: 0.9961 - recall: 0.8966 - f1_score: 0.9430 - val_loss: 0.3680 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3406 - acc: 0.9494 - precision: 0.9975 - recall: 0.8996 - f1_score: 0.9454 - val_loss: 0.3673 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3399 - acc: 0.9494 - precision: 0.9966 - recall: 0.8988 - f1_score: 0.9442 - val_loss: 0.3665 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3391 - acc: 0.9494 - precision: 0.9961 - recall: 0.9008 - f1_score: 0.9453 - val_loss: 0.3658 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3384 - acc: 0.9494 - precision: 0.9974 - recall: 0.8976 - f1_score: 0.9438 - val_loss: 0.3651 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3376 - acc: 0.9494 - precision: 0.9967 - recall: 0.8972 - f1_score: 0.9433 - val_loss: 0.3643 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3369 - acc: 0.9494 - precision: 0.9966 - recall: 0.8985 - f1_score: 0.9439 - val_loss: 0.3636 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3362 - acc: 0.9494 - precision: 0.9956 - recall: 0.8997 - f1_score: 0.9438 - val_loss: 0.3629 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3354 - acc: 0.9494 - precision: 0.9967 - recall: 0.9043 - f1_score: 0.9468 - val_loss: 0.3622 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3347 - acc: 0.9494 - precision: 0.9968 - recall: 0.9046 - f1_score: 0.9461 - val_loss: 0.3615 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3340 - acc: 0.9494 - precision: 0.9966 - recall: 0.9001 - f1_score: 0.9450 - val_loss: 0.3608 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3332 - acc: 0.9494 - precision: 0.9958 - recall: 0.9017 - f1_score: 0.9456 - val_loss: 0.3601 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3325 - acc: 0.9494 - precision: 0.9954 - recall: 0.8986 - f1_score: 0.9439 - val_loss: 0.3593 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3318 - acc: 0.9494 - precision: 0.9967 - recall: 0.9013 - f1_score: 0.9457 - val_loss: 0.3586 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3311 - acc: 0.9494 - precision: 0.9967 - recall: 0.9003 - f1_score: 0.9452 - val_loss: 0.3579 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3304 - acc: 0.9494 - precision: 0.9974 - recall: 0.9015 - f1_score: 0.9458 - val_loss: 0.3572 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3297 - acc: 0.9494 - precision: 0.9966 - recall: 0.9043 - f1_score: 0.9469 - val_loss: 0.3566 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3290 - acc: 0.9494 - precision: 0.9964 - recall: 0.8991 - f1_score: 0.9442 - val_loss: 0.3559 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3283 - acc: 0.9494 - precision: 0.9970 - recall: 0.8968 - f1_score: 0.9432 - val_loss: 0.3552 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3276 - acc: 0.9494 - precision: 0.9961 - recall: 0.9006 - f1_score: 0.9456 - val_loss: 0.3545 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3269 - acc: 0.9494 - precision: 0.9966 - recall: 0.8978 - f1_score: 0.9434 - val_loss: 0.3538 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3262 - acc: 0.9494 - precision: 0.9967 - recall: 0.8984 - f1_score: 0.9434 - val_loss: 0.3531 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3255 - acc: 0.9494 - precision: 0.9966 - recall: 0.8981 - f1_score: 0.9433 - val_loss: 0.3525 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3249 - acc: 0.9494 - precision: 0.9961 - recall: 0.9044 - f1_score: 0.9472 - val_loss: 0.3518 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3242 - acc: 0.9494 - precision: 0.9964 - recall: 0.8999 - f1_score: 0.9449 - val_loss: 0.3511 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3235 - acc: 0.9494 - precision: 0.9956 - recall: 0.9012 - f1_score: 0.9453 - val_loss: 0.3505 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3228 - acc: 0.9494 - precision: 0.9966 - recall: 0.9002 - f1_score: 0.9456 - val_loss: 0.3498 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3222 - acc: 0.9494 - precision: 0.9964 - recall: 0.8994 - f1_score: 0.9444 - val_loss: 0.3492 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3215 - acc: 0.9494 - precision: 0.9956 - recall: 0.9013 - f1_score: 0.9455 - val_loss: 0.3485 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3208 - acc: 0.9494 - precision: 0.9956 - recall: 0.8989 - f1_score: 0.9441 - val_loss: 0.3479 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3202 - acc: 0.9494 - precision: 0.9957 - recall: 0.8969 - f1_score: 0.9430 - val_loss: 0.3472 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3195 - acc: 0.9494 - precision: 0.9964 - recall: 0.8979 - f1_score: 0.9441 - val_loss: 0.3466 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3188 - acc: 0.9494 - precision: 0.9958 - recall: 0.9007 - f1_score: 0.9455 - val_loss: 0.3459 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3182 - acc: 0.9494 - precision: 0.9961 - recall: 0.9007 - f1_score: 0.9443 - val_loss: 0.3453 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3175 - acc: 0.9494 - precision: 0.9970 - recall: 0.9051 - f1_score: 0.9480 - val_loss: 0.3447 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3169 - acc: 0.9494 - precision: 0.9961 - recall: 0.9012 - f1_score: 0.9452 - val_loss: 0.3440 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3163 - acc: 0.9494 - precision: 0.9956 - recall: 0.9042 - f1_score: 0.9470 - val_loss: 0.3434 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3156 - acc: 0.9494 - precision: 0.9958 - recall: 0.9001 - f1_score: 0.9446 - val_loss: 0.3428 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3150 - acc: 0.9494 - precision: 0.9970 - recall: 0.8985 - f1_score: 0.9443 - val_loss: 0.3421 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3144 - acc: 0.9494 - precision: 0.9962 - recall: 0.9000 - f1_score: 0.9448 - val_loss: 0.3415 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3137 - acc: 0.9494 - precision: 0.9962 - recall: 0.9013 - f1_score: 0.9455 - val_loss: 0.3409 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3131 - acc: 0.9494 - precision: 0.9962 - recall: 0.9006 - f1_score: 0.9456 - val_loss: 0.3403 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3125 - acc: 0.9494 - precision: 0.9971 - recall: 0.8998 - f1_score: 0.9453 - val_loss: 0.3397 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3118 - acc: 0.9494 - precision: 0.9958 - recall: 0.8962 - f1_score: 0.9426 - val_loss: 0.3390 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3112 - acc: 0.9494 - precision: 0.9967 - recall: 0.8953 - f1_score: 0.9415 - val_loss: 0.3384 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3106 - acc: 0.9494 - precision: 0.9974 - recall: 0.8962 - f1_score: 0.9426 - val_loss: 0.3378 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3100 - acc: 0.9494 - precision: 0.9967 - recall: 0.9020 - f1_score: 0.9457 - val_loss: 0.3372 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3094 - acc: 0.9494 - precision: 0.9958 - recall: 0.9002 - f1_score: 0.9450 - val_loss: 0.3366 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3088 - acc: 0.9494 - precision: 0.9958 - recall: 0.8986 - f1_score: 0.9433 - val_loss: 0.3360 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3082 - acc: 0.9494 - precision: 0.9961 - recall: 0.8989 - f1_score: 0.9440 - val_loss: 0.3354 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3076 - acc: 0.9494 - precision: 0.9958 - recall: 0.9018 - f1_score: 0.9461 - val_loss: 0.3349 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3070 - acc: 0.9494 - precision: 0.9962 - recall: 0.8965 - f1_score: 0.9428 - val_loss: 0.3343 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3064 - acc: 0.9494 - precision: 0.9967 - recall: 0.8994 - f1_score: 0.9434 - val_loss: 0.3337 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9494 - precision: 0.9973 - recall: 0.9032 - f1_score: 0.9471 - val_loss: 0.3331 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3052 - acc: 0.9494 - precision: 0.9962 - recall: 0.9028 - f1_score: 0.9456 - val_loss: 0.3325 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3046 - acc: 0.9494 - precision: 0.9962 - recall: 0.8975 - f1_score: 0.9426 - val_loss: 0.3319 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3040 - acc: 0.9494 - precision: 0.9967 - recall: 0.9003 - f1_score: 0.9455 - val_loss: 0.3314 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3034 - acc: 0.9494 - precision: 0.9969 - recall: 0.8974 - f1_score: 0.9434 - val_loss: 0.3308 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3029 - acc: 0.9494 - precision: 0.9963 - recall: 0.8997 - f1_score: 0.9442 - val_loss: 0.3302 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3023 - acc: 0.9494 - precision: 0.9956 - recall: 0.8980 - f1_score: 0.9431 - val_loss: 0.3297 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3017 - acc: 0.9494 - precision: 0.9947 - recall: 0.9014 - f1_score: 0.9445 - val_loss: 0.3291 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3011 - acc: 0.9494 - precision: 0.9962 - recall: 0.9008 - f1_score: 0.9452 - val_loss: 0.3285 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3006 - acc: 0.9494 - precision: 0.9968 - recall: 0.9015 - f1_score: 0.9452 - val_loss: 0.3280 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3000 - acc: 0.9494 - precision: 0.9975 - recall: 0.8989 - f1_score: 0.9446 - val_loss: 0.3274 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2994 - acc: 0.9494 - precision: 0.9968 - recall: 0.9011 - f1_score: 0.9459 - val_loss: 0.3269 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2989 - acc: 0.9494 - precision: 0.9958 - recall: 0.8993 - f1_score: 0.9442 - val_loss: 0.3263 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2983 - acc: 0.9494 - precision: 0.9966 - recall: 0.9018 - f1_score: 0.9454 - val_loss: 0.3258 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2977 - acc: 0.9494 - precision: 0.9965 - recall: 0.9012 - f1_score: 0.9456 - val_loss: 0.3252 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2972 - acc: 0.9494 - precision: 0.9971 - recall: 0.8987 - f1_score: 0.9436 - val_loss: 0.3247 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2966 - acc: 0.9494 - precision: 0.9968 - recall: 0.9052 - f1_score: 0.9478 - val_loss: 0.3241 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2961 - acc: 0.9494 - precision: 0.9966 - recall: 0.9025 - f1_score: 0.9463 - val_loss: 0.3236 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2955 - acc: 0.9494 - precision: 0.9958 - recall: 0.9015 - f1_score: 0.9458 - val_loss: 0.3231 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2950 - acc: 0.9494 - precision: 0.9961 - recall: 0.9002 - f1_score: 0.9454 - val_loss: 0.3226 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2945 - acc: 0.9494 - precision: 0.9968 - recall: 0.8987 - f1_score: 0.9436 - val_loss: 0.3220 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2939 - acc: 0.9494 - precision: 0.9957 - recall: 0.9024 - f1_score: 0.9463 - val_loss: 0.3215 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2934 - acc: 0.9494 - precision: 0.9971 - recall: 0.8982 - f1_score: 0.9443 - val_loss: 0.3210 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2928 - acc: 0.9494 - precision: 0.9964 - recall: 0.8990 - f1_score: 0.9436 - val_loss: 0.3205 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2923 - acc: 0.9494 - precision: 0.9964 - recall: 0.8978 - f1_score: 0.9432 - val_loss: 0.3199 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2918 - acc: 0.9494 - precision: 0.9971 - recall: 0.8997 - f1_score: 0.9453 - val_loss: 0.3194 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2913 - acc: 0.9494 - precision: 0.9966 - recall: 0.9024 - f1_score: 0.9462 - val_loss: 0.3189 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2907 - acc: 0.9494 - precision: 0.9966 - recall: 0.9028 - f1_score: 0.9460 - val_loss: 0.3184 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2902 - acc: 0.9494 - precision: 0.9964 - recall: 0.9006 - f1_score: 0.9448 - val_loss: 0.3179 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2897 - acc: 0.9494 - precision: 0.9971 - recall: 0.9017 - f1_score: 0.9466 - val_loss: 0.3174 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2892 - acc: 0.9494 - precision: 0.9964 - recall: 0.9012 - f1_score: 0.9460 - val_loss: 0.3169 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2887 - acc: 0.9494 - precision: 0.9954 - recall: 0.9007 - f1_score: 0.9446 - val_loss: 0.3164 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2881 - acc: 0.9494 - precision: 0.9964 - recall: 0.9004 - f1_score: 0.9450 - val_loss: 0.3159 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2876 - acc: 0.9494 - precision: 0.9958 - recall: 0.9023 - f1_score: 0.9459 - val_loss: 0.3154 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2871 - acc: 0.9494 - precision: 0.9961 - recall: 0.9045 - f1_score: 0.9471 - val_loss: 0.3149 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2866 - acc: 0.9494 - precision: 0.9958 - recall: 0.8995 - f1_score: 0.9449 - val_loss: 0.3144 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2861 - acc: 0.9494 - precision: 0.9958 - recall: 0.9011 - f1_score: 0.9447 - val_loss: 0.3139 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2856 - acc: 0.9494 - precision: 0.9967 - recall: 0.8978 - f1_score: 0.9432 - val_loss: 0.3134 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2851 - acc: 0.9494 - precision: 0.9966 - recall: 0.9008 - f1_score: 0.9451 - val_loss: 0.3129 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2846 - acc: 0.9494 - precision: 0.9966 - recall: 0.9032 - f1_score: 0.9456 - val_loss: 0.3124 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2841 - acc: 0.9494 - precision: 0.9960 - recall: 0.9001 - f1_score: 0.9443 - val_loss: 0.3120 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2836 - acc: 0.9494 - precision: 0.9961 - recall: 0.8975 - f1_score: 0.9427 - val_loss: 0.3115 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2831 - acc: 0.9494 - precision: 0.9961 - recall: 0.9036 - f1_score: 0.9466 - val_loss: 0.3110 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2827 - acc: 0.9494 - precision: 0.9961 - recall: 0.9016 - f1_score: 0.9454 - val_loss: 0.3105 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2822 - acc: 0.9494 - precision: 0.9962 - recall: 0.8996 - f1_score: 0.9447 - val_loss: 0.3100 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2817 - acc: 0.9494 - precision: 0.9964 - recall: 0.8997 - f1_score: 0.9442 - val_loss: 0.3096 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2812 - acc: 0.9494 - precision: 0.9962 - recall: 0.9039 - f1_score: 0.9471 - val_loss: 0.3091 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2807 - acc: 0.9494 - precision: 0.9961 - recall: 0.9045 - f1_score: 0.9469 - val_loss: 0.3086 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2803 - acc: 0.9494 - precision: 0.9970 - recall: 0.8989 - f1_score: 0.9424 - val_loss: 0.3082 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2798 - acc: 0.9494 - precision: 0.9964 - recall: 0.8985 - f1_score: 0.9441 - val_loss: 0.3077 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2793 - acc: 0.9494 - precision: 0.9964 - recall: 0.9016 - f1_score: 0.9461 - val_loss: 0.3073 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2788 - acc: 0.9494 - precision: 0.9956 - recall: 0.8961 - f1_score: 0.9423 - val_loss: 0.3068 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2784 - acc: 0.9494 - precision: 0.9970 - recall: 0.9000 - f1_score: 0.9452 - val_loss: 0.3064 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2779 - acc: 0.9494 - precision: 0.9967 - recall: 0.8986 - f1_score: 0.9441 - val_loss: 0.3059 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2774 - acc: 0.9494 - precision: 0.9958 - recall: 0.9037 - f1_score: 0.9467 - val_loss: 0.3054 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2770 - acc: 0.9494 - precision: 0.9970 - recall: 0.9024 - f1_score: 0.9456 - val_loss: 0.3050 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2765 - acc: 0.9494 - precision: 0.9956 - recall: 0.8990 - f1_score: 0.9441 - val_loss: 0.3045 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9494 - precision: 0.9956 - recall: 0.9010 - f1_score: 0.9456 - val_loss: 0.3041 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2756 - acc: 0.9494 - precision: 0.9958 - recall: 0.9013 - f1_score: 0.9453 - val_loss: 0.3037 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2751 - acc: 0.9494 - precision: 0.9970 - recall: 0.8989 - f1_score: 0.9443 - val_loss: 0.3032 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2747 - acc: 0.9494 - precision: 0.9970 - recall: 0.9016 - f1_score: 0.9462 - val_loss: 0.3028 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2742 - acc: 0.9494 - precision: 0.9973 - recall: 0.8986 - f1_score: 0.9438 - val_loss: 0.3023 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2738 - acc: 0.9494 - precision: 0.9951 - recall: 0.9006 - f1_score: 0.9443 - val_loss: 0.3019 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2733 - acc: 0.9494 - precision: 0.9966 - recall: 0.8996 - f1_score: 0.9449 - val_loss: 0.3014 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2729 - acc: 0.9494 - precision: 0.9961 - recall: 0.9011 - f1_score: 0.9453 - val_loss: 0.3010 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2725 - acc: 0.9494 - precision: 0.9958 - recall: 0.9041 - f1_score: 0.9465 - val_loss: 0.3006 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2720 - acc: 0.9494 - precision: 0.9953 - recall: 0.9010 - f1_score: 0.9450 - val_loss: 0.3002 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2716 - acc: 0.9494 - precision: 0.9968 - recall: 0.9016 - f1_score: 0.9457 - val_loss: 0.2997 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2711 - acc: 0.9494 - precision: 0.9966 - recall: 0.9028 - f1_score: 0.9464 - val_loss: 0.2993 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2707 - acc: 0.9494 - precision: 0.9966 - recall: 0.8991 - f1_score: 0.9439 - val_loss: 0.2989 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2703 - acc: 0.9494 - precision: 0.9968 - recall: 0.8995 - f1_score: 0.9451 - val_loss: 0.2985 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2698 - acc: 0.9494 - precision: 0.9964 - recall: 0.8943 - f1_score: 0.9405 - val_loss: 0.2981 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2694 - acc: 0.9494 - precision: 0.9974 - recall: 0.8986 - f1_score: 0.9441 - val_loss: 0.2976 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2690 - acc: 0.9494 - precision: 0.9964 - recall: 0.9006 - f1_score: 0.9453 - val_loss: 0.2972 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 846/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2686 - acc: 0.9494 - precision: 0.9972 - recall: 0.9014 - f1_score: 0.9452 - val_loss: 0.2968 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2681 - acc: 0.9494 - precision: 0.9964 - recall: 0.9027 - f1_score: 0.9453 - val_loss: 0.2964 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2677 - acc: 0.9494 - precision: 0.9961 - recall: 0.8991 - f1_score: 0.9439 - val_loss: 0.2960 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2673 - acc: 0.9494 - precision: 0.9954 - recall: 0.8940 - f1_score: 0.9407 - val_loss: 0.2956 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2669 - acc: 0.9494 - precision: 0.9966 - recall: 0.8997 - f1_score: 0.9439 - val_loss: 0.2952 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2665 - acc: 0.9494 - precision: 0.9968 - recall: 0.8945 - f1_score: 0.9417 - val_loss: 0.2948 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2661 - acc: 0.9494 - precision: 0.9960 - recall: 0.9062 - f1_score: 0.9477 - val_loss: 0.2944 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2656 - acc: 0.9494 - precision: 0.9961 - recall: 0.8987 - f1_score: 0.9444 - val_loss: 0.2940 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9494 - precision: 0.9967 - recall: 0.8993 - f1_score: 0.9452 - val_loss: 0.2936 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9494 - precision: 0.9971 - recall: 0.8996 - f1_score: 0.9450 - val_loss: 0.2932 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2644 - acc: 0.9494 - precision: 0.9970 - recall: 0.8996 - f1_score: 0.9453 - val_loss: 0.2928 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2640 - acc: 0.9494 - precision: 0.9967 - recall: 0.9032 - f1_score: 0.9469 - val_loss: 0.2924 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2636 - acc: 0.9494 - precision: 0.9967 - recall: 0.8987 - f1_score: 0.9444 - val_loss: 0.2920 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2632 - acc: 0.9494 - precision: 0.9963 - recall: 0.9005 - f1_score: 0.9450 - val_loss: 0.2916 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2628 - acc: 0.9494 - precision: 0.9968 - recall: 0.9027 - f1_score: 0.9468 - val_loss: 0.2912 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2624 - acc: 0.9494 - precision: 0.9964 - recall: 0.9012 - f1_score: 0.9456 - val_loss: 0.2908 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2620 - acc: 0.9494 - precision: 0.9975 - recall: 0.8990 - f1_score: 0.9453 - val_loss: 0.2905 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2616 - acc: 0.9494 - precision: 0.9964 - recall: 0.8960 - f1_score: 0.9423 - val_loss: 0.2901 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2612 - acc: 0.9494 - precision: 0.9968 - recall: 0.9022 - f1_score: 0.9460 - val_loss: 0.2897 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2608 - acc: 0.9494 - precision: 0.9968 - recall: 0.9005 - f1_score: 0.9457 - val_loss: 0.2893 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2605 - acc: 0.9494 - precision: 0.9961 - recall: 0.9029 - f1_score: 0.9461 - val_loss: 0.2889 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2601 - acc: 0.9494 - precision: 0.9957 - recall: 0.8999 - f1_score: 0.9446 - val_loss: 0.2886 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2597 - acc: 0.9494 - precision: 0.9967 - recall: 0.8989 - f1_score: 0.9445 - val_loss: 0.2882 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2593 - acc: 0.9494 - precision: 0.9967 - recall: 0.9017 - f1_score: 0.9462 - val_loss: 0.2878 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2589 - acc: 0.9494 - precision: 0.9961 - recall: 0.8984 - f1_score: 0.9442 - val_loss: 0.2875 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9494 - precision: 0.9964 - recall: 0.9009 - f1_score: 0.9461 - val_loss: 0.2871 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2582 - acc: 0.9510 - precision: 0.9956 - recall: 0.9061 - f1_score: 0.9479 - val_loss: 0.2867 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9494 - precision: 0.9964 - recall: 0.9025 - f1_score: 0.9459 - val_loss: 0.2864 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2574 - acc: 0.9510 - precision: 0.9975 - recall: 0.9019 - f1_score: 0.9461 - val_loss: 0.2860 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2570 - acc: 0.9510 - precision: 0.9958 - recall: 0.9027 - f1_score: 0.9461 - val_loss: 0.2856 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2567 - acc: 0.9510 - precision: 0.9973 - recall: 0.9019 - f1_score: 0.9460 - val_loss: 0.2853 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2563 - acc: 0.9494 - precision: 0.9966 - recall: 0.9008 - f1_score: 0.9455 - val_loss: 0.2849 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 878/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2559 - acc: 0.9510 - precision: 0.9961 - recall: 0.9051 - f1_score: 0.9468 - val_loss: 0.2846 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2556 - acc: 0.9510 - precision: 0.9968 - recall: 0.9053 - f1_score: 0.9471 - val_loss: 0.2842 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2552 - acc: 0.9510 - precision: 0.9967 - recall: 0.9040 - f1_score: 0.9470 - val_loss: 0.2839 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2548 - acc: 0.9510 - precision: 0.9970 - recall: 0.8988 - f1_score: 0.9431 - val_loss: 0.2835 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2545 - acc: 0.9510 - precision: 0.9966 - recall: 0.9075 - f1_score: 0.9491 - val_loss: 0.2832 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2541 - acc: 0.9510 - precision: 0.9973 - recall: 0.9032 - f1_score: 0.9466 - val_loss: 0.2829 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2538 - acc: 0.9510 - precision: 0.9958 - recall: 0.9013 - f1_score: 0.9456 - val_loss: 0.2825 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2534 - acc: 0.9510 - precision: 0.9964 - recall: 0.9023 - f1_score: 0.9452 - val_loss: 0.2822 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2530 - acc: 0.9510 - precision: 0.9967 - recall: 0.9039 - f1_score: 0.9466 - val_loss: 0.2818 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2527 - acc: 0.9510 - precision: 0.9958 - recall: 0.9063 - f1_score: 0.9479 - val_loss: 0.2815 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2523 - acc: 0.9510 - precision: 0.9948 - recall: 0.9014 - f1_score: 0.9443 - val_loss: 0.2811 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2520 - acc: 0.9510 - precision: 0.9954 - recall: 0.9023 - f1_score: 0.9456 - val_loss: 0.2808 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2516 - acc: 0.9510 - precision: 0.9969 - recall: 0.9025 - f1_score: 0.9466 - val_loss: 0.2805 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2513 - acc: 0.9510 - precision: 0.9968 - recall: 0.9066 - f1_score: 0.9488 - val_loss: 0.2801 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2509 - acc: 0.9510 - precision: 0.9967 - recall: 0.9045 - f1_score: 0.9476 - val_loss: 0.2798 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2506 - acc: 0.9510 - precision: 0.9968 - recall: 0.9044 - f1_score: 0.9475 - val_loss: 0.2795 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9510 - precision: 0.9956 - recall: 0.9027 - f1_score: 0.9455 - val_loss: 0.2791 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2499 - acc: 0.9510 - precision: 0.9961 - recall: 0.9053 - f1_score: 0.9476 - val_loss: 0.2788 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9510 - precision: 0.9967 - recall: 0.9011 - f1_score: 0.9454 - val_loss: 0.2785 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2492 - acc: 0.9510 - precision: 0.9970 - recall: 0.9033 - f1_score: 0.9469 - val_loss: 0.2781 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9510 - precision: 0.9974 - recall: 0.9049 - f1_score: 0.9482 - val_loss: 0.2778 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2486 - acc: 0.9510 - precision: 0.9947 - recall: 0.9019 - f1_score: 0.9451 - val_loss: 0.2775 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2482 - acc: 0.9510 - precision: 0.9974 - recall: 0.9051 - f1_score: 0.9481 - val_loss: 0.2772 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2479 - acc: 0.9510 - precision: 0.9958 - recall: 0.9034 - f1_score: 0.9464 - val_loss: 0.2769 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2476 - acc: 0.9510 - precision: 0.9968 - recall: 0.9011 - f1_score: 0.9449 - val_loss: 0.2765 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2472 - acc: 0.9510 - precision: 0.9962 - recall: 0.9046 - f1_score: 0.9476 - val_loss: 0.2762 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2469 - acc: 0.9510 - precision: 0.9964 - recall: 0.9056 - f1_score: 0.9483 - val_loss: 0.2759 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2466 - acc: 0.9510 - precision: 0.9961 - recall: 0.9012 - f1_score: 0.9448 - val_loss: 0.2756 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2463 - acc: 0.9510 - precision: 0.9962 - recall: 0.9062 - f1_score: 0.9483 - val_loss: 0.2753 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9510 - precision: 0.9965 - recall: 0.9017 - f1_score: 0.9449 - val_loss: 0.2749 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9510 - precision: 0.9958 - recall: 0.9032 - f1_score: 0.9461 - val_loss: 0.2746 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9510 - precision: 0.9967 - recall: 0.9028 - f1_score: 0.9465 - val_loss: 0.2743 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 910/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9510 - precision: 0.9964 - recall: 0.9050 - f1_score: 0.9477 - val_loss: 0.2740 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2447 - acc: 0.9510 - precision: 0.9964 - recall: 0.9048 - f1_score: 0.9474 - val_loss: 0.2737 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2443 - acc: 0.9510 - precision: 0.9968 - recall: 0.9049 - f1_score: 0.9473 - val_loss: 0.2734 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2440 - acc: 0.9510 - precision: 0.9956 - recall: 0.9017 - f1_score: 0.9455 - val_loss: 0.2731 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2437 - acc: 0.9510 - precision: 0.9956 - recall: 0.9045 - f1_score: 0.9467 - val_loss: 0.2728 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2434 - acc: 0.9510 - precision: 0.9971 - recall: 0.9017 - f1_score: 0.9452 - val_loss: 0.2725 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2431 - acc: 0.9510 - precision: 0.9962 - recall: 0.9021 - f1_score: 0.9460 - val_loss: 0.2722 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2428 - acc: 0.9510 - precision: 0.9968 - recall: 0.9030 - f1_score: 0.9469 - val_loss: 0.2719 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2425 - acc: 0.9510 - precision: 0.9970 - recall: 0.9093 - f1_score: 0.9488 - val_loss: 0.2716 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2422 - acc: 0.9510 - precision: 0.9968 - recall: 0.9065 - f1_score: 0.9481 - val_loss: 0.2713 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2419 - acc: 0.9510 - precision: 0.9966 - recall: 0.9015 - f1_score: 0.9447 - val_loss: 0.2710 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2416 - acc: 0.9510 - precision: 0.9964 - recall: 0.9006 - f1_score: 0.9453 - val_loss: 0.2707 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2413 - acc: 0.9510 - precision: 0.9970 - recall: 0.9005 - f1_score: 0.9447 - val_loss: 0.2704 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2409 - acc: 0.9510 - precision: 0.9954 - recall: 0.9058 - f1_score: 0.9477 - val_loss: 0.2701 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9510 - precision: 0.9958 - recall: 0.9010 - f1_score: 0.9447 - val_loss: 0.2699 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2403 - acc: 0.9510 - precision: 0.9969 - recall: 0.9034 - f1_score: 0.9474 - val_loss: 0.2696 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2400 - acc: 0.9510 - precision: 0.9962 - recall: 0.9010 - f1_score: 0.9457 - val_loss: 0.2693 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2398 - acc: 0.9510 - precision: 0.9966 - recall: 0.9074 - f1_score: 0.9485 - val_loss: 0.2690 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2395 - acc: 0.9510 - precision: 0.9971 - recall: 0.9047 - f1_score: 0.9469 - val_loss: 0.2687 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9510 - precision: 0.9967 - recall: 0.9045 - f1_score: 0.9479 - val_loss: 0.2684 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9510 - precision: 0.9964 - recall: 0.9050 - f1_score: 0.9466 - val_loss: 0.2681 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9510 - precision: 0.9964 - recall: 0.9019 - f1_score: 0.9456 - val_loss: 0.2679 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2383 - acc: 0.9510 - precision: 0.9962 - recall: 0.9007 - f1_score: 0.9457 - val_loss: 0.2676 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2380 - acc: 0.9510 - precision: 0.9939 - recall: 0.8980 - f1_score: 0.9414 - val_loss: 0.2673 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9510 - precision: 0.9962 - recall: 0.9071 - f1_score: 0.9486 - val_loss: 0.2671 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2374 - acc: 0.9510 - precision: 0.9966 - recall: 0.9012 - f1_score: 0.9451 - val_loss: 0.2668 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2371 - acc: 0.9510 - precision: 0.9966 - recall: 0.9019 - f1_score: 0.9455 - val_loss: 0.2665 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2369 - acc: 0.9510 - precision: 0.9966 - recall: 0.9025 - f1_score: 0.9464 - val_loss: 0.2662 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2366 - acc: 0.9510 - precision: 0.9964 - recall: 0.9041 - f1_score: 0.9473 - val_loss: 0.2660 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2363 - acc: 0.9510 - precision: 0.9962 - recall: 0.9055 - f1_score: 0.9476 - val_loss: 0.2657 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9510 - precision: 0.9961 - recall: 0.9025 - f1_score: 0.9462 - val_loss: 0.2654 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2357 - acc: 0.9510 - precision: 0.9956 - recall: 0.9019 - f1_score: 0.9453 - val_loss: 0.2652 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 942/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9510 - precision: 0.9967 - recall: 0.9069 - f1_score: 0.9485 - val_loss: 0.2649 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2352 - acc: 0.9510 - precision: 0.9961 - recall: 0.9045 - f1_score: 0.9475 - val_loss: 0.2646 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2349 - acc: 0.9510 - precision: 0.9967 - recall: 0.9008 - f1_score: 0.9449 - val_loss: 0.2644 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9510 - precision: 0.9964 - recall: 0.9065 - f1_score: 0.9483 - val_loss: 0.2641 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9510 - precision: 0.9962 - recall: 0.9074 - f1_score: 0.9491 - val_loss: 0.2638 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9510 - precision: 0.9962 - recall: 0.9033 - f1_score: 0.9467 - val_loss: 0.2636 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2338 - acc: 0.9510 - precision: 0.9964 - recall: 0.9045 - f1_score: 0.9473 - val_loss: 0.2633 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2335 - acc: 0.9510 - precision: 0.9971 - recall: 0.9017 - f1_score: 0.9453 - val_loss: 0.2631 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2333 - acc: 0.9510 - precision: 0.9958 - recall: 0.9041 - f1_score: 0.9472 - val_loss: 0.2628 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2330 - acc: 0.9510 - precision: 0.9973 - recall: 0.9052 - f1_score: 0.9479 - val_loss: 0.2625 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2327 - acc: 0.9510 - precision: 0.9974 - recall: 0.9020 - f1_score: 0.9464 - val_loss: 0.2623 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9510 - precision: 0.9967 - recall: 0.9030 - f1_score: 0.9465 - val_loss: 0.2620 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2322 - acc: 0.9510 - precision: 0.9968 - recall: 0.9032 - f1_score: 0.9470 - val_loss: 0.2618 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9510 - precision: 0.9964 - recall: 0.9048 - f1_score: 0.9476 - val_loss: 0.2615 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2317 - acc: 0.9510 - precision: 0.9958 - recall: 0.9086 - f1_score: 0.9494 - val_loss: 0.2613 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2314 - acc: 0.9510 - precision: 0.9971 - recall: 0.9066 - f1_score: 0.9490 - val_loss: 0.2610 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2312 - acc: 0.9510 - precision: 0.9967 - recall: 0.9038 - f1_score: 0.9472 - val_loss: 0.2608 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2309 - acc: 0.9510 - precision: 0.9966 - recall: 0.9040 - f1_score: 0.9476 - val_loss: 0.2605 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2306 - acc: 0.9510 - precision: 0.9970 - recall: 0.9059 - f1_score: 0.9480 - val_loss: 0.2603 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2304 - acc: 0.9510 - precision: 0.9972 - recall: 0.9054 - f1_score: 0.9477 - val_loss: 0.2600 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2301 - acc: 0.9510 - precision: 0.9961 - recall: 0.9003 - f1_score: 0.9440 - val_loss: 0.2598 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2299 - acc: 0.9510 - precision: 0.9964 - recall: 0.9093 - f1_score: 0.9502 - val_loss: 0.2596 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2296 - acc: 0.9510 - precision: 0.9971 - recall: 0.9067 - f1_score: 0.9488 - val_loss: 0.2593 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2294 - acc: 0.9510 - precision: 0.9968 - recall: 0.9072 - f1_score: 0.9490 - val_loss: 0.2591 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2291 - acc: 0.9510 - precision: 0.9966 - recall: 0.9029 - f1_score: 0.9468 - val_loss: 0.2588 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2289 - acc: 0.9510 - precision: 0.9961 - recall: 0.9048 - f1_score: 0.9477 - val_loss: 0.2586 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2286 - acc: 0.9510 - precision: 0.9968 - recall: 0.9065 - f1_score: 0.9483 - val_loss: 0.2583 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2284 - acc: 0.9510 - precision: 0.9964 - recall: 0.9033 - f1_score: 0.9466 - val_loss: 0.2581 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2281 - acc: 0.9510 - precision: 0.9967 - recall: 0.9008 - f1_score: 0.9455 - val_loss: 0.2579 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2279 - acc: 0.9510 - precision: 0.9964 - recall: 0.9061 - f1_score: 0.9482 - val_loss: 0.2576 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2276 - acc: 0.9510 - precision: 0.9964 - recall: 0.9028 - f1_score: 0.9453 - val_loss: 0.2574 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2274 - acc: 0.9510 - precision: 0.9968 - recall: 0.9060 - f1_score: 0.9482 - val_loss: 0.2572 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 974/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2271 - acc: 0.9510 - precision: 0.9967 - recall: 0.9064 - f1_score: 0.9483 - val_loss: 0.2569 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2269 - acc: 0.9510 - precision: 0.9970 - recall: 0.9072 - f1_score: 0.9486 - val_loss: 0.2567 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2267 - acc: 0.9510 - precision: 0.9968 - recall: 0.9028 - f1_score: 0.9466 - val_loss: 0.2565 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2264 - acc: 0.9510 - precision: 0.9966 - recall: 0.9030 - f1_score: 0.9465 - val_loss: 0.2563 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2262 - acc: 0.9510 - precision: 0.9972 - recall: 0.9036 - f1_score: 0.9466 - val_loss: 0.2560 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2260 - acc: 0.9510 - precision: 0.9971 - recall: 0.9053 - f1_score: 0.9480 - val_loss: 0.2558 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2257 - acc: 0.9510 - precision: 0.9967 - recall: 0.9049 - f1_score: 0.9482 - val_loss: 0.2556 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2255 - acc: 0.9510 - precision: 0.9967 - recall: 0.9065 - f1_score: 0.9482 - val_loss: 0.2554 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2252 - acc: 0.9510 - precision: 0.9964 - recall: 0.9048 - f1_score: 0.9476 - val_loss: 0.2552 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2250 - acc: 0.9510 - precision: 0.9972 - recall: 0.9014 - f1_score: 0.9448 - val_loss: 0.2549 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2248 - acc: 0.9510 - precision: 0.9967 - recall: 0.9058 - f1_score: 0.9483 - val_loss: 0.2547 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2245 - acc: 0.9510 - precision: 0.9972 - recall: 0.9066 - f1_score: 0.9485 - val_loss: 0.2545 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2243 - acc: 0.9510 - precision: 0.9960 - recall: 0.9043 - f1_score: 0.9469 - val_loss: 0.2543 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2241 - acc: 0.9510 - precision: 0.9964 - recall: 0.9052 - f1_score: 0.9477 - val_loss: 0.2541 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2239 - acc: 0.9510 - precision: 0.9958 - recall: 0.9012 - f1_score: 0.9451 - val_loss: 0.2539 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2236 - acc: 0.9510 - precision: 0.9967 - recall: 0.8997 - f1_score: 0.9447 - val_loss: 0.2536 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2234 - acc: 0.9510 - precision: 0.9964 - recall: 0.9044 - f1_score: 0.9470 - val_loss: 0.2534 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2232 - acc: 0.9510 - precision: 0.9970 - recall: 0.9030 - f1_score: 0.9464 - val_loss: 0.2532 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2229 - acc: 0.9510 - precision: 0.9967 - recall: 0.9054 - f1_score: 0.9481 - val_loss: 0.2530 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2227 - acc: 0.9510 - precision: 0.9966 - recall: 0.9001 - f1_score: 0.9453 - val_loss: 0.2528 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2225 - acc: 0.9510 - precision: 0.9967 - recall: 0.9021 - f1_score: 0.9456 - val_loss: 0.2526 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2223 - acc: 0.9510 - precision: 0.9964 - recall: 0.9039 - f1_score: 0.9475 - val_loss: 0.2524 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2221 - acc: 0.9510 - precision: 0.9961 - recall: 0.9032 - f1_score: 0.9462 - val_loss: 0.2522 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2218 - acc: 0.9510 - precision: 0.9964 - recall: 0.9017 - f1_score: 0.9457 - val_loss: 0.2520 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2216 - acc: 0.9510 - precision: 0.9967 - recall: 0.9017 - f1_score: 0.9457 - val_loss: 0.2518 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2214 - acc: 0.9510 - precision: 0.9961 - recall: 0.9064 - f1_score: 0.9478 - val_loss: 0.2516 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2212 - acc: 0.9510 - precision: 0.9962 - recall: 0.8974 - f1_score: 0.9429 - val_loss: 0.2514 - val_acc: 0.9177 - val_precision: 0.9587 - val_recall: 0.8801 - val_f1_score: 0.9156\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9167 - acc: 0.7678 - precision: 0.7082 - recall: 0.8960 - f1_score: 0.7874 - val_loss: 5.8937 - val_acc: 0.7785 - val_precision: 0.7122 - val_recall: 0.9059 - val_f1_score: 0.7973\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8610 - acc: 0.7741 - precision: 0.7106 - recall: 0.9176 - f1_score: 0.7994 - val_loss: 5.8363 - val_acc: 0.7785 - val_precision: 0.7074 - val_recall: 0.9186 - val_f1_score: 0.7992\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8188 - acc: 0.7804 - precision: 0.7167 - recall: 0.9325 - f1_score: 0.8070 - val_loss: 5.7901 - val_acc: 0.7785 - val_precision: 0.7046 - val_recall: 0.9324 - val_f1_score: 0.8023\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7815 - acc: 0.7852 - precision: 0.7146 - recall: 0.9355 - f1_score: 0.8083 - val_loss: 5.7489 - val_acc: 0.7785 - val_precision: 0.7046 - val_recall: 0.9324 - val_f1_score: 0.8023\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7466 - acc: 0.7867 - precision: 0.7186 - recall: 0.9295 - f1_score: 0.8098 - val_loss: 5.7111 - val_acc: 0.7848 - val_precision: 0.7112 - val_recall: 0.9324 - val_f1_score: 0.8067\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.7131 - acc: 0.7994 - precision: 0.7371 - recall: 0.9344 - f1_score: 0.8198 - val_loss: 5.6754 - val_acc: 0.7911 - val_precision: 0.7180 - val_recall: 0.9324 - val_f1_score: 0.8111\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6805 - acc: 0.8152 - precision: 0.7513 - recall: 0.9403 - f1_score: 0.8306 - val_loss: 5.6411 - val_acc: 0.8165 - val_precision: 0.7346 - val_recall: 0.9736 - val_f1_score: 0.8367\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6487 - acc: 0.8183 - precision: 0.7539 - recall: 0.9428 - f1_score: 0.8348 - val_loss: 5.6083 - val_acc: 0.8291 - val_precision: 0.7488 - val_recall: 0.9736 - val_f1_score: 0.8464\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6174 - acc: 0.8231 - precision: 0.7606 - recall: 0.9391 - f1_score: 0.8391 - val_loss: 5.5763 - val_acc: 0.8354 - val_precision: 0.7568 - val_recall: 0.9736 - val_f1_score: 0.8513\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5867 - acc: 0.8262 - precision: 0.7646 - recall: 0.9278 - f1_score: 0.8353 - val_loss: 5.5450 - val_acc: 0.8354 - val_precision: 0.7568 - val_recall: 0.9736 - val_f1_score: 0.8513\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5563 - acc: 0.8341 - precision: 0.7790 - recall: 0.9295 - f1_score: 0.8460 - val_loss: 5.5142 - val_acc: 0.8354 - val_precision: 0.7626 - val_recall: 0.9610 - val_f1_score: 0.8500\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5263 - acc: 0.8389 - precision: 0.7846 - recall: 0.9323 - f1_score: 0.8505 - val_loss: 5.4838 - val_acc: 0.8418 - val_precision: 0.7700 - val_recall: 0.9610 - val_f1_score: 0.8547\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4966 - acc: 0.8499 - precision: 0.7976 - recall: 0.9357 - f1_score: 0.8580 - val_loss: 5.4538 - val_acc: 0.8481 - val_precision: 0.7784 - val_recall: 0.9610 - val_f1_score: 0.8600\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4672 - acc: 0.8578 - precision: 0.8126 - recall: 0.9310 - f1_score: 0.8648 - val_loss: 5.4241 - val_acc: 0.8481 - val_precision: 0.7784 - val_recall: 0.9610 - val_f1_score: 0.8600\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4380 - acc: 0.8657 - precision: 0.8236 - recall: 0.9305 - f1_score: 0.8709 - val_loss: 5.3947 - val_acc: 0.8544 - val_precision: 0.7874 - val_recall: 0.9610 - val_f1_score: 0.8655\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4090 - acc: 0.8736 - precision: 0.8304 - recall: 0.9279 - f1_score: 0.8747 - val_loss: 5.3656 - val_acc: 0.8734 - val_precision: 0.8125 - val_recall: 0.9610 - val_f1_score: 0.8801\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3803 - acc: 0.8768 - precision: 0.8392 - recall: 0.9229 - f1_score: 0.8776 - val_loss: 5.3368 - val_acc: 0.8734 - val_precision: 0.8125 - val_recall: 0.9610 - val_f1_score: 0.8801\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3518 - acc: 0.8815 - precision: 0.8492 - recall: 0.9283 - f1_score: 0.8851 - val_loss: 5.3082 - val_acc: 0.8734 - val_precision: 0.8125 - val_recall: 0.9610 - val_f1_score: 0.8801\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3236 - acc: 0.8894 - precision: 0.8590 - recall: 0.9281 - f1_score: 0.8906 - val_loss: 5.2798 - val_acc: 0.8734 - val_precision: 0.8125 - val_recall: 0.9610 - val_f1_score: 0.8801\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2955 - acc: 0.8926 - precision: 0.8648 - recall: 0.9284 - f1_score: 0.8935 - val_loss: 5.2517 - val_acc: 0.8734 - val_precision: 0.8125 - val_recall: 0.9610 - val_f1_score: 0.8801\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2676 - acc: 0.8989 - precision: 0.8760 - recall: 0.9222 - f1_score: 0.8967 - val_loss: 5.2237 - val_acc: 0.8797 - val_precision: 0.8219 - val_recall: 0.9610 - val_f1_score: 0.8854\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2400 - acc: 0.9036 - precision: 0.8838 - recall: 0.9298 - f1_score: 0.9053 - val_loss: 5.1960 - val_acc: 0.8797 - val_precision: 0.8288 - val_recall: 0.9483 - val_f1_score: 0.8838\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2125 - acc: 0.9052 - precision: 0.8972 - recall: 0.9187 - f1_score: 0.9059 - val_loss: 5.1686 - val_acc: 0.8861 - val_precision: 0.8384 - val_recall: 0.9483 - val_f1_score: 0.8895\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1853 - acc: 0.9115 - precision: 0.9031 - recall: 0.9159 - f1_score: 0.9067 - val_loss: 5.1413 - val_acc: 0.8861 - val_precision: 0.8384 - val_recall: 0.9483 - val_f1_score: 0.8895\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1582 - acc: 0.9131 - precision: 0.9101 - recall: 0.9194 - f1_score: 0.9128 - val_loss: 5.1141 - val_acc: 0.8861 - val_precision: 0.8384 - val_recall: 0.9483 - val_f1_score: 0.8895\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1313 - acc: 0.9147 - precision: 0.9125 - recall: 0.9157 - f1_score: 0.9132 - val_loss: 5.0872 - val_acc: 0.8987 - val_precision: 0.8580 - val_recall: 0.9483 - val_f1_score: 0.9007\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1046 - acc: 0.9131 - precision: 0.9137 - recall: 0.9144 - f1_score: 0.9132 - val_loss: 5.0605 - val_acc: 0.9114 - val_precision: 0.8791 - val_recall: 0.9483 - val_f1_score: 0.9123\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0781 - acc: 0.9147 - precision: 0.9187 - recall: 0.9106 - f1_score: 0.9128 - val_loss: 5.0340 - val_acc: 0.9177 - val_precision: 0.8912 - val_recall: 0.9483 - val_f1_score: 0.9188\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0518 - acc: 0.9179 - precision: 0.9251 - recall: 0.9104 - f1_score: 0.9168 - val_loss: 5.0076 - val_acc: 0.9177 - val_precision: 0.8912 - val_recall: 0.9483 - val_f1_score: 0.9188\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0256 - acc: 0.9179 - precision: 0.9254 - recall: 0.9069 - f1_score: 0.9154 - val_loss: 4.9815 - val_acc: 0.9241 - val_precision: 0.9020 - val_recall: 0.9483 - val_f1_score: 0.9245\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9997 - acc: 0.9163 - precision: 0.9272 - recall: 0.9069 - f1_score: 0.9150 - val_loss: 4.9554 - val_acc: 0.9241 - val_precision: 0.9020 - val_recall: 0.9483 - val_f1_score: 0.9245\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9738 - acc: 0.9179 - precision: 0.9291 - recall: 0.9036 - f1_score: 0.9148 - val_loss: 4.9296 - val_acc: 0.9241 - val_precision: 0.9020 - val_recall: 0.9483 - val_f1_score: 0.9245\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9482 - acc: 0.9179 - precision: 0.9297 - recall: 0.9049 - f1_score: 0.9164 - val_loss: 4.9039 - val_acc: 0.9304 - val_precision: 0.9123 - val_recall: 0.9483 - val_f1_score: 0.9300\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9227 - acc: 0.9210 - precision: 0.9346 - recall: 0.9062 - f1_score: 0.9188 - val_loss: 4.8784 - val_acc: 0.9304 - val_precision: 0.9123 - val_recall: 0.9483 - val_f1_score: 0.9300\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8974 - acc: 0.9210 - precision: 0.9394 - recall: 0.9021 - f1_score: 0.9189 - val_loss: 4.8531 - val_acc: 0.9304 - val_precision: 0.9123 - val_recall: 0.9483 - val_f1_score: 0.9300\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8722 - acc: 0.9226 - precision: 0.9398 - recall: 0.9039 - f1_score: 0.9194 - val_loss: 4.8279 - val_acc: 0.9367 - val_precision: 0.9239 - val_recall: 0.9483 - val_f1_score: 0.9359\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8472 - acc: 0.9242 - precision: 0.9458 - recall: 0.9031 - f1_score: 0.9229 - val_loss: 4.8028 - val_acc: 0.9367 - val_precision: 0.9239 - val_recall: 0.9483 - val_f1_score: 0.9359\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.8224 - acc: 0.9242 - precision: 0.9400 - recall: 0.9015 - f1_score: 0.9186 - val_loss: 4.7780 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7976 - acc: 0.9242 - precision: 0.9479 - recall: 0.8992 - f1_score: 0.9210 - val_loss: 4.7533 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7731 - acc: 0.9273 - precision: 0.9518 - recall: 0.8956 - f1_score: 0.9197 - val_loss: 4.7288 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7487 - acc: 0.9273 - precision: 0.9550 - recall: 0.8977 - f1_score: 0.9239 - val_loss: 4.7044 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7245 - acc: 0.9258 - precision: 0.9510 - recall: 0.8946 - f1_score: 0.9210 - val_loss: 4.6802 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7004 - acc: 0.9273 - precision: 0.9557 - recall: 0.8953 - f1_score: 0.9234 - val_loss: 4.6561 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6765 - acc: 0.9273 - precision: 0.9564 - recall: 0.8949 - f1_score: 0.9238 - val_loss: 4.6322 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6527 - acc: 0.9273 - precision: 0.9545 - recall: 0.8918 - f1_score: 0.9208 - val_loss: 4.6084 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6291 - acc: 0.9242 - precision: 0.9572 - recall: 0.8887 - f1_score: 0.9191 - val_loss: 4.5848 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6056 - acc: 0.9242 - precision: 0.9547 - recall: 0.8919 - f1_score: 0.9208 - val_loss: 4.5613 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5822 - acc: 0.9242 - precision: 0.9547 - recall: 0.8892 - f1_score: 0.9203 - val_loss: 4.5380 - val_acc: 0.9494 - val_precision: 0.9473 - val_recall: 0.9483 - val_f1_score: 0.9475\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5590 - acc: 0.9242 - precision: 0.9556 - recall: 0.8892 - f1_score: 0.9184 - val_loss: 4.5148 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5359 - acc: 0.9242 - precision: 0.9555 - recall: 0.8875 - f1_score: 0.9188 - val_loss: 4.4917 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5130 - acc: 0.9226 - precision: 0.9559 - recall: 0.8859 - f1_score: 0.9188 - val_loss: 4.4688 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4902 - acc: 0.9226 - precision: 0.9572 - recall: 0.8843 - f1_score: 0.9183 - val_loss: 4.4460 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4675 - acc: 0.9226 - precision: 0.9549 - recall: 0.8774 - f1_score: 0.9135 - val_loss: 4.4233 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4450 - acc: 0.9226 - precision: 0.9589 - recall: 0.8790 - f1_score: 0.9162 - val_loss: 4.4008 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4226 - acc: 0.9242 - precision: 0.9627 - recall: 0.8833 - f1_score: 0.9200 - val_loss: 4.3784 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4003 - acc: 0.9242 - precision: 0.9625 - recall: 0.8855 - f1_score: 0.9216 - val_loss: 4.3561 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3782 - acc: 0.9242 - precision: 0.9616 - recall: 0.8860 - f1_score: 0.9211 - val_loss: 4.3341 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3562 - acc: 0.9258 - precision: 0.9659 - recall: 0.8820 - f1_score: 0.9210 - val_loss: 4.3121 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3343 - acc: 0.9289 - precision: 0.9676 - recall: 0.8832 - f1_score: 0.9222 - val_loss: 4.2902 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3125 - acc: 0.9305 - precision: 0.9739 - recall: 0.8863 - f1_score: 0.9256 - val_loss: 4.2684 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2909 - acc: 0.9305 - precision: 0.9724 - recall: 0.8824 - f1_score: 0.9238 - val_loss: 4.2469 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2694 - acc: 0.9305 - precision: 0.9702 - recall: 0.8858 - f1_score: 0.9247 - val_loss: 4.2254 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2480 - acc: 0.9305 - precision: 0.9719 - recall: 0.8869 - f1_score: 0.9262 - val_loss: 4.2040 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2268 - acc: 0.9289 - precision: 0.9727 - recall: 0.8855 - f1_score: 0.9261 - val_loss: 4.1828 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2056 - acc: 0.9289 - precision: 0.9701 - recall: 0.8782 - f1_score: 0.9211 - val_loss: 4.1617 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1846 - acc: 0.9289 - precision: 0.9685 - recall: 0.8817 - f1_score: 0.9215 - val_loss: 4.1407 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1637 - acc: 0.9289 - precision: 0.9723 - recall: 0.8815 - f1_score: 0.9231 - val_loss: 4.1199 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1430 - acc: 0.9289 - precision: 0.9702 - recall: 0.8872 - f1_score: 0.9250 - val_loss: 4.0991 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1223 - acc: 0.9289 - precision: 0.9744 - recall: 0.8794 - f1_score: 0.9200 - val_loss: 4.0785 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.1018 - acc: 0.9289 - precision: 0.9684 - recall: 0.8803 - f1_score: 0.9214 - val_loss: 4.0580 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0814 - acc: 0.9289 - precision: 0.9728 - recall: 0.8831 - f1_score: 0.9241 - val_loss: 4.0376 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0611 - acc: 0.9289 - precision: 0.9718 - recall: 0.8848 - f1_score: 0.9256 - val_loss: 4.0174 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0409 - acc: 0.9305 - precision: 0.9751 - recall: 0.8851 - f1_score: 0.9270 - val_loss: 3.9972 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0208 - acc: 0.9305 - precision: 0.9734 - recall: 0.8786 - f1_score: 0.9224 - val_loss: 3.9772 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0009 - acc: 0.9305 - precision: 0.9765 - recall: 0.8792 - f1_score: 0.9242 - val_loss: 3.9573 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9810 - acc: 0.9305 - precision: 0.9764 - recall: 0.8835 - f1_score: 0.9266 - val_loss: 3.9374 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9613 - acc: 0.9305 - precision: 0.9761 - recall: 0.8847 - f1_score: 0.9265 - val_loss: 3.9177 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9417 - acc: 0.9305 - precision: 0.9748 - recall: 0.8807 - f1_score: 0.9243 - val_loss: 3.8982 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9222 - acc: 0.9321 - precision: 0.9792 - recall: 0.8868 - f1_score: 0.9292 - val_loss: 3.8787 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9028 - acc: 0.9321 - precision: 0.9767 - recall: 0.8814 - f1_score: 0.9257 - val_loss: 3.8594 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8835 - acc: 0.9336 - precision: 0.9798 - recall: 0.8912 - f1_score: 0.9325 - val_loss: 3.8401 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8643 - acc: 0.9336 - precision: 0.9785 - recall: 0.8819 - f1_score: 0.9267 - val_loss: 3.8210 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8452 - acc: 0.9336 - precision: 0.9786 - recall: 0.8843 - f1_score: 0.9283 - val_loss: 3.8019 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8262 - acc: 0.9336 - precision: 0.9796 - recall: 0.8919 - f1_score: 0.9322 - val_loss: 3.7830 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8073 - acc: 0.9336 - precision: 0.9805 - recall: 0.8809 - f1_score: 0.9274 - val_loss: 3.7642 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7886 - acc: 0.9336 - precision: 0.9801 - recall: 0.8878 - f1_score: 0.9305 - val_loss: 3.7454 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7699 - acc: 0.9336 - precision: 0.9760 - recall: 0.8846 - f1_score: 0.9272 - val_loss: 3.7268 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7514 - acc: 0.9336 - precision: 0.9784 - recall: 0.8863 - f1_score: 0.9298 - val_loss: 3.7083 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7329 - acc: 0.9336 - precision: 0.9778 - recall: 0.8857 - f1_score: 0.9288 - val_loss: 3.6899 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7146 - acc: 0.9336 - precision: 0.9813 - recall: 0.8810 - f1_score: 0.9265 - val_loss: 3.6716 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6963 - acc: 0.9336 - precision: 0.9800 - recall: 0.8881 - f1_score: 0.9304 - val_loss: 3.6533 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6782 - acc: 0.9336 - precision: 0.9796 - recall: 0.8840 - f1_score: 0.9285 - val_loss: 3.6352 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6601 - acc: 0.9336 - precision: 0.9775 - recall: 0.8853 - f1_score: 0.9283 - val_loss: 3.6172 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6422 - acc: 0.9336 - precision: 0.9795 - recall: 0.8874 - f1_score: 0.9304 - val_loss: 3.5993 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6243 - acc: 0.9336 - precision: 0.9778 - recall: 0.8852 - f1_score: 0.9282 - val_loss: 3.5815 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6065 - acc: 0.9336 - precision: 0.9813 - recall: 0.8886 - f1_score: 0.9312 - val_loss: 3.5638 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5889 - acc: 0.9336 - precision: 0.9788 - recall: 0.8875 - f1_score: 0.9295 - val_loss: 3.5462 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5713 - acc: 0.9336 - precision: 0.9791 - recall: 0.8876 - f1_score: 0.9298 - val_loss: 3.5287 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5539 - acc: 0.9336 - precision: 0.9820 - recall: 0.8854 - f1_score: 0.9288 - val_loss: 3.5113 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5365 - acc: 0.9352 - precision: 0.9821 - recall: 0.8860 - f1_score: 0.9308 - val_loss: 3.4940 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5192 - acc: 0.9352 - precision: 0.9819 - recall: 0.8862 - f1_score: 0.9301 - val_loss: 3.4767 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.5020 - acc: 0.9352 - precision: 0.9812 - recall: 0.8870 - f1_score: 0.9304 - val_loss: 3.4596 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4850 - acc: 0.9352 - precision: 0.9833 - recall: 0.8841 - f1_score: 0.9298 - val_loss: 3.4426 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4680 - acc: 0.9352 - precision: 0.9804 - recall: 0.8871 - f1_score: 0.9297 - val_loss: 3.4256 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4511 - acc: 0.9352 - precision: 0.9818 - recall: 0.8841 - f1_score: 0.9290 - val_loss: 3.4088 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4342 - acc: 0.9352 - precision: 0.9830 - recall: 0.8798 - f1_score: 0.9269 - val_loss: 3.3920 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4175 - acc: 0.9352 - precision: 0.9827 - recall: 0.8863 - f1_score: 0.9306 - val_loss: 3.3753 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4009 - acc: 0.9352 - precision: 0.9843 - recall: 0.8871 - f1_score: 0.9315 - val_loss: 3.3587 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3844 - acc: 0.9352 - precision: 0.9826 - recall: 0.8878 - f1_score: 0.9304 - val_loss: 3.3423 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3679 - acc: 0.9352 - precision: 0.9826 - recall: 0.8867 - f1_score: 0.9315 - val_loss: 3.3259 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3515 - acc: 0.9352 - precision: 0.9818 - recall: 0.8869 - f1_score: 0.9292 - val_loss: 3.3096 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3353 - acc: 0.9336 - precision: 0.9813 - recall: 0.8773 - f1_score: 0.9240 - val_loss: 3.2933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3191 - acc: 0.9336 - precision: 0.9823 - recall: 0.8858 - f1_score: 0.9297 - val_loss: 3.2772 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3030 - acc: 0.9336 - precision: 0.9825 - recall: 0.8834 - f1_score: 0.9294 - val_loss: 3.2612 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2870 - acc: 0.9336 - precision: 0.9837 - recall: 0.8808 - f1_score: 0.9273 - val_loss: 3.2452 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2711 - acc: 0.9336 - precision: 0.9816 - recall: 0.8789 - f1_score: 0.9262 - val_loss: 3.2293 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2552 - acc: 0.9336 - precision: 0.9834 - recall: 0.8825 - f1_score: 0.9295 - val_loss: 3.2135 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2395 - acc: 0.9336 - precision: 0.9808 - recall: 0.8869 - f1_score: 0.9306 - val_loss: 3.1979 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2238 - acc: 0.9336 - precision: 0.9832 - recall: 0.8860 - f1_score: 0.9300 - val_loss: 3.1822 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2082 - acc: 0.9336 - precision: 0.9814 - recall: 0.8807 - f1_score: 0.9277 - val_loss: 3.1667 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1927 - acc: 0.9336 - precision: 0.9822 - recall: 0.8823 - f1_score: 0.9282 - val_loss: 3.1513 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1773 - acc: 0.9336 - precision: 0.9841 - recall: 0.8785 - f1_score: 0.9267 - val_loss: 3.1359 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1620 - acc: 0.9336 - precision: 0.9830 - recall: 0.8801 - f1_score: 0.9282 - val_loss: 3.1206 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1467 - acc: 0.9336 - precision: 0.9799 - recall: 0.8864 - f1_score: 0.9289 - val_loss: 3.1054 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1315 - acc: 0.9336 - precision: 0.9813 - recall: 0.8844 - f1_score: 0.9288 - val_loss: 3.0903 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1164 - acc: 0.9336 - precision: 0.9830 - recall: 0.8823 - f1_score: 0.9290 - val_loss: 3.0753 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1014 - acc: 0.9336 - precision: 0.9818 - recall: 0.8822 - f1_score: 0.9282 - val_loss: 3.0603 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0865 - acc: 0.9336 - precision: 0.9815 - recall: 0.8846 - f1_score: 0.9294 - val_loss: 3.0454 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0717 - acc: 0.9336 - precision: 0.9826 - recall: 0.8835 - f1_score: 0.9288 - val_loss: 3.0307 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0569 - acc: 0.9336 - precision: 0.9836 - recall: 0.8833 - f1_score: 0.9291 - val_loss: 3.0159 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0421 - acc: 0.9336 - precision: 0.9825 - recall: 0.8803 - f1_score: 0.9268 - val_loss: 3.0013 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0276 - acc: 0.9336 - precision: 0.9848 - recall: 0.8851 - f1_score: 0.9310 - val_loss: 2.9867 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0130 - acc: 0.9321 - precision: 0.9827 - recall: 0.8836 - f1_score: 0.9284 - val_loss: 2.9723 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.9986 - acc: 0.9321 - precision: 0.9833 - recall: 0.8818 - f1_score: 0.9289 - val_loss: 2.9579 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9842 - acc: 0.9321 - precision: 0.9827 - recall: 0.8804 - f1_score: 0.9277 - val_loss: 2.9435 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9699 - acc: 0.9321 - precision: 0.9831 - recall: 0.8832 - f1_score: 0.9283 - val_loss: 2.9293 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9557 - acc: 0.9321 - precision: 0.9845 - recall: 0.8801 - f1_score: 0.9284 - val_loss: 2.9151 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9415 - acc: 0.9321 - precision: 0.9842 - recall: 0.8798 - f1_score: 0.9276 - val_loss: 2.9010 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9275 - acc: 0.9321 - precision: 0.9810 - recall: 0.8797 - f1_score: 0.9270 - val_loss: 2.8870 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9135 - acc: 0.9321 - precision: 0.9816 - recall: 0.8768 - f1_score: 0.9248 - val_loss: 2.8730 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8995 - acc: 0.9321 - precision: 0.9818 - recall: 0.8743 - f1_score: 0.9228 - val_loss: 2.8591 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8857 - acc: 0.9321 - precision: 0.9829 - recall: 0.8784 - f1_score: 0.9271 - val_loss: 2.8453 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8719 - acc: 0.9321 - precision: 0.9820 - recall: 0.8774 - f1_score: 0.9248 - val_loss: 2.8316 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8582 - acc: 0.9321 - precision: 0.9825 - recall: 0.8800 - f1_score: 0.9276 - val_loss: 2.8179 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8446 - acc: 0.9321 - precision: 0.9846 - recall: 0.8771 - f1_score: 0.9266 - val_loss: 2.8044 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8310 - acc: 0.9321 - precision: 0.9804 - recall: 0.8787 - f1_score: 0.9264 - val_loss: 2.7909 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8175 - acc: 0.9336 - precision: 0.9867 - recall: 0.8777 - f1_score: 0.9276 - val_loss: 2.7774 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8041 - acc: 0.9336 - precision: 0.9861 - recall: 0.8795 - f1_score: 0.9287 - val_loss: 2.7641 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7908 - acc: 0.9336 - precision: 0.9837 - recall: 0.8819 - f1_score: 0.9280 - val_loss: 2.7508 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7775 - acc: 0.9336 - precision: 0.9849 - recall: 0.8794 - f1_score: 0.9283 - val_loss: 2.7376 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7643 - acc: 0.9336 - precision: 0.9852 - recall: 0.8815 - f1_score: 0.9294 - val_loss: 2.7244 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7511 - acc: 0.9336 - precision: 0.9867 - recall: 0.8815 - f1_score: 0.9304 - val_loss: 2.7113 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7381 - acc: 0.9336 - precision: 0.9856 - recall: 0.8764 - f1_score: 0.9261 - val_loss: 2.6983 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7251 - acc: 0.9336 - precision: 0.9857 - recall: 0.8798 - f1_score: 0.9278 - val_loss: 2.6854 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7121 - acc: 0.9336 - precision: 0.9857 - recall: 0.8801 - f1_score: 0.9285 - val_loss: 2.6725 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6993 - acc: 0.9336 - precision: 0.9854 - recall: 0.8860 - f1_score: 0.9319 - val_loss: 2.6597 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6865 - acc: 0.9336 - precision: 0.9861 - recall: 0.8760 - f1_score: 0.9257 - val_loss: 2.6470 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6738 - acc: 0.9336 - precision: 0.9882 - recall: 0.8801 - f1_score: 0.9296 - val_loss: 2.6343 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6611 - acc: 0.9336 - precision: 0.9856 - recall: 0.8774 - f1_score: 0.9268 - val_loss: 2.6217 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6485 - acc: 0.9336 - precision: 0.9855 - recall: 0.8791 - f1_score: 0.9287 - val_loss: 2.6091 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6360 - acc: 0.9336 - precision: 0.9861 - recall: 0.8766 - f1_score: 0.9266 - val_loss: 2.5967 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6236 - acc: 0.9336 - precision: 0.9865 - recall: 0.8795 - f1_score: 0.9293 - val_loss: 2.5843 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6112 - acc: 0.9336 - precision: 0.9865 - recall: 0.8785 - f1_score: 0.9274 - val_loss: 2.5719 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5989 - acc: 0.9336 - precision: 0.9870 - recall: 0.8820 - f1_score: 0.9303 - val_loss: 2.5596 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5866 - acc: 0.9336 - precision: 0.9863 - recall: 0.8743 - f1_score: 0.9257 - val_loss: 2.5474 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.5744 - acc: 0.9336 - precision: 0.9859 - recall: 0.8762 - f1_score: 0.9264 - val_loss: 2.5353 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5623 - acc: 0.9336 - precision: 0.9844 - recall: 0.8777 - f1_score: 0.9269 - val_loss: 2.5232 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5502 - acc: 0.9336 - precision: 0.9861 - recall: 0.8814 - f1_score: 0.9298 - val_loss: 2.5112 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5382 - acc: 0.9336 - precision: 0.9860 - recall: 0.8798 - f1_score: 0.9289 - val_loss: 2.4992 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5262 - acc: 0.9336 - precision: 0.9847 - recall: 0.8806 - f1_score: 0.9280 - val_loss: 2.4873 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.4956 - acc: 0.9400 - precision: 1.0000 - recall: 0.8636 - f1_score: 0.926 - 0s - loss: 2.5144 - acc: 0.9336 - precision: 0.9861 - recall: 0.8782 - f1_score: 0.9279 - val_loss: 2.4755 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5025 - acc: 0.9336 - precision: 0.9847 - recall: 0.8783 - f1_score: 0.9274 - val_loss: 2.4637 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4908 - acc: 0.9336 - precision: 0.9849 - recall: 0.8748 - f1_score: 0.9252 - val_loss: 2.4520 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4791 - acc: 0.9336 - precision: 0.9878 - recall: 0.8774 - f1_score: 0.9277 - val_loss: 2.4404 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4675 - acc: 0.9336 - precision: 0.9869 - recall: 0.8746 - f1_score: 0.9245 - val_loss: 2.4288 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 2.4541 - acc: 0.9350 - precision: 0.9952 - recall: 0.8792 - f1_score: 0.932 - 0s - loss: 2.4559 - acc: 0.9336 - precision: 0.9853 - recall: 0.8767 - f1_score: 0.9271 - val_loss: 2.4173 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4444 - acc: 0.9336 - precision: 0.9856 - recall: 0.8774 - f1_score: 0.9276 - val_loss: 2.4058 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4329 - acc: 0.9336 - precision: 0.9856 - recall: 0.8823 - f1_score: 0.9302 - val_loss: 2.3944 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4216 - acc: 0.9336 - precision: 0.9856 - recall: 0.8798 - f1_score: 0.9287 - val_loss: 2.3831 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4102 - acc: 0.9336 - precision: 0.9872 - recall: 0.8815 - f1_score: 0.9297 - val_loss: 2.3718 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3990 - acc: 0.9336 - precision: 0.9864 - recall: 0.8834 - f1_score: 0.9313 - val_loss: 2.3606 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3878 - acc: 0.9336 - precision: 0.9841 - recall: 0.8811 - f1_score: 0.9275 - val_loss: 2.3494 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3766 - acc: 0.9336 - precision: 0.9852 - recall: 0.8792 - f1_score: 0.9283 - val_loss: 2.3383 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3655 - acc: 0.9336 - precision: 0.9875 - recall: 0.8781 - f1_score: 0.9283 - val_loss: 2.3272 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3545 - acc: 0.9336 - precision: 0.9859 - recall: 0.8791 - f1_score: 0.9280 - val_loss: 2.3162 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3435 - acc: 0.9336 - precision: 0.9851 - recall: 0.8798 - f1_score: 0.9281 - val_loss: 2.3053 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3326 - acc: 0.9336 - precision: 0.9865 - recall: 0.8774 - f1_score: 0.9269 - val_loss: 2.2944 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3217 - acc: 0.9336 - precision: 0.9858 - recall: 0.8814 - f1_score: 0.9290 - val_loss: 2.2836 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3109 - acc: 0.9336 - precision: 0.9859 - recall: 0.8809 - f1_score: 0.9297 - val_loss: 2.2728 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3002 - acc: 0.9336 - precision: 0.9848 - recall: 0.8789 - f1_score: 0.9278 - val_loss: 2.2621 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2895 - acc: 0.9336 - precision: 0.9854 - recall: 0.8816 - f1_score: 0.9295 - val_loss: 2.2515 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2788 - acc: 0.9336 - precision: 0.9854 - recall: 0.8773 - f1_score: 0.9257 - val_loss: 2.2409 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2683 - acc: 0.9336 - precision: 0.9822 - recall: 0.8755 - f1_score: 0.9245 - val_loss: 2.2304 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2577 - acc: 0.9336 - precision: 0.9867 - recall: 0.8852 - f1_score: 0.9312 - val_loss: 2.2199 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2473 - acc: 0.9336 - precision: 0.9868 - recall: 0.8819 - f1_score: 0.9300 - val_loss: 2.2095 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2368 - acc: 0.9336 - precision: 0.9847 - recall: 0.8839 - f1_score: 0.9290 - val_loss: 2.1991 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.2265 - acc: 0.9336 - precision: 0.9863 - recall: 0.8791 - f1_score: 0.9274 - val_loss: 2.1887 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2162 - acc: 0.9336 - precision: 0.9849 - recall: 0.8785 - f1_score: 0.9272 - val_loss: 2.1785 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2059 - acc: 0.9336 - precision: 0.9865 - recall: 0.8800 - f1_score: 0.9293 - val_loss: 2.1683 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1957 - acc: 0.9336 - precision: 0.9863 - recall: 0.8809 - f1_score: 0.9290 - val_loss: 2.1581 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1856 - acc: 0.9336 - precision: 0.9864 - recall: 0.8827 - f1_score: 0.9303 - val_loss: 2.1480 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1755 - acc: 0.9336 - precision: 0.9872 - recall: 0.8806 - f1_score: 0.9296 - val_loss: 2.1379 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1655 - acc: 0.9336 - precision: 0.9854 - recall: 0.8834 - f1_score: 0.9307 - val_loss: 2.1279 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1555 - acc: 0.9336 - precision: 0.9850 - recall: 0.8799 - f1_score: 0.9279 - val_loss: 2.1180 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1455 - acc: 0.9336 - precision: 0.9871 - recall: 0.8805 - f1_score: 0.9295 - val_loss: 2.1081 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1356 - acc: 0.9336 - precision: 0.9861 - recall: 0.8812 - f1_score: 0.9296 - val_loss: 2.0983 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1258 - acc: 0.9336 - precision: 0.9865 - recall: 0.8812 - f1_score: 0.9298 - val_loss: 2.0885 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1160 - acc: 0.9336 - precision: 0.9845 - recall: 0.8792 - f1_score: 0.9270 - val_loss: 2.0787 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1063 - acc: 0.9336 - precision: 0.9863 - recall: 0.8785 - f1_score: 0.9281 - val_loss: 2.0691 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0966 - acc: 0.9336 - precision: 0.9845 - recall: 0.8802 - f1_score: 0.9277 - val_loss: 2.0594 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0870 - acc: 0.9336 - precision: 0.9861 - recall: 0.8745 - f1_score: 0.9243 - val_loss: 2.0498 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0774 - acc: 0.9336 - precision: 0.9827 - recall: 0.8778 - f1_score: 0.9261 - val_loss: 2.0403 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0679 - acc: 0.9336 - precision: 0.9847 - recall: 0.8789 - f1_score: 0.9275 - val_loss: 2.0308 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0584 - acc: 0.9336 - precision: 0.9848 - recall: 0.8777 - f1_score: 0.9273 - val_loss: 2.0214 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0490 - acc: 0.9336 - precision: 0.9864 - recall: 0.8816 - f1_score: 0.9292 - val_loss: 2.0120 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0396 - acc: 0.9336 - precision: 0.9833 - recall: 0.8743 - f1_score: 0.9244 - val_loss: 2.0026 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0303 - acc: 0.9336 - precision: 0.9856 - recall: 0.8822 - f1_score: 0.9300 - val_loss: 1.9933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0210 - acc: 0.9336 - precision: 0.9876 - recall: 0.8779 - f1_score: 0.9275 - val_loss: 1.9841 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0117 - acc: 0.9336 - precision: 0.9842 - recall: 0.8803 - f1_score: 0.9286 - val_loss: 1.9749 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0025 - acc: 0.9336 - precision: 0.9841 - recall: 0.8739 - f1_score: 0.9242 - val_loss: 1.9657 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9934 - acc: 0.9336 - precision: 0.9843 - recall: 0.8794 - f1_score: 0.9272 - val_loss: 1.9566 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9843 - acc: 0.9336 - precision: 0.9863 - recall: 0.8816 - f1_score: 0.9298 - val_loss: 1.9476 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9753 - acc: 0.9336 - precision: 0.9832 - recall: 0.8793 - f1_score: 0.9269 - val_loss: 1.9386 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9663 - acc: 0.9336 - precision: 0.9863 - recall: 0.8769 - f1_score: 0.9277 - val_loss: 1.9296 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9573 - acc: 0.9336 - precision: 0.9858 - recall: 0.8787 - f1_score: 0.9281 - val_loss: 1.9207 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9484 - acc: 0.9336 - precision: 0.9854 - recall: 0.8817 - f1_score: 0.9292 - val_loss: 1.9118 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9396 - acc: 0.9336 - precision: 0.9866 - recall: 0.8795 - f1_score: 0.9293 - val_loss: 1.9030 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9308 - acc: 0.9336 - precision: 0.9844 - recall: 0.8810 - f1_score: 0.9284 - val_loss: 1.8942 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.9220 - acc: 0.9336 - precision: 0.9865 - recall: 0.8819 - f1_score: 0.9297 - val_loss: 1.8855 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9133 - acc: 0.9336 - precision: 0.9863 - recall: 0.8767 - f1_score: 0.9268 - val_loss: 1.8768 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9046 - acc: 0.9336 - precision: 0.9859 - recall: 0.8783 - f1_score: 0.9282 - val_loss: 1.8682 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8960 - acc: 0.9336 - precision: 0.9847 - recall: 0.8796 - f1_score: 0.9282 - val_loss: 1.8596 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8874 - acc: 0.9336 - precision: 0.9871 - recall: 0.8812 - f1_score: 0.9303 - val_loss: 1.8511 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8788 - acc: 0.9336 - precision: 0.9878 - recall: 0.8808 - f1_score: 0.9300 - val_loss: 1.8426 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8704 - acc: 0.9336 - precision: 0.9860 - recall: 0.8762 - f1_score: 0.9257 - val_loss: 1.8341 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8619 - acc: 0.9336 - precision: 0.9847 - recall: 0.8809 - f1_score: 0.9294 - val_loss: 1.8257 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8535 - acc: 0.9336 - precision: 0.9866 - recall: 0.8790 - f1_score: 0.9278 - val_loss: 1.8173 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8451 - acc: 0.9336 - precision: 0.9858 - recall: 0.8771 - f1_score: 0.9274 - val_loss: 1.8090 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8368 - acc: 0.9336 - precision: 0.9872 - recall: 0.8827 - f1_score: 0.9312 - val_loss: 1.8007 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8285 - acc: 0.9336 - precision: 0.9878 - recall: 0.8708 - f1_score: 0.9227 - val_loss: 1.7924 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8203 - acc: 0.9336 - precision: 0.9868 - recall: 0.8775 - f1_score: 0.9283 - val_loss: 1.7842 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8121 - acc: 0.9336 - precision: 0.9876 - recall: 0.8788 - f1_score: 0.9274 - val_loss: 1.7761 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8040 - acc: 0.9336 - precision: 0.9855 - recall: 0.8813 - f1_score: 0.9293 - val_loss: 1.7680 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7958 - acc: 0.9336 - precision: 0.9845 - recall: 0.8791 - f1_score: 0.9278 - val_loss: 1.7599 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7878 - acc: 0.9336 - precision: 0.9854 - recall: 0.8773 - f1_score: 0.9272 - val_loss: 1.7519 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7798 - acc: 0.9336 - precision: 0.9864 - recall: 0.8780 - f1_score: 0.9273 - val_loss: 1.7439 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7718 - acc: 0.9336 - precision: 0.9865 - recall: 0.8737 - f1_score: 0.9256 - val_loss: 1.7359 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7638 - acc: 0.9336 - precision: 0.9833 - recall: 0.8761 - f1_score: 0.9259 - val_loss: 1.7280 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7559 - acc: 0.9336 - precision: 0.9847 - recall: 0.8751 - f1_score: 0.9255 - val_loss: 1.7202 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7481 - acc: 0.9336 - precision: 0.9848 - recall: 0.8793 - f1_score: 0.9285 - val_loss: 1.7123 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7403 - acc: 0.9336 - precision: 0.9856 - recall: 0.8827 - f1_score: 0.9295 - val_loss: 1.7046 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7325 - acc: 0.9336 - precision: 0.9869 - recall: 0.8777 - f1_score: 0.9273 - val_loss: 1.6968 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7248 - acc: 0.9336 - precision: 0.9870 - recall: 0.8811 - f1_score: 0.9297 - val_loss: 1.6891 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7171 - acc: 0.9336 - precision: 0.9877 - recall: 0.8801 - f1_score: 0.9290 - val_loss: 1.6814 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7094 - acc: 0.9336 - precision: 0.9861 - recall: 0.8798 - f1_score: 0.9288 - val_loss: 1.6738 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7018 - acc: 0.9336 - precision: 0.9871 - recall: 0.8790 - f1_score: 0.9292 - val_loss: 1.6662 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6942 - acc: 0.9336 - precision: 0.9871 - recall: 0.8788 - f1_score: 0.9289 - val_loss: 1.6587 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6867 - acc: 0.9336 - precision: 0.9870 - recall: 0.8779 - f1_score: 0.9278 - val_loss: 1.6512 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6792 - acc: 0.9336 - precision: 0.9859 - recall: 0.8764 - f1_score: 0.9251 - val_loss: 1.6437 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6717 - acc: 0.9336 - precision: 0.9854 - recall: 0.8779 - f1_score: 0.9274 - val_loss: 1.6363 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 261/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.6643 - acc: 0.9336 - precision: 0.9858 - recall: 0.8772 - f1_score: 0.9280 - val_loss: 1.6289 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6569 - acc: 0.9336 - precision: 0.9861 - recall: 0.8794 - f1_score: 0.9291 - val_loss: 1.6215 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6496 - acc: 0.9336 - precision: 0.9852 - recall: 0.8788 - f1_score: 0.9279 - val_loss: 1.6142 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6423 - acc: 0.9336 - precision: 0.9844 - recall: 0.8769 - f1_score: 0.9248 - val_loss: 1.6069 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6350 - acc: 0.9336 - precision: 0.9861 - recall: 0.8775 - f1_score: 0.9276 - val_loss: 1.5997 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6278 - acc: 0.9336 - precision: 0.9869 - recall: 0.8799 - f1_score: 0.9299 - val_loss: 1.5925 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6206 - acc: 0.9336 - precision: 0.9858 - recall: 0.8803 - f1_score: 0.9291 - val_loss: 1.5854 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6134 - acc: 0.9336 - precision: 0.9849 - recall: 0.8821 - f1_score: 0.9296 - val_loss: 1.5782 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6063 - acc: 0.9336 - precision: 0.9864 - recall: 0.8827 - f1_score: 0.9305 - val_loss: 1.5711 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5992 - acc: 0.9336 - precision: 0.9861 - recall: 0.8800 - f1_score: 0.9293 - val_loss: 1.5641 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5922 - acc: 0.9336 - precision: 0.9849 - recall: 0.8800 - f1_score: 0.9286 - val_loss: 1.5571 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5851 - acc: 0.9336 - precision: 0.9866 - recall: 0.8748 - f1_score: 0.9252 - val_loss: 1.5501 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5782 - acc: 0.9336 - precision: 0.9853 - recall: 0.8778 - f1_score: 0.9277 - val_loss: 1.5431 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5712 - acc: 0.9336 - precision: 0.9865 - recall: 0.8822 - f1_score: 0.9280 - val_loss: 1.5362 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5643 - acc: 0.9336 - precision: 0.9851 - recall: 0.8793 - f1_score: 0.9286 - val_loss: 1.5293 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5575 - acc: 0.9336 - precision: 0.9858 - recall: 0.8782 - f1_score: 0.9270 - val_loss: 1.5225 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5506 - acc: 0.9336 - precision: 0.9861 - recall: 0.8794 - f1_score: 0.9287 - val_loss: 1.5157 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5438 - acc: 0.9336 - precision: 0.9844 - recall: 0.8763 - f1_score: 0.9259 - val_loss: 1.5089 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5371 - acc: 0.9336 - precision: 0.9856 - recall: 0.8884 - f1_score: 0.9329 - val_loss: 1.5022 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5303 - acc: 0.9336 - precision: 0.9865 - recall: 0.8777 - f1_score: 0.9276 - val_loss: 1.4955 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5236 - acc: 0.9336 - precision: 0.9847 - recall: 0.8790 - f1_score: 0.9281 - val_loss: 1.4888 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5170 - acc: 0.9336 - precision: 0.9861 - recall: 0.8764 - f1_score: 0.9266 - val_loss: 1.4822 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5104 - acc: 0.9336 - precision: 0.9867 - recall: 0.8785 - f1_score: 0.9282 - val_loss: 1.4756 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5038 - acc: 0.9336 - precision: 0.9855 - recall: 0.8792 - f1_score: 0.9281 - val_loss: 1.4690 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4972 - acc: 0.9336 - precision: 0.9852 - recall: 0.8783 - f1_score: 0.9272 - val_loss: 1.4625 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4907 - acc: 0.9336 - precision: 0.9872 - recall: 0.8723 - f1_score: 0.9246 - val_loss: 1.4560 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4842 - acc: 0.9336 - precision: 0.9836 - recall: 0.8747 - f1_score: 0.9250 - val_loss: 1.4495 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4778 - acc: 0.9336 - precision: 0.9883 - recall: 0.8767 - f1_score: 0.9286 - val_loss: 1.4431 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4713 - acc: 0.9336 - precision: 0.9859 - recall: 0.8777 - f1_score: 0.9269 - val_loss: 1.4367 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4650 - acc: 0.9336 - precision: 0.9851 - recall: 0.8775 - f1_score: 0.9270 - val_loss: 1.4304 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4586 - acc: 0.9336 - precision: 0.9851 - recall: 0.8784 - f1_score: 0.9279 - val_loss: 1.4240 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4523 - acc: 0.9336 - precision: 0.9858 - recall: 0.8758 - f1_score: 0.9265 - val_loss: 1.4177 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4460 - acc: 0.9336 - precision: 0.9849 - recall: 0.8758 - f1_score: 0.9264 - val_loss: 1.4115 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4397 - acc: 0.9336 - precision: 0.9868 - recall: 0.8799 - f1_score: 0.9286 - val_loss: 1.4052 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4335 - acc: 0.9336 - precision: 0.9854 - recall: 0.8803 - f1_score: 0.9289 - val_loss: 1.3990 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4273 - acc: 0.9336 - precision: 0.9849 - recall: 0.8773 - f1_score: 0.9274 - val_loss: 1.3928 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4212 - acc: 0.9336 - precision: 0.9855 - recall: 0.8795 - f1_score: 0.9287 - val_loss: 1.3867 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4150 - acc: 0.9336 - precision: 0.9847 - recall: 0.8788 - f1_score: 0.9279 - val_loss: 1.3806 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4089 - acc: 0.9336 - precision: 0.9860 - recall: 0.8786 - f1_score: 0.9282 - val_loss: 1.3745 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4029 - acc: 0.9336 - precision: 0.9872 - recall: 0.8794 - f1_score: 0.9293 - val_loss: 1.3685 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3968 - acc: 0.9336 - precision: 0.9838 - recall: 0.8770 - f1_score: 0.9264 - val_loss: 1.3625 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3908 - acc: 0.9336 - precision: 0.9868 - recall: 0.8803 - f1_score: 0.9292 - val_loss: 1.3565 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3848 - acc: 0.9336 - precision: 0.9847 - recall: 0.8795 - f1_score: 0.9285 - val_loss: 1.3505 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3789 - acc: 0.9336 - precision: 0.9864 - recall: 0.8782 - f1_score: 0.9274 - val_loss: 1.3446 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3730 - acc: 0.9336 - precision: 0.9863 - recall: 0.8778 - f1_score: 0.9277 - val_loss: 1.3387 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3671 - acc: 0.9336 - precision: 0.9868 - recall: 0.8799 - f1_score: 0.9283 - val_loss: 1.3329 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3613 - acc: 0.9336 - precision: 0.9879 - recall: 0.8809 - f1_score: 0.9287 - val_loss: 1.3271 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3554 - acc: 0.9336 - precision: 0.9853 - recall: 0.8806 - f1_score: 0.9288 - val_loss: 1.3213 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3496 - acc: 0.9336 - precision: 0.9854 - recall: 0.8794 - f1_score: 0.9283 - val_loss: 1.3155 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3439 - acc: 0.9336 - precision: 0.9860 - recall: 0.8806 - f1_score: 0.9287 - val_loss: 1.3098 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3382 - acc: 0.9336 - precision: 0.9853 - recall: 0.8757 - f1_score: 0.9260 - val_loss: 1.3041 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3325 - acc: 0.9336 - precision: 0.9866 - recall: 0.8792 - f1_score: 0.9277 - val_loss: 1.2984 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3268 - acc: 0.9336 - precision: 0.9871 - recall: 0.8772 - f1_score: 0.9274 - val_loss: 1.2927 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3211 - acc: 0.9336 - precision: 0.9828 - recall: 0.8735 - f1_score: 0.9242 - val_loss: 1.2871 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3155 - acc: 0.9336 - precision: 0.9853 - recall: 0.8740 - f1_score: 0.9250 - val_loss: 1.2815 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3099 - acc: 0.9336 - precision: 0.9861 - recall: 0.8780 - f1_score: 0.9281 - val_loss: 1.2759 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3044 - acc: 0.9336 - precision: 0.9858 - recall: 0.8798 - f1_score: 0.9280 - val_loss: 1.2704 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2988 - acc: 0.9336 - precision: 0.9869 - recall: 0.8806 - f1_score: 0.9286 - val_loss: 1.2649 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2933 - acc: 0.9336 - precision: 0.9854 - recall: 0.8755 - f1_score: 0.9265 - val_loss: 1.2594 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2879 - acc: 0.9336 - precision: 0.9877 - recall: 0.8829 - f1_score: 0.9300 - val_loss: 1.2540 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2824 - acc: 0.9336 - precision: 0.9874 - recall: 0.8808 - f1_score: 0.9288 - val_loss: 1.2485 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2770 - acc: 0.9336 - precision: 0.9869 - recall: 0.8819 - f1_score: 0.9300 - val_loss: 1.2431 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2716 - acc: 0.9336 - precision: 0.9856 - recall: 0.8794 - f1_score: 0.9283 - val_loss: 1.2378 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2663 - acc: 0.9336 - precision: 0.9854 - recall: 0.8803 - f1_score: 0.9281 - val_loss: 1.2324 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2609 - acc: 0.9336 - precision: 0.9851 - recall: 0.8816 - f1_score: 0.9284 - val_loss: 1.2271 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2556 - acc: 0.9336 - precision: 0.9868 - recall: 0.8751 - f1_score: 0.9258 - val_loss: 1.2218 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2503 - acc: 0.9336 - precision: 0.9866 - recall: 0.8805 - f1_score: 0.9290 - val_loss: 1.2165 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2451 - acc: 0.9336 - precision: 0.9869 - recall: 0.8815 - f1_score: 0.9303 - val_loss: 1.2113 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2399 - acc: 0.9336 - precision: 0.9856 - recall: 0.8811 - f1_score: 0.9283 - val_loss: 1.2061 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2347 - acc: 0.9336 - precision: 0.9865 - recall: 0.8804 - f1_score: 0.9289 - val_loss: 1.2009 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2295 - acc: 0.9336 - precision: 0.9853 - recall: 0.8802 - f1_score: 0.9281 - val_loss: 1.1958 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2244 - acc: 0.9336 - precision: 0.9862 - recall: 0.8791 - f1_score: 0.9278 - val_loss: 1.1906 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2192 - acc: 0.9336 - precision: 0.9830 - recall: 0.8781 - f1_score: 0.9261 - val_loss: 1.1855 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2141 - acc: 0.9336 - precision: 0.9857 - recall: 0.8772 - f1_score: 0.9275 - val_loss: 1.1805 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2091 - acc: 0.9336 - precision: 0.9866 - recall: 0.8775 - f1_score: 0.9275 - val_loss: 1.1754 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2040 - acc: 0.9336 - precision: 0.9856 - recall: 0.8763 - f1_score: 0.9269 - val_loss: 1.1704 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1990 - acc: 0.9336 - precision: 0.9867 - recall: 0.8815 - f1_score: 0.9297 - val_loss: 1.1654 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1940 - acc: 0.9336 - precision: 0.9863 - recall: 0.8810 - f1_score: 0.9297 - val_loss: 1.1604 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1891 - acc: 0.9336 - precision: 0.9868 - recall: 0.8788 - f1_score: 0.9284 - val_loss: 1.1555 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1841 - acc: 0.9336 - precision: 0.9839 - recall: 0.8793 - f1_score: 0.9276 - val_loss: 1.1506 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1792 - acc: 0.9336 - precision: 0.9864 - recall: 0.8826 - f1_score: 0.9304 - val_loss: 1.1457 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1743 - acc: 0.9336 - precision: 0.9864 - recall: 0.8831 - f1_score: 0.9306 - val_loss: 1.1408 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1695 - acc: 0.9336 - precision: 0.9840 - recall: 0.8785 - f1_score: 0.9271 - val_loss: 1.1360 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1646 - acc: 0.9336 - precision: 0.9873 - recall: 0.8774 - f1_score: 0.9272 - val_loss: 1.1311 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1598 - acc: 0.9336 - precision: 0.9848 - recall: 0.8813 - f1_score: 0.9292 - val_loss: 1.1263 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1550 - acc: 0.9336 - precision: 0.9862 - recall: 0.8748 - f1_score: 0.9253 - val_loss: 1.1216 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1503 - acc: 0.9336 - precision: 0.9868 - recall: 0.8746 - f1_score: 0.9260 - val_loss: 1.1168 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1455 - acc: 0.9336 - precision: 0.9862 - recall: 0.8800 - f1_score: 0.9291 - val_loss: 1.1121 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1408 - acc: 0.9336 - precision: 0.9860 - recall: 0.8774 - f1_score: 0.9276 - val_loss: 1.1074 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1361 - acc: 0.9336 - precision: 0.9857 - recall: 0.8780 - f1_score: 0.9281 - val_loss: 1.1027 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1315 - acc: 0.9336 - precision: 0.9855 - recall: 0.8823 - f1_score: 0.9290 - val_loss: 1.0981 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1268 - acc: 0.9336 - precision: 0.9845 - recall: 0.8779 - f1_score: 0.9272 - val_loss: 1.0935 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1222 - acc: 0.9336 - precision: 0.9861 - recall: 0.8783 - f1_score: 0.9284 - val_loss: 1.0888 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1176 - acc: 0.9336 - precision: 0.9858 - recall: 0.8788 - f1_score: 0.9281 - val_loss: 1.0843 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1130 - acc: 0.9336 - precision: 0.9838 - recall: 0.8771 - f1_score: 0.9256 - val_loss: 1.0797 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1085 - acc: 0.9336 - precision: 0.9847 - recall: 0.8763 - f1_score: 0.9266 - val_loss: 1.0752 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1040 - acc: 0.9336 - precision: 0.9871 - recall: 0.8763 - f1_score: 0.9260 - val_loss: 1.0707 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0995 - acc: 0.9336 - precision: 0.9849 - recall: 0.8819 - f1_score: 0.9295 - val_loss: 1.0662 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0950 - acc: 0.9336 - precision: 0.9851 - recall: 0.8778 - f1_score: 0.9272 - val_loss: 1.0617 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0905 - acc: 0.9336 - precision: 0.9848 - recall: 0.8813 - f1_score: 0.9291 - val_loss: 1.0573 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0861 - acc: 0.9336 - precision: 0.9862 - recall: 0.8792 - f1_score: 0.9286 - val_loss: 1.0529 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0817 - acc: 0.9336 - precision: 0.9867 - recall: 0.8823 - f1_score: 0.9300 - val_loss: 1.0485 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0773 - acc: 0.9336 - precision: 0.9852 - recall: 0.8784 - f1_score: 0.9271 - val_loss: 1.0441 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0729 - acc: 0.9336 - precision: 0.9861 - recall: 0.8796 - f1_score: 0.9289 - val_loss: 1.0397 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0686 - acc: 0.9336 - precision: 0.9869 - recall: 0.8825 - f1_score: 0.9308 - val_loss: 1.0354 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0643 - acc: 0.9336 - precision: 0.9871 - recall: 0.8790 - f1_score: 0.9285 - val_loss: 1.0311 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0600 - acc: 0.9336 - precision: 0.9840 - recall: 0.8820 - f1_score: 0.9297 - val_loss: 1.0268 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0557 - acc: 0.9336 - precision: 0.9850 - recall: 0.8794 - f1_score: 0.9278 - val_loss: 1.0225 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0515 - acc: 0.9336 - precision: 0.9846 - recall: 0.8786 - f1_score: 0.9266 - val_loss: 1.0183 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0472 - acc: 0.9336 - precision: 0.9846 - recall: 0.8820 - f1_score: 0.9300 - val_loss: 1.0141 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0430 - acc: 0.9336 - precision: 0.9836 - recall: 0.8775 - f1_score: 0.9266 - val_loss: 1.0099 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0388 - acc: 0.9336 - precision: 0.9849 - recall: 0.8740 - f1_score: 0.9255 - val_loss: 1.0057 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0347 - acc: 0.9336 - precision: 0.9860 - recall: 0.8830 - f1_score: 0.9296 - val_loss: 1.0016 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0305 - acc: 0.9336 - precision: 0.9869 - recall: 0.8799 - f1_score: 0.9286 - val_loss: 0.9974 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0264 - acc: 0.9336 - precision: 0.9865 - recall: 0.8825 - f1_score: 0.9299 - val_loss: 0.9933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0223 - acc: 0.9336 - precision: 0.9854 - recall: 0.8759 - f1_score: 0.9269 - val_loss: 0.9892 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0182 - acc: 0.9336 - precision: 0.9855 - recall: 0.8817 - f1_score: 0.9293 - val_loss: 0.9851 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0141 - acc: 0.9336 - precision: 0.9859 - recall: 0.8762 - f1_score: 0.9262 - val_loss: 0.9811 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0101 - acc: 0.9336 - precision: 0.9880 - recall: 0.8788 - f1_score: 0.9291 - val_loss: 0.9771 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0061 - acc: 0.9336 - precision: 0.9863 - recall: 0.8731 - f1_score: 0.9249 - val_loss: 0.9731 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0021 - acc: 0.9336 - precision: 0.9847 - recall: 0.8789 - f1_score: 0.9279 - val_loss: 0.9691 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9981 - acc: 0.9336 - precision: 0.9857 - recall: 0.8796 - f1_score: 0.9281 - val_loss: 0.9651 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9941 - acc: 0.9336 - precision: 0.9859 - recall: 0.8772 - f1_score: 0.9268 - val_loss: 0.9612 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9902 - acc: 0.9336 - precision: 0.9855 - recall: 0.8809 - f1_score: 0.9291 - val_loss: 0.9572 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9863 - acc: 0.9336 - precision: 0.9852 - recall: 0.8763 - f1_score: 0.9254 - val_loss: 0.9533 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9824 - acc: 0.9336 - precision: 0.9871 - recall: 0.8830 - f1_score: 0.9306 - val_loss: 0.9494 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9785 - acc: 0.9336 - precision: 0.9837 - recall: 0.8776 - f1_score: 0.9263 - val_loss: 0.9456 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9746 - acc: 0.9336 - precision: 0.9864 - recall: 0.8789 - f1_score: 0.9291 - val_loss: 0.9417 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9708 - acc: 0.9336 - precision: 0.9837 - recall: 0.8798 - f1_score: 0.9276 - val_loss: 0.9379 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9669 - acc: 0.9336 - precision: 0.9864 - recall: 0.8758 - f1_score: 0.9253 - val_loss: 0.9341 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9631 - acc: 0.9336 - precision: 0.9869 - recall: 0.8826 - f1_score: 0.9304 - val_loss: 0.9303 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9594 - acc: 0.9336 - precision: 0.9847 - recall: 0.8787 - f1_score: 0.9275 - val_loss: 0.9265 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9556 - acc: 0.9336 - precision: 0.9840 - recall: 0.8717 - f1_score: 0.9218 - val_loss: 0.9227 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9519 - acc: 0.9336 - precision: 0.9823 - recall: 0.8790 - f1_score: 0.9270 - val_loss: 0.9190 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9481 - acc: 0.9336 - precision: 0.9856 - recall: 0.8733 - f1_score: 0.9236 - val_loss: 0.9153 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9444 - acc: 0.9336 - precision: 0.9859 - recall: 0.8786 - f1_score: 0.9286 - val_loss: 0.9116 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9407 - acc: 0.9336 - precision: 0.9829 - recall: 0.8743 - f1_score: 0.9236 - val_loss: 0.9079 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9371 - acc: 0.9336 - precision: 0.9873 - recall: 0.8815 - f1_score: 0.9303 - val_loss: 0.9042 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9334 - acc: 0.9336 - precision: 0.9858 - recall: 0.8793 - f1_score: 0.9268 - val_loss: 0.9006 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9298 - acc: 0.9336 - precision: 0.9868 - recall: 0.8793 - f1_score: 0.9285 - val_loss: 0.8970 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9262 - acc: 0.9336 - precision: 0.9856 - recall: 0.8801 - f1_score: 0.9291 - val_loss: 0.8934 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9226 - acc: 0.9336 - precision: 0.9847 - recall: 0.8794 - f1_score: 0.9279 - val_loss: 0.8898 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9190 - acc: 0.9336 - precision: 0.9861 - recall: 0.8788 - f1_score: 0.9279 - val_loss: 0.8862 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9154 - acc: 0.9336 - precision: 0.9870 - recall: 0.8766 - f1_score: 0.9276 - val_loss: 0.8827 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9119 - acc: 0.9336 - precision: 0.9855 - recall: 0.8769 - f1_score: 0.9268 - val_loss: 0.8791 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9084 - acc: 0.9336 - precision: 0.9861 - recall: 0.8820 - f1_score: 0.9296 - val_loss: 0.8756 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9049 - acc: 0.9336 - precision: 0.9848 - recall: 0.8808 - f1_score: 0.9287 - val_loss: 0.8721 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9014 - acc: 0.9336 - precision: 0.9861 - recall: 0.8831 - f1_score: 0.9301 - val_loss: 0.8686 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8979 - acc: 0.9336 - precision: 0.9869 - recall: 0.8768 - f1_score: 0.9268 - val_loss: 0.8652 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8945 - acc: 0.9336 - precision: 0.9841 - recall: 0.8772 - f1_score: 0.9265 - val_loss: 0.8617 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8910 - acc: 0.9336 - precision: 0.9844 - recall: 0.8786 - f1_score: 0.9274 - val_loss: 0.8583 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8876 - acc: 0.9336 - precision: 0.9859 - recall: 0.8772 - f1_score: 0.9263 - val_loss: 0.8549 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8842 - acc: 0.9336 - precision: 0.9845 - recall: 0.8802 - f1_score: 0.9282 - val_loss: 0.8515 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8808 - acc: 0.9336 - precision: 0.9849 - recall: 0.8773 - f1_score: 0.9269 - val_loss: 0.8481 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8775 - acc: 0.9336 - precision: 0.9856 - recall: 0.8785 - f1_score: 0.9281 - val_loss: 0.8448 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8741 - acc: 0.9336 - precision: 0.9879 - recall: 0.8766 - f1_score: 0.9275 - val_loss: 0.8414 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8708 - acc: 0.9336 - precision: 0.9821 - recall: 0.8769 - f1_score: 0.9254 - val_loss: 0.8381 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8675 - acc: 0.9336 - precision: 0.9867 - recall: 0.8810 - f1_score: 0.9301 - val_loss: 0.8348 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8642 - acc: 0.9336 - precision: 0.9875 - recall: 0.8796 - f1_score: 0.9289 - val_loss: 0.8315 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8609 - acc: 0.9336 - precision: 0.9852 - recall: 0.8800 - f1_score: 0.9288 - val_loss: 0.8283 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8577 - acc: 0.9336 - precision: 0.9861 - recall: 0.8774 - f1_score: 0.9266 - val_loss: 0.8250 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8544 - acc: 0.9336 - precision: 0.9865 - recall: 0.8775 - f1_score: 0.9269 - val_loss: 0.8218 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8512 - acc: 0.9352 - precision: 0.9859 - recall: 0.8863 - f1_score: 0.9324 - val_loss: 0.8185 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8480 - acc: 0.9352 - precision: 0.9844 - recall: 0.8807 - f1_score: 0.9289 - val_loss: 0.8153 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8448 - acc: 0.9336 - precision: 0.9854 - recall: 0.8779 - f1_score: 0.9268 - val_loss: 0.8121 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8416 - acc: 0.9352 - precision: 0.9865 - recall: 0.8855 - f1_score: 0.9322 - val_loss: 0.8090 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8384 - acc: 0.9352 - precision: 0.9840 - recall: 0.8805 - f1_score: 0.9275 - val_loss: 0.8058 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8353 - acc: 0.9352 - precision: 0.9863 - recall: 0.8830 - f1_score: 0.9297 - val_loss: 0.8027 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8321 - acc: 0.9352 - precision: 0.9845 - recall: 0.8887 - f1_score: 0.9324 - val_loss: 0.7995 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8290 - acc: 0.9352 - precision: 0.9878 - recall: 0.8846 - f1_score: 0.9321 - val_loss: 0.7964 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8259 - acc: 0.9352 - precision: 0.9862 - recall: 0.8792 - f1_score: 0.9283 - val_loss: 0.7933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8228 - acc: 0.9352 - precision: 0.9834 - recall: 0.8854 - f1_score: 0.9306 - val_loss: 0.7903 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8198 - acc: 0.9352 - precision: 0.9875 - recall: 0.8801 - f1_score: 0.9295 - val_loss: 0.7872 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8167 - acc: 0.9352 - precision: 0.9862 - recall: 0.8848 - f1_score: 0.9305 - val_loss: 0.7841 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8137 - acc: 0.9352 - precision: 0.9861 - recall: 0.8816 - f1_score: 0.9299 - val_loss: 0.7811 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8106 - acc: 0.9352 - precision: 0.9868 - recall: 0.8765 - f1_score: 0.9272 - val_loss: 0.7781 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8076 - acc: 0.9352 - precision: 0.9854 - recall: 0.8772 - f1_score: 0.9267 - val_loss: 0.7751 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8046 - acc: 0.9352 - precision: 0.9848 - recall: 0.8821 - f1_score: 0.9295 - val_loss: 0.7721 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8017 - acc: 0.9352 - precision: 0.9867 - recall: 0.8807 - f1_score: 0.9296 - val_loss: 0.7691 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7987 - acc: 0.9352 - precision: 0.9864 - recall: 0.8833 - f1_score: 0.9311 - val_loss: 0.7662 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7957 - acc: 0.9352 - precision: 0.9851 - recall: 0.8801 - f1_score: 0.9290 - val_loss: 0.7632 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7928 - acc: 0.9352 - precision: 0.9836 - recall: 0.8804 - f1_score: 0.9279 - val_loss: 0.7603 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7899 - acc: 0.9352 - precision: 0.9864 - recall: 0.8759 - f1_score: 0.9259 - val_loss: 0.7574 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7870 - acc: 0.9352 - precision: 0.9842 - recall: 0.8774 - f1_score: 0.9269 - val_loss: 0.7545 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7841 - acc: 0.9352 - precision: 0.9867 - recall: 0.8851 - f1_score: 0.9321 - val_loss: 0.7516 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7812 - acc: 0.9352 - precision: 0.9856 - recall: 0.8822 - f1_score: 0.9305 - val_loss: 0.7487 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7784 - acc: 0.9352 - precision: 0.9859 - recall: 0.8859 - f1_score: 0.9313 - val_loss: 0.7458 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7755 - acc: 0.9352 - precision: 0.9866 - recall: 0.8802 - f1_score: 0.9297 - val_loss: 0.7430 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7727 - acc: 0.9352 - precision: 0.9849 - recall: 0.8869 - f1_score: 0.9309 - val_loss: 0.7402 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7699 - acc: 0.9352 - precision: 0.9854 - recall: 0.8861 - f1_score: 0.9316 - val_loss: 0.7374 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7671 - acc: 0.9352 - precision: 0.9858 - recall: 0.8790 - f1_score: 0.9276 - val_loss: 0.7346 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7643 - acc: 0.9352 - precision: 0.9857 - recall: 0.8827 - f1_score: 0.9306 - val_loss: 0.7318 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7615 - acc: 0.9352 - precision: 0.9862 - recall: 0.8789 - f1_score: 0.9286 - val_loss: 0.7290 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7588 - acc: 0.9352 - precision: 0.9871 - recall: 0.8840 - f1_score: 0.9312 - val_loss: 0.7262 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7560 - acc: 0.9352 - precision: 0.9856 - recall: 0.8816 - f1_score: 0.9295 - val_loss: 0.7235 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7533 - acc: 0.9352 - precision: 0.9865 - recall: 0.8800 - f1_score: 0.9286 - val_loss: 0.7208 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7506 - acc: 0.9352 - precision: 0.9857 - recall: 0.8797 - f1_score: 0.9278 - val_loss: 0.7181 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7478 - acc: 0.9352 - precision: 0.9879 - recall: 0.8800 - f1_score: 0.9296 - val_loss: 0.7154 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7452 - acc: 0.9352 - precision: 0.9875 - recall: 0.8777 - f1_score: 0.9277 - val_loss: 0.7127 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7425 - acc: 0.9352 - precision: 0.9859 - recall: 0.8788 - f1_score: 0.9271 - val_loss: 0.7100 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7398 - acc: 0.9352 - precision: 0.9841 - recall: 0.8823 - f1_score: 0.9299 - val_loss: 0.7073 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7372 - acc: 0.9352 - precision: 0.9869 - recall: 0.8800 - f1_score: 0.9294 - val_loss: 0.7047 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7345 - acc: 0.9352 - precision: 0.9848 - recall: 0.8792 - f1_score: 0.9280 - val_loss: 0.7021 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7319 - acc: 0.9352 - precision: 0.9877 - recall: 0.8818 - f1_score: 0.9312 - val_loss: 0.6994 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7293 - acc: 0.9352 - precision: 0.9871 - recall: 0.8820 - f1_score: 0.9306 - val_loss: 0.6968 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7267 - acc: 0.9352 - precision: 0.9870 - recall: 0.8812 - f1_score: 0.9305 - val_loss: 0.6942 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7241 - acc: 0.9352 - precision: 0.9852 - recall: 0.8807 - f1_score: 0.9289 - val_loss: 0.6916 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7215 - acc: 0.9352 - precision: 0.9862 - recall: 0.8819 - f1_score: 0.9304 - val_loss: 0.6891 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7190 - acc: 0.9352 - precision: 0.9845 - recall: 0.8767 - f1_score: 0.9256 - val_loss: 0.6865 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7164 - acc: 0.9352 - precision: 0.9856 - recall: 0.8790 - f1_score: 0.9287 - val_loss: 0.6840 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7139 - acc: 0.9352 - precision: 0.9869 - recall: 0.8811 - f1_score: 0.9288 - val_loss: 0.6814 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7114 - acc: 0.9352 - precision: 0.9845 - recall: 0.8798 - f1_score: 0.9273 - val_loss: 0.6789 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7089 - acc: 0.9352 - precision: 0.9853 - recall: 0.8796 - f1_score: 0.9282 - val_loss: 0.6764 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7064 - acc: 0.9352 - precision: 0.9860 - recall: 0.8816 - f1_score: 0.9299 - val_loss: 0.6739 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7039 - acc: 0.9352 - precision: 0.9861 - recall: 0.8825 - f1_score: 0.9307 - val_loss: 0.6714 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7014 - acc: 0.9352 - precision: 0.9865 - recall: 0.8832 - f1_score: 0.9305 - val_loss: 0.6690 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6990 - acc: 0.9352 - precision: 0.9854 - recall: 0.8822 - f1_score: 0.9299 - val_loss: 0.6665 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6965 - acc: 0.9352 - precision: 0.9864 - recall: 0.8807 - f1_score: 0.9287 - val_loss: 0.6641 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6941 - acc: 0.9352 - precision: 0.9858 - recall: 0.8793 - f1_score: 0.9280 - val_loss: 0.6616 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6917 - acc: 0.9352 - precision: 0.9859 - recall: 0.8846 - f1_score: 0.9311 - val_loss: 0.6592 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6892 - acc: 0.9352 - precision: 0.9848 - recall: 0.8827 - f1_score: 0.9290 - val_loss: 0.6568 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6868 - acc: 0.9352 - precision: 0.9852 - recall: 0.8787 - f1_score: 0.9275 - val_loss: 0.6544 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6845 - acc: 0.9352 - precision: 0.9872 - recall: 0.8791 - f1_score: 0.9287 - val_loss: 0.6520 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6821 - acc: 0.9352 - precision: 0.9872 - recall: 0.8788 - f1_score: 0.9279 - val_loss: 0.6497 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 485/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6797 - acc: 0.9352 - precision: 0.9857 - recall: 0.8810 - f1_score: 0.9293 - val_loss: 0.6473 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6774 - acc: 0.9352 - precision: 0.9858 - recall: 0.8828 - f1_score: 0.9297 - val_loss: 0.6449 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6750 - acc: 0.9352 - precision: 0.9873 - recall: 0.8791 - f1_score: 0.9286 - val_loss: 0.6426 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6727 - acc: 0.9352 - precision: 0.9837 - recall: 0.8797 - f1_score: 0.9280 - val_loss: 0.6403 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6704 - acc: 0.9352 - precision: 0.9862 - recall: 0.8787 - f1_score: 0.9287 - val_loss: 0.6380 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6681 - acc: 0.9352 - precision: 0.9841 - recall: 0.8852 - f1_score: 0.9306 - val_loss: 0.6357 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6658 - acc: 0.9352 - precision: 0.9869 - recall: 0.8838 - f1_score: 0.9310 - val_loss: 0.6334 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6635 - acc: 0.9352 - precision: 0.9863 - recall: 0.8770 - f1_score: 0.9258 - val_loss: 0.6311 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6613 - acc: 0.9352 - precision: 0.9868 - recall: 0.8766 - f1_score: 0.9256 - val_loss: 0.6288 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6590 - acc: 0.9352 - precision: 0.9853 - recall: 0.8799 - f1_score: 0.9284 - val_loss: 0.6266 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6568 - acc: 0.9352 - precision: 0.9856 - recall: 0.8813 - f1_score: 0.9293 - val_loss: 0.6243 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6545 - acc: 0.9352 - precision: 0.9858 - recall: 0.8796 - f1_score: 0.9281 - val_loss: 0.6221 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6523 - acc: 0.9352 - precision: 0.9865 - recall: 0.8824 - f1_score: 0.9299 - val_loss: 0.6199 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6501 - acc: 0.9352 - precision: 0.9866 - recall: 0.8814 - f1_score: 0.9302 - val_loss: 0.6177 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6479 - acc: 0.9352 - precision: 0.9846 - recall: 0.8811 - f1_score: 0.9290 - val_loss: 0.6155 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6457 - acc: 0.9352 - precision: 0.9858 - recall: 0.8825 - f1_score: 0.9303 - val_loss: 0.6133 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6435 - acc: 0.9352 - precision: 0.9855 - recall: 0.8791 - f1_score: 0.9279 - val_loss: 0.6111 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6413 - acc: 0.9352 - precision: 0.9854 - recall: 0.8817 - f1_score: 0.9296 - val_loss: 0.6089 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6392 - acc: 0.9352 - precision: 0.9852 - recall: 0.8832 - f1_score: 0.9304 - val_loss: 0.6068 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6370 - acc: 0.9352 - precision: 0.9866 - recall: 0.8849 - f1_score: 0.9314 - val_loss: 0.6046 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6349 - acc: 0.9352 - precision: 0.9857 - recall: 0.8824 - f1_score: 0.9300 - val_loss: 0.6025 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6328 - acc: 0.9352 - precision: 0.9847 - recall: 0.8825 - f1_score: 0.9295 - val_loss: 0.6004 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6307 - acc: 0.9352 - precision: 0.9835 - recall: 0.8800 - f1_score: 0.9266 - val_loss: 0.5983 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6286 - acc: 0.9352 - precision: 0.9860 - recall: 0.8861 - f1_score: 0.9321 - val_loss: 0.5962 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6265 - acc: 0.9352 - precision: 0.9837 - recall: 0.8870 - f1_score: 0.9312 - val_loss: 0.5941 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6244 - acc: 0.9352 - precision: 0.9864 - recall: 0.8820 - f1_score: 0.9300 - val_loss: 0.5920 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6223 - acc: 0.9352 - precision: 0.9863 - recall: 0.8819 - f1_score: 0.9301 - val_loss: 0.5899 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6202 - acc: 0.9352 - precision: 0.9848 - recall: 0.8807 - f1_score: 0.9289 - val_loss: 0.5878 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6182 - acc: 0.9352 - precision: 0.9850 - recall: 0.8851 - f1_score: 0.9316 - val_loss: 0.5858 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6162 - acc: 0.9352 - precision: 0.9869 - recall: 0.8831 - f1_score: 0.9294 - val_loss: 0.5837 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6141 - acc: 0.9352 - precision: 0.9854 - recall: 0.8859 - f1_score: 0.9318 - val_loss: 0.5817 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6121 - acc: 0.9352 - precision: 0.9867 - recall: 0.8810 - f1_score: 0.9291 - val_loss: 0.5797 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6101 - acc: 0.9352 - precision: 0.9856 - recall: 0.8825 - f1_score: 0.9304 - val_loss: 0.5777 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6081 - acc: 0.9352 - precision: 0.9868 - recall: 0.8798 - f1_score: 0.9284 - val_loss: 0.5757 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6061 - acc: 0.9352 - precision: 0.9854 - recall: 0.8855 - f1_score: 0.9317 - val_loss: 0.5737 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6041 - acc: 0.9352 - precision: 0.9847 - recall: 0.8822 - f1_score: 0.9297 - val_loss: 0.5717 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6021 - acc: 0.9352 - precision: 0.9875 - recall: 0.8848 - f1_score: 0.9319 - val_loss: 0.5697 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6002 - acc: 0.9352 - precision: 0.9845 - recall: 0.8789 - f1_score: 0.9281 - val_loss: 0.5678 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5982 - acc: 0.9352 - precision: 0.9837 - recall: 0.8806 - f1_score: 0.9285 - val_loss: 0.5658 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5963 - acc: 0.9352 - precision: 0.9861 - recall: 0.8835 - f1_score: 0.9304 - val_loss: 0.5639 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5943 - acc: 0.9352 - precision: 0.9848 - recall: 0.8803 - f1_score: 0.9285 - val_loss: 0.5619 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5924 - acc: 0.9352 - precision: 0.9884 - recall: 0.8789 - f1_score: 0.9288 - val_loss: 0.5600 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5905 - acc: 0.9352 - precision: 0.9861 - recall: 0.8832 - f1_score: 0.9307 - val_loss: 0.5581 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5886 - acc: 0.9352 - precision: 0.9868 - recall: 0.8832 - f1_score: 0.9308 - val_loss: 0.5562 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5867 - acc: 0.9352 - precision: 0.9854 - recall: 0.8832 - f1_score: 0.9303 - val_loss: 0.5543 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5848 - acc: 0.9352 - precision: 0.9877 - recall: 0.8876 - f1_score: 0.9333 - val_loss: 0.5524 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5829 - acc: 0.9352 - precision: 0.9865 - recall: 0.8829 - f1_score: 0.9301 - val_loss: 0.5505 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5811 - acc: 0.9352 - precision: 0.9873 - recall: 0.8838 - f1_score: 0.9320 - val_loss: 0.5487 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5792 - acc: 0.9352 - precision: 0.9865 - recall: 0.8834 - f1_score: 0.9298 - val_loss: 0.5468 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5774 - acc: 0.9352 - precision: 0.9865 - recall: 0.8817 - f1_score: 0.9298 - val_loss: 0.5449 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5755 - acc: 0.9352 - precision: 0.9864 - recall: 0.8853 - f1_score: 0.9309 - val_loss: 0.5431 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5737 - acc: 0.9352 - precision: 0.9874 - recall: 0.8784 - f1_score: 0.9281 - val_loss: 0.5413 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5719 - acc: 0.9352 - precision: 0.9858 - recall: 0.8844 - f1_score: 0.9316 - val_loss: 0.5394 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5701 - acc: 0.9352 - precision: 0.9828 - recall: 0.8809 - f1_score: 0.9281 - val_loss: 0.5376 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5683 - acc: 0.9352 - precision: 0.9832 - recall: 0.8795 - f1_score: 0.9277 - val_loss: 0.5358 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5665 - acc: 0.9352 - precision: 0.9858 - recall: 0.8762 - f1_score: 0.9264 - val_loss: 0.5340 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5647 - acc: 0.9352 - precision: 0.9843 - recall: 0.8807 - f1_score: 0.9278 - val_loss: 0.5322 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5629 - acc: 0.9352 - precision: 0.9860 - recall: 0.8768 - f1_score: 0.9271 - val_loss: 0.5304 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5611 - acc: 0.9352 - precision: 0.9847 - recall: 0.8812 - f1_score: 0.9292 - val_loss: 0.5287 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5594 - acc: 0.9352 - precision: 0.9854 - recall: 0.8818 - f1_score: 0.9300 - val_loss: 0.5269 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5576 - acc: 0.9352 - precision: 0.9876 - recall: 0.8834 - f1_score: 0.9299 - val_loss: 0.5252 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5559 - acc: 0.9352 - precision: 0.9859 - recall: 0.8874 - f1_score: 0.9319 - val_loss: 0.5234 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5542 - acc: 0.9352 - precision: 0.9873 - recall: 0.8821 - f1_score: 0.9293 - val_loss: 0.5217 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5524 - acc: 0.9352 - precision: 0.9830 - recall: 0.8811 - f1_score: 0.9282 - val_loss: 0.5200 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 549/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5507 - acc: 0.9352 - precision: 0.9851 - recall: 0.8851 - f1_score: 0.9319 - val_loss: 0.5182 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5490 - acc: 0.9352 - precision: 0.9878 - recall: 0.8822 - f1_score: 0.9302 - val_loss: 0.5165 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5473 - acc: 0.9352 - precision: 0.9870 - recall: 0.8801 - f1_score: 0.9281 - val_loss: 0.5148 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5456 - acc: 0.9352 - precision: 0.9852 - recall: 0.8823 - f1_score: 0.9295 - val_loss: 0.5131 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5439 - acc: 0.9352 - precision: 0.9877 - recall: 0.8823 - f1_score: 0.9302 - val_loss: 0.5114 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5423 - acc: 0.9352 - precision: 0.9841 - recall: 0.8839 - f1_score: 0.9304 - val_loss: 0.5098 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5406 - acc: 0.9352 - precision: 0.9846 - recall: 0.8826 - f1_score: 0.9292 - val_loss: 0.5081 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5390 - acc: 0.9352 - precision: 0.9857 - recall: 0.8810 - f1_score: 0.9288 - val_loss: 0.5064 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5373 - acc: 0.9352 - precision: 0.9848 - recall: 0.8850 - f1_score: 0.9303 - val_loss: 0.5048 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5357 - acc: 0.9352 - precision: 0.9846 - recall: 0.8798 - f1_score: 0.9279 - val_loss: 0.5031 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5340 - acc: 0.9352 - precision: 0.9855 - recall: 0.8802 - f1_score: 0.9292 - val_loss: 0.5015 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5324 - acc: 0.9352 - precision: 0.9868 - recall: 0.8818 - f1_score: 0.9298 - val_loss: 0.4998 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5308 - acc: 0.9352 - precision: 0.9864 - recall: 0.8758 - f1_score: 0.9247 - val_loss: 0.4982 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5292 - acc: 0.9352 - precision: 0.9876 - recall: 0.8819 - f1_score: 0.9305 - val_loss: 0.4966 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5276 - acc: 0.9352 - precision: 0.9844 - recall: 0.8821 - f1_score: 0.9291 - val_loss: 0.4950 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5260 - acc: 0.9352 - precision: 0.9850 - recall: 0.8788 - f1_score: 0.9276 - val_loss: 0.4934 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5244 - acc: 0.9352 - precision: 0.9857 - recall: 0.8844 - f1_score: 0.9312 - val_loss: 0.4918 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5228 - acc: 0.9352 - precision: 0.9827 - recall: 0.8807 - f1_score: 0.9281 - val_loss: 0.4902 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5213 - acc: 0.9352 - precision: 0.9851 - recall: 0.8898 - f1_score: 0.9334 - val_loss: 0.4887 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5197 - acc: 0.9352 - precision: 0.9869 - recall: 0.8801 - f1_score: 0.9297 - val_loss: 0.4871 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5181 - acc: 0.9352 - precision: 0.9853 - recall: 0.8835 - f1_score: 0.9306 - val_loss: 0.4855 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5166 - acc: 0.9352 - precision: 0.9863 - recall: 0.8838 - f1_score: 0.9274 - val_loss: 0.4840 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5151 - acc: 0.9352 - precision: 0.9864 - recall: 0.8843 - f1_score: 0.9309 - val_loss: 0.4824 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5135 - acc: 0.9352 - precision: 0.9857 - recall: 0.8848 - f1_score: 0.9319 - val_loss: 0.4809 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5120 - acc: 0.9352 - precision: 0.9857 - recall: 0.8819 - f1_score: 0.9298 - val_loss: 0.4794 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5105 - acc: 0.9352 - precision: 0.9854 - recall: 0.8851 - f1_score: 0.9313 - val_loss: 0.4778 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5090 - acc: 0.9352 - precision: 0.9872 - recall: 0.8818 - f1_score: 0.9298 - val_loss: 0.4763 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5075 - acc: 0.9352 - precision: 0.9856 - recall: 0.8835 - f1_score: 0.9292 - val_loss: 0.4748 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5060 - acc: 0.9352 - precision: 0.9854 - recall: 0.8852 - f1_score: 0.9319 - val_loss: 0.4733 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5045 - acc: 0.9352 - precision: 0.9858 - recall: 0.8786 - f1_score: 0.9266 - val_loss: 0.4718 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5030 - acc: 0.9352 - precision: 0.9865 - recall: 0.8805 - f1_score: 0.9297 - val_loss: 0.4703 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5016 - acc: 0.9352 - precision: 0.9865 - recall: 0.8832 - f1_score: 0.9304 - val_loss: 0.4689 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5001 - acc: 0.9352 - precision: 0.9850 - recall: 0.8826 - f1_score: 0.9305 - val_loss: 0.4674 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4986 - acc: 0.9352 - precision: 0.9856 - recall: 0.8797 - f1_score: 0.9275 - val_loss: 0.4659 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4972 - acc: 0.9352 - precision: 0.9851 - recall: 0.8800 - f1_score: 0.9283 - val_loss: 0.4645 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4957 - acc: 0.9352 - precision: 0.9867 - recall: 0.8821 - f1_score: 0.9309 - val_loss: 0.4630 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4943 - acc: 0.9352 - precision: 0.9858 - recall: 0.8847 - f1_score: 0.9316 - val_loss: 0.4616 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4929 - acc: 0.9352 - precision: 0.9858 - recall: 0.8821 - f1_score: 0.9290 - val_loss: 0.4602 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4915 - acc: 0.9352 - precision: 0.9846 - recall: 0.8829 - f1_score: 0.9297 - val_loss: 0.4587 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4900 - acc: 0.9352 - precision: 0.9878 - recall: 0.8793 - f1_score: 0.9288 - val_loss: 0.4573 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4886 - acc: 0.9352 - precision: 0.9860 - recall: 0.8820 - f1_score: 0.9304 - val_loss: 0.4559 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4872 - acc: 0.9352 - precision: 0.9876 - recall: 0.8855 - f1_score: 0.9319 - val_loss: 0.4545 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4858 - acc: 0.9352 - precision: 0.9861 - recall: 0.8806 - f1_score: 0.9296 - val_loss: 0.4531 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4844 - acc: 0.9352 - precision: 0.9849 - recall: 0.8763 - f1_score: 0.9261 - val_loss: 0.4517 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4831 - acc: 0.9352 - precision: 0.9862 - recall: 0.8840 - f1_score: 0.9311 - val_loss: 0.4503 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4817 - acc: 0.9352 - precision: 0.9860 - recall: 0.8833 - f1_score: 0.9302 - val_loss: 0.4490 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4803 - acc: 0.9352 - precision: 0.9834 - recall: 0.8840 - f1_score: 0.9302 - val_loss: 0.4476 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4790 - acc: 0.9352 - precision: 0.9852 - recall: 0.8807 - f1_score: 0.9292 - val_loss: 0.4462 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4776 - acc: 0.9352 - precision: 0.9861 - recall: 0.8821 - f1_score: 0.9298 - val_loss: 0.4449 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4763 - acc: 0.9352 - precision: 0.9861 - recall: 0.8825 - f1_score: 0.9301 - val_loss: 0.4435 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4749 - acc: 0.9352 - precision: 0.9847 - recall: 0.8819 - f1_score: 0.9288 - val_loss: 0.4422 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4736 - acc: 0.9352 - precision: 0.9841 - recall: 0.8840 - f1_score: 0.9302 - val_loss: 0.4408 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4723 - acc: 0.9352 - precision: 0.9837 - recall: 0.8822 - f1_score: 0.9285 - val_loss: 0.4395 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4709 - acc: 0.9352 - precision: 0.9861 - recall: 0.8908 - f1_score: 0.9336 - val_loss: 0.4382 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4696 - acc: 0.9352 - precision: 0.9862 - recall: 0.8821 - f1_score: 0.9299 - val_loss: 0.4368 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4683 - acc: 0.9352 - precision: 0.9856 - recall: 0.8844 - f1_score: 0.9312 - val_loss: 0.4355 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4670 - acc: 0.9352 - precision: 0.9863 - recall: 0.8818 - f1_score: 0.9298 - val_loss: 0.4342 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4657 - acc: 0.9352 - precision: 0.9857 - recall: 0.8825 - f1_score: 0.9304 - val_loss: 0.4329 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4644 - acc: 0.9352 - precision: 0.9855 - recall: 0.8809 - f1_score: 0.9290 - val_loss: 0.4316 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4632 - acc: 0.9352 - precision: 0.9876 - recall: 0.8814 - f1_score: 0.9304 - val_loss: 0.4303 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4619 - acc: 0.9352 - precision: 0.9855 - recall: 0.8803 - f1_score: 0.9286 - val_loss: 0.4291 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4606 - acc: 0.9352 - precision: 0.9853 - recall: 0.8867 - f1_score: 0.9319 - val_loss: 0.4278 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4593 - acc: 0.9352 - precision: 0.9863 - recall: 0.8822 - f1_score: 0.9299 - val_loss: 0.4265 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4581 - acc: 0.9352 - precision: 0.9851 - recall: 0.8775 - f1_score: 0.9264 - val_loss: 0.4253 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4568 - acc: 0.9352 - precision: 0.9879 - recall: 0.8818 - f1_score: 0.9297 - val_loss: 0.4240 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4556 - acc: 0.9352 - precision: 0.9855 - recall: 0.8859 - f1_score: 0.9320 - val_loss: 0.4227 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4543 - acc: 0.9352 - precision: 0.9846 - recall: 0.8812 - f1_score: 0.9294 - val_loss: 0.4215 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4531 - acc: 0.9352 - precision: 0.9867 - recall: 0.8848 - f1_score: 0.9313 - val_loss: 0.4202 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4519 - acc: 0.9352 - precision: 0.9877 - recall: 0.8844 - f1_score: 0.9314 - val_loss: 0.4190 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4507 - acc: 0.9352 - precision: 0.9871 - recall: 0.8852 - f1_score: 0.9320 - val_loss: 0.4178 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4494 - acc: 0.9352 - precision: 0.9876 - recall: 0.8830 - f1_score: 0.9312 - val_loss: 0.4166 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4482 - acc: 0.9352 - precision: 0.9858 - recall: 0.8852 - f1_score: 0.9317 - val_loss: 0.4153 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4470 - acc: 0.9352 - precision: 0.9856 - recall: 0.8818 - f1_score: 0.9289 - val_loss: 0.4141 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4458 - acc: 0.9352 - precision: 0.9856 - recall: 0.8827 - f1_score: 0.9305 - val_loss: 0.4129 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4446 - acc: 0.9352 - precision: 0.9861 - recall: 0.8848 - f1_score: 0.9311 - val_loss: 0.4117 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4435 - acc: 0.9352 - precision: 0.9860 - recall: 0.8853 - f1_score: 0.9316 - val_loss: 0.4105 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4423 - acc: 0.9352 - precision: 0.9854 - recall: 0.8821 - f1_score: 0.9304 - val_loss: 0.4093 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4411 - acc: 0.9352 - precision: 0.9881 - recall: 0.8776 - f1_score: 0.9273 - val_loss: 0.4082 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4399 - acc: 0.9352 - precision: 0.9849 - recall: 0.8812 - f1_score: 0.9293 - val_loss: 0.4070 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4388 - acc: 0.9352 - precision: 0.9855 - recall: 0.8813 - f1_score: 0.9295 - val_loss: 0.4058 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4376 - acc: 0.9352 - precision: 0.9855 - recall: 0.8821 - f1_score: 0.9297 - val_loss: 0.4046 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4365 - acc: 0.9352 - precision: 0.9851 - recall: 0.8814 - f1_score: 0.9276 - val_loss: 0.4035 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4353 - acc: 0.9352 - precision: 0.9871 - recall: 0.8896 - f1_score: 0.9346 - val_loss: 0.4023 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4342 - acc: 0.9352 - precision: 0.9839 - recall: 0.8880 - f1_score: 0.9323 - val_loss: 0.4012 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4330 - acc: 0.9352 - precision: 0.9863 - recall: 0.8820 - f1_score: 0.9294 - val_loss: 0.4000 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4319 - acc: 0.9352 - precision: 0.9847 - recall: 0.8892 - f1_score: 0.9329 - val_loss: 0.3989 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4308 - acc: 0.9352 - precision: 0.9849 - recall: 0.8839 - f1_score: 0.9301 - val_loss: 0.3978 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4297 - acc: 0.9352 - precision: 0.9864 - recall: 0.8826 - f1_score: 0.9303 - val_loss: 0.3967 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4285 - acc: 0.9352 - precision: 0.9861 - recall: 0.8876 - f1_score: 0.9326 - val_loss: 0.3956 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4274 - acc: 0.9352 - precision: 0.9875 - recall: 0.8837 - f1_score: 0.9316 - val_loss: 0.3944 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4263 - acc: 0.9352 - precision: 0.9861 - recall: 0.8826 - f1_score: 0.9303 - val_loss: 0.3933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4252 - acc: 0.9352 - precision: 0.9836 - recall: 0.8802 - f1_score: 0.9268 - val_loss: 0.3922 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4241 - acc: 0.9352 - precision: 0.9872 - recall: 0.8821 - f1_score: 0.9294 - val_loss: 0.3911 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4230 - acc: 0.9352 - precision: 0.9869 - recall: 0.8830 - f1_score: 0.9302 - val_loss: 0.3900 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4220 - acc: 0.9352 - precision: 0.9853 - recall: 0.8792 - f1_score: 0.9276 - val_loss: 0.3889 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4209 - acc: 0.9352 - precision: 0.9871 - recall: 0.8821 - f1_score: 0.9307 - val_loss: 0.3879 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 645/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4198 - acc: 0.9352 - precision: 0.9850 - recall: 0.8819 - f1_score: 0.9298 - val_loss: 0.3868 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4187 - acc: 0.9352 - precision: 0.9831 - recall: 0.8773 - f1_score: 0.9265 - val_loss: 0.3857 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4177 - acc: 0.9352 - precision: 0.9850 - recall: 0.8854 - f1_score: 0.9313 - val_loss: 0.3846 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4166 - acc: 0.9352 - precision: 0.9851 - recall: 0.8766 - f1_score: 0.9265 - val_loss: 0.3836 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4156 - acc: 0.9352 - precision: 0.9871 - recall: 0.8795 - f1_score: 0.9283 - val_loss: 0.3825 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4145 - acc: 0.9352 - precision: 0.9854 - recall: 0.8828 - f1_score: 0.9299 - val_loss: 0.3815 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4135 - acc: 0.9352 - precision: 0.9867 - recall: 0.8820 - f1_score: 0.9310 - val_loss: 0.3804 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4124 - acc: 0.9352 - precision: 0.9859 - recall: 0.8822 - f1_score: 0.9304 - val_loss: 0.3794 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4114 - acc: 0.9352 - precision: 0.9862 - recall: 0.8827 - f1_score: 0.9301 - val_loss: 0.3783 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4104 - acc: 0.9352 - precision: 0.9856 - recall: 0.8830 - f1_score: 0.9304 - val_loss: 0.3773 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4094 - acc: 0.9352 - precision: 0.9876 - recall: 0.8811 - f1_score: 0.9303 - val_loss: 0.3763 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4084 - acc: 0.9352 - precision: 0.9862 - recall: 0.8802 - f1_score: 0.9290 - val_loss: 0.3753 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4073 - acc: 0.9352 - precision: 0.9856 - recall: 0.8817 - f1_score: 0.9302 - val_loss: 0.3742 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4063 - acc: 0.9352 - precision: 0.9867 - recall: 0.8839 - f1_score: 0.9296 - val_loss: 0.3732 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4053 - acc: 0.9352 - precision: 0.9852 - recall: 0.8845 - f1_score: 0.9310 - val_loss: 0.3722 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4043 - acc: 0.9352 - precision: 0.9883 - recall: 0.8794 - f1_score: 0.9286 - val_loss: 0.3712 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4033 - acc: 0.9352 - precision: 0.9864 - recall: 0.8834 - f1_score: 0.9296 - val_loss: 0.3702 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4023 - acc: 0.9352 - precision: 0.9855 - recall: 0.8770 - f1_score: 0.9264 - val_loss: 0.3692 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4014 - acc: 0.9352 - precision: 0.9859 - recall: 0.8875 - f1_score: 0.9326 - val_loss: 0.3682 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4004 - acc: 0.9352 - precision: 0.9863 - recall: 0.8799 - f1_score: 0.9278 - val_loss: 0.3672 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3994 - acc: 0.9368 - precision: 0.9894 - recall: 0.8825 - f1_score: 0.9320 - val_loss: 0.3662 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3984 - acc: 0.9368 - precision: 0.9880 - recall: 0.8787 - f1_score: 0.9290 - val_loss: 0.3653 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3975 - acc: 0.9368 - precision: 0.9899 - recall: 0.8810 - f1_score: 0.9311 - val_loss: 0.3643 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3965 - acc: 0.9368 - precision: 0.9891 - recall: 0.8872 - f1_score: 0.9336 - val_loss: 0.3633 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3956 - acc: 0.9368 - precision: 0.9895 - recall: 0.8811 - f1_score: 0.9315 - val_loss: 0.3624 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3946 - acc: 0.9368 - precision: 0.9897 - recall: 0.8809 - f1_score: 0.9302 - val_loss: 0.3614 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3937 - acc: 0.9368 - precision: 0.9902 - recall: 0.8859 - f1_score: 0.9338 - val_loss: 0.3605 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3927 - acc: 0.9368 - precision: 0.9901 - recall: 0.8821 - f1_score: 0.9316 - val_loss: 0.3595 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3918 - acc: 0.9368 - precision: 0.9899 - recall: 0.8827 - f1_score: 0.9315 - val_loss: 0.3586 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3908 - acc: 0.9368 - precision: 0.9892 - recall: 0.8762 - f1_score: 0.9279 - val_loss: 0.3577 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3899 - acc: 0.9368 - precision: 0.9898 - recall: 0.8853 - f1_score: 0.9335 - val_loss: 0.3567 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3890 - acc: 0.9368 - precision: 0.9908 - recall: 0.8816 - f1_score: 0.9315 - val_loss: 0.3558 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 677/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9368 - precision: 0.9901 - recall: 0.8813 - f1_score: 0.9314 - val_loss: 0.3549 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3872 - acc: 0.9368 - precision: 0.9904 - recall: 0.8821 - f1_score: 0.9313 - val_loss: 0.3539 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3863 - acc: 0.9368 - precision: 0.9896 - recall: 0.8864 - f1_score: 0.9336 - val_loss: 0.3530 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3853 - acc: 0.9368 - precision: 0.9875 - recall: 0.8824 - f1_score: 0.9303 - val_loss: 0.3521 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3844 - acc: 0.9368 - precision: 0.9892 - recall: 0.8838 - f1_score: 0.9310 - val_loss: 0.3512 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3835 - acc: 0.9368 - precision: 0.9883 - recall: 0.8832 - f1_score: 0.9307 - val_loss: 0.3503 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3827 - acc: 0.9368 - precision: 0.9890 - recall: 0.8827 - f1_score: 0.9317 - val_loss: 0.3494 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3818 - acc: 0.9368 - precision: 0.9888 - recall: 0.8834 - f1_score: 0.9322 - val_loss: 0.3485 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3809 - acc: 0.9368 - precision: 0.9906 - recall: 0.8829 - f1_score: 0.9326 - val_loss: 0.3476 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3800 - acc: 0.9368 - precision: 0.9908 - recall: 0.8811 - f1_score: 0.9314 - val_loss: 0.3467 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3791 - acc: 0.9368 - precision: 0.9890 - recall: 0.8830 - f1_score: 0.9320 - val_loss: 0.3458 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3782 - acc: 0.9368 - precision: 0.9887 - recall: 0.8823 - f1_score: 0.9311 - val_loss: 0.3449 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3774 - acc: 0.9368 - precision: 0.9894 - recall: 0.8848 - f1_score: 0.9330 - val_loss: 0.3441 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3765 - acc: 0.9368 - precision: 0.9894 - recall: 0.8807 - f1_score: 0.9313 - val_loss: 0.3432 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3757 - acc: 0.9368 - precision: 0.9880 - recall: 0.8801 - f1_score: 0.9302 - val_loss: 0.3423 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3748 - acc: 0.9368 - precision: 0.9887 - recall: 0.8806 - f1_score: 0.9311 - val_loss: 0.3415 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3739 - acc: 0.9368 - precision: 0.9897 - recall: 0.8862 - f1_score: 0.9339 - val_loss: 0.3406 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3731 - acc: 0.9368 - precision: 0.9891 - recall: 0.8841 - f1_score: 0.9319 - val_loss: 0.3398 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3723 - acc: 0.9368 - precision: 0.9902 - recall: 0.8826 - f1_score: 0.9318 - val_loss: 0.3389 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3714 - acc: 0.9368 - precision: 0.9891 - recall: 0.8821 - f1_score: 0.9311 - val_loss: 0.3381 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3706 - acc: 0.9368 - precision: 0.9911 - recall: 0.8787 - f1_score: 0.9302 - val_loss: 0.3372 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3697 - acc: 0.9368 - precision: 0.9907 - recall: 0.8829 - f1_score: 0.9327 - val_loss: 0.3364 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3689 - acc: 0.9368 - precision: 0.9900 - recall: 0.8796 - f1_score: 0.9298 - val_loss: 0.3355 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3681 - acc: 0.9368 - precision: 0.9888 - recall: 0.8828 - f1_score: 0.9316 - val_loss: 0.3347 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3673 - acc: 0.9368 - precision: 0.9898 - recall: 0.8846 - f1_score: 0.9326 - val_loss: 0.3339 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3665 - acc: 0.9368 - precision: 0.9884 - recall: 0.8827 - f1_score: 0.9322 - val_loss: 0.3331 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3656 - acc: 0.9368 - precision: 0.9900 - recall: 0.8789 - f1_score: 0.9298 - val_loss: 0.3322 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3648 - acc: 0.9368 - precision: 0.9877 - recall: 0.8789 - f1_score: 0.9292 - val_loss: 0.3314 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3640 - acc: 0.9368 - precision: 0.9903 - recall: 0.8809 - f1_score: 0.9310 - val_loss: 0.3306 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3632 - acc: 0.9368 - precision: 0.9873 - recall: 0.8790 - f1_score: 0.9284 - val_loss: 0.3298 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3624 - acc: 0.9368 - precision: 0.9905 - recall: 0.8835 - f1_score: 0.9326 - val_loss: 0.3290 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3616 - acc: 0.9368 - precision: 0.9884 - recall: 0.8810 - f1_score: 0.9296 - val_loss: 0.3282 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3608 - acc: 0.9368 - precision: 0.9904 - recall: 0.8843 - f1_score: 0.9330 - val_loss: 0.3274 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3601 - acc: 0.9368 - precision: 0.9895 - recall: 0.8841 - f1_score: 0.9318 - val_loss: 0.3266 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3593 - acc: 0.9368 - precision: 0.9892 - recall: 0.8870 - f1_score: 0.9338 - val_loss: 0.3258 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3585 - acc: 0.9368 - precision: 0.9904 - recall: 0.8799 - f1_score: 0.9300 - val_loss: 0.3250 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3577 - acc: 0.9368 - precision: 0.9895 - recall: 0.8898 - f1_score: 0.9358 - val_loss: 0.3243 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3569 - acc: 0.9368 - precision: 0.9911 - recall: 0.8816 - f1_score: 0.9315 - val_loss: 0.3235 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3562 - acc: 0.9368 - precision: 0.9891 - recall: 0.8846 - f1_score: 0.9324 - val_loss: 0.3227 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3554 - acc: 0.9368 - precision: 0.9895 - recall: 0.8746 - f1_score: 0.9264 - val_loss: 0.3219 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3546 - acc: 0.9368 - precision: 0.9910 - recall: 0.8814 - f1_score: 0.9313 - val_loss: 0.3212 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3539 - acc: 0.9368 - precision: 0.9893 - recall: 0.8840 - f1_score: 0.9318 - val_loss: 0.3204 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3531 - acc: 0.9368 - precision: 0.9889 - recall: 0.8848 - f1_score: 0.9328 - val_loss: 0.3197 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3524 - acc: 0.9368 - precision: 0.9901 - recall: 0.8835 - f1_score: 0.9326 - val_loss: 0.3189 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3516 - acc: 0.9368 - precision: 0.9899 - recall: 0.8839 - f1_score: 0.9308 - val_loss: 0.3182 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3509 - acc: 0.9368 - precision: 0.9898 - recall: 0.8816 - f1_score: 0.9319 - val_loss: 0.3174 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3502 - acc: 0.9368 - precision: 0.9902 - recall: 0.8829 - f1_score: 0.9328 - val_loss: 0.3167 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3494 - acc: 0.9368 - precision: 0.9891 - recall: 0.8815 - f1_score: 0.9314 - val_loss: 0.3159 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3487 - acc: 0.9368 - precision: 0.9889 - recall: 0.8812 - f1_score: 0.9308 - val_loss: 0.3152 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3480 - acc: 0.9368 - precision: 0.9892 - recall: 0.8850 - f1_score: 0.9336 - val_loss: 0.3144 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3472 - acc: 0.9368 - precision: 0.9893 - recall: 0.8826 - f1_score: 0.9324 - val_loss: 0.3137 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3465 - acc: 0.9368 - precision: 0.9887 - recall: 0.8822 - f1_score: 0.9315 - val_loss: 0.3130 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3458 - acc: 0.9368 - precision: 0.9883 - recall: 0.8793 - f1_score: 0.9303 - val_loss: 0.3122 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3451 - acc: 0.9368 - precision: 0.9900 - recall: 0.8808 - f1_score: 0.9300 - val_loss: 0.3115 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3444 - acc: 0.9368 - precision: 0.9891 - recall: 0.8809 - f1_score: 0.9312 - val_loss: 0.3108 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3436 - acc: 0.9368 - precision: 0.9901 - recall: 0.8824 - f1_score: 0.9328 - val_loss: 0.3101 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3429 - acc: 0.9368 - precision: 0.9885 - recall: 0.8872 - f1_score: 0.9333 - val_loss: 0.3094 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3422 - acc: 0.9368 - precision: 0.9916 - recall: 0.8772 - f1_score: 0.9293 - val_loss: 0.3087 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3415 - acc: 0.9368 - precision: 0.9879 - recall: 0.8822 - f1_score: 0.9305 - val_loss: 0.3080 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3408 - acc: 0.9368 - precision: 0.9894 - recall: 0.8822 - f1_score: 0.9318 - val_loss: 0.3073 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3401 - acc: 0.9368 - precision: 0.9911 - recall: 0.8802 - f1_score: 0.9304 - val_loss: 0.3066 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3395 - acc: 0.9368 - precision: 0.9876 - recall: 0.8800 - f1_score: 0.9281 - val_loss: 0.3059 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3388 - acc: 0.9368 - precision: 0.9890 - recall: 0.8829 - f1_score: 0.9314 - val_loss: 0.3052 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3381 - acc: 0.9368 - precision: 0.9895 - recall: 0.8822 - f1_score: 0.9315 - val_loss: 0.3045 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3374 - acc: 0.9368 - precision: 0.9900 - recall: 0.8841 - f1_score: 0.9323 - val_loss: 0.3038 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3367 - acc: 0.9368 - precision: 0.9908 - recall: 0.8796 - f1_score: 0.9295 - val_loss: 0.3031 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3361 - acc: 0.9368 - precision: 0.9895 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 0.3025 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3354 - acc: 0.9368 - precision: 0.9889 - recall: 0.8827 - f1_score: 0.9317 - val_loss: 0.3018 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3347 - acc: 0.9368 - precision: 0.9907 - recall: 0.8826 - f1_score: 0.9320 - val_loss: 0.3011 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3341 - acc: 0.9368 - precision: 0.9898 - recall: 0.8796 - f1_score: 0.9295 - val_loss: 0.3004 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3334 - acc: 0.9368 - precision: 0.9888 - recall: 0.8807 - f1_score: 0.9306 - val_loss: 0.2998 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3327 - acc: 0.9368 - precision: 0.9903 - recall: 0.8834 - f1_score: 0.9330 - val_loss: 0.2991 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3321 - acc: 0.9368 - precision: 0.9883 - recall: 0.8818 - f1_score: 0.9311 - val_loss: 0.2984 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9368 - precision: 0.9892 - recall: 0.8785 - f1_score: 0.9294 - val_loss: 0.2978 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3308 - acc: 0.9368 - precision: 0.9890 - recall: 0.8799 - f1_score: 0.9301 - val_loss: 0.2971 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3301 - acc: 0.9368 - precision: 0.9884 - recall: 0.8838 - f1_score: 0.9325 - val_loss: 0.2965 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3295 - acc: 0.9368 - precision: 0.9904 - recall: 0.8793 - f1_score: 0.9302 - val_loss: 0.2958 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3289 - acc: 0.9368 - precision: 0.9898 - recall: 0.8831 - f1_score: 0.9319 - val_loss: 0.2952 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3282 - acc: 0.9368 - precision: 0.9903 - recall: 0.8770 - f1_score: 0.9285 - val_loss: 0.2945 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3276 - acc: 0.9368 - precision: 0.9898 - recall: 0.8842 - f1_score: 0.9327 - val_loss: 0.2939 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3270 - acc: 0.9368 - precision: 0.9874 - recall: 0.8846 - f1_score: 0.9315 - val_loss: 0.2933 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3263 - acc: 0.9368 - precision: 0.9883 - recall: 0.8832 - f1_score: 0.9317 - val_loss: 0.2926 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3257 - acc: 0.9368 - precision: 0.9903 - recall: 0.8853 - f1_score: 0.9330 - val_loss: 0.2920 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3251 - acc: 0.9368 - precision: 0.9901 - recall: 0.8820 - f1_score: 0.9309 - val_loss: 0.2914 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3245 - acc: 0.9368 - precision: 0.9900 - recall: 0.8889 - f1_score: 0.9358 - val_loss: 0.2907 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3238 - acc: 0.9368 - precision: 0.9902 - recall: 0.8800 - f1_score: 0.9311 - val_loss: 0.2901 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3232 - acc: 0.9368 - precision: 0.9899 - recall: 0.8854 - f1_score: 0.9331 - val_loss: 0.2895 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3226 - acc: 0.9368 - precision: 0.9895 - recall: 0.8831 - f1_score: 0.9322 - val_loss: 0.2889 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3220 - acc: 0.9368 - precision: 0.9903 - recall: 0.8842 - f1_score: 0.9328 - val_loss: 0.2883 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3214 - acc: 0.9368 - precision: 0.9891 - recall: 0.8887 - f1_score: 0.9345 - val_loss: 0.2876 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3208 - acc: 0.9368 - precision: 0.9895 - recall: 0.8838 - f1_score: 0.9327 - val_loss: 0.2870 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3202 - acc: 0.9368 - precision: 0.9892 - recall: 0.8832 - f1_score: 0.9319 - val_loss: 0.2864 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3196 - acc: 0.9368 - precision: 0.9898 - recall: 0.8847 - f1_score: 0.9334 - val_loss: 0.2858 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3190 - acc: 0.9368 - precision: 0.9894 - recall: 0.8853 - f1_score: 0.9330 - val_loss: 0.2852 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3184 - acc: 0.9368 - precision: 0.9886 - recall: 0.8811 - f1_score: 0.9302 - val_loss: 0.2846 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3178 - acc: 0.9368 - precision: 0.9886 - recall: 0.8824 - f1_score: 0.9317 - val_loss: 0.2840 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3172 - acc: 0.9368 - precision: 0.9868 - recall: 0.8790 - f1_score: 0.9290 - val_loss: 0.2834 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3167 - acc: 0.9368 - precision: 0.9883 - recall: 0.8807 - f1_score: 0.9302 - val_loss: 0.2829 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3161 - acc: 0.9368 - precision: 0.9906 - recall: 0.8822 - f1_score: 0.9317 - val_loss: 0.2823 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3155 - acc: 0.9368 - precision: 0.9895 - recall: 0.8814 - f1_score: 0.9312 - val_loss: 0.2817 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3149 - acc: 0.9368 - precision: 0.9868 - recall: 0.8762 - f1_score: 0.9270 - val_loss: 0.2811 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3143 - acc: 0.9368 - precision: 0.9872 - recall: 0.8797 - f1_score: 0.9276 - val_loss: 0.2805 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3138 - acc: 0.9368 - precision: 0.9890 - recall: 0.8818 - f1_score: 0.9306 - val_loss: 0.2799 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3132 - acc: 0.9368 - precision: 0.9892 - recall: 0.8825 - f1_score: 0.9321 - val_loss: 0.2794 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3126 - acc: 0.9368 - precision: 0.9901 - recall: 0.8818 - f1_score: 0.9315 - val_loss: 0.2788 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3121 - acc: 0.9368 - precision: 0.9896 - recall: 0.8822 - f1_score: 0.9313 - val_loss: 0.2782 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3115 - acc: 0.9368 - precision: 0.9889 - recall: 0.8804 - f1_score: 0.9305 - val_loss: 0.2776 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3110 - acc: 0.9368 - precision: 0.9886 - recall: 0.8800 - f1_score: 0.9303 - val_loss: 0.2771 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3104 - acc: 0.9368 - precision: 0.9888 - recall: 0.8801 - f1_score: 0.9303 - val_loss: 0.2765 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3099 - acc: 0.9368 - precision: 0.9904 - recall: 0.8847 - f1_score: 0.9337 - val_loss: 0.2759 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3093 - acc: 0.9368 - precision: 0.9897 - recall: 0.8846 - f1_score: 0.9338 - val_loss: 0.2754 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3088 - acc: 0.9368 - precision: 0.9887 - recall: 0.8853 - f1_score: 0.9333 - val_loss: 0.2749 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3082 - acc: 0.9368 - precision: 0.9910 - recall: 0.8846 - f1_score: 0.9339 - val_loss: 0.2743 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3077 - acc: 0.9368 - precision: 0.9900 - recall: 0.8850 - f1_score: 0.9335 - val_loss: 0.2737 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3071 - acc: 0.9368 - precision: 0.9880 - recall: 0.8841 - f1_score: 0.9315 - val_loss: 0.2732 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3066 - acc: 0.9368 - precision: 0.9910 - recall: 0.8792 - f1_score: 0.9300 - val_loss: 0.2727 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3061 - acc: 0.9368 - precision: 0.9880 - recall: 0.8796 - f1_score: 0.9294 - val_loss: 0.2721 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3055 - acc: 0.9368 - precision: 0.9898 - recall: 0.8863 - f1_score: 0.9342 - val_loss: 0.2716 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3050 - acc: 0.9368 - precision: 0.9886 - recall: 0.8770 - f1_score: 0.9277 - val_loss: 0.2710 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3045 - acc: 0.9368 - precision: 0.9896 - recall: 0.8796 - f1_score: 0.9308 - val_loss: 0.2705 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3039 - acc: 0.9368 - precision: 0.9882 - recall: 0.8811 - f1_score: 0.9298 - val_loss: 0.2700 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3034 - acc: 0.9368 - precision: 0.9894 - recall: 0.8817 - f1_score: 0.9309 - val_loss: 0.2694 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3029 - acc: 0.9368 - precision: 0.9892 - recall: 0.8862 - f1_score: 0.9335 - val_loss: 0.2689 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3024 - acc: 0.9368 - precision: 0.9879 - recall: 0.8799 - f1_score: 0.9297 - val_loss: 0.2684 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3019 - acc: 0.9368 - precision: 0.9900 - recall: 0.8821 - f1_score: 0.9325 - val_loss: 0.2679 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3014 - acc: 0.9368 - precision: 0.9901 - recall: 0.8867 - f1_score: 0.9339 - val_loss: 0.2674 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3008 - acc: 0.9368 - precision: 0.9890 - recall: 0.8806 - f1_score: 0.9314 - val_loss: 0.2668 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3003 - acc: 0.9368 - precision: 0.9884 - recall: 0.8825 - f1_score: 0.9310 - val_loss: 0.2663 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2998 - acc: 0.9368 - precision: 0.9896 - recall: 0.8877 - f1_score: 0.9345 - val_loss: 0.2658 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2993 - acc: 0.9368 - precision: 0.9910 - recall: 0.8807 - f1_score: 0.9315 - val_loss: 0.2653 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2988 - acc: 0.9368 - precision: 0.9898 - recall: 0.8762 - f1_score: 0.9283 - val_loss: 0.2648 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2983 - acc: 0.9368 - precision: 0.9875 - recall: 0.8846 - f1_score: 0.9317 - val_loss: 0.2643 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9368 - precision: 0.9895 - recall: 0.8785 - f1_score: 0.9298 - val_loss: 0.2638 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2973 - acc: 0.9368 - precision: 0.9897 - recall: 0.8834 - f1_score: 0.9326 - val_loss: 0.2633 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2968 - acc: 0.9368 - precision: 0.9886 - recall: 0.8815 - f1_score: 0.9312 - val_loss: 0.2628 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2963 - acc: 0.9368 - precision: 0.9885 - recall: 0.8834 - f1_score: 0.9309 - val_loss: 0.2623 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2958 - acc: 0.9368 - precision: 0.9899 - recall: 0.8874 - f1_score: 0.9342 - val_loss: 0.2618 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2954 - acc: 0.9368 - precision: 0.9900 - recall: 0.8828 - f1_score: 0.9321 - val_loss: 0.2613 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2949 - acc: 0.9368 - precision: 0.9869 - recall: 0.8792 - f1_score: 0.9286 - val_loss: 0.2608 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2944 - acc: 0.9368 - precision: 0.9897 - recall: 0.8845 - f1_score: 0.9319 - val_loss: 0.2603 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2939 - acc: 0.9368 - precision: 0.9858 - recall: 0.8785 - f1_score: 0.9276 - val_loss: 0.2598 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2934 - acc: 0.9368 - precision: 0.9894 - recall: 0.8827 - f1_score: 0.9312 - val_loss: 0.2593 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2930 - acc: 0.9368 - precision: 0.9898 - recall: 0.8847 - f1_score: 0.9323 - val_loss: 0.2589 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2925 - acc: 0.9368 - precision: 0.9908 - recall: 0.8792 - f1_score: 0.9302 - val_loss: 0.2584 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2920 - acc: 0.9368 - precision: 0.9877 - recall: 0.8779 - f1_score: 0.9289 - val_loss: 0.2579 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2915 - acc: 0.9368 - precision: 0.9883 - recall: 0.8801 - f1_score: 0.9295 - val_loss: 0.2574 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2911 - acc: 0.9368 - precision: 0.9886 - recall: 0.8822 - f1_score: 0.9311 - val_loss: 0.2570 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2906 - acc: 0.9368 - precision: 0.9900 - recall: 0.8818 - f1_score: 0.9321 - val_loss: 0.2565 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2902 - acc: 0.9368 - precision: 0.9876 - recall: 0.8830 - f1_score: 0.9315 - val_loss: 0.2560 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2897 - acc: 0.9368 - precision: 0.9887 - recall: 0.8808 - f1_score: 0.9301 - val_loss: 0.2556 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2892 - acc: 0.9368 - precision: 0.9895 - recall: 0.8805 - f1_score: 0.9291 - val_loss: 0.2551 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2888 - acc: 0.9368 - precision: 0.9875 - recall: 0.8811 - f1_score: 0.9295 - val_loss: 0.2546 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2883 - acc: 0.9368 - precision: 0.9902 - recall: 0.8800 - f1_score: 0.9295 - val_loss: 0.2542 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2879 - acc: 0.9368 - precision: 0.9894 - recall: 0.8784 - f1_score: 0.9297 - val_loss: 0.2537 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2874 - acc: 0.9368 - precision: 0.9905 - recall: 0.8846 - f1_score: 0.9334 - val_loss: 0.2533 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2870 - acc: 0.9368 - precision: 0.9898 - recall: 0.8778 - f1_score: 0.9283 - val_loss: 0.2528 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2865 - acc: 0.9368 - precision: 0.9887 - recall: 0.8848 - f1_score: 0.9327 - val_loss: 0.2524 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2861 - acc: 0.9368 - precision: 0.9895 - recall: 0.8819 - f1_score: 0.9313 - val_loss: 0.2519 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2856 - acc: 0.9368 - precision: 0.9875 - recall: 0.8792 - f1_score: 0.9296 - val_loss: 0.2515 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2852 - acc: 0.9368 - precision: 0.9902 - recall: 0.8827 - f1_score: 0.9322 - val_loss: 0.2510 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9368 - precision: 0.9894 - recall: 0.8819 - f1_score: 0.9308 - val_loss: 0.2506 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9368 - precision: 0.9892 - recall: 0.8826 - f1_score: 0.9325 - val_loss: 0.2501 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2839 - acc: 0.9368 - precision: 0.9887 - recall: 0.8852 - f1_score: 0.9325 - val_loss: 0.2497 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2835 - acc: 0.9368 - precision: 0.9891 - recall: 0.8812 - f1_score: 0.9308 - val_loss: 0.2493 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2830 - acc: 0.9368 - precision: 0.9898 - recall: 0.8835 - f1_score: 0.9322 - val_loss: 0.2488 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2826 - acc: 0.9368 - precision: 0.9892 - recall: 0.8840 - f1_score: 0.9331 - val_loss: 0.2484 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2822 - acc: 0.9368 - precision: 0.9896 - recall: 0.8802 - f1_score: 0.9307 - val_loss: 0.2480 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2817 - acc: 0.9368 - precision: 0.9880 - recall: 0.8838 - f1_score: 0.9321 - val_loss: 0.2475 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2813 - acc: 0.9368 - precision: 0.9902 - recall: 0.8852 - f1_score: 0.9330 - val_loss: 0.2471 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2809 - acc: 0.9368 - precision: 0.9892 - recall: 0.8825 - f1_score: 0.9321 - val_loss: 0.2467 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2805 - acc: 0.9368 - precision: 0.9903 - recall: 0.8803 - f1_score: 0.9314 - val_loss: 0.2462 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2801 - acc: 0.9368 - precision: 0.9887 - recall: 0.8835 - f1_score: 0.9313 - val_loss: 0.2458 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2797 - acc: 0.9368 - precision: 0.9892 - recall: 0.8810 - f1_score: 0.9311 - val_loss: 0.2454 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2792 - acc: 0.9368 - precision: 0.9884 - recall: 0.8802 - f1_score: 0.9290 - val_loss: 0.2450 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2788 - acc: 0.9368 - precision: 0.9892 - recall: 0.8791 - f1_score: 0.9295 - val_loss: 0.2446 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2784 - acc: 0.9368 - precision: 0.9895 - recall: 0.8835 - f1_score: 0.9320 - val_loss: 0.2442 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2780 - acc: 0.9368 - precision: 0.9911 - recall: 0.8793 - f1_score: 0.9298 - val_loss: 0.2438 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2776 - acc: 0.9368 - precision: 0.9902 - recall: 0.8783 - f1_score: 0.9297 - val_loss: 0.2433 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2772 - acc: 0.9368 - precision: 0.9905 - recall: 0.8862 - f1_score: 0.9339 - val_loss: 0.2429 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2768 - acc: 0.9368 - precision: 0.9902 - recall: 0.8801 - f1_score: 0.9292 - val_loss: 0.2425 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2764 - acc: 0.9368 - precision: 0.9899 - recall: 0.8847 - f1_score: 0.9336 - val_loss: 0.2421 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2760 - acc: 0.9368 - precision: 0.9901 - recall: 0.8798 - f1_score: 0.9301 - val_loss: 0.2417 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2756 - acc: 0.9368 - precision: 0.9872 - recall: 0.8856 - f1_score: 0.9329 - val_loss: 0.2413 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2752 - acc: 0.9368 - precision: 0.9894 - recall: 0.8844 - f1_score: 0.9333 - val_loss: 0.2409 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2748 - acc: 0.9368 - precision: 0.9879 - recall: 0.8757 - f1_score: 0.9268 - val_loss: 0.2405 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9368 - precision: 0.9902 - recall: 0.8780 - f1_score: 0.9272 - val_loss: 0.2401 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9368 - precision: 0.9892 - recall: 0.8820 - f1_score: 0.9308 - val_loss: 0.2397 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2736 - acc: 0.9368 - precision: 0.9898 - recall: 0.8817 - f1_score: 0.9317 - val_loss: 0.2393 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2733 - acc: 0.9368 - precision: 0.9889 - recall: 0.8862 - f1_score: 0.9332 - val_loss: 0.2389 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2729 - acc: 0.9368 - precision: 0.9892 - recall: 0.8863 - f1_score: 0.9335 - val_loss: 0.2385 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2725 - acc: 0.9368 - precision: 0.9900 - recall: 0.8775 - f1_score: 0.9288 - val_loss: 0.2382 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2721 - acc: 0.9368 - precision: 0.9875 - recall: 0.8854 - f1_score: 0.9321 - val_loss: 0.2378 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 869/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2717 - acc: 0.9368 - precision: 0.9903 - recall: 0.8837 - f1_score: 0.9332 - val_loss: 0.2374 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2713 - acc: 0.9368 - precision: 0.9897 - recall: 0.8824 - f1_score: 0.9323 - val_loss: 0.2370 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2710 - acc: 0.9368 - precision: 0.9884 - recall: 0.8846 - f1_score: 0.9327 - val_loss: 0.2366 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2706 - acc: 0.9368 - precision: 0.9893 - recall: 0.8862 - f1_score: 0.9336 - val_loss: 0.2363 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2702 - acc: 0.9368 - precision: 0.9887 - recall: 0.8828 - f1_score: 0.9322 - val_loss: 0.2359 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2709 - acc: 0.9345 - precision: 0.9881 - recall: 0.8823 - f1_score: 0.931 - 0s - loss: 0.2698 - acc: 0.9368 - precision: 0.9897 - recall: 0.8822 - f1_score: 0.9320 - val_loss: 0.2355 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2695 - acc: 0.9368 - precision: 0.9883 - recall: 0.8828 - f1_score: 0.9321 - val_loss: 0.2351 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2691 - acc: 0.9368 - precision: 0.9906 - recall: 0.8849 - f1_score: 0.9335 - val_loss: 0.2348 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2687 - acc: 0.9368 - precision: 0.9904 - recall: 0.8789 - f1_score: 0.9295 - val_loss: 0.2344 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2684 - acc: 0.9368 - precision: 0.9901 - recall: 0.8844 - f1_score: 0.9324 - val_loss: 0.2340 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2680 - acc: 0.9368 - precision: 0.9884 - recall: 0.8822 - f1_score: 0.9313 - val_loss: 0.2336 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2676 - acc: 0.9368 - precision: 0.9909 - recall: 0.8828 - f1_score: 0.9322 - val_loss: 0.2333 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2673 - acc: 0.9368 - precision: 0.9902 - recall: 0.8838 - f1_score: 0.9333 - val_loss: 0.2329 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2669 - acc: 0.9368 - precision: 0.9895 - recall: 0.8832 - f1_score: 0.9314 - val_loss: 0.2325 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2666 - acc: 0.9368 - precision: 0.9890 - recall: 0.8844 - f1_score: 0.9322 - val_loss: 0.2322 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2662 - acc: 0.9368 - precision: 0.9905 - recall: 0.8805 - f1_score: 0.9307 - val_loss: 0.2318 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2659 - acc: 0.9368 - precision: 0.9888 - recall: 0.8819 - f1_score: 0.9298 - val_loss: 0.2315 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2655 - acc: 0.9368 - precision: 0.9879 - recall: 0.8767 - f1_score: 0.9258 - val_loss: 0.2311 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2652 - acc: 0.9368 - precision: 0.9906 - recall: 0.8811 - f1_score: 0.9319 - val_loss: 0.2308 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9368 - precision: 0.9899 - recall: 0.8817 - f1_score: 0.9316 - val_loss: 0.2304 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2645 - acc: 0.9368 - precision: 0.9894 - recall: 0.8799 - f1_score: 0.9295 - val_loss: 0.2300 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2641 - acc: 0.9368 - precision: 0.9906 - recall: 0.8816 - f1_score: 0.9305 - val_loss: 0.2297 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2638 - acc: 0.9368 - precision: 0.9905 - recall: 0.8824 - f1_score: 0.9326 - val_loss: 0.2293 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2634 - acc: 0.9368 - precision: 0.9890 - recall: 0.8815 - f1_score: 0.9308 - val_loss: 0.2290 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2631 - acc: 0.9368 - precision: 0.9892 - recall: 0.8764 - f1_score: 0.9278 - val_loss: 0.2286 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2627 - acc: 0.9368 - precision: 0.9913 - recall: 0.8810 - f1_score: 0.9319 - val_loss: 0.2283 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2624 - acc: 0.9368 - precision: 0.9895 - recall: 0.8846 - f1_score: 0.9332 - val_loss: 0.2279 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2621 - acc: 0.9368 - precision: 0.9898 - recall: 0.8844 - f1_score: 0.9330 - val_loss: 0.2276 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2617 - acc: 0.9368 - precision: 0.9886 - recall: 0.8828 - f1_score: 0.9314 - val_loss: 0.2273 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2614 - acc: 0.9368 - precision: 0.9900 - recall: 0.8788 - f1_score: 0.9295 - val_loss: 0.2269 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2611 - acc: 0.9368 - precision: 0.9891 - recall: 0.8800 - f1_score: 0.9299 - val_loss: 0.2266 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2607 - acc: 0.9368 - precision: 0.9894 - recall: 0.8810 - f1_score: 0.9309 - val_loss: 0.2262 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2604 - acc: 0.9384 - precision: 0.9904 - recall: 0.8850 - f1_score: 0.9332 - val_loss: 0.2259 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2601 - acc: 0.9384 - precision: 0.9882 - recall: 0.8845 - f1_score: 0.9322 - val_loss: 0.2256 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2597 - acc: 0.9368 - precision: 0.9893 - recall: 0.8805 - f1_score: 0.9308 - val_loss: 0.2252 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2594 - acc: 0.9384 - precision: 0.9906 - recall: 0.8815 - f1_score: 0.9315 - val_loss: 0.2249 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2591 - acc: 0.9368 - precision: 0.9885 - recall: 0.8816 - f1_score: 0.9307 - val_loss: 0.2246 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2588 - acc: 0.9384 - precision: 0.9881 - recall: 0.8837 - f1_score: 0.9318 - val_loss: 0.2243 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2584 - acc: 0.9384 - precision: 0.9903 - recall: 0.8879 - f1_score: 0.9356 - val_loss: 0.2239 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9384 - precision: 0.9891 - recall: 0.8865 - f1_score: 0.9336 - val_loss: 0.2236 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9384 - precision: 0.9880 - recall: 0.8845 - f1_score: 0.9318 - val_loss: 0.2233 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9384 - precision: 0.9890 - recall: 0.8863 - f1_score: 0.9330 - val_loss: 0.2229 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2572 - acc: 0.9384 - precision: 0.9893 - recall: 0.8839 - f1_score: 0.9323 - val_loss: 0.2226 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2569 - acc: 0.9384 - precision: 0.9894 - recall: 0.8830 - f1_score: 0.9316 - val_loss: 0.2223 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9384 - precision: 0.9876 - recall: 0.8868 - f1_score: 0.9329 - val_loss: 0.2220 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2562 - acc: 0.9384 - precision: 0.9901 - recall: 0.8871 - f1_score: 0.9341 - val_loss: 0.2217 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2559 - acc: 0.9384 - precision: 0.9904 - recall: 0.8844 - f1_score: 0.9333 - val_loss: 0.2213 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2556 - acc: 0.9384 - precision: 0.9900 - recall: 0.8813 - f1_score: 0.9312 - val_loss: 0.2210 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2553 - acc: 0.9384 - precision: 0.9908 - recall: 0.8837 - f1_score: 0.9336 - val_loss: 0.2207 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2550 - acc: 0.9384 - precision: 0.9880 - recall: 0.8829 - f1_score: 0.9315 - val_loss: 0.2204 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2547 - acc: 0.9384 - precision: 0.9886 - recall: 0.8820 - f1_score: 0.9314 - val_loss: 0.2201 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2544 - acc: 0.9384 - precision: 0.9908 - recall: 0.8890 - f1_score: 0.9365 - val_loss: 0.2198 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2541 - acc: 0.9384 - precision: 0.9899 - recall: 0.8863 - f1_score: 0.9340 - val_loss: 0.2195 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2538 - acc: 0.9384 - precision: 0.9900 - recall: 0.8868 - f1_score: 0.9341 - val_loss: 0.2192 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2535 - acc: 0.9384 - precision: 0.9889 - recall: 0.8824 - f1_score: 0.9317 - val_loss: 0.2189 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2532 - acc: 0.9384 - precision: 0.9892 - recall: 0.8871 - f1_score: 0.9344 - val_loss: 0.2186 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2529 - acc: 0.9384 - precision: 0.9884 - recall: 0.8879 - f1_score: 0.9345 - val_loss: 0.2183 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9384 - precision: 0.9895 - recall: 0.8840 - f1_score: 0.9328 - val_loss: 0.2180 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2523 - acc: 0.9384 - precision: 0.9915 - recall: 0.8828 - f1_score: 0.9321 - val_loss: 0.2177 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2520 - acc: 0.9384 - precision: 0.9897 - recall: 0.8858 - f1_score: 0.9334 - val_loss: 0.2174 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2517 - acc: 0.9384 - precision: 0.9899 - recall: 0.8853 - f1_score: 0.9331 - val_loss: 0.2171 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2514 - acc: 0.9384 - precision: 0.9882 - recall: 0.8862 - f1_score: 0.9334 - val_loss: 0.2168 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2511 - acc: 0.9384 - precision: 0.9900 - recall: 0.8837 - f1_score: 0.9323 - val_loss: 0.2165 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2509 - acc: 0.9384 - precision: 0.9886 - recall: 0.8843 - f1_score: 0.9324 - val_loss: 0.2162 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 933/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2506 - acc: 0.9384 - precision: 0.9878 - recall: 0.8859 - f1_score: 0.9327 - val_loss: 0.2159 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2503 - acc: 0.9384 - precision: 0.9871 - recall: 0.8854 - f1_score: 0.9320 - val_loss: 0.2156 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2500 - acc: 0.9384 - precision: 0.9910 - recall: 0.8838 - f1_score: 0.9324 - val_loss: 0.2153 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2497 - acc: 0.9384 - precision: 0.9891 - recall: 0.8863 - f1_score: 0.9337 - val_loss: 0.2150 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2494 - acc: 0.9384 - precision: 0.9887 - recall: 0.8901 - f1_score: 0.9358 - val_loss: 0.2148 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2492 - acc: 0.9384 - precision: 0.9888 - recall: 0.8869 - f1_score: 0.9346 - val_loss: 0.2145 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2489 - acc: 0.9384 - precision: 0.9894 - recall: 0.8852 - f1_score: 0.9325 - val_loss: 0.2142 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2486 - acc: 0.9384 - precision: 0.9900 - recall: 0.8851 - f1_score: 0.9335 - val_loss: 0.2139 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2483 - acc: 0.9384 - precision: 0.9891 - recall: 0.8836 - f1_score: 0.9313 - val_loss: 0.2136 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2480 - acc: 0.9384 - precision: 0.9900 - recall: 0.8775 - f1_score: 0.9283 - val_loss: 0.2133 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9384 - precision: 0.9897 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 0.2131 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2475 - acc: 0.9384 - precision: 0.9892 - recall: 0.8874 - f1_score: 0.9348 - val_loss: 0.2128 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2472 - acc: 0.9384 - precision: 0.9894 - recall: 0.8848 - f1_score: 0.9333 - val_loss: 0.2125 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9384 - precision: 0.9887 - recall: 0.8855 - f1_score: 0.9330 - val_loss: 0.2122 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9384 - precision: 0.9897 - recall: 0.8889 - f1_score: 0.9347 - val_loss: 0.2120 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9384 - precision: 0.9872 - recall: 0.8803 - f1_score: 0.9288 - val_loss: 0.2117 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2462 - acc: 0.9384 - precision: 0.9889 - recall: 0.8869 - f1_score: 0.9340 - val_loss: 0.2114 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2459 - acc: 0.9384 - precision: 0.9886 - recall: 0.8852 - f1_score: 0.9330 - val_loss: 0.2112 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2456 - acc: 0.9384 - precision: 0.9901 - recall: 0.8854 - f1_score: 0.9336 - val_loss: 0.2109 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2454 - acc: 0.9384 - precision: 0.9909 - recall: 0.8828 - f1_score: 0.9323 - val_loss: 0.2106 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2451 - acc: 0.9384 - precision: 0.9903 - recall: 0.8877 - f1_score: 0.9359 - val_loss: 0.2104 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2448 - acc: 0.9384 - precision: 0.9894 - recall: 0.8867 - f1_score: 0.9339 - val_loss: 0.2101 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2446 - acc: 0.9384 - precision: 0.9874 - recall: 0.8839 - f1_score: 0.9307 - val_loss: 0.2098 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2443 - acc: 0.9384 - precision: 0.9885 - recall: 0.8845 - f1_score: 0.9327 - val_loss: 0.2096 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2441 - acc: 0.9384 - precision: 0.9896 - recall: 0.8821 - f1_score: 0.9318 - val_loss: 0.2093 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2438 - acc: 0.9384 - precision: 0.9890 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 0.2090 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2435 - acc: 0.9384 - precision: 0.9868 - recall: 0.8874 - f1_score: 0.9339 - val_loss: 0.2088 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2433 - acc: 0.9384 - precision: 0.9881 - recall: 0.8826 - f1_score: 0.9296 - val_loss: 0.2085 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2430 - acc: 0.9384 - precision: 0.9882 - recall: 0.8853 - f1_score: 0.9333 - val_loss: 0.2082 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2428 - acc: 0.9384 - precision: 0.9871 - recall: 0.8813 - f1_score: 0.9298 - val_loss: 0.2080 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2425 - acc: 0.9384 - precision: 0.9900 - recall: 0.8804 - f1_score: 0.9295 - val_loss: 0.2077 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9384 - precision: 0.9891 - recall: 0.8853 - f1_score: 0.9337 - val_loss: 0.2075 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2420 - acc: 0.9384 - precision: 0.9908 - recall: 0.8853 - f1_score: 0.9335 - val_loss: 0.2072 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2418 - acc: 0.9384 - precision: 0.9883 - recall: 0.8843 - f1_score: 0.9320 - val_loss: 0.2070 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2415 - acc: 0.9384 - precision: 0.9914 - recall: 0.8853 - f1_score: 0.9340 - val_loss: 0.2067 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2413 - acc: 0.9384 - precision: 0.9881 - recall: 0.8875 - f1_score: 0.9343 - val_loss: 0.2065 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2410 - acc: 0.9384 - precision: 0.9894 - recall: 0.8893 - f1_score: 0.9348 - val_loss: 0.2062 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2408 - acc: 0.9384 - precision: 0.9875 - recall: 0.8847 - f1_score: 0.9323 - val_loss: 0.2060 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2406 - acc: 0.9384 - precision: 0.9895 - recall: 0.8857 - f1_score: 0.9327 - val_loss: 0.2057 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2403 - acc: 0.9384 - precision: 0.9864 - recall: 0.8836 - f1_score: 0.9307 - val_loss: 0.2055 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2401 - acc: 0.9384 - precision: 0.9911 - recall: 0.8875 - f1_score: 0.9351 - val_loss: 0.2052 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2398 - acc: 0.9384 - precision: 0.9890 - recall: 0.8856 - f1_score: 0.9335 - val_loss: 0.2050 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2252 - acc: 0.9200 - precision: 0.8947 - recall: 0.8947 - f1_score: 0.894 - 0s - loss: 0.2396 - acc: 0.9384 - precision: 0.9886 - recall: 0.8863 - f1_score: 0.9335 - val_loss: 0.2048 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2393 - acc: 0.9384 - precision: 0.9896 - recall: 0.8829 - f1_score: 0.9325 - val_loss: 0.2045 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2391 - acc: 0.9384 - precision: 0.9892 - recall: 0.8841 - f1_score: 0.9327 - val_loss: 0.2043 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9384 - precision: 0.9909 - recall: 0.8849 - f1_score: 0.9341 - val_loss: 0.2040 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2386 - acc: 0.9384 - precision: 0.9900 - recall: 0.8861 - f1_score: 0.9335 - val_loss: 0.2038 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9384 - precision: 0.9883 - recall: 0.8854 - f1_score: 0.9326 - val_loss: 0.2036 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2382 - acc: 0.9384 - precision: 0.9892 - recall: 0.8844 - f1_score: 0.9322 - val_loss: 0.2033 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2379 - acc: 0.9384 - precision: 0.9897 - recall: 0.8889 - f1_score: 0.9360 - val_loss: 0.2031 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9384 - precision: 0.9895 - recall: 0.8864 - f1_score: 0.9346 - val_loss: 0.2029 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2375 - acc: 0.9384 - precision: 0.9879 - recall: 0.8849 - f1_score: 0.9326 - val_loss: 0.2026 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9384 - precision: 0.9893 - recall: 0.8847 - f1_score: 0.9329 - val_loss: 0.2024 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9384 - precision: 0.9908 - recall: 0.8798 - f1_score: 0.9298 - val_loss: 0.2022 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2368 - acc: 0.9384 - precision: 0.9909 - recall: 0.8858 - f1_score: 0.9348 - val_loss: 0.2019 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2366 - acc: 0.9384 - precision: 0.9918 - recall: 0.8888 - f1_score: 0.9349 - val_loss: 0.2017 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2364 - acc: 0.9384 - precision: 0.9876 - recall: 0.8849 - f1_score: 0.9313 - val_loss: 0.2015 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2361 - acc: 0.9384 - precision: 0.9901 - recall: 0.8861 - f1_score: 0.9348 - val_loss: 0.2012 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2359 - acc: 0.9384 - precision: 0.9891 - recall: 0.8851 - f1_score: 0.9331 - val_loss: 0.2010 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2357 - acc: 0.9384 - precision: 0.9885 - recall: 0.8904 - f1_score: 0.9347 - val_loss: 0.2008 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9384 - precision: 0.9891 - recall: 0.8843 - f1_score: 0.9329 - val_loss: 0.2006 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2352 - acc: 0.9384 - precision: 0.9889 - recall: 0.8798 - f1_score: 0.9301 - val_loss: 0.2004 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9384 - precision: 0.9908 - recall: 0.8836 - f1_score: 0.9332 - val_loss: 0.2001 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2348 - acc: 0.9384 - precision: 0.9890 - recall: 0.8852 - f1_score: 0.9329 - val_loss: 0.1999 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9384 - precision: 0.9884 - recall: 0.8819 - f1_score: 0.9307 - val_loss: 0.1997 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9384 - precision: 0.9900 - recall: 0.8879 - f1_score: 0.9353 - val_loss: 0.1995 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9384 - precision: 0.9886 - recall: 0.8903 - f1_score: 0.9354 - val_loss: 0.1993 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9384 - precision: 0.9903 - recall: 0.8878 - f1_score: 0.9339 - val_loss: 0.1990 - val_acc: 0.9557 - val_precision: 0.9599 - val_recall: 0.9483 - val_f1_score: 0.9537\n",
      " 50/158 [========>.....................] - ETA: 0sTrain on 633 samples, validate on 158 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 0s - loss: 5.9599 - acc: 0.8041 - precision: 0.8255 - recall: 0.7636 - f1_score: 0.7893 - val_loss: 5.9147 - val_acc: 0.7405 - val_precision: 0.6860 - val_recall: 0.8409 - val_f1_score: 0.7501\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8711 - acc: 0.8262 - precision: 0.8129 - recall: 0.8420 - f1_score: 0.8252 - val_loss: 5.8567 - val_acc: 0.7468 - val_precision: 0.6889 - val_recall: 0.8531 - val_f1_score: 0.7574\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s - loss: 5.8187 - acc: 0.8183 - precision: 0.8081 - recall: 0.8490 - f1_score: 0.8232 - val_loss: 5.8129 - val_acc: 0.7468 - val_precision: 0.6889 - val_recall: 0.8531 - val_f1_score: 0.7574\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7766 - acc: 0.8262 - precision: 0.8089 - recall: 0.8526 - f1_score: 0.8284 - val_loss: 5.7743 - val_acc: 0.7595 - val_precision: 0.7043 - val_recall: 0.8531 - val_f1_score: 0.7669\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7389 - acc: 0.8310 - precision: 0.8162 - recall: 0.8564 - f1_score: 0.8328 - val_loss: 5.7385 - val_acc: 0.7595 - val_precision: 0.7043 - val_recall: 0.8531 - val_f1_score: 0.7669\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s - loss: 5.7035 - acc: 0.8436 - precision: 0.8238 - recall: 0.8756 - f1_score: 0.8458 - val_loss: 5.7042 - val_acc: 0.7911 - val_precision: 0.7338 - val_recall: 0.8784 - val_f1_score: 0.7964\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6695 - acc: 0.8531 - precision: 0.8243 - recall: 0.8890 - f1_score: 0.8523 - val_loss: 5.6710 - val_acc: 0.8101 - val_precision: 0.7423 - val_recall: 0.9028 - val_f1_score: 0.8131\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6366 - acc: 0.8562 - precision: 0.8330 - recall: 0.8971 - f1_score: 0.8631 - val_loss: 5.6387 - val_acc: 0.8418 - val_precision: 0.7755 - val_recall: 0.9326 - val_f1_score: 0.8460\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s - loss: 5.6046 - acc: 0.8657 - precision: 0.8381 - recall: 0.9004 - f1_score: 0.8652 - val_loss: 5.6070 - val_acc: 0.8544 - val_precision: 0.7944 - val_recall: 0.9326 - val_f1_score: 0.8574\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5732 - acc: 0.8705 - precision: 0.8478 - recall: 0.9029 - f1_score: 0.8733 - val_loss: 5.5758 - val_acc: 0.8671 - val_precision: 0.8022 - val_recall: 0.9448 - val_f1_score: 0.8676\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5423 - acc: 0.8768 - precision: 0.8626 - recall: 0.8960 - f1_score: 0.8761 - val_loss: 5.5450 - val_acc: 0.8671 - val_precision: 0.8022 - val_recall: 0.9448 - val_f1_score: 0.8676\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s - loss: 5.5118 - acc: 0.8847 - precision: 0.8765 - recall: 0.9042 - f1_score: 0.8857 - val_loss: 5.5147 - val_acc: 0.8671 - val_precision: 0.8082 - val_recall: 0.9281 - val_f1_score: 0.8639\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4817 - acc: 0.8847 - precision: 0.8765 - recall: 0.8982 - f1_score: 0.8850 - val_loss: 5.4846 - val_acc: 0.8734 - val_precision: 0.8096 - val_recall: 0.9403 - val_f1_score: 0.8701\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4520 - acc: 0.8878 - precision: 0.8814 - recall: 0.8992 - f1_score: 0.8885 - val_loss: 5.4548 - val_acc: 0.8861 - val_precision: 0.8307 - val_recall: 0.9403 - val_f1_score: 0.8820\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s - loss: 5.4225 - acc: 0.8957 - precision: 0.8920 - recall: 0.9005 - f1_score: 0.8952 - val_loss: 5.4254 - val_acc: 0.8987 - val_precision: 0.8501 - val_recall: 0.9403 - val_f1_score: 0.8928\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3934 - acc: 0.8957 - precision: 0.9002 - recall: 0.8948 - f1_score: 0.8949 - val_loss: 5.3961 - val_acc: 0.9114 - val_precision: 0.8728 - val_recall: 0.9403 - val_f1_score: 0.9051\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3645 - acc: 0.8989 - precision: 0.8976 - recall: 0.8973 - f1_score: 0.8952 - val_loss: 5.3672 - val_acc: 0.9241 - val_precision: 0.8977 - val_recall: 0.9403 - val_f1_score: 0.9181\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3358 - acc: 0.9021 - precision: 0.8998 - recall: 0.9018 - f1_score: 0.8994 - val_loss: 5.3384 - val_acc: 0.9241 - val_precision: 0.8977 - val_recall: 0.9403 - val_f1_score: 0.9181\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s - loss: 5.3074 - acc: 0.9084 - precision: 0.9145 - recall: 0.9021 - f1_score: 0.9071 - val_loss: 5.3099 - val_acc: 0.9304 - val_precision: 0.9093 - val_recall: 0.9403 - val_f1_score: 0.9240\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2793 - acc: 0.9084 - precision: 0.9155 - recall: 0.8993 - f1_score: 0.9060 - val_loss: 5.2817 - val_acc: 0.9304 - val_precision: 0.9093 - val_recall: 0.9403 - val_f1_score: 0.9240\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2513 - acc: 0.9084 - precision: 0.9230 - recall: 0.9029 - f1_score: 0.9107 - val_loss: 5.2536 - val_acc: 0.9304 - val_precision: 0.9093 - val_recall: 0.9403 - val_f1_score: 0.9240\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s - loss: 5.2236 - acc: 0.9084 - precision: 0.9237 - recall: 0.9038 - f1_score: 0.9110 - val_loss: 5.2258 - val_acc: 0.9367 - val_precision: 0.9250 - val_recall: 0.9403 - val_f1_score: 0.9316\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1961 - acc: 0.9147 - precision: 0.9231 - recall: 0.9016 - f1_score: 0.9117 - val_loss: 5.1982 - val_acc: 0.9304 - val_precision: 0.9240 - val_recall: 0.9237 - val_f1_score: 0.9221\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1688 - acc: 0.9131 - precision: 0.9293 - recall: 0.8976 - f1_score: 0.9115 - val_loss: 5.1708 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1418 - acc: 0.9194 - precision: 0.9419 - recall: 0.8993 - f1_score: 0.9184 - val_loss: 5.1436 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s - loss: 5.1149 - acc: 0.9179 - precision: 0.9398 - recall: 0.8979 - f1_score: 0.9165 - val_loss: 5.1166 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0882 - acc: 0.9163 - precision: 0.9460 - recall: 0.8880 - f1_score: 0.9143 - val_loss: 5.0898 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0616 - acc: 0.9179 - precision: 0.9433 - recall: 0.8866 - f1_score: 0.9117 - val_loss: 5.0631 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 5.0353 - acc: 0.9194 - precision: 0.9482 - recall: 0.8838 - f1_score: 0.9140 - val_loss: 5.0367 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s - loss: 5.0092 - acc: 0.9194 - precision: 0.9497 - recall: 0.8892 - f1_score: 0.9172 - val_loss: 5.0104 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9832 - acc: 0.9210 - precision: 0.9546 - recall: 0.8903 - f1_score: 0.9185 - val_loss: 4.9843 - val_acc: 0.9304 - val_precision: 0.9313 - val_recall: 0.9105 - val_f1_score: 0.9195\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9574 - acc: 0.9226 - precision: 0.9581 - recall: 0.8910 - f1_score: 0.9210 - val_loss: 4.9584 - val_acc: 0.9367 - val_precision: 0.9444 - val_recall: 0.9105 - val_f1_score: 0.9256\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9317 - acc: 0.9210 - precision: 0.9565 - recall: 0.8822 - f1_score: 0.9171 - val_loss: 4.9327 - val_acc: 0.9430 - val_precision: 0.9553 - val_recall: 0.9105 - val_f1_score: 0.9313\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s - loss: 4.9063 - acc: 0.9226 - precision: 0.9587 - recall: 0.8815 - f1_score: 0.9166 - val_loss: 4.9071 - val_acc: 0.9430 - val_precision: 0.9553 - val_recall: 0.9105 - val_f1_score: 0.9313\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8810 - acc: 0.9210 - precision: 0.9582 - recall: 0.8806 - f1_score: 0.9167 - val_loss: 4.8818 - val_acc: 0.9430 - val_precision: 0.9553 - val_recall: 0.9105 - val_f1_score: 0.9313\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8559 - acc: 0.9210 - precision: 0.9607 - recall: 0.8809 - f1_score: 0.9177 - val_loss: 4.8565 - val_acc: 0.9494 - val_precision: 0.9802 - val_recall: 0.8938 - val_f1_score: 0.9337\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8310 - acc: 0.9242 - precision: 0.9670 - recall: 0.8817 - f1_score: 0.9214 - val_loss: 4.8315 - val_acc: 0.9494 - val_precision: 0.9802 - val_recall: 0.8938 - val_f1_score: 0.9337\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s - loss: 4.8062 - acc: 0.9242 - precision: 0.9662 - recall: 0.8810 - f1_score: 0.9190 - val_loss: 4.8066 - val_acc: 0.9494 - val_precision: 0.9802 - val_recall: 0.8938 - val_f1_score: 0.9337\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7815 - acc: 0.9242 - precision: 0.9687 - recall: 0.8788 - f1_score: 0.9194 - val_loss: 4.7819 - val_acc: 0.9494 - val_precision: 0.9802 - val_recall: 0.8938 - val_f1_score: 0.9337\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7571 - acc: 0.9242 - precision: 0.9657 - recall: 0.8768 - f1_score: 0.9158 - val_loss: 4.7573 - val_acc: 0.9430 - val_precision: 0.9802 - val_recall: 0.8806 - val_f1_score: 0.9260\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7328 - acc: 0.9242 - precision: 0.9624 - recall: 0.8750 - f1_score: 0.9157 - val_loss: 4.7329 - val_acc: 0.9430 - val_precision: 0.9802 - val_recall: 0.8806 - val_f1_score: 0.9260\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s - loss: 4.7086 - acc: 0.9242 - precision: 0.9686 - recall: 0.8762 - f1_score: 0.9180 - val_loss: 4.7086 - val_acc: 0.9430 - val_precision: 0.9802 - val_recall: 0.8806 - val_f1_score: 0.9260\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6846 - acc: 0.9242 - precision: 0.9649 - recall: 0.8822 - f1_score: 0.9206 - val_loss: 4.6845 - val_acc: 0.9430 - val_precision: 0.9802 - val_recall: 0.8806 - val_f1_score: 0.9260\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 4.6415 - acc: 0.9600 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.956 - 0s - loss: 4.6607 - acc: 0.9242 - precision: 0.9629 - recall: 0.8793 - f1_score: 0.9179 - val_loss: 4.6606 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6370 - acc: 0.9258 - precision: 0.9677 - recall: 0.8772 - f1_score: 0.9195 - val_loss: 4.6368 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s - loss: 4.6134 - acc: 0.9242 - precision: 0.9644 - recall: 0.8830 - f1_score: 0.9204 - val_loss: 4.6131 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5900 - acc: 0.9258 - precision: 0.9670 - recall: 0.8809 - f1_score: 0.9211 - val_loss: 4.5896 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5667 - acc: 0.9242 - precision: 0.9637 - recall: 0.8806 - f1_score: 0.9182 - val_loss: 4.5662 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5435 - acc: 0.9258 - precision: 0.9683 - recall: 0.8792 - f1_score: 0.9201 - val_loss: 4.5430 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s - loss: 4.5205 - acc: 0.9273 - precision: 0.9702 - recall: 0.8819 - f1_score: 0.9227 - val_loss: 4.5199 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4976 - acc: 0.9289 - precision: 0.9753 - recall: 0.8839 - f1_score: 0.9266 - val_loss: 4.4969 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4749 - acc: 0.9289 - precision: 0.9716 - recall: 0.8819 - f1_score: 0.9240 - val_loss: 4.4741 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4523 - acc: 0.9289 - precision: 0.9706 - recall: 0.8930 - f1_score: 0.9268 - val_loss: 4.4514 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4298 - acc: 0.9289 - precision: 0.9716 - recall: 0.8852 - f1_score: 0.9246 - val_loss: 4.4289 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s - loss: 4.4075 - acc: 0.9289 - precision: 0.9749 - recall: 0.8939 - f1_score: 0.9305 - val_loss: 4.4065 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3853 - acc: 0.9289 - precision: 0.9705 - recall: 0.8829 - f1_score: 0.9235 - val_loss: 4.3842 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3633 - acc: 0.9305 - precision: 0.9727 - recall: 0.8808 - f1_score: 0.9230 - val_loss: 4.3621 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3413 - acc: 0.9305 - precision: 0.9759 - recall: 0.8848 - f1_score: 0.9273 - val_loss: 4.3401 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s - loss: 4.3195 - acc: 0.9305 - precision: 0.9741 - recall: 0.8842 - f1_score: 0.9258 - val_loss: 4.3183 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2978 - acc: 0.9305 - precision: 0.9731 - recall: 0.8863 - f1_score: 0.9261 - val_loss: 4.2965 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 4.2763 - acc: 0.9305 - precision: 0.9774 - recall: 0.8872 - f1_score: 0.9289 - val_loss: 4.2749 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2548 - acc: 0.9305 - precision: 0.9754 - recall: 0.8817 - f1_score: 0.9257 - val_loss: 4.2534 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2336 - acc: 0.9305 - precision: 0.9783 - recall: 0.8846 - f1_score: 0.9280 - val_loss: 4.2321 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s - loss: 4.2124 - acc: 0.9289 - precision: 0.9746 - recall: 0.8826 - f1_score: 0.9248 - val_loss: 4.2108 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1913 - acc: 0.9289 - precision: 0.9758 - recall: 0.8814 - f1_score: 0.9248 - val_loss: 4.1897 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1704 - acc: 0.9305 - precision: 0.9808 - recall: 0.8774 - f1_score: 0.9251 - val_loss: 4.1687 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1496 - acc: 0.9305 - precision: 0.9802 - recall: 0.8754 - f1_score: 0.9234 - val_loss: 4.1479 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1289 - acc: 0.9305 - precision: 0.9799 - recall: 0.8805 - f1_score: 0.9266 - val_loss: 4.1271 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s - loss: 4.1083 - acc: 0.9305 - precision: 0.9786 - recall: 0.8837 - f1_score: 0.9269 - val_loss: 4.1065 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0878 - acc: 0.9305 - precision: 0.9774 - recall: 0.8872 - f1_score: 0.9271 - val_loss: 4.0860 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0675 - acc: 0.9305 - precision: 0.9789 - recall: 0.8837 - f1_score: 0.9273 - val_loss: 4.0656 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0472 - acc: 0.9305 - precision: 0.9791 - recall: 0.8826 - f1_score: 0.9274 - val_loss: 4.0453 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0271 - acc: 0.9305 - precision: 0.9790 - recall: 0.8801 - f1_score: 0.9261 - val_loss: 4.0251 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s - loss: 4.0071 - acc: 0.9305 - precision: 0.9800 - recall: 0.8801 - f1_score: 0.9255 - val_loss: 4.0051 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9872 - acc: 0.9305 - precision: 0.9803 - recall: 0.8775 - f1_score: 0.9244 - val_loss: 3.9852 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9674 - acc: 0.9305 - precision: 0.9783 - recall: 0.8768 - f1_score: 0.9235 - val_loss: 3.9654 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9478 - acc: 0.9305 - precision: 0.9757 - recall: 0.8760 - f1_score: 0.9216 - val_loss: 3.9457 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9282 - acc: 0.9305 - precision: 0.9786 - recall: 0.8846 - f1_score: 0.9261 - val_loss: 3.9261 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s - loss: 3.9088 - acc: 0.9305 - precision: 0.9801 - recall: 0.8770 - f1_score: 0.9246 - val_loss: 3.9066 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8894 - acc: 0.9305 - precision: 0.9781 - recall: 0.8788 - f1_score: 0.9250 - val_loss: 3.8873 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8702 - acc: 0.9305 - precision: 0.9792 - recall: 0.8872 - f1_score: 0.9283 - val_loss: 3.8680 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8511 - acc: 0.9305 - precision: 0.9763 - recall: 0.8769 - f1_score: 0.9228 - val_loss: 3.8489 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8321 - acc: 0.9305 - precision: 0.9766 - recall: 0.8794 - f1_score: 0.9244 - val_loss: 3.8298 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s - loss: 3.8132 - acc: 0.9305 - precision: 0.9765 - recall: 0.8787 - f1_score: 0.9237 - val_loss: 3.8109 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7944 - acc: 0.9305 - precision: 0.9781 - recall: 0.8775 - f1_score: 0.9240 - val_loss: 3.7921 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7757 - acc: 0.9305 - precision: 0.9795 - recall: 0.8811 - f1_score: 0.9265 - val_loss: 3.7734 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7571 - acc: 0.9305 - precision: 0.9776 - recall: 0.8807 - f1_score: 0.9256 - val_loss: 3.7547 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7386 - acc: 0.9305 - precision: 0.9792 - recall: 0.8802 - f1_score: 0.9251 - val_loss: 3.7362 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7202 - acc: 0.9305 - precision: 0.9783 - recall: 0.8833 - f1_score: 0.9269 - val_loss: 3.7178 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s - loss: 3.7019 - acc: 0.9305 - precision: 0.9781 - recall: 0.8834 - f1_score: 0.9266 - val_loss: 3.6995 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6837 - acc: 0.9305 - precision: 0.9797 - recall: 0.8779 - f1_score: 0.9236 - val_loss: 3.6812 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6656 - acc: 0.9305 - precision: 0.9797 - recall: 0.8773 - f1_score: 0.9244 - val_loss: 3.6632 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.6476 - acc: 0.9321 - precision: 0.9848 - recall: 0.8768 - f1_score: 0.9255 - val_loss: 3.6452 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6297 - acc: 0.9321 - precision: 0.9829 - recall: 0.8756 - f1_score: 0.9242 - val_loss: 3.6272 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s - loss: 3.6119 - acc: 0.9321 - precision: 0.9817 - recall: 0.8842 - f1_score: 0.9279 - val_loss: 3.6095 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5942 - acc: 0.9321 - precision: 0.9827 - recall: 0.8824 - f1_score: 0.9285 - val_loss: 3.5917 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5766 - acc: 0.9305 - precision: 0.9836 - recall: 0.8800 - f1_score: 0.9270 - val_loss: 3.5741 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5591 - acc: 0.9305 - precision: 0.9806 - recall: 0.8745 - f1_score: 0.9229 - val_loss: 3.5566 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5417 - acc: 0.9321 - precision: 0.9820 - recall: 0.8819 - f1_score: 0.9288 - val_loss: 3.5392 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5244 - acc: 0.9321 - precision: 0.9825 - recall: 0.8848 - f1_score: 0.9294 - val_loss: 3.5219 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s - loss: 3.5072 - acc: 0.9336 - precision: 0.9835 - recall: 0.8850 - f1_score: 0.9303 - val_loss: 3.5046 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4901 - acc: 0.9336 - precision: 0.9835 - recall: 0.8886 - f1_score: 0.9313 - val_loss: 3.4875 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4730 - acc: 0.9336 - precision: 0.9819 - recall: 0.8816 - f1_score: 0.9282 - val_loss: 3.4705 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4561 - acc: 0.9336 - precision: 0.9820 - recall: 0.8831 - f1_score: 0.9296 - val_loss: 3.4535 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4393 - acc: 0.9336 - precision: 0.9824 - recall: 0.8808 - f1_score: 0.9276 - val_loss: 3.4367 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4225 - acc: 0.9336 - precision: 0.9832 - recall: 0.8804 - f1_score: 0.9271 - val_loss: 3.4199 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s - loss: 3.4058 - acc: 0.9336 - precision: 0.9834 - recall: 0.8853 - f1_score: 0.9300 - val_loss: 3.4032 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3893 - acc: 0.9336 - precision: 0.9815 - recall: 0.8887 - f1_score: 0.9318 - val_loss: 3.3867 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3728 - acc: 0.9336 - precision: 0.9835 - recall: 0.8840 - f1_score: 0.9301 - val_loss: 3.3702 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3564 - acc: 0.9336 - precision: 0.9824 - recall: 0.8812 - f1_score: 0.9281 - val_loss: 3.3538 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3401 - acc: 0.9336 - precision: 0.9809 - recall: 0.8804 - f1_score: 0.9273 - val_loss: 3.3375 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3239 - acc: 0.9336 - precision: 0.9834 - recall: 0.8828 - f1_score: 0.9287 - val_loss: 3.3213 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s - loss: 3.3077 - acc: 0.9336 - precision: 0.9811 - recall: 0.8866 - f1_score: 0.9286 - val_loss: 3.3051 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2917 - acc: 0.9336 - precision: 0.9835 - recall: 0.8832 - f1_score: 0.9296 - val_loss: 3.2891 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2757 - acc: 0.9336 - precision: 0.9833 - recall: 0.8808 - f1_score: 0.9271 - val_loss: 3.2731 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2599 - acc: 0.9336 - precision: 0.9830 - recall: 0.8875 - f1_score: 0.9315 - val_loss: 3.2572 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2441 - acc: 0.9336 - precision: 0.9824 - recall: 0.8845 - f1_score: 0.9296 - val_loss: 3.2414 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2284 - acc: 0.9336 - precision: 0.9839 - recall: 0.8854 - f1_score: 0.9299 - val_loss: 3.2257 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s - loss: 3.2128 - acc: 0.9336 - precision: 0.9820 - recall: 0.8822 - f1_score: 0.9284 - val_loss: 3.2101 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1972 - acc: 0.9336 - precision: 0.9823 - recall: 0.8827 - f1_score: 0.9289 - val_loss: 3.1946 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1818 - acc: 0.9336 - precision: 0.9808 - recall: 0.8788 - f1_score: 0.9261 - val_loss: 3.1792 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1664 - acc: 0.9336 - precision: 0.9837 - recall: 0.8796 - f1_score: 0.9276 - val_loss: 3.1638 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1511 - acc: 0.9336 - precision: 0.9822 - recall: 0.8824 - f1_score: 0.9285 - val_loss: 3.1485 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1359 - acc: 0.9336 - precision: 0.9826 - recall: 0.8833 - f1_score: 0.9296 - val_loss: 3.1333 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 125/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 3.1208 - acc: 0.9336 - precision: 0.9826 - recall: 0.8807 - f1_score: 0.9264 - val_loss: 3.1182 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s - loss: 3.1058 - acc: 0.9336 - precision: 0.9842 - recall: 0.8841 - f1_score: 0.9304 - val_loss: 3.1032 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0908 - acc: 0.9336 - precision: 0.9842 - recall: 0.8787 - f1_score: 0.9273 - val_loss: 3.0882 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0759 - acc: 0.9336 - precision: 0.9810 - recall: 0.8844 - f1_score: 0.9280 - val_loss: 3.0733 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0611 - acc: 0.9336 - precision: 0.9811 - recall: 0.8833 - f1_score: 0.9287 - val_loss: 3.0586 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0464 - acc: 0.9336 - precision: 0.9826 - recall: 0.8881 - f1_score: 0.9318 - val_loss: 3.0438 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0317 - acc: 0.9336 - precision: 0.9821 - recall: 0.8859 - f1_score: 0.9305 - val_loss: 3.0292 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0172 - acc: 0.9336 - precision: 0.9843 - recall: 0.8818 - f1_score: 0.9298 - val_loss: 3.0146 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s - loss: 3.0027 - acc: 0.9336 - precision: 0.9831 - recall: 0.8794 - f1_score: 0.9269 - val_loss: 3.0001 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9883 - acc: 0.9336 - precision: 0.9816 - recall: 0.8843 - f1_score: 0.9292 - val_loss: 2.9857 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9739 - acc: 0.9336 - precision: 0.9833 - recall: 0.8849 - f1_score: 0.9294 - val_loss: 2.9714 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9597 - acc: 0.9336 - precision: 0.9825 - recall: 0.8838 - f1_score: 0.9292 - val_loss: 2.9572 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9455 - acc: 0.9336 - precision: 0.9825 - recall: 0.8799 - f1_score: 0.9266 - val_loss: 2.9430 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9314 - acc: 0.9336 - precision: 0.9808 - recall: 0.8816 - f1_score: 0.9278 - val_loss: 2.9289 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9174 - acc: 0.9336 - precision: 0.9788 - recall: 0.8811 - f1_score: 0.9267 - val_loss: 2.9149 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s - loss: 2.9034 - acc: 0.9336 - precision: 0.9845 - recall: 0.8836 - f1_score: 0.9287 - val_loss: 2.9010 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8895 - acc: 0.9336 - precision: 0.9835 - recall: 0.8849 - f1_score: 0.9300 - val_loss: 2.8871 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8757 - acc: 0.9352 - precision: 0.9819 - recall: 0.8864 - f1_score: 0.9311 - val_loss: 2.8733 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8620 - acc: 0.9352 - precision: 0.9837 - recall: 0.8858 - f1_score: 0.9307 - val_loss: 2.8596 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8483 - acc: 0.9352 - precision: 0.9839 - recall: 0.8917 - f1_score: 0.9342 - val_loss: 2.8459 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8347 - acc: 0.9352 - precision: 0.9836 - recall: 0.8872 - f1_score: 0.9318 - val_loss: 2.8323 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8212 - acc: 0.9352 - precision: 0.9815 - recall: 0.8853 - f1_score: 0.9285 - val_loss: 2.8188 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s - loss: 2.8078 - acc: 0.9352 - precision: 0.9835 - recall: 0.8853 - f1_score: 0.9306 - val_loss: 2.8054 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7944 - acc: 0.9352 - precision: 0.9831 - recall: 0.8888 - f1_score: 0.9327 - val_loss: 2.7920 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7811 - acc: 0.9352 - precision: 0.9840 - recall: 0.8808 - f1_score: 0.9283 - val_loss: 2.7787 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7679 - acc: 0.9352 - precision: 0.9828 - recall: 0.8853 - f1_score: 0.9304 - val_loss: 2.7655 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7547 - acc: 0.9352 - precision: 0.9832 - recall: 0.8854 - f1_score: 0.9312 - val_loss: 2.7523 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7416 - acc: 0.9352 - precision: 0.9799 - recall: 0.8836 - f1_score: 0.9283 - val_loss: 2.7393 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7286 - acc: 0.9352 - precision: 0.9832 - recall: 0.8885 - f1_score: 0.9315 - val_loss: 2.7262 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7156 - acc: 0.9352 - precision: 0.9846 - recall: 0.8850 - f1_score: 0.9313 - val_loss: 2.7133 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s - loss: 2.7027 - acc: 0.9352 - precision: 0.9818 - recall: 0.8851 - f1_score: 0.9300 - val_loss: 2.7004 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6899 - acc: 0.9352 - precision: 0.9836 - recall: 0.8820 - f1_score: 0.9285 - val_loss: 2.6876 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.6772 - acc: 0.9352 - precision: 0.9840 - recall: 0.8880 - f1_score: 0.9326 - val_loss: 2.6749 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6645 - acc: 0.9352 - precision: 0.9831 - recall: 0.8843 - f1_score: 0.9298 - val_loss: 2.6622 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6519 - acc: 0.9352 - precision: 0.9807 - recall: 0.8882 - f1_score: 0.9312 - val_loss: 2.6496 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6393 - acc: 0.9352 - precision: 0.9821 - recall: 0.8870 - f1_score: 0.9311 - val_loss: 2.6371 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6268 - acc: 0.9352 - precision: 0.9827 - recall: 0.8863 - f1_score: 0.9299 - val_loss: 2.6246 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6144 - acc: 0.9352 - precision: 0.9831 - recall: 0.8873 - f1_score: 0.9321 - val_loss: 2.6122 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s - loss: 2.6020 - acc: 0.9352 - precision: 0.9794 - recall: 0.8867 - f1_score: 0.9297 - val_loss: 2.5998 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5898 - acc: 0.9352 - precision: 0.9816 - recall: 0.8863 - f1_score: 0.9300 - val_loss: 2.5875 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5775 - acc: 0.9352 - precision: 0.9832 - recall: 0.8887 - f1_score: 0.9327 - val_loss: 2.5753 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5654 - acc: 0.9352 - precision: 0.9825 - recall: 0.8866 - f1_score: 0.9304 - val_loss: 2.5632 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5533 - acc: 0.9352 - precision: 0.9833 - recall: 0.8847 - f1_score: 0.9293 - val_loss: 2.5511 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5412 - acc: 0.9352 - precision: 0.9827 - recall: 0.8852 - f1_score: 0.9305 - val_loss: 2.5391 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5293 - acc: 0.9352 - precision: 0.9827 - recall: 0.8861 - f1_score: 0.9307 - val_loss: 2.5271 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5174 - acc: 0.9352 - precision: 0.9837 - recall: 0.8857 - f1_score: 0.9306 - val_loss: 2.5152 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s - loss: 2.5055 - acc: 0.9352 - precision: 0.9823 - recall: 0.8849 - f1_score: 0.9295 - val_loss: 2.5034 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4937 - acc: 0.9352 - precision: 0.9827 - recall: 0.8901 - f1_score: 0.9323 - val_loss: 2.4917 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4820 - acc: 0.9352 - precision: 0.9816 - recall: 0.8867 - f1_score: 0.9301 - val_loss: 2.4799 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4703 - acc: 0.9352 - precision: 0.9834 - recall: 0.8858 - f1_score: 0.9314 - val_loss: 2.4683 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4588 - acc: 0.9352 - precision: 0.9822 - recall: 0.8867 - f1_score: 0.9308 - val_loss: 2.4567 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4472 - acc: 0.9352 - precision: 0.9824 - recall: 0.8879 - f1_score: 0.9321 - val_loss: 2.4452 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4357 - acc: 0.9352 - precision: 0.9844 - recall: 0.8833 - f1_score: 0.9294 - val_loss: 2.4338 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4243 - acc: 0.9352 - precision: 0.9830 - recall: 0.8887 - f1_score: 0.9322 - val_loss: 2.4223 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4130 - acc: 0.9352 - precision: 0.9842 - recall: 0.8865 - f1_score: 0.9316 - val_loss: 2.4110 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s - loss: 2.4017 - acc: 0.9352 - precision: 0.9829 - recall: 0.8880 - f1_score: 0.9320 - val_loss: 2.3997 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3904 - acc: 0.9352 - precision: 0.9827 - recall: 0.8839 - f1_score: 0.9283 - val_loss: 2.3885 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3793 - acc: 0.9352 - precision: 0.9813 - recall: 0.8899 - f1_score: 0.9323 - val_loss: 2.3773 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3681 - acc: 0.9352 - precision: 0.9819 - recall: 0.8890 - f1_score: 0.9321 - val_loss: 2.3662 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3571 - acc: 0.9352 - precision: 0.9827 - recall: 0.8870 - f1_score: 0.9316 - val_loss: 2.3552 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3461 - acc: 0.9352 - precision: 0.9822 - recall: 0.8899 - f1_score: 0.9321 - val_loss: 2.3442 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3351 - acc: 0.9352 - precision: 0.9841 - recall: 0.8831 - f1_score: 0.9280 - val_loss: 2.3333 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3242 - acc: 0.9352 - precision: 0.9850 - recall: 0.8875 - f1_score: 0.9319 - val_loss: 2.3224 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s - loss: 2.3134 - acc: 0.9352 - precision: 0.9819 - recall: 0.8883 - f1_score: 0.9316 - val_loss: 2.3116 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 189/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 2.3026 - acc: 0.9352 - precision: 0.9825 - recall: 0.8879 - f1_score: 0.9312 - val_loss: 2.3008 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2919 - acc: 0.9352 - precision: 0.9811 - recall: 0.8845 - f1_score: 0.9292 - val_loss: 2.2901 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2813 - acc: 0.9352 - precision: 0.9830 - recall: 0.8850 - f1_score: 0.9308 - val_loss: 2.2795 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2706 - acc: 0.9352 - precision: 0.9823 - recall: 0.8886 - f1_score: 0.9318 - val_loss: 2.2689 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2601 - acc: 0.9352 - precision: 0.9826 - recall: 0.8849 - f1_score: 0.9304 - val_loss: 2.2584 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2496 - acc: 0.9352 - precision: 0.9834 - recall: 0.8855 - f1_score: 0.9306 - val_loss: 2.2479 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2392 - acc: 0.9352 - precision: 0.9849 - recall: 0.8853 - f1_score: 0.9307 - val_loss: 2.2374 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2288 - acc: 0.9352 - precision: 0.9801 - recall: 0.8868 - f1_score: 0.9307 - val_loss: 2.2271 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2184 - acc: 0.9352 - precision: 0.9826 - recall: 0.8860 - f1_score: 0.9302 - val_loss: 2.2168 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s - loss: 2.2082 - acc: 0.9352 - precision: 0.9822 - recall: 0.8818 - f1_score: 0.9276 - val_loss: 2.2065 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1979 - acc: 0.9352 - precision: 0.9830 - recall: 0.8882 - f1_score: 0.9317 - val_loss: 2.1963 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1878 - acc: 0.9352 - precision: 0.9819 - recall: 0.8844 - f1_score: 0.9302 - val_loss: 2.1861 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1776 - acc: 0.9352 - precision: 0.9841 - recall: 0.8873 - f1_score: 0.9320 - val_loss: 2.1760 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1676 - acc: 0.9352 - precision: 0.9829 - recall: 0.8887 - f1_score: 0.9330 - val_loss: 2.1660 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1576 - acc: 0.9352 - precision: 0.9817 - recall: 0.8885 - f1_score: 0.9320 - val_loss: 2.1560 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1476 - acc: 0.9368 - precision: 0.9823 - recall: 0.8837 - f1_score: 0.9285 - val_loss: 2.1460 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1377 - acc: 0.9368 - precision: 0.9826 - recall: 0.8869 - f1_score: 0.9315 - val_loss: 2.1361 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1278 - acc: 0.9368 - precision: 0.9815 - recall: 0.8903 - f1_score: 0.9333 - val_loss: 2.1263 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1180 - acc: 0.9368 - precision: 0.9821 - recall: 0.8917 - f1_score: 0.9339 - val_loss: 2.1165 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s - loss: 2.1083 - acc: 0.9368 - precision: 0.9834 - recall: 0.8897 - f1_score: 0.9329 - val_loss: 2.1068 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0986 - acc: 0.9368 - precision: 0.9816 - recall: 0.8902 - f1_score: 0.9324 - val_loss: 2.0971 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0889 - acc: 0.9368 - precision: 0.9820 - recall: 0.8852 - f1_score: 0.9296 - val_loss: 2.0874 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0793 - acc: 0.9368 - precision: 0.9825 - recall: 0.8908 - f1_score: 0.9323 - val_loss: 2.0778 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0698 - acc: 0.9368 - precision: 0.9801 - recall: 0.8837 - f1_score: 0.9271 - val_loss: 2.0683 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0603 - acc: 0.9368 - precision: 0.9820 - recall: 0.8913 - f1_score: 0.9331 - val_loss: 2.0588 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0508 - acc: 0.9368 - precision: 0.9823 - recall: 0.8929 - f1_score: 0.9343 - val_loss: 2.0494 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0414 - acc: 0.9368 - precision: 0.9836 - recall: 0.8904 - f1_score: 0.9334 - val_loss: 2.0400 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0320 - acc: 0.9368 - precision: 0.9835 - recall: 0.8898 - f1_score: 0.9331 - val_loss: 2.0306 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0227 - acc: 0.9368 - precision: 0.9833 - recall: 0.8906 - f1_score: 0.9339 - val_loss: 2.0213 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0135 - acc: 0.9368 - precision: 0.9827 - recall: 0.8905 - f1_score: 0.9333 - val_loss: 2.0121 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s - loss: 2.0043 - acc: 0.9368 - precision: 0.9818 - recall: 0.8866 - f1_score: 0.9309 - val_loss: 2.0029 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9951 - acc: 0.9368 - precision: 0.9838 - recall: 0.8921 - f1_score: 0.9349 - val_loss: 1.9938 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.9860 - acc: 0.9368 - precision: 0.9815 - recall: 0.8879 - f1_score: 0.9315 - val_loss: 1.9847 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9769 - acc: 0.9368 - precision: 0.9813 - recall: 0.8821 - f1_score: 0.9278 - val_loss: 1.9756 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9679 - acc: 0.9368 - precision: 0.9827 - recall: 0.8881 - f1_score: 0.9316 - val_loss: 1.9666 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9589 - acc: 0.9368 - precision: 0.9841 - recall: 0.8908 - f1_score: 0.9342 - val_loss: 1.9576 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9500 - acc: 0.9368 - precision: 0.9822 - recall: 0.8863 - f1_score: 0.9313 - val_loss: 1.9487 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9411 - acc: 0.9368 - precision: 0.9848 - recall: 0.8892 - f1_score: 0.9329 - val_loss: 1.9399 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9323 - acc: 0.9368 - precision: 0.9821 - recall: 0.8901 - f1_score: 0.9330 - val_loss: 1.9310 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9235 - acc: 0.9368 - precision: 0.9836 - recall: 0.8886 - f1_score: 0.9327 - val_loss: 1.9223 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9148 - acc: 0.9368 - precision: 0.9844 - recall: 0.8892 - f1_score: 0.9325 - val_loss: 1.9135 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s - loss: 1.9061 - acc: 0.9368 - precision: 0.9836 - recall: 0.8933 - f1_score: 0.9352 - val_loss: 1.9048 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8974 - acc: 0.9368 - precision: 0.9808 - recall: 0.8910 - f1_score: 0.9329 - val_loss: 1.8962 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8888 - acc: 0.9368 - precision: 0.9834 - recall: 0.8889 - f1_score: 0.9326 - val_loss: 1.8876 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8802 - acc: 0.9368 - precision: 0.9850 - recall: 0.8923 - f1_score: 0.9349 - val_loss: 1.8791 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8717 - acc: 0.9368 - precision: 0.9827 - recall: 0.8906 - f1_score: 0.9330 - val_loss: 1.8705 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8632 - acc: 0.9368 - precision: 0.9831 - recall: 0.8891 - f1_score: 0.9331 - val_loss: 1.8621 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8548 - acc: 0.9368 - precision: 0.9829 - recall: 0.8900 - f1_score: 0.9314 - val_loss: 1.8537 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8464 - acc: 0.9368 - precision: 0.9832 - recall: 0.8929 - f1_score: 0.9346 - val_loss: 1.8453 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8381 - acc: 0.9368 - precision: 0.9816 - recall: 0.8860 - f1_score: 0.9300 - val_loss: 1.8370 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8298 - acc: 0.9368 - precision: 0.9823 - recall: 0.8870 - f1_score: 0.9300 - val_loss: 1.8287 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8215 - acc: 0.9368 - precision: 0.9813 - recall: 0.8928 - f1_score: 0.9331 - val_loss: 1.8204 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8133 - acc: 0.9368 - precision: 0.9810 - recall: 0.8891 - f1_score: 0.9317 - val_loss: 1.8122 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s - loss: 1.8051 - acc: 0.9368 - precision: 0.9804 - recall: 0.8885 - f1_score: 0.9312 - val_loss: 1.8041 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7970 - acc: 0.9368 - precision: 0.9836 - recall: 0.8913 - f1_score: 0.9341 - val_loss: 1.7960 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7889 - acc: 0.9368 - precision: 0.9809 - recall: 0.8950 - f1_score: 0.9344 - val_loss: 1.7879 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7809 - acc: 0.9368 - precision: 0.9815 - recall: 0.8900 - f1_score: 0.9329 - val_loss: 1.7799 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7729 - acc: 0.9368 - precision: 0.9831 - recall: 0.8898 - f1_score: 0.9321 - val_loss: 1.7719 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7649 - acc: 0.9368 - precision: 0.9849 - recall: 0.8915 - f1_score: 0.9351 - val_loss: 1.7639 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7570 - acc: 0.9368 - precision: 0.9827 - recall: 0.8903 - f1_score: 0.9332 - val_loss: 1.7560 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7491 - acc: 0.9368 - precision: 0.9820 - recall: 0.8868 - f1_score: 0.9305 - val_loss: 1.7482 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7413 - acc: 0.9368 - precision: 0.9832 - recall: 0.8894 - f1_score: 0.9322 - val_loss: 1.7403 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7335 - acc: 0.9368 - precision: 0.9820 - recall: 0.8930 - f1_score: 0.9340 - val_loss: 1.7325 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7257 - acc: 0.9368 - precision: 0.9828 - recall: 0.8894 - f1_score: 0.9318 - val_loss: 1.7248 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.7180 - acc: 0.9368 - precision: 0.9820 - recall: 0.8877 - f1_score: 0.9311 - val_loss: 1.7171 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7103 - acc: 0.9368 - precision: 0.9819 - recall: 0.8929 - f1_score: 0.9342 - val_loss: 1.7094 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s - loss: 1.7027 - acc: 0.9368 - precision: 0.9842 - recall: 0.8862 - f1_score: 0.9300 - val_loss: 1.7018 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.6947 - acc: 0.9367 - precision: 0.9856 - recall: 0.8890 - f1_score: 0.934 - 0s - loss: 1.6951 - acc: 0.9368 - precision: 0.9823 - recall: 0.8908 - f1_score: 0.9337 - val_loss: 1.6942 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6875 - acc: 0.9368 - precision: 0.9821 - recall: 0.8892 - f1_score: 0.9323 - val_loss: 1.6867 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6800 - acc: 0.9368 - precision: 0.9826 - recall: 0.8895 - f1_score: 0.9329 - val_loss: 1.6792 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6725 - acc: 0.9368 - precision: 0.9797 - recall: 0.8932 - f1_score: 0.9323 - val_loss: 1.6717 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6651 - acc: 0.9368 - precision: 0.9814 - recall: 0.8909 - f1_score: 0.9324 - val_loss: 1.6643 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6577 - acc: 0.9368 - precision: 0.9841 - recall: 0.8863 - f1_score: 0.9313 - val_loss: 1.6569 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6503 - acc: 0.9368 - precision: 0.9831 - recall: 0.8880 - f1_score: 0.9321 - val_loss: 1.6495 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6430 - acc: 0.9368 - precision: 0.9820 - recall: 0.8891 - f1_score: 0.9317 - val_loss: 1.6422 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6357 - acc: 0.9368 - precision: 0.9813 - recall: 0.8923 - f1_score: 0.9335 - val_loss: 1.6349 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6285 - acc: 0.9368 - precision: 0.9833 - recall: 0.8930 - f1_score: 0.9346 - val_loss: 1.6277 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6212 - acc: 0.9368 - precision: 0.9823 - recall: 0.8882 - f1_score: 0.9324 - val_loss: 1.6205 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6141 - acc: 0.9368 - precision: 0.9839 - recall: 0.8911 - f1_score: 0.9343 - val_loss: 1.6133 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s - loss: 1.6069 - acc: 0.9368 - precision: 0.9826 - recall: 0.8916 - f1_score: 0.9334 - val_loss: 1.6062 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5998 - acc: 0.9368 - precision: 0.9846 - recall: 0.8876 - f1_score: 0.9313 - val_loss: 1.5991 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5928 - acc: 0.9368 - precision: 0.9824 - recall: 0.8898 - f1_score: 0.9330 - val_loss: 1.5920 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5857 - acc: 0.9368 - precision: 0.9818 - recall: 0.8836 - f1_score: 0.9280 - val_loss: 1.5850 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5787 - acc: 0.9368 - precision: 0.9806 - recall: 0.8873 - f1_score: 0.9297 - val_loss: 1.5780 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5718 - acc: 0.9368 - precision: 0.9816 - recall: 0.8888 - f1_score: 0.9318 - val_loss: 1.5711 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5649 - acc: 0.9368 - precision: 0.9821 - recall: 0.8898 - f1_score: 0.9330 - val_loss: 1.5642 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5580 - acc: 0.9368 - precision: 0.9847 - recall: 0.8889 - f1_score: 0.9322 - val_loss: 1.5573 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5511 - acc: 0.9368 - precision: 0.9819 - recall: 0.8898 - f1_score: 0.9326 - val_loss: 1.5505 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5443 - acc: 0.9368 - precision: 0.9823 - recall: 0.8889 - f1_score: 0.9327 - val_loss: 1.5437 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5375 - acc: 0.9368 - precision: 0.9835 - recall: 0.8918 - f1_score: 0.9336 - val_loss: 1.5369 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5308 - acc: 0.9368 - precision: 0.9827 - recall: 0.8894 - f1_score: 0.9332 - val_loss: 1.5302 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5241 - acc: 0.9368 - precision: 0.9828 - recall: 0.8908 - f1_score: 0.9338 - val_loss: 1.5235 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5174 - acc: 0.9368 - precision: 0.9826 - recall: 0.8898 - f1_score: 0.9326 - val_loss: 1.5168 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5108 - acc: 0.9368 - precision: 0.9816 - recall: 0.8890 - f1_score: 0.9317 - val_loss: 1.5102 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s - loss: 1.5041 - acc: 0.9368 - precision: 0.9841 - recall: 0.8910 - f1_score: 0.9339 - val_loss: 1.5036 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4976 - acc: 0.9368 - precision: 0.9811 - recall: 0.8860 - f1_score: 0.9305 - val_loss: 1.4970 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.4910 - acc: 0.9368 - precision: 0.9827 - recall: 0.8921 - f1_score: 0.9347 - val_loss: 1.4905 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4845 - acc: 0.9368 - precision: 0.9822 - recall: 0.8887 - f1_score: 0.9316 - val_loss: 1.4840 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4781 - acc: 0.9368 - precision: 0.9811 - recall: 0.8921 - f1_score: 0.9330 - val_loss: 1.4775 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4716 - acc: 0.9368 - precision: 0.9826 - recall: 0.8895 - f1_score: 0.9326 - val_loss: 1.4711 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4652 - acc: 0.9368 - precision: 0.9841 - recall: 0.8861 - f1_score: 0.9312 - val_loss: 1.4647 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4588 - acc: 0.9368 - precision: 0.9845 - recall: 0.8914 - f1_score: 0.9330 - val_loss: 1.4583 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4525 - acc: 0.9368 - precision: 0.9818 - recall: 0.8895 - f1_score: 0.9327 - val_loss: 1.4520 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4462 - acc: 0.9368 - precision: 0.9816 - recall: 0.8907 - f1_score: 0.9321 - val_loss: 1.4457 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4399 - acc: 0.9368 - precision: 0.9842 - recall: 0.8909 - f1_score: 0.9340 - val_loss: 1.4394 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4337 - acc: 0.9368 - precision: 0.9830 - recall: 0.8924 - f1_score: 0.9343 - val_loss: 1.4332 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4275 - acc: 0.9368 - precision: 0.9827 - recall: 0.8906 - f1_score: 0.9338 - val_loss: 1.4270 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4213 - acc: 0.9368 - precision: 0.9826 - recall: 0.8888 - f1_score: 0.9320 - val_loss: 1.4208 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4151 - acc: 0.9384 - precision: 0.9832 - recall: 0.8919 - f1_score: 0.9342 - val_loss: 1.4147 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4090 - acc: 0.9384 - precision: 0.9818 - recall: 0.8910 - f1_score: 0.9328 - val_loss: 1.4086 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s - loss: 1.4029 - acc: 0.9384 - precision: 0.9831 - recall: 0.8904 - f1_score: 0.9328 - val_loss: 1.4025 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3969 - acc: 0.9384 - precision: 0.9826 - recall: 0.8943 - f1_score: 0.9357 - val_loss: 1.3965 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3909 - acc: 0.9384 - precision: 0.9829 - recall: 0.8899 - f1_score: 0.9334 - val_loss: 1.3904 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3849 - acc: 0.9384 - precision: 0.9838 - recall: 0.8917 - f1_score: 0.9336 - val_loss: 1.3845 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3789 - acc: 0.9384 - precision: 0.9825 - recall: 0.8933 - f1_score: 0.9339 - val_loss: 1.3785 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3730 - acc: 0.9384 - precision: 0.9831 - recall: 0.8961 - f1_score: 0.9367 - val_loss: 1.3726 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3671 - acc: 0.9384 - precision: 0.9817 - recall: 0.8929 - f1_score: 0.9338 - val_loss: 1.3667 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3612 - acc: 0.9384 - precision: 0.9808 - recall: 0.8878 - f1_score: 0.9310 - val_loss: 1.3608 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3554 - acc: 0.9384 - precision: 0.9840 - recall: 0.8953 - f1_score: 0.9364 - val_loss: 1.3550 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3496 - acc: 0.9384 - precision: 0.9832 - recall: 0.8984 - f1_score: 0.9381 - val_loss: 1.3492 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3438 - acc: 0.9384 - precision: 0.9834 - recall: 0.8925 - f1_score: 0.9351 - val_loss: 1.3434 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3380 - acc: 0.9384 - precision: 0.9836 - recall: 0.8969 - f1_score: 0.9374 - val_loss: 1.3377 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3323 - acc: 0.9384 - precision: 0.9815 - recall: 0.8940 - f1_score: 0.9349 - val_loss: 1.3320 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3266 - acc: 0.9384 - precision: 0.9805 - recall: 0.8897 - f1_score: 0.9306 - val_loss: 1.3263 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3210 - acc: 0.9384 - precision: 0.9808 - recall: 0.8898 - f1_score: 0.9320 - val_loss: 1.3207 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3154 - acc: 0.9384 - precision: 0.9807 - recall: 0.8928 - f1_score: 0.9335 - val_loss: 1.3150 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3097 - acc: 0.9384 - precision: 0.9822 - recall: 0.8922 - f1_score: 0.9344 - val_loss: 1.3095 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s - loss: 1.3042 - acc: 0.9384 - precision: 0.9807 - recall: 0.8851 - f1_score: 0.9295 - val_loss: 1.3039 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.2986 - acc: 0.9384 - precision: 0.9828 - recall: 0.8893 - f1_score: 0.9311 - val_loss: 1.2983 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2931 - acc: 0.9384 - precision: 0.9832 - recall: 0.8930 - f1_score: 0.9346 - val_loss: 1.2928 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2876 - acc: 0.9384 - precision: 0.9820 - recall: 0.8936 - f1_score: 0.9344 - val_loss: 1.2874 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2822 - acc: 0.9384 - precision: 0.9828 - recall: 0.8901 - f1_score: 0.9332 - val_loss: 1.2819 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2767 - acc: 0.9384 - precision: 0.9821 - recall: 0.8970 - f1_score: 0.9363 - val_loss: 1.2765 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2713 - acc: 0.9384 - precision: 0.9820 - recall: 0.8963 - f1_score: 0.9365 - val_loss: 1.2711 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2660 - acc: 0.9384 - precision: 0.9850 - recall: 0.8911 - f1_score: 0.9333 - val_loss: 1.2657 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2606 - acc: 0.9384 - precision: 0.9853 - recall: 0.8927 - f1_score: 0.9343 - val_loss: 1.2604 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2553 - acc: 0.9384 - precision: 0.9827 - recall: 0.8925 - f1_score: 0.9343 - val_loss: 1.2551 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2500 - acc: 0.9384 - precision: 0.9834 - recall: 0.8966 - f1_score: 0.9355 - val_loss: 1.2498 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2447 - acc: 0.9384 - precision: 0.9795 - recall: 0.8890 - f1_score: 0.9307 - val_loss: 1.2445 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2395 - acc: 0.9384 - precision: 0.9829 - recall: 0.8903 - f1_score: 0.9332 - val_loss: 1.2393 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2343 - acc: 0.9384 - precision: 0.9814 - recall: 0.8890 - f1_score: 0.9316 - val_loss: 1.2341 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2291 - acc: 0.9384 - precision: 0.9833 - recall: 0.8955 - f1_score: 0.9355 - val_loss: 1.2289 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2239 - acc: 0.9384 - precision: 0.9826 - recall: 0.8937 - f1_score: 0.9355 - val_loss: 1.2238 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2188 - acc: 0.9384 - precision: 0.9831 - recall: 0.8936 - f1_score: 0.9349 - val_loss: 1.2186 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2137 - acc: 0.9384 - precision: 0.9818 - recall: 0.8883 - f1_score: 0.9312 - val_loss: 1.2135 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2086 - acc: 0.9384 - precision: 0.9803 - recall: 0.8943 - f1_score: 0.9340 - val_loss: 1.2084 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s - loss: 1.2036 - acc: 0.9384 - precision: 0.9823 - recall: 0.8956 - f1_score: 0.9360 - val_loss: 1.2034 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1985 - acc: 0.9384 - precision: 0.9824 - recall: 0.8929 - f1_score: 0.9341 - val_loss: 1.1984 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1935 - acc: 0.9384 - precision: 0.9805 - recall: 0.8917 - f1_score: 0.9332 - val_loss: 1.1934 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1885 - acc: 0.9384 - precision: 0.9824 - recall: 0.8924 - f1_score: 0.9343 - val_loss: 1.1884 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1836 - acc: 0.9368 - precision: 0.9754 - recall: 0.8973 - f1_score: 0.9334 - val_loss: 1.1835 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1787 - acc: 0.9384 - precision: 0.9760 - recall: 0.8963 - f1_score: 0.9325 - val_loss: 1.1786 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1738 - acc: 0.9400 - precision: 0.9841 - recall: 0.8974 - f1_score: 0.9376 - val_loss: 1.1737 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1689 - acc: 0.9384 - precision: 0.9781 - recall: 0.8952 - f1_score: 0.9341 - val_loss: 1.1688 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1640 - acc: 0.9400 - precision: 0.9816 - recall: 0.8933 - f1_score: 0.9350 - val_loss: 1.1639 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1592 - acc: 0.9400 - precision: 0.9855 - recall: 0.8945 - f1_score: 0.9369 - val_loss: 1.1591 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1544 - acc: 0.9400 - precision: 0.9839 - recall: 0.8982 - f1_score: 0.9362 - val_loss: 1.1543 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1496 - acc: 0.9400 - precision: 0.9804 - recall: 0.8941 - f1_score: 0.9345 - val_loss: 1.1496 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1449 - acc: 0.9384 - precision: 0.9781 - recall: 0.8987 - f1_score: 0.9360 - val_loss: 1.1448 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1402 - acc: 0.9384 - precision: 0.9772 - recall: 0.9008 - f1_score: 0.9358 - val_loss: 1.1401 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 1.1354 - acc: 0.9384 - precision: 0.9795 - recall: 0.8983 - f1_score: 0.9361 - val_loss: 1.1354 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1308 - acc: 0.9384 - precision: 0.9798 - recall: 0.8959 - f1_score: 0.9345 - val_loss: 1.1307 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1261 - acc: 0.9384 - precision: 0.9812 - recall: 0.8961 - f1_score: 0.9347 - val_loss: 1.1261 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1215 - acc: 0.9384 - precision: 0.9791 - recall: 0.8957 - f1_score: 0.9346 - val_loss: 1.1214 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1169 - acc: 0.9384 - precision: 0.9810 - recall: 0.8943 - f1_score: 0.9344 - val_loss: 1.1168 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1123 - acc: 0.9384 - precision: 0.9793 - recall: 0.8964 - f1_score: 0.9353 - val_loss: 1.1123 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1077 - acc: 0.9384 - precision: 0.9785 - recall: 0.9013 - f1_score: 0.9366 - val_loss: 1.1077 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s - loss: 1.1032 - acc: 0.9384 - precision: 0.9790 - recall: 0.8930 - f1_score: 0.9325 - val_loss: 1.1032 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0987 - acc: 0.9384 - precision: 0.9797 - recall: 0.8951 - f1_score: 0.9343 - val_loss: 1.0987 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0942 - acc: 0.9384 - precision: 0.9776 - recall: 0.8921 - f1_score: 0.9323 - val_loss: 1.0942 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0897 - acc: 0.9384 - precision: 0.9795 - recall: 0.8983 - f1_score: 0.9360 - val_loss: 1.0897 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0853 - acc: 0.9384 - precision: 0.9796 - recall: 0.8952 - f1_score: 0.9345 - val_loss: 1.0853 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0808 - acc: 0.9384 - precision: 0.9812 - recall: 0.8947 - f1_score: 0.9346 - val_loss: 1.0809 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0764 - acc: 0.9384 - precision: 0.9801 - recall: 0.9009 - f1_score: 0.9371 - val_loss: 1.0764 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0721 - acc: 0.9384 - precision: 0.9795 - recall: 0.8989 - f1_score: 0.9367 - val_loss: 1.0721 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0677 - acc: 0.9384 - precision: 0.9797 - recall: 0.8928 - f1_score: 0.9333 - val_loss: 1.0677 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0634 - acc: 0.9384 - precision: 0.9780 - recall: 0.8955 - f1_score: 0.9335 - val_loss: 1.0634 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0591 - acc: 0.9384 - precision: 0.9794 - recall: 0.8964 - f1_score: 0.9353 - val_loss: 1.0591 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0548 - acc: 0.9384 - precision: 0.9781 - recall: 0.8938 - f1_score: 0.9335 - val_loss: 1.0548 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0505 - acc: 0.9384 - precision: 0.9795 - recall: 0.8954 - f1_score: 0.9337 - val_loss: 1.0505 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0462 - acc: 0.9384 - precision: 0.9799 - recall: 0.8984 - f1_score: 0.9355 - val_loss: 1.0463 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0420 - acc: 0.9384 - precision: 0.9802 - recall: 0.8962 - f1_score: 0.9356 - val_loss: 1.0421 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0378 - acc: 0.9384 - precision: 0.9780 - recall: 0.8962 - f1_score: 0.9344 - val_loss: 1.0379 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0336 - acc: 0.9384 - precision: 0.9793 - recall: 0.8970 - f1_score: 0.9351 - val_loss: 1.0337 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0295 - acc: 0.9384 - precision: 0.9807 - recall: 0.8987 - f1_score: 0.9367 - val_loss: 1.0296 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0253 - acc: 0.9384 - precision: 0.9829 - recall: 0.8947 - f1_score: 0.9355 - val_loss: 1.0254 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0212 - acc: 0.9384 - precision: 0.9796 - recall: 0.8942 - f1_score: 0.9340 - val_loss: 1.0213 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0171 - acc: 0.9384 - precision: 0.9765 - recall: 0.8930 - f1_score: 0.9322 - val_loss: 1.0172 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.0175 - acc: 0.9400 - precision: 1.0000 - recall: 0.8929 - f1_score: 0.943 - 0s - loss: 1.0130 - acc: 0.9384 - precision: 0.9770 - recall: 0.8985 - f1_score: 0.9355 - val_loss: 1.0131 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0090 - acc: 0.9384 - precision: 0.9793 - recall: 0.8974 - f1_score: 0.9349 - val_loss: 1.0091 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0049 - acc: 0.9384 - precision: 0.9780 - recall: 0.8956 - f1_score: 0.9331 - val_loss: 1.0051 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s - loss: 1.0009 - acc: 0.9384 - precision: 0.9777 - recall: 0.8972 - f1_score: 0.9351 - val_loss: 1.0011 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.9969 - acc: 0.9384 - precision: 0.9770 - recall: 0.8972 - f1_score: 0.9335 - val_loss: 0.9971 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9930 - acc: 0.9384 - precision: 0.9802 - recall: 0.8958 - f1_score: 0.9354 - val_loss: 0.9931 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9890 - acc: 0.9384 - precision: 0.9800 - recall: 0.8972 - f1_score: 0.9353 - val_loss: 0.9891 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9851 - acc: 0.9384 - precision: 0.9782 - recall: 0.9000 - f1_score: 0.9359 - val_loss: 0.9852 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9812 - acc: 0.9384 - precision: 0.9804 - recall: 0.8990 - f1_score: 0.9360 - val_loss: 0.9813 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9773 - acc: 0.9384 - precision: 0.9784 - recall: 0.8959 - f1_score: 0.9341 - val_loss: 0.9774 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9734 - acc: 0.9384 - precision: 0.9798 - recall: 0.8957 - f1_score: 0.9337 - val_loss: 0.9735 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9695 - acc: 0.9384 - precision: 0.9803 - recall: 0.8981 - f1_score: 0.9364 - val_loss: 0.9697 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9657 - acc: 0.9384 - precision: 0.9772 - recall: 0.8958 - f1_score: 0.9343 - val_loss: 0.9658 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9619 - acc: 0.9384 - precision: 0.9776 - recall: 0.8936 - f1_score: 0.9330 - val_loss: 0.9620 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9581 - acc: 0.9384 - precision: 0.9787 - recall: 0.8973 - f1_score: 0.9353 - val_loss: 0.9582 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9543 - acc: 0.9384 - precision: 0.9787 - recall: 0.8917 - f1_score: 0.9309 - val_loss: 0.9545 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9506 - acc: 0.9384 - precision: 0.9809 - recall: 0.8985 - f1_score: 0.9363 - val_loss: 0.9507 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9468 - acc: 0.9400 - precision: 0.9816 - recall: 0.8960 - f1_score: 0.9355 - val_loss: 0.9470 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9431 - acc: 0.9400 - precision: 0.9814 - recall: 0.8939 - f1_score: 0.9347 - val_loss: 0.9433 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9394 - acc: 0.9384 - precision: 0.9794 - recall: 0.8960 - f1_score: 0.9345 - val_loss: 0.9396 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9357 - acc: 0.9400 - precision: 0.9833 - recall: 0.8943 - f1_score: 0.9355 - val_loss: 0.9359 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9320 - acc: 0.9400 - precision: 0.9836 - recall: 0.8973 - f1_score: 0.9372 - val_loss: 0.9322 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9284 - acc: 0.9400 - precision: 0.9817 - recall: 0.8963 - f1_score: 0.9365 - val_loss: 0.9286 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9248 - acc: 0.9400 - precision: 0.9830 - recall: 0.8975 - f1_score: 0.9376 - val_loss: 0.9250 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9212 - acc: 0.9400 - precision: 0.9842 - recall: 0.8967 - f1_score: 0.9363 - val_loss: 0.9213 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9176 - acc: 0.9400 - precision: 0.9810 - recall: 0.8927 - f1_score: 0.9331 - val_loss: 0.9178 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9140 - acc: 0.9400 - precision: 0.9833 - recall: 0.8978 - f1_score: 0.9369 - val_loss: 0.9142 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9105 - acc: 0.9400 - precision: 0.9815 - recall: 0.8950 - f1_score: 0.9357 - val_loss: 0.9106 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9069 - acc: 0.9400 - precision: 0.9832 - recall: 0.8972 - f1_score: 0.9362 - val_loss: 0.9071 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s - loss: 0.9034 - acc: 0.9400 - precision: 0.9823 - recall: 0.8963 - f1_score: 0.9368 - val_loss: 0.9036 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8999 - acc: 0.9400 - precision: 0.9828 - recall: 0.8974 - f1_score: 0.9373 - val_loss: 0.9001 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8964 - acc: 0.9400 - precision: 0.9827 - recall: 0.8931 - f1_score: 0.9351 - val_loss: 0.8966 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8930 - acc: 0.9400 - precision: 0.9823 - recall: 0.8938 - f1_score: 0.9350 - val_loss: 0.8932 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8895 - acc: 0.9400 - precision: 0.9831 - recall: 0.8947 - f1_score: 0.9354 - val_loss: 0.8897 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8861 - acc: 0.9400 - precision: 0.9823 - recall: 0.9005 - f1_score: 0.9383 - val_loss: 0.8863 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8827 - acc: 0.9400 - precision: 0.9858 - recall: 0.8997 - f1_score: 0.9389 - val_loss: 0.8829 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.8793 - acc: 0.9400 - precision: 0.9839 - recall: 0.8958 - f1_score: 0.9367 - val_loss: 0.8795 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8759 - acc: 0.9400 - precision: 0.9820 - recall: 0.8979 - f1_score: 0.9371 - val_loss: 0.8761 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8726 - acc: 0.9400 - precision: 0.9839 - recall: 0.8961 - f1_score: 0.9362 - val_loss: 0.8728 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8692 - acc: 0.9400 - precision: 0.9825 - recall: 0.8917 - f1_score: 0.9332 - val_loss: 0.8694 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8659 - acc: 0.9400 - precision: 0.9820 - recall: 0.8996 - f1_score: 0.9379 - val_loss: 0.8661 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8626 - acc: 0.9400 - precision: 0.9825 - recall: 0.8949 - f1_score: 0.9360 - val_loss: 0.8628 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8593 - acc: 0.9400 - precision: 0.9824 - recall: 0.8930 - f1_score: 0.9332 - val_loss: 0.8595 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8560 - acc: 0.9400 - precision: 0.9827 - recall: 0.8980 - f1_score: 0.9378 - val_loss: 0.8562 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8528 - acc: 0.9400 - precision: 0.9844 - recall: 0.8953 - f1_score: 0.9360 - val_loss: 0.8530 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8495 - acc: 0.9400 - precision: 0.9794 - recall: 0.8912 - f1_score: 0.9328 - val_loss: 0.8497 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8463 - acc: 0.9400 - precision: 0.9810 - recall: 0.8938 - f1_score: 0.9342 - val_loss: 0.8465 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8431 - acc: 0.9400 - precision: 0.9834 - recall: 0.8969 - f1_score: 0.9374 - val_loss: 0.8433 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8399 - acc: 0.9400 - precision: 0.9833 - recall: 0.8945 - f1_score: 0.9353 - val_loss: 0.8401 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8367 - acc: 0.9400 - precision: 0.9817 - recall: 0.8983 - f1_score: 0.9364 - val_loss: 0.8369 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.8137 - acc: 0.9400 - precision: 0.9615 - recall: 0.9259 - f1_score: 0.943 - 0s - loss: 0.8335 - acc: 0.9400 - precision: 0.9847 - recall: 0.8973 - f1_score: 0.9380 - val_loss: 0.8338 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8304 - acc: 0.9400 - precision: 0.9835 - recall: 0.8943 - f1_score: 0.9354 - val_loss: 0.8306 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8273 - acc: 0.9400 - precision: 0.9799 - recall: 0.8939 - f1_score: 0.9339 - val_loss: 0.8275 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8242 - acc: 0.9400 - precision: 0.9830 - recall: 0.8958 - f1_score: 0.9358 - val_loss: 0.8244 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8211 - acc: 0.9400 - precision: 0.9828 - recall: 0.8927 - f1_score: 0.9345 - val_loss: 0.8213 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8180 - acc: 0.9400 - precision: 0.9835 - recall: 0.8946 - f1_score: 0.9358 - val_loss: 0.8182 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8149 - acc: 0.9400 - precision: 0.9838 - recall: 0.8927 - f1_score: 0.9345 - val_loss: 0.8151 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8119 - acc: 0.9400 - precision: 0.9834 - recall: 0.8976 - f1_score: 0.9377 - val_loss: 0.8121 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8088 - acc: 0.9400 - precision: 0.9822 - recall: 0.8982 - f1_score: 0.9372 - val_loss: 0.8090 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8058 - acc: 0.9400 - precision: 0.9808 - recall: 0.8963 - f1_score: 0.9339 - val_loss: 0.8060 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s - loss: 0.8028 - acc: 0.9400 - precision: 0.9842 - recall: 0.8934 - f1_score: 0.9356 - val_loss: 0.8030 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7998 - acc: 0.9400 - precision: 0.9823 - recall: 0.8980 - f1_score: 0.9368 - val_loss: 0.8000 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7968 - acc: 0.9400 - precision: 0.9841 - recall: 0.8937 - f1_score: 0.9358 - val_loss: 0.7970 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7939 - acc: 0.9400 - precision: 0.9830 - recall: 0.8930 - f1_score: 0.9345 - val_loss: 0.7941 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7909 - acc: 0.9400 - precision: 0.9817 - recall: 0.8919 - f1_score: 0.9336 - val_loss: 0.7911 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7880 - acc: 0.9400 - precision: 0.9828 - recall: 0.8988 - f1_score: 0.9379 - val_loss: 0.7882 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7851 - acc: 0.9400 - precision: 0.9829 - recall: 0.8971 - f1_score: 0.9346 - val_loss: 0.7853 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7822 - acc: 0.9400 - precision: 0.9842 - recall: 0.8943 - f1_score: 0.9359 - val_loss: 0.7824 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.7793 - acc: 0.9400 - precision: 0.9833 - recall: 0.8945 - f1_score: 0.9357 - val_loss: 0.7795 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7764 - acc: 0.9400 - precision: 0.9838 - recall: 0.8982 - f1_score: 0.9371 - val_loss: 0.7766 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7736 - acc: 0.9400 - precision: 0.9839 - recall: 0.8936 - f1_score: 0.9356 - val_loss: 0.7738 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7707 - acc: 0.9400 - precision: 0.9824 - recall: 0.8931 - f1_score: 0.9345 - val_loss: 0.7709 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7679 - acc: 0.9400 - precision: 0.9829 - recall: 0.8961 - f1_score: 0.9364 - val_loss: 0.7681 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7651 - acc: 0.9400 - precision: 0.9825 - recall: 0.8972 - f1_score: 0.9371 - val_loss: 0.7653 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7623 - acc: 0.9400 - precision: 0.9824 - recall: 0.8935 - f1_score: 0.9344 - val_loss: 0.7625 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7595 - acc: 0.9400 - precision: 0.9852 - recall: 0.8913 - f1_score: 0.9334 - val_loss: 0.7597 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7567 - acc: 0.9400 - precision: 0.9830 - recall: 0.8950 - f1_score: 0.9350 - val_loss: 0.7569 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7540 - acc: 0.9400 - precision: 0.9832 - recall: 0.8930 - f1_score: 0.9347 - val_loss: 0.7542 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7512 - acc: 0.9400 - precision: 0.9812 - recall: 0.8945 - f1_score: 0.9354 - val_loss: 0.7514 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7485 - acc: 0.9400 - precision: 0.9822 - recall: 0.8958 - f1_score: 0.9362 - val_loss: 0.7487 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7458 - acc: 0.9400 - precision: 0.9832 - recall: 0.8983 - f1_score: 0.9381 - val_loss: 0.7460 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7431 - acc: 0.9400 - precision: 0.9834 - recall: 0.8976 - f1_score: 0.9374 - val_loss: 0.7433 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7404 - acc: 0.9400 - precision: 0.9807 - recall: 0.8926 - f1_score: 0.9333 - val_loss: 0.7406 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7377 - acc: 0.9400 - precision: 0.9841 - recall: 0.8994 - f1_score: 0.9384 - val_loss: 0.7379 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7350 - acc: 0.9400 - precision: 0.9814 - recall: 0.8973 - f1_score: 0.9364 - val_loss: 0.7352 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7324 - acc: 0.9400 - precision: 0.9826 - recall: 0.8962 - f1_score: 0.9365 - val_loss: 0.7326 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7298 - acc: 0.9400 - precision: 0.9822 - recall: 0.8929 - f1_score: 0.9341 - val_loss: 0.7299 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7271 - acc: 0.9400 - precision: 0.9822 - recall: 0.8911 - f1_score: 0.9332 - val_loss: 0.7273 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7245 - acc: 0.9400 - precision: 0.9829 - recall: 0.9010 - f1_score: 0.9387 - val_loss: 0.7247 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7219 - acc: 0.9400 - precision: 0.9826 - recall: 0.8956 - f1_score: 0.9360 - val_loss: 0.7221 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7194 - acc: 0.9400 - precision: 0.9831 - recall: 0.8963 - f1_score: 0.9359 - val_loss: 0.7195 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7168 - acc: 0.9400 - precision: 0.9825 - recall: 0.8975 - f1_score: 0.9375 - val_loss: 0.7169 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7142 - acc: 0.9400 - precision: 0.9814 - recall: 0.8949 - f1_score: 0.9357 - val_loss: 0.7144 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7117 - acc: 0.9400 - precision: 0.9834 - recall: 0.8986 - f1_score: 0.9383 - val_loss: 0.7118 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7092 - acc: 0.9400 - precision: 0.9834 - recall: 0.8955 - f1_score: 0.9358 - val_loss: 0.7093 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7066 - acc: 0.9400 - precision: 0.9787 - recall: 0.8939 - f1_score: 0.9339 - val_loss: 0.7068 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7041 - acc: 0.9400 - precision: 0.9833 - recall: 0.8979 - f1_score: 0.9378 - val_loss: 0.7042 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s - loss: 0.7016 - acc: 0.9400 - precision: 0.9846 - recall: 0.8951 - f1_score: 0.9367 - val_loss: 0.7018 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6992 - acc: 0.9400 - precision: 0.9804 - recall: 0.8962 - f1_score: 0.9349 - val_loss: 0.6993 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6967 - acc: 0.9400 - precision: 0.9837 - recall: 0.8966 - f1_score: 0.9370 - val_loss: 0.6968 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6942 - acc: 0.9400 - precision: 0.9807 - recall: 0.8956 - f1_score: 0.9352 - val_loss: 0.6943 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6918 - acc: 0.9400 - precision: 0.9834 - recall: 0.8923 - f1_score: 0.9347 - val_loss: 0.6919 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6894 - acc: 0.9400 - precision: 0.9832 - recall: 0.8947 - f1_score: 0.9355 - val_loss: 0.6895 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6869 - acc: 0.9400 - precision: 0.9834 - recall: 0.8906 - f1_score: 0.9316 - val_loss: 0.6870 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6845 - acc: 0.9400 - precision: 0.9819 - recall: 0.8952 - f1_score: 0.9360 - val_loss: 0.6846 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6821 - acc: 0.9400 - precision: 0.9827 - recall: 0.8945 - f1_score: 0.9361 - val_loss: 0.6822 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6798 - acc: 0.9400 - precision: 0.9817 - recall: 0.8960 - f1_score: 0.9356 - val_loss: 0.6798 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6774 - acc: 0.9400 - precision: 0.9842 - recall: 0.8959 - f1_score: 0.9365 - val_loss: 0.6775 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6750 - acc: 0.9400 - precision: 0.9814 - recall: 0.8967 - f1_score: 0.9364 - val_loss: 0.6751 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6727 - acc: 0.9400 - precision: 0.9810 - recall: 0.8980 - f1_score: 0.9364 - val_loss: 0.6728 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6703 - acc: 0.9400 - precision: 0.9827 - recall: 0.8944 - f1_score: 0.9348 - val_loss: 0.6704 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6680 - acc: 0.9400 - precision: 0.9839 - recall: 0.8930 - f1_score: 0.9348 - val_loss: 0.6681 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6657 - acc: 0.9400 - precision: 0.9819 - recall: 0.8953 - f1_score: 0.9355 - val_loss: 0.6658 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6634 - acc: 0.9400 - precision: 0.9847 - recall: 0.8944 - f1_score: 0.9355 - val_loss: 0.6635 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6611 - acc: 0.9400 - precision: 0.9823 - recall: 0.8944 - f1_score: 0.9345 - val_loss: 0.6612 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6588 - acc: 0.9400 - precision: 0.9835 - recall: 0.8937 - f1_score: 0.9353 - val_loss: 0.6589 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6566 - acc: 0.9400 - precision: 0.9824 - recall: 0.8969 - f1_score: 0.9362 - val_loss: 0.6566 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6543 - acc: 0.9400 - precision: 0.9814 - recall: 0.8893 - f1_score: 0.9319 - val_loss: 0.6544 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6521 - acc: 0.9400 - precision: 0.9825 - recall: 0.8986 - f1_score: 0.9373 - val_loss: 0.6521 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6498 - acc: 0.9400 - precision: 0.9804 - recall: 0.8913 - f1_score: 0.9324 - val_loss: 0.6499 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6476 - acc: 0.9400 - precision: 0.9825 - recall: 0.8975 - f1_score: 0.9376 - val_loss: 0.6477 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6454 - acc: 0.9400 - precision: 0.9817 - recall: 0.8978 - f1_score: 0.9366 - val_loss: 0.6454 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6432 - acc: 0.9400 - precision: 0.9826 - recall: 0.8971 - f1_score: 0.9366 - val_loss: 0.6432 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6410 - acc: 0.9400 - precision: 0.9819 - recall: 0.8957 - f1_score: 0.9358 - val_loss: 0.6410 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6388 - acc: 0.9400 - precision: 0.9822 - recall: 0.8944 - f1_score: 0.9353 - val_loss: 0.6389 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6367 - acc: 0.9400 - precision: 0.9822 - recall: 0.8956 - f1_score: 0.9362 - val_loss: 0.6367 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6345 - acc: 0.9400 - precision: 0.9824 - recall: 0.8982 - f1_score: 0.9373 - val_loss: 0.6345 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6324 - acc: 0.9400 - precision: 0.9827 - recall: 0.8985 - f1_score: 0.9378 - val_loss: 0.6324 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6302 - acc: 0.9400 - precision: 0.9845 - recall: 0.8949 - f1_score: 0.9364 - val_loss: 0.6302 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6281 - acc: 0.9400 - precision: 0.9821 - recall: 0.8974 - f1_score: 0.9369 - val_loss: 0.6281 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6260 - acc: 0.9400 - precision: 0.9830 - recall: 0.8979 - f1_score: 0.9371 - val_loss: 0.6260 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6239 - acc: 0.9400 - precision: 0.9833 - recall: 0.8971 - f1_score: 0.9365 - val_loss: 0.6239 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 509/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.6218 - acc: 0.9400 - precision: 0.9810 - recall: 0.8916 - f1_score: 0.9331 - val_loss: 0.6218 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6197 - acc: 0.9400 - precision: 0.9782 - recall: 0.8929 - f1_score: 0.9327 - val_loss: 0.6197 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6177 - acc: 0.9400 - precision: 0.9828 - recall: 0.8997 - f1_score: 0.9377 - val_loss: 0.6176 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6156 - acc: 0.9400 - precision: 0.9837 - recall: 0.8971 - f1_score: 0.9373 - val_loss: 0.6155 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6135 - acc: 0.9400 - precision: 0.9813 - recall: 0.8955 - f1_score: 0.9360 - val_loss: 0.6135 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6115 - acc: 0.9400 - precision: 0.9837 - recall: 0.8984 - f1_score: 0.9382 - val_loss: 0.6114 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6095 - acc: 0.9400 - precision: 0.9839 - recall: 0.9014 - f1_score: 0.9387 - val_loss: 0.6094 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6074 - acc: 0.9400 - precision: 0.9832 - recall: 0.8989 - f1_score: 0.9382 - val_loss: 0.6074 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6054 - acc: 0.9400 - precision: 0.9826 - recall: 0.8951 - f1_score: 0.9355 - val_loss: 0.6054 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6034 - acc: 0.9400 - precision: 0.9828 - recall: 0.8972 - f1_score: 0.9376 - val_loss: 0.6034 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s - loss: 0.6014 - acc: 0.9400 - precision: 0.9858 - recall: 0.8936 - f1_score: 0.9364 - val_loss: 0.6014 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5995 - acc: 0.9400 - precision: 0.9834 - recall: 0.8944 - f1_score: 0.9355 - val_loss: 0.5994 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5975 - acc: 0.9400 - precision: 0.9832 - recall: 0.8943 - f1_score: 0.9349 - val_loss: 0.5974 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5955 - acc: 0.9400 - precision: 0.9830 - recall: 0.8952 - f1_score: 0.9357 - val_loss: 0.5954 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5936 - acc: 0.9400 - precision: 0.9832 - recall: 0.8961 - f1_score: 0.9363 - val_loss: 0.5935 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5916 - acc: 0.9400 - precision: 0.9839 - recall: 0.8957 - f1_score: 0.9360 - val_loss: 0.5915 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5897 - acc: 0.9400 - precision: 0.9830 - recall: 0.8953 - f1_score: 0.9358 - val_loss: 0.5896 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5878 - acc: 0.9400 - precision: 0.9821 - recall: 0.8924 - f1_score: 0.9339 - val_loss: 0.5877 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5859 - acc: 0.9400 - precision: 0.9840 - recall: 0.8926 - f1_score: 0.9349 - val_loss: 0.5857 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5840 - acc: 0.9400 - precision: 0.9852 - recall: 0.8951 - f1_score: 0.9373 - val_loss: 0.5838 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5821 - acc: 0.9400 - precision: 0.9835 - recall: 0.8983 - f1_score: 0.9376 - val_loss: 0.5819 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5802 - acc: 0.9400 - precision: 0.9834 - recall: 0.8989 - f1_score: 0.9377 - val_loss: 0.5800 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5783 - acc: 0.9400 - precision: 0.9848 - recall: 0.8899 - f1_score: 0.9332 - val_loss: 0.5782 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5764 - acc: 0.9400 - precision: 0.9832 - recall: 0.8954 - f1_score: 0.9355 - val_loss: 0.5763 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5746 - acc: 0.9400 - precision: 0.9833 - recall: 0.8960 - f1_score: 0.9359 - val_loss: 0.5744 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5727 - acc: 0.9400 - precision: 0.9819 - recall: 0.8952 - f1_score: 0.9356 - val_loss: 0.5726 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5709 - acc: 0.9400 - precision: 0.9841 - recall: 0.8941 - f1_score: 0.9352 - val_loss: 0.5707 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5691 - acc: 0.9400 - precision: 0.9814 - recall: 0.8945 - f1_score: 0.9355 - val_loss: 0.5689 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5673 - acc: 0.9400 - precision: 0.9822 - recall: 0.8981 - f1_score: 0.9375 - val_loss: 0.5671 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5654 - acc: 0.9400 - precision: 0.9828 - recall: 0.8955 - f1_score: 0.9357 - val_loss: 0.5652 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5636 - acc: 0.9400 - precision: 0.9826 - recall: 0.8929 - f1_score: 0.9333 - val_loss: 0.5634 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5618 - acc: 0.9400 - precision: 0.9841 - recall: 0.8970 - f1_score: 0.9369 - val_loss: 0.5616 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5601 - acc: 0.9415 - precision: 0.9865 - recall: 0.8909 - f1_score: 0.9341 - val_loss: 0.5598 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5583 - acc: 0.9400 - precision: 0.9841 - recall: 0.8954 - f1_score: 0.9361 - val_loss: 0.5580 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5565 - acc: 0.9415 - precision: 0.9865 - recall: 0.8928 - f1_score: 0.9367 - val_loss: 0.5563 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5548 - acc: 0.9415 - precision: 0.9864 - recall: 0.8990 - f1_score: 0.9400 - val_loss: 0.5545 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.5528 - acc: 0.9417 - precision: 0.9842 - recall: 0.8915 - f1_score: 0.934 - 0s - loss: 0.5530 - acc: 0.9415 - precision: 0.9850 - recall: 0.8920 - f1_score: 0.9354 - val_loss: 0.5528 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5513 - acc: 0.9415 - precision: 0.9864 - recall: 0.8972 - f1_score: 0.9387 - val_loss: 0.5510 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5495 - acc: 0.9415 - precision: 0.9867 - recall: 0.8977 - f1_score: 0.9393 - val_loss: 0.5493 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5478 - acc: 0.9415 - precision: 0.9846 - recall: 0.8981 - f1_score: 0.9373 - val_loss: 0.5475 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5461 - acc: 0.9415 - precision: 0.9875 - recall: 0.8982 - f1_score: 0.9396 - val_loss: 0.5458 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5444 - acc: 0.9415 - precision: 0.9867 - recall: 0.8927 - f1_score: 0.9367 - val_loss: 0.5441 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5427 - acc: 0.9415 - precision: 0.9856 - recall: 0.8968 - f1_score: 0.9380 - val_loss: 0.5424 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5410 - acc: 0.9415 - precision: 0.9863 - recall: 0.8977 - f1_score: 0.9392 - val_loss: 0.5407 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5393 - acc: 0.9415 - precision: 0.9859 - recall: 0.8992 - f1_score: 0.9399 - val_loss: 0.5390 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5376 - acc: 0.9415 - precision: 0.9877 - recall: 0.8948 - f1_score: 0.9376 - val_loss: 0.5373 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.5437 - acc: 0.9200 - precision: 1.0000 - recall: 0.8519 - f1_score: 0.920 - 0s - loss: 0.5360 - acc: 0.9415 - precision: 0.9866 - recall: 0.8961 - f1_score: 0.9378 - val_loss: 0.5357 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5343 - acc: 0.9415 - precision: 0.9862 - recall: 0.8988 - f1_score: 0.9399 - val_loss: 0.5340 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5327 - acc: 0.9415 - precision: 0.9851 - recall: 0.8948 - f1_score: 0.9370 - val_loss: 0.5323 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5310 - acc: 0.9415 - precision: 0.9864 - recall: 0.8994 - f1_score: 0.9394 - val_loss: 0.5307 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5294 - acc: 0.9415 - precision: 0.9865 - recall: 0.8949 - f1_score: 0.9373 - val_loss: 0.5291 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5278 - acc: 0.9415 - precision: 0.9853 - recall: 0.8982 - f1_score: 0.9383 - val_loss: 0.5274 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5262 - acc: 0.9415 - precision: 0.9850 - recall: 0.8946 - f1_score: 0.9370 - val_loss: 0.5258 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5246 - acc: 0.9415 - precision: 0.9861 - recall: 0.8967 - f1_score: 0.9385 - val_loss: 0.5242 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5230 - acc: 0.9415 - precision: 0.9853 - recall: 0.8942 - f1_score: 0.9368 - val_loss: 0.5226 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5214 - acc: 0.9415 - precision: 0.9866 - recall: 0.8966 - f1_score: 0.9382 - val_loss: 0.5210 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5198 - acc: 0.9415 - precision: 0.9877 - recall: 0.8990 - f1_score: 0.9396 - val_loss: 0.5194 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5182 - acc: 0.9415 - precision: 0.9875 - recall: 0.8923 - f1_score: 0.9355 - val_loss: 0.5178 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5166 - acc: 0.9415 - precision: 0.9864 - recall: 0.8988 - f1_score: 0.9386 - val_loss: 0.5162 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5151 - acc: 0.9415 - precision: 0.9863 - recall: 0.8941 - f1_score: 0.9364 - val_loss: 0.5147 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5135 - acc: 0.9415 - precision: 0.9871 - recall: 0.8956 - f1_score: 0.9373 - val_loss: 0.5131 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5120 - acc: 0.9415 - precision: 0.9857 - recall: 0.8948 - f1_score: 0.9368 - val_loss: 0.5115 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5104 - acc: 0.9415 - precision: 0.9854 - recall: 0.8987 - f1_score: 0.9385 - val_loss: 0.5100 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.5089 - acc: 0.9415 - precision: 0.9859 - recall: 0.8978 - f1_score: 0.9381 - val_loss: 0.5085 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5074 - acc: 0.9415 - precision: 0.9854 - recall: 0.8903 - f1_score: 0.9329 - val_loss: 0.5069 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5059 - acc: 0.9415 - precision: 0.9865 - recall: 0.8984 - f1_score: 0.9394 - val_loss: 0.5054 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5044 - acc: 0.9415 - precision: 0.9878 - recall: 0.8936 - f1_score: 0.9374 - val_loss: 0.5039 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5029 - acc: 0.9415 - precision: 0.9872 - recall: 0.8938 - f1_score: 0.9367 - val_loss: 0.5024 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s - loss: 0.5014 - acc: 0.9415 - precision: 0.9852 - recall: 0.8961 - f1_score: 0.9375 - val_loss: 0.5009 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4999 - acc: 0.9415 - precision: 0.9834 - recall: 0.8908 - f1_score: 0.9341 - val_loss: 0.4994 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4984 - acc: 0.9415 - precision: 0.9842 - recall: 0.8946 - f1_score: 0.9354 - val_loss: 0.4979 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.4583 - acc: 0.9800 - precision: 1.0000 - recall: 0.9545 - f1_score: 0.976 - 0s - loss: 0.4969 - acc: 0.9415 - precision: 0.9877 - recall: 0.8996 - f1_score: 0.9400 - val_loss: 0.4964 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4955 - acc: 0.9415 - precision: 0.9868 - recall: 0.8957 - f1_score: 0.9386 - val_loss: 0.4949 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4940 - acc: 0.9415 - precision: 0.9864 - recall: 0.8958 - f1_score: 0.9378 - val_loss: 0.4935 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4925 - acc: 0.9415 - precision: 0.9864 - recall: 0.8975 - f1_score: 0.9390 - val_loss: 0.4920 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4911 - acc: 0.9415 - precision: 0.9868 - recall: 0.8923 - f1_score: 0.9356 - val_loss: 0.4906 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4897 - acc: 0.9415 - precision: 0.9858 - recall: 0.9011 - f1_score: 0.9407 - val_loss: 0.4891 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4882 - acc: 0.9415 - precision: 0.9865 - recall: 0.8842 - f1_score: 0.9284 - val_loss: 0.4877 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4868 - acc: 0.9415 - precision: 0.9838 - recall: 0.8947 - f1_score: 0.9357 - val_loss: 0.4862 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4854 - acc: 0.9415 - precision: 0.9864 - recall: 0.8959 - f1_score: 0.9385 - val_loss: 0.4848 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4840 - acc: 0.9415 - precision: 0.9858 - recall: 0.8955 - f1_score: 0.9373 - val_loss: 0.4834 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4826 - acc: 0.9415 - precision: 0.9852 - recall: 0.8994 - f1_score: 0.9394 - val_loss: 0.4820 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4812 - acc: 0.9415 - precision: 0.9867 - recall: 0.8975 - f1_score: 0.9393 - val_loss: 0.4806 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4798 - acc: 0.9415 - precision: 0.9873 - recall: 0.8903 - f1_score: 0.9350 - val_loss: 0.4792 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4784 - acc: 0.9415 - precision: 0.9868 - recall: 0.8953 - f1_score: 0.9382 - val_loss: 0.4778 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4770 - acc: 0.9415 - precision: 0.9853 - recall: 0.8957 - f1_score: 0.9375 - val_loss: 0.4764 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4757 - acc: 0.9415 - precision: 0.9834 - recall: 0.8955 - f1_score: 0.9365 - val_loss: 0.4750 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4743 - acc: 0.9415 - precision: 0.9856 - recall: 0.8996 - f1_score: 0.9392 - val_loss: 0.4737 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4730 - acc: 0.9415 - precision: 0.9865 - recall: 0.8984 - f1_score: 0.9390 - val_loss: 0.4723 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4716 - acc: 0.9415 - precision: 0.9867 - recall: 0.9052 - f1_score: 0.9426 - val_loss: 0.4709 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4703 - acc: 0.9415 - precision: 0.9869 - recall: 0.8925 - f1_score: 0.9356 - val_loss: 0.4696 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4689 - acc: 0.9415 - precision: 0.9859 - recall: 0.8961 - f1_score: 0.9378 - val_loss: 0.4682 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4676 - acc: 0.9415 - precision: 0.9854 - recall: 0.8932 - f1_score: 0.9361 - val_loss: 0.4669 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4663 - acc: 0.9415 - precision: 0.9855 - recall: 0.8939 - f1_score: 0.9355 - val_loss: 0.4656 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4650 - acc: 0.9415 - precision: 0.9865 - recall: 0.8982 - f1_score: 0.9398 - val_loss: 0.4642 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4637 - acc: 0.9415 - precision: 0.9857 - recall: 0.8967 - f1_score: 0.9374 - val_loss: 0.4629 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4624 - acc: 0.9415 - precision: 0.9847 - recall: 0.8985 - f1_score: 0.9385 - val_loss: 0.4616 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4611 - acc: 0.9415 - precision: 0.9868 - recall: 0.8939 - f1_score: 0.9357 - val_loss: 0.4603 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4598 - acc: 0.9415 - precision: 0.9876 - recall: 0.8965 - f1_score: 0.9385 - val_loss: 0.4590 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4585 - acc: 0.9415 - precision: 0.9847 - recall: 0.8965 - f1_score: 0.9379 - val_loss: 0.4577 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4572 - acc: 0.9415 - precision: 0.9858 - recall: 0.8954 - f1_score: 0.9374 - val_loss: 0.4564 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4559 - acc: 0.9415 - precision: 0.9874 - recall: 0.8974 - f1_score: 0.9394 - val_loss: 0.4552 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4547 - acc: 0.9415 - precision: 0.9862 - recall: 0.8953 - f1_score: 0.9380 - val_loss: 0.4539 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4534 - acc: 0.9415 - precision: 0.9861 - recall: 0.8944 - f1_score: 0.9374 - val_loss: 0.4526 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4522 - acc: 0.9415 - precision: 0.9854 - recall: 0.8918 - f1_score: 0.9347 - val_loss: 0.4514 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4509 - acc: 0.9415 - precision: 0.9858 - recall: 0.8950 - f1_score: 0.9363 - val_loss: 0.4501 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4497 - acc: 0.9415 - precision: 0.9863 - recall: 0.8924 - f1_score: 0.9358 - val_loss: 0.4488 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4485 - acc: 0.9415 - precision: 0.9866 - recall: 0.8970 - f1_score: 0.9385 - val_loss: 0.4476 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4472 - acc: 0.9415 - precision: 0.9851 - recall: 0.9010 - f1_score: 0.9398 - val_loss: 0.4464 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4460 - acc: 0.9415 - precision: 0.9845 - recall: 0.8963 - f1_score: 0.9369 - val_loss: 0.4451 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4448 - acc: 0.9415 - precision: 0.9865 - recall: 0.8977 - f1_score: 0.9385 - val_loss: 0.4439 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4436 - acc: 0.9415 - precision: 0.9868 - recall: 0.8962 - f1_score: 0.9381 - val_loss: 0.4427 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4424 - acc: 0.9415 - precision: 0.9867 - recall: 0.8944 - f1_score: 0.9375 - val_loss: 0.4415 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4412 - acc: 0.9415 - precision: 0.9860 - recall: 0.8915 - f1_score: 0.9355 - val_loss: 0.4403 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4400 - acc: 0.9415 - precision: 0.9878 - recall: 0.8967 - f1_score: 0.9392 - val_loss: 0.4390 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4388 - acc: 0.9415 - precision: 0.9868 - recall: 0.8955 - f1_score: 0.9382 - val_loss: 0.4379 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4376 - acc: 0.9415 - precision: 0.9862 - recall: 0.8980 - f1_score: 0.9393 - val_loss: 0.4367 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4364 - acc: 0.9415 - precision: 0.9853 - recall: 0.8994 - f1_score: 0.9392 - val_loss: 0.4355 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4353 - acc: 0.9415 - precision: 0.9857 - recall: 0.8966 - f1_score: 0.9383 - val_loss: 0.4343 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4341 - acc: 0.9415 - precision: 0.9854 - recall: 0.8967 - f1_score: 0.9379 - val_loss: 0.4331 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4329 - acc: 0.9415 - precision: 0.9849 - recall: 0.8925 - f1_score: 0.9351 - val_loss: 0.4319 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4318 - acc: 0.9431 - precision: 0.9900 - recall: 0.8959 - f1_score: 0.9396 - val_loss: 0.4308 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4306 - acc: 0.9415 - precision: 0.9852 - recall: 0.8959 - f1_score: 0.9378 - val_loss: 0.4296 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4295 - acc: 0.9415 - precision: 0.9865 - recall: 0.8964 - f1_score: 0.9383 - val_loss: 0.4285 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4284 - acc: 0.9415 - precision: 0.9867 - recall: 0.8914 - f1_score: 0.9356 - val_loss: 0.4273 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4272 - acc: 0.9431 - precision: 0.9896 - recall: 0.8947 - f1_score: 0.9388 - val_loss: 0.4262 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4261 - acc: 0.9415 - precision: 0.9856 - recall: 0.8932 - f1_score: 0.9358 - val_loss: 0.4250 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.4250 - acc: 0.9415 - precision: 0.9859 - recall: 0.8943 - f1_score: 0.9368 - val_loss: 0.4239 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4239 - acc: 0.9415 - precision: 0.9847 - recall: 0.8959 - f1_score: 0.9371 - val_loss: 0.4228 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4228 - acc: 0.9431 - precision: 0.9898 - recall: 0.8937 - f1_score: 0.9379 - val_loss: 0.4216 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4217 - acc: 0.9431 - precision: 0.9910 - recall: 0.8943 - f1_score: 0.9394 - val_loss: 0.4205 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4206 - acc: 0.9431 - precision: 0.9914 - recall: 0.8954 - f1_score: 0.9399 - val_loss: 0.4194 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4195 - acc: 0.9431 - precision: 0.9902 - recall: 0.8923 - f1_score: 0.9373 - val_loss: 0.4183 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4184 - acc: 0.9431 - precision: 0.9906 - recall: 0.8948 - f1_score: 0.9393 - val_loss: 0.4172 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4173 - acc: 0.9431 - precision: 0.9901 - recall: 0.8910 - f1_score: 0.9368 - val_loss: 0.4161 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4162 - acc: 0.9431 - precision: 0.9897 - recall: 0.8964 - f1_score: 0.9393 - val_loss: 0.4150 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4151 - acc: 0.9431 - precision: 0.9893 - recall: 0.8957 - f1_score: 0.9396 - val_loss: 0.4139 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4141 - acc: 0.9431 - precision: 0.9905 - recall: 0.9001 - f1_score: 0.9416 - val_loss: 0.4129 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4130 - acc: 0.9431 - precision: 0.9895 - recall: 0.8994 - f1_score: 0.9416 - val_loss: 0.4118 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4120 - acc: 0.9431 - precision: 0.9895 - recall: 0.8951 - f1_score: 0.9395 - val_loss: 0.4107 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4109 - acc: 0.9431 - precision: 0.9888 - recall: 0.8922 - f1_score: 0.9367 - val_loss: 0.4097 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4099 - acc: 0.9431 - precision: 0.9904 - recall: 0.8926 - f1_score: 0.9379 - val_loss: 0.4086 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4088 - acc: 0.9431 - precision: 0.9897 - recall: 0.9001 - f1_score: 0.9415 - val_loss: 0.4075 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4078 - acc: 0.9431 - precision: 0.9903 - recall: 0.8942 - f1_score: 0.9380 - val_loss: 0.4065 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4067 - acc: 0.9431 - precision: 0.9879 - recall: 0.8957 - f1_score: 0.9386 - val_loss: 0.4055 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4057 - acc: 0.9431 - precision: 0.9904 - recall: 0.8941 - f1_score: 0.9386 - val_loss: 0.4044 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4047 - acc: 0.9431 - precision: 0.9877 - recall: 0.8966 - f1_score: 0.9389 - val_loss: 0.4034 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4037 - acc: 0.9431 - precision: 0.9898 - recall: 0.8962 - f1_score: 0.9397 - val_loss: 0.4023 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4027 - acc: 0.9431 - precision: 0.9911 - recall: 0.8961 - f1_score: 0.9401 - val_loss: 0.4013 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4017 - acc: 0.9431 - precision: 0.9891 - recall: 0.8904 - f1_score: 0.9364 - val_loss: 0.4003 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s - loss: 0.4007 - acc: 0.9431 - precision: 0.9893 - recall: 0.8955 - f1_score: 0.9396 - val_loss: 0.3993 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3997 - acc: 0.9431 - precision: 0.9906 - recall: 0.8982 - f1_score: 0.9415 - val_loss: 0.3983 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3987 - acc: 0.9431 - precision: 0.9904 - recall: 0.8951 - f1_score: 0.9391 - val_loss: 0.3973 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3977 - acc: 0.9431 - precision: 0.9894 - recall: 0.8984 - f1_score: 0.9403 - val_loss: 0.3963 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3967 - acc: 0.9431 - precision: 0.9901 - recall: 0.8943 - f1_score: 0.9385 - val_loss: 0.3953 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3957 - acc: 0.9431 - precision: 0.9882 - recall: 0.8925 - f1_score: 0.9372 - val_loss: 0.3943 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3947 - acc: 0.9431 - precision: 0.9898 - recall: 0.8993 - f1_score: 0.9412 - val_loss: 0.3933 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3938 - acc: 0.9431 - precision: 0.9890 - recall: 0.8929 - f1_score: 0.9376 - val_loss: 0.3923 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3928 - acc: 0.9431 - precision: 0.9905 - recall: 0.8927 - f1_score: 0.9382 - val_loss: 0.3913 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3918 - acc: 0.9431 - precision: 0.9887 - recall: 0.8947 - f1_score: 0.9386 - val_loss: 0.3904 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3909 - acc: 0.9431 - precision: 0.9884 - recall: 0.8977 - f1_score: 0.9392 - val_loss: 0.3894 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3899 - acc: 0.9431 - precision: 0.9898 - recall: 0.8961 - f1_score: 0.9399 - val_loss: 0.3884 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3890 - acc: 0.9431 - precision: 0.9898 - recall: 0.8960 - f1_score: 0.9394 - val_loss: 0.3875 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3881 - acc: 0.9431 - precision: 0.9909 - recall: 0.8964 - f1_score: 0.9401 - val_loss: 0.3865 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3871 - acc: 0.9431 - precision: 0.9885 - recall: 0.8980 - f1_score: 0.9401 - val_loss: 0.3856 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3862 - acc: 0.9431 - precision: 0.9890 - recall: 0.8986 - f1_score: 0.9407 - val_loss: 0.3846 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3853 - acc: 0.9431 - precision: 0.9914 - recall: 0.8969 - f1_score: 0.9407 - val_loss: 0.3837 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3843 - acc: 0.9431 - precision: 0.9905 - recall: 0.8965 - f1_score: 0.9397 - val_loss: 0.3827 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3834 - acc: 0.9431 - precision: 0.9914 - recall: 0.8936 - f1_score: 0.9390 - val_loss: 0.3818 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3825 - acc: 0.9431 - precision: 0.9900 - recall: 0.8930 - f1_score: 0.9380 - val_loss: 0.3809 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3816 - acc: 0.9431 - precision: 0.9895 - recall: 0.8958 - f1_score: 0.9396 - val_loss: 0.3799 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3807 - acc: 0.9431 - precision: 0.9894 - recall: 0.8979 - f1_score: 0.9399 - val_loss: 0.3790 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3798 - acc: 0.9431 - precision: 0.9893 - recall: 0.8958 - f1_score: 0.9391 - val_loss: 0.3781 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3789 - acc: 0.9431 - precision: 0.9896 - recall: 0.8955 - f1_score: 0.9383 - val_loss: 0.3772 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3780 - acc: 0.9431 - precision: 0.9911 - recall: 0.8961 - f1_score: 0.9396 - val_loss: 0.3763 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3771 - acc: 0.9431 - precision: 0.9900 - recall: 0.8944 - f1_score: 0.9390 - val_loss: 0.3754 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3762 - acc: 0.9431 - precision: 0.9900 - recall: 0.8957 - f1_score: 0.9392 - val_loss: 0.3745 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3753 - acc: 0.9431 - precision: 0.9885 - recall: 0.8965 - f1_score: 0.9392 - val_loss: 0.3736 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3745 - acc: 0.9431 - precision: 0.9905 - recall: 0.9002 - f1_score: 0.9418 - val_loss: 0.3727 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3736 - acc: 0.9431 - precision: 0.9895 - recall: 0.8967 - f1_score: 0.9395 - val_loss: 0.3718 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3727 - acc: 0.9431 - precision: 0.9893 - recall: 0.8955 - f1_score: 0.9392 - val_loss: 0.3709 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3719 - acc: 0.9431 - precision: 0.9893 - recall: 0.8946 - f1_score: 0.9388 - val_loss: 0.3700 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3710 - acc: 0.9431 - precision: 0.9905 - recall: 0.8958 - f1_score: 0.9392 - val_loss: 0.3692 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3701 - acc: 0.9431 - precision: 0.9902 - recall: 0.8937 - f1_score: 0.9383 - val_loss: 0.3683 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3693 - acc: 0.9431 - precision: 0.9893 - recall: 0.8989 - f1_score: 0.9394 - val_loss: 0.3674 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3684 - acc: 0.9431 - precision: 0.9904 - recall: 0.8966 - f1_score: 0.9404 - val_loss: 0.3666 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3676 - acc: 0.9431 - precision: 0.9900 - recall: 0.8959 - f1_score: 0.9388 - val_loss: 0.3657 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3668 - acc: 0.9431 - precision: 0.9903 - recall: 0.8876 - f1_score: 0.9335 - val_loss: 0.3648 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3659 - acc: 0.9431 - precision: 0.9900 - recall: 0.8983 - f1_score: 0.9404 - val_loss: 0.3640 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3651 - acc: 0.9431 - precision: 0.9884 - recall: 0.8990 - f1_score: 0.9407 - val_loss: 0.3631 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3643 - acc: 0.9431 - precision: 0.9884 - recall: 0.8957 - f1_score: 0.9391 - val_loss: 0.3623 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 700/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3634 - acc: 0.9431 - precision: 0.9879 - recall: 0.8950 - f1_score: 0.9382 - val_loss: 0.3615 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3626 - acc: 0.9431 - precision: 0.9884 - recall: 0.8977 - f1_score: 0.9400 - val_loss: 0.3606 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3618 - acc: 0.9431 - precision: 0.9898 - recall: 0.8961 - f1_score: 0.9399 - val_loss: 0.3598 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3610 - acc: 0.9431 - precision: 0.9902 - recall: 0.8960 - f1_score: 0.9397 - val_loss: 0.3590 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3602 - acc: 0.9431 - precision: 0.9897 - recall: 0.8971 - f1_score: 0.9405 - val_loss: 0.3581 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3594 - acc: 0.9431 - precision: 0.9894 - recall: 0.8933 - f1_score: 0.9386 - val_loss: 0.3573 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3586 - acc: 0.9431 - precision: 0.9896 - recall: 0.8949 - f1_score: 0.9390 - val_loss: 0.3565 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3578 - acc: 0.9431 - precision: 0.9897 - recall: 0.8952 - f1_score: 0.9389 - val_loss: 0.3557 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3570 - acc: 0.9431 - precision: 0.9890 - recall: 0.8983 - f1_score: 0.9405 - val_loss: 0.3549 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3562 - acc: 0.9431 - precision: 0.9892 - recall: 0.8964 - f1_score: 0.9399 - val_loss: 0.3541 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3554 - acc: 0.9431 - precision: 0.9874 - recall: 0.8929 - f1_score: 0.9372 - val_loss: 0.3533 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3546 - acc: 0.9431 - precision: 0.9904 - recall: 0.8902 - f1_score: 0.9352 - val_loss: 0.3525 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3539 - acc: 0.9431 - precision: 0.9898 - recall: 0.8971 - f1_score: 0.9403 - val_loss: 0.3517 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3531 - acc: 0.9431 - precision: 0.9889 - recall: 0.8964 - f1_score: 0.9392 - val_loss: 0.3509 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3523 - acc: 0.9431 - precision: 0.9869 - recall: 0.8924 - f1_score: 0.9366 - val_loss: 0.3501 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3515 - acc: 0.9431 - precision: 0.9878 - recall: 0.8933 - f1_score: 0.9375 - val_loss: 0.3493 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3508 - acc: 0.9431 - precision: 0.9895 - recall: 0.8962 - f1_score: 0.9400 - val_loss: 0.3486 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3500 - acc: 0.9431 - precision: 0.9909 - recall: 0.8943 - f1_score: 0.9391 - val_loss: 0.3478 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3493 - acc: 0.9431 - precision: 0.9905 - recall: 0.8960 - f1_score: 0.9390 - val_loss: 0.3470 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3485 - acc: 0.9431 - precision: 0.9878 - recall: 0.8940 - f1_score: 0.9380 - val_loss: 0.3462 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3478 - acc: 0.9431 - precision: 0.9905 - recall: 0.8969 - f1_score: 0.9400 - val_loss: 0.3455 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3470 - acc: 0.9431 - precision: 0.9886 - recall: 0.8975 - f1_score: 0.9391 - val_loss: 0.3447 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3463 - acc: 0.9431 - precision: 0.9892 - recall: 0.8962 - f1_score: 0.9392 - val_loss: 0.3439 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3455 - acc: 0.9431 - precision: 0.9893 - recall: 0.8944 - f1_score: 0.9387 - val_loss: 0.3432 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3448 - acc: 0.9431 - precision: 0.9893 - recall: 0.8944 - f1_score: 0.9386 - val_loss: 0.3424 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3441 - acc: 0.9431 - precision: 0.9906 - recall: 0.8952 - f1_score: 0.9390 - val_loss: 0.3417 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3433 - acc: 0.9431 - precision: 0.9899 - recall: 0.8968 - f1_score: 0.9400 - val_loss: 0.3410 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3426 - acc: 0.9431 - precision: 0.9897 - recall: 0.8963 - f1_score: 0.9394 - val_loss: 0.3402 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3419 - acc: 0.9431 - precision: 0.9901 - recall: 0.8983 - f1_score: 0.9412 - val_loss: 0.3395 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3412 - acc: 0.9431 - precision: 0.9883 - recall: 0.8990 - f1_score: 0.9393 - val_loss: 0.3387 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3405 - acc: 0.9431 - precision: 0.9885 - recall: 0.8982 - f1_score: 0.9402 - val_loss: 0.3380 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3397 - acc: 0.9431 - precision: 0.9891 - recall: 0.8953 - f1_score: 0.9393 - val_loss: 0.3373 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 732/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3390 - acc: 0.9431 - precision: 0.9902 - recall: 0.8952 - f1_score: 0.9391 - val_loss: 0.3366 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3383 - acc: 0.9431 - precision: 0.9903 - recall: 0.8950 - f1_score: 0.9390 - val_loss: 0.3358 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3376 - acc: 0.9431 - precision: 0.9884 - recall: 0.8957 - f1_score: 0.9383 - val_loss: 0.3351 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3369 - acc: 0.9431 - precision: 0.9896 - recall: 0.8960 - f1_score: 0.9387 - val_loss: 0.3344 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3362 - acc: 0.9431 - precision: 0.9894 - recall: 0.8957 - f1_score: 0.9395 - val_loss: 0.3337 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3355 - acc: 0.9431 - precision: 0.9895 - recall: 0.8955 - f1_score: 0.9395 - val_loss: 0.3330 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3349 - acc: 0.9431 - precision: 0.9879 - recall: 0.8936 - f1_score: 0.9376 - val_loss: 0.3323 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3342 - acc: 0.9431 - precision: 0.9905 - recall: 0.8932 - f1_score: 0.9381 - val_loss: 0.3316 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3335 - acc: 0.9431 - precision: 0.9900 - recall: 0.8938 - f1_score: 0.9375 - val_loss: 0.3309 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3328 - acc: 0.9431 - precision: 0.9901 - recall: 0.8966 - f1_score: 0.9401 - val_loss: 0.3302 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3321 - acc: 0.9431 - precision: 0.9897 - recall: 0.8983 - f1_score: 0.9406 - val_loss: 0.3295 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3314 - acc: 0.9431 - precision: 0.9894 - recall: 0.8962 - f1_score: 0.9399 - val_loss: 0.3288 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3308 - acc: 0.9431 - precision: 0.9901 - recall: 0.8958 - f1_score: 0.9396 - val_loss: 0.3281 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3301 - acc: 0.9431 - precision: 0.9886 - recall: 0.8933 - f1_score: 0.9374 - val_loss: 0.3274 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3294 - acc: 0.9431 - precision: 0.9898 - recall: 0.8946 - f1_score: 0.9387 - val_loss: 0.3267 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3288 - acc: 0.9431 - precision: 0.9892 - recall: 0.8994 - f1_score: 0.9414 - val_loss: 0.3261 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3281 - acc: 0.9431 - precision: 0.9898 - recall: 0.8973 - f1_score: 0.9387 - val_loss: 0.3254 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3275 - acc: 0.9431 - precision: 0.9903 - recall: 0.8934 - f1_score: 0.9385 - val_loss: 0.3247 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3268 - acc: 0.9431 - precision: 0.9888 - recall: 0.8922 - f1_score: 0.9371 - val_loss: 0.3240 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3262 - acc: 0.9431 - precision: 0.9899 - recall: 0.8981 - f1_score: 0.9406 - val_loss: 0.3234 - val_acc: 0.9430 - val_precision: 0.9849 - val_recall: 0.8806 - val_f1_score: 0.9276\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3255 - acc: 0.9431 - precision: 0.9902 - recall: 0.8989 - f1_score: 0.9410 - val_loss: 0.3227 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3249 - acc: 0.9431 - precision: 0.9885 - recall: 0.9006 - f1_score: 0.9417 - val_loss: 0.3220 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3242 - acc: 0.9431 - precision: 0.9900 - recall: 0.8910 - f1_score: 0.9358 - val_loss: 0.3214 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3236 - acc: 0.9431 - precision: 0.9912 - recall: 0.8977 - f1_score: 0.9411 - val_loss: 0.3207 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3230 - acc: 0.9431 - precision: 0.9891 - recall: 0.8950 - f1_score: 0.9378 - val_loss: 0.3201 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3224 - acc: 0.9431 - precision: 0.9886 - recall: 0.8958 - f1_score: 0.9387 - val_loss: 0.3195 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3217 - acc: 0.9431 - precision: 0.9878 - recall: 0.8957 - f1_score: 0.9389 - val_loss: 0.3188 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3211 - acc: 0.9431 - precision: 0.9872 - recall: 0.8927 - f1_score: 0.9369 - val_loss: 0.3182 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3205 - acc: 0.9431 - precision: 0.9882 - recall: 0.8925 - f1_score: 0.9370 - val_loss: 0.3175 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3199 - acc: 0.9431 - precision: 0.9907 - recall: 0.8939 - f1_score: 0.9389 - val_loss: 0.3169 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3192 - acc: 0.9431 - precision: 0.9905 - recall: 0.8936 - f1_score: 0.9381 - val_loss: 0.3163 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3186 - acc: 0.9431 - precision: 0.9895 - recall: 0.8954 - f1_score: 0.9397 - val_loss: 0.3156 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.3180 - acc: 0.9431 - precision: 0.9898 - recall: 0.8946 - f1_score: 0.9392 - val_loss: 0.3150 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3174 - acc: 0.9431 - precision: 0.9879 - recall: 0.9001 - f1_score: 0.9404 - val_loss: 0.3144 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3168 - acc: 0.9431 - precision: 0.9915 - recall: 0.8935 - f1_score: 0.9374 - val_loss: 0.3138 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3162 - acc: 0.9431 - precision: 0.9900 - recall: 0.9007 - f1_score: 0.9429 - val_loss: 0.3131 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3156 - acc: 0.9431 - precision: 0.9901 - recall: 0.8996 - f1_score: 0.9420 - val_loss: 0.3125 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3150 - acc: 0.9431 - precision: 0.9903 - recall: 0.8964 - f1_score: 0.9394 - val_loss: 0.3119 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3144 - acc: 0.9431 - precision: 0.9879 - recall: 0.8961 - f1_score: 0.9393 - val_loss: 0.3113 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3138 - acc: 0.9431 - precision: 0.9885 - recall: 0.8966 - f1_score: 0.9395 - val_loss: 0.3107 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3132 - acc: 0.9431 - precision: 0.9883 - recall: 0.8981 - f1_score: 0.9398 - val_loss: 0.3101 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3127 - acc: 0.9431 - precision: 0.9893 - recall: 0.9019 - f1_score: 0.9422 - val_loss: 0.3095 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3121 - acc: 0.9431 - precision: 0.9903 - recall: 0.8937 - f1_score: 0.9385 - val_loss: 0.3089 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3115 - acc: 0.9431 - precision: 0.9892 - recall: 0.8968 - f1_score: 0.9397 - val_loss: 0.3083 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3109 - acc: 0.9431 - precision: 0.9896 - recall: 0.8954 - f1_score: 0.9381 - val_loss: 0.3077 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3103 - acc: 0.9431 - precision: 0.9904 - recall: 0.8950 - f1_score: 0.9391 - val_loss: 0.3071 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3098 - acc: 0.9431 - precision: 0.9891 - recall: 0.8955 - f1_score: 0.9392 - val_loss: 0.3065 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3092 - acc: 0.9431 - precision: 0.9912 - recall: 0.8951 - f1_score: 0.9384 - val_loss: 0.3059 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3086 - acc: 0.9431 - precision: 0.9893 - recall: 0.9007 - f1_score: 0.9417 - val_loss: 0.3053 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3081 - acc: 0.9431 - precision: 0.9897 - recall: 0.8970 - f1_score: 0.9398 - val_loss: 0.3047 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3075 - acc: 0.9431 - precision: 0.9908 - recall: 0.8961 - f1_score: 0.9400 - val_loss: 0.3042 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3070 - acc: 0.9431 - precision: 0.9890 - recall: 0.8949 - f1_score: 0.9383 - val_loss: 0.3036 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3064 - acc: 0.9431 - precision: 0.9886 - recall: 0.8989 - f1_score: 0.9404 - val_loss: 0.3030 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3058 - acc: 0.9431 - precision: 0.9902 - recall: 0.8954 - f1_score: 0.9393 - val_loss: 0.3024 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3053 - acc: 0.9431 - precision: 0.9876 - recall: 0.8996 - f1_score: 0.9402 - val_loss: 0.3019 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3047 - acc: 0.9431 - precision: 0.9883 - recall: 0.8972 - f1_score: 0.9386 - val_loss: 0.3013 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3042 - acc: 0.9431 - precision: 0.9903 - recall: 0.8948 - f1_score: 0.9387 - val_loss: 0.3007 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3037 - acc: 0.9431 - precision: 0.9897 - recall: 0.8962 - f1_score: 0.9396 - val_loss: 0.3002 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3031 - acc: 0.9431 - precision: 0.9902 - recall: 0.8992 - f1_score: 0.9412 - val_loss: 0.2996 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3026 - acc: 0.9431 - precision: 0.9897 - recall: 0.8963 - f1_score: 0.9395 - val_loss: 0.2991 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3020 - acc: 0.9431 - precision: 0.9870 - recall: 0.8954 - f1_score: 0.9377 - val_loss: 0.2985 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3015 - acc: 0.9431 - precision: 0.9885 - recall: 0.8955 - f1_score: 0.9384 - val_loss: 0.2980 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3010 - acc: 0.9431 - precision: 0.9901 - recall: 0.8976 - f1_score: 0.9410 - val_loss: 0.2974 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s - loss: 0.3005 - acc: 0.9431 - precision: 0.9895 - recall: 0.8963 - f1_score: 0.9394 - val_loss: 0.2969 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2999 - acc: 0.9431 - precision: 0.9891 - recall: 0.8950 - f1_score: 0.9385 - val_loss: 0.2963 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2994 - acc: 0.9431 - precision: 0.9911 - recall: 0.9012 - f1_score: 0.9429 - val_loss: 0.2958 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2989 - acc: 0.9431 - precision: 0.9870 - recall: 0.8945 - f1_score: 0.9375 - val_loss: 0.2953 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2984 - acc: 0.9431 - precision: 0.9903 - recall: 0.8940 - f1_score: 0.9387 - val_loss: 0.2947 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2978 - acc: 0.9431 - precision: 0.9885 - recall: 0.8975 - f1_score: 0.9398 - val_loss: 0.2942 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2973 - acc: 0.9431 - precision: 0.9898 - recall: 0.8977 - f1_score: 0.9400 - val_loss: 0.2937 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2968 - acc: 0.9431 - precision: 0.9875 - recall: 0.8913 - f1_score: 0.9359 - val_loss: 0.2931 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2963 - acc: 0.9431 - precision: 0.9901 - recall: 0.8934 - f1_score: 0.9380 - val_loss: 0.2926 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2958 - acc: 0.9431 - precision: 0.9901 - recall: 0.8985 - f1_score: 0.9406 - val_loss: 0.2921 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2953 - acc: 0.9431 - precision: 0.9905 - recall: 0.8999 - f1_score: 0.9417 - val_loss: 0.2916 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2948 - acc: 0.9431 - precision: 0.9886 - recall: 0.8929 - f1_score: 0.9370 - val_loss: 0.2910 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2943 - acc: 0.9431 - precision: 0.9892 - recall: 0.8961 - f1_score: 0.9394 - val_loss: 0.2905 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2938 - acc: 0.9431 - precision: 0.9898 - recall: 0.8966 - f1_score: 0.9399 - val_loss: 0.2900 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2933 - acc: 0.9431 - precision: 0.9901 - recall: 0.8980 - f1_score: 0.9392 - val_loss: 0.2895 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2928 - acc: 0.9431 - precision: 0.9898 - recall: 0.8989 - f1_score: 0.9408 - val_loss: 0.2890 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2923 - acc: 0.9431 - precision: 0.9905 - recall: 0.8972 - f1_score: 0.9402 - val_loss: 0.2885 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2918 - acc: 0.9431 - precision: 0.9910 - recall: 0.8951 - f1_score: 0.9394 - val_loss: 0.2880 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2913 - acc: 0.9431 - precision: 0.9894 - recall: 0.8963 - f1_score: 0.9401 - val_loss: 0.2875 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2909 - acc: 0.9431 - precision: 0.9898 - recall: 0.8958 - f1_score: 0.9390 - val_loss: 0.2870 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2904 - acc: 0.9431 - precision: 0.9853 - recall: 0.8936 - f1_score: 0.9365 - val_loss: 0.2865 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2899 - acc: 0.9431 - precision: 0.9899 - recall: 0.8965 - f1_score: 0.9387 - val_loss: 0.2860 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2894 - acc: 0.9431 - precision: 0.9879 - recall: 0.8918 - f1_score: 0.9364 - val_loss: 0.2855 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2890 - acc: 0.9431 - precision: 0.9900 - recall: 0.8976 - f1_score: 0.9398 - val_loss: 0.2850 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2885 - acc: 0.9431 - precision: 0.9896 - recall: 0.8934 - f1_score: 0.9379 - val_loss: 0.2845 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2880 - acc: 0.9431 - precision: 0.9896 - recall: 0.8933 - f1_score: 0.9380 - val_loss: 0.2840 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2875 - acc: 0.9431 - precision: 0.9893 - recall: 0.8939 - f1_score: 0.9386 - val_loss: 0.2835 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2871 - acc: 0.9431 - precision: 0.9895 - recall: 0.8977 - f1_score: 0.9400 - val_loss: 0.2830 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2866 - acc: 0.9431 - precision: 0.9900 - recall: 0.8973 - f1_score: 0.9404 - val_loss: 0.2825 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2861 - acc: 0.9431 - precision: 0.9898 - recall: 0.8958 - f1_score: 0.9399 - val_loss: 0.2820 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2857 - acc: 0.9431 - precision: 0.9897 - recall: 0.8913 - f1_score: 0.9367 - val_loss: 0.2816 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2852 - acc: 0.9431 - precision: 0.9897 - recall: 0.8946 - f1_score: 0.9377 - val_loss: 0.2811 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2848 - acc: 0.9431 - precision: 0.9886 - recall: 0.8953 - f1_score: 0.9382 - val_loss: 0.2806 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2843 - acc: 0.9431 - precision: 0.9898 - recall: 0.8933 - f1_score: 0.9377 - val_loss: 0.2801 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2839 - acc: 0.9431 - precision: 0.9885 - recall: 0.8990 - f1_score: 0.9406 - val_loss: 0.2797 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2834 - acc: 0.9431 - precision: 0.9891 - recall: 0.8938 - f1_score: 0.9374 - val_loss: 0.2792 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2830 - acc: 0.9431 - precision: 0.9907 - recall: 0.8965 - f1_score: 0.9402 - val_loss: 0.2787 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2825 - acc: 0.9431 - precision: 0.9901 - recall: 0.8944 - f1_score: 0.9380 - val_loss: 0.2783 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2821 - acc: 0.9431 - precision: 0.9889 - recall: 0.8952 - f1_score: 0.9382 - val_loss: 0.2778 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2816 - acc: 0.9431 - precision: 0.9898 - recall: 0.8960 - f1_score: 0.9397 - val_loss: 0.2774 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2812 - acc: 0.9431 - precision: 0.9898 - recall: 0.8974 - f1_score: 0.9406 - val_loss: 0.2769 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2808 - acc: 0.9431 - precision: 0.9896 - recall: 0.8935 - f1_score: 0.9377 - val_loss: 0.2764 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2803 - acc: 0.9431 - precision: 0.9901 - recall: 0.8971 - f1_score: 0.9393 - val_loss: 0.2760 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2799 - acc: 0.9431 - precision: 0.9907 - recall: 0.8963 - f1_score: 0.9402 - val_loss: 0.2755 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2795 - acc: 0.9431 - precision: 0.9886 - recall: 0.8947 - f1_score: 0.9378 - val_loss: 0.2751 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2790 - acc: 0.9431 - precision: 0.9913 - recall: 0.9001 - f1_score: 0.9425 - val_loss: 0.2746 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2786 - acc: 0.9431 - precision: 0.9894 - recall: 0.8941 - f1_score: 0.9387 - val_loss: 0.2742 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2782 - acc: 0.9431 - precision: 0.9895 - recall: 0.8963 - f1_score: 0.9391 - val_loss: 0.2737 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2778 - acc: 0.9431 - precision: 0.9905 - recall: 0.8996 - f1_score: 0.9418 - val_loss: 0.2733 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2773 - acc: 0.9431 - precision: 0.9887 - recall: 0.9014 - f1_score: 0.9413 - val_loss: 0.2729 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2769 - acc: 0.9431 - precision: 0.9904 - recall: 0.8938 - f1_score: 0.9389 - val_loss: 0.2724 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2765 - acc: 0.9431 - precision: 0.9879 - recall: 0.8958 - f1_score: 0.9382 - val_loss: 0.2720 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2761 - acc: 0.9431 - precision: 0.9883 - recall: 0.8977 - f1_score: 0.9398 - val_loss: 0.2715 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2757 - acc: 0.9431 - precision: 0.9897 - recall: 0.8929 - f1_score: 0.9381 - val_loss: 0.2711 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2752 - acc: 0.9431 - precision: 0.9891 - recall: 0.8938 - f1_score: 0.9376 - val_loss: 0.2707 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2748 - acc: 0.9431 - precision: 0.9907 - recall: 0.8952 - f1_score: 0.9394 - val_loss: 0.2702 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2744 - acc: 0.9431 - precision: 0.9892 - recall: 0.8897 - f1_score: 0.9343 - val_loss: 0.2698 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2740 - acc: 0.9431 - precision: 0.9893 - recall: 0.8905 - f1_score: 0.9338 - val_loss: 0.2694 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2736 - acc: 0.9431 - precision: 0.9901 - recall: 0.8946 - f1_score: 0.9392 - val_loss: 0.2690 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2732 - acc: 0.9431 - precision: 0.9905 - recall: 0.9004 - f1_score: 0.9418 - val_loss: 0.2686 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2728 - acc: 0.9431 - precision: 0.9894 - recall: 0.8969 - f1_score: 0.9396 - val_loss: 0.2681 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2724 - acc: 0.9431 - precision: 0.9897 - recall: 0.8987 - f1_score: 0.9413 - val_loss: 0.2677 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2720 - acc: 0.9431 - precision: 0.9895 - recall: 0.8952 - f1_score: 0.9387 - val_loss: 0.2673 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2716 - acc: 0.9431 - precision: 0.9891 - recall: 0.8959 - f1_score: 0.9389 - val_loss: 0.2669 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2712 - acc: 0.9431 - precision: 0.9901 - recall: 0.8934 - f1_score: 0.9380 - val_loss: 0.2665 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 860/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2708 - acc: 0.9431 - precision: 0.9899 - recall: 0.8984 - f1_score: 0.9405 - val_loss: 0.2661 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2704 - acc: 0.9431 - precision: 0.9906 - recall: 0.8926 - f1_score: 0.9369 - val_loss: 0.2657 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2700 - acc: 0.9431 - precision: 0.9904 - recall: 0.8931 - f1_score: 0.9381 - val_loss: 0.2652 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2697 - acc: 0.9431 - precision: 0.9906 - recall: 0.8970 - f1_score: 0.9405 - val_loss: 0.2648 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2693 - acc: 0.9431 - precision: 0.9898 - recall: 0.8944 - f1_score: 0.9381 - val_loss: 0.2644 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2689 - acc: 0.9431 - precision: 0.9900 - recall: 0.8938 - f1_score: 0.9388 - val_loss: 0.2640 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2685 - acc: 0.9431 - precision: 0.9890 - recall: 0.8972 - f1_score: 0.9400 - val_loss: 0.2636 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2681 - acc: 0.9431 - precision: 0.9889 - recall: 0.8936 - f1_score: 0.9381 - val_loss: 0.2632 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2677 - acc: 0.9431 - precision: 0.9895 - recall: 0.9004 - f1_score: 0.9421 - val_loss: 0.2628 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2674 - acc: 0.9431 - precision: 0.9895 - recall: 0.8978 - f1_score: 0.9400 - val_loss: 0.2624 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2670 - acc: 0.9431 - precision: 0.9898 - recall: 0.8966 - f1_score: 0.9398 - val_loss: 0.2620 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2666 - acc: 0.9431 - precision: 0.9899 - recall: 0.8922 - f1_score: 0.9367 - val_loss: 0.2617 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2662 - acc: 0.9431 - precision: 0.9901 - recall: 0.8944 - f1_score: 0.9386 - val_loss: 0.2613 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2659 - acc: 0.9431 - precision: 0.9898 - recall: 0.8921 - f1_score: 0.9369 - val_loss: 0.2609 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2655 - acc: 0.9431 - precision: 0.9873 - recall: 0.8922 - f1_score: 0.9362 - val_loss: 0.2605 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2651 - acc: 0.9431 - precision: 0.9896 - recall: 0.8952 - f1_score: 0.9392 - val_loss: 0.2601 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2648 - acc: 0.9431 - precision: 0.9898 - recall: 0.8995 - f1_score: 0.9418 - val_loss: 0.2597 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2644 - acc: 0.9431 - precision: 0.9898 - recall: 0.8980 - f1_score: 0.9388 - val_loss: 0.2593 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2640 - acc: 0.9431 - precision: 0.9898 - recall: 0.8994 - f1_score: 0.9411 - val_loss: 0.2589 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2637 - acc: 0.9431 - precision: 0.9900 - recall: 0.8945 - f1_score: 0.9391 - val_loss: 0.2586 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2633 - acc: 0.9431 - precision: 0.9898 - recall: 0.8954 - f1_score: 0.9392 - val_loss: 0.2582 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2630 - acc: 0.9431 - precision: 0.9885 - recall: 0.8940 - f1_score: 0.9382 - val_loss: 0.2578 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2626 - acc: 0.9431 - precision: 0.9889 - recall: 0.8969 - f1_score: 0.9396 - val_loss: 0.2574 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2622 - acc: 0.9431 - precision: 0.9898 - recall: 0.8967 - f1_score: 0.9402 - val_loss: 0.2571 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2619 - acc: 0.9431 - precision: 0.9884 - recall: 0.8966 - f1_score: 0.9390 - val_loss: 0.2567 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2615 - acc: 0.9431 - precision: 0.9919 - recall: 0.8978 - f1_score: 0.9416 - val_loss: 0.2563 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2612 - acc: 0.9431 - precision: 0.9892 - recall: 0.8947 - f1_score: 0.9383 - val_loss: 0.2559 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2608 - acc: 0.9431 - precision: 0.9897 - recall: 0.8994 - f1_score: 0.9412 - val_loss: 0.2556 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2605 - acc: 0.9431 - precision: 0.9906 - recall: 0.8980 - f1_score: 0.9408 - val_loss: 0.2552 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2602 - acc: 0.9431 - precision: 0.9901 - recall: 0.8971 - f1_score: 0.9395 - val_loss: 0.2548 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2598 - acc: 0.9431 - precision: 0.9904 - recall: 0.8946 - f1_score: 0.9393 - val_loss: 0.2545 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2595 - acc: 0.9415 - precision: 0.9859 - recall: 0.8962 - f1_score: 0.9380 - val_loss: 0.2541 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2591 - acc: 0.9415 - precision: 0.9866 - recall: 0.8962 - f1_score: 0.9379 - val_loss: 0.2538 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2588 - acc: 0.9415 - precision: 0.9855 - recall: 0.8958 - f1_score: 0.9375 - val_loss: 0.2534 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2585 - acc: 0.9415 - precision: 0.9862 - recall: 0.8968 - f1_score: 0.9386 - val_loss: 0.2531 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2581 - acc: 0.9415 - precision: 0.9863 - recall: 0.8966 - f1_score: 0.9385 - val_loss: 0.2527 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2578 - acc: 0.9415 - precision: 0.9850 - recall: 0.8945 - f1_score: 0.9358 - val_loss: 0.2524 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2575 - acc: 0.9415 - precision: 0.9861 - recall: 0.8973 - f1_score: 0.9385 - val_loss: 0.2520 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2571 - acc: 0.9415 - precision: 0.9872 - recall: 0.8976 - f1_score: 0.9384 - val_loss: 0.2517 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2568 - acc: 0.9415 - precision: 0.9860 - recall: 0.8980 - f1_score: 0.9393 - val_loss: 0.2513 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2565 - acc: 0.9415 - precision: 0.9860 - recall: 0.8992 - f1_score: 0.9385 - val_loss: 0.2510 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2561 - acc: 0.9415 - precision: 0.9880 - recall: 0.8949 - f1_score: 0.9376 - val_loss: 0.2506 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2558 - acc: 0.9415 - precision: 0.9869 - recall: 0.8937 - f1_score: 0.9369 - val_loss: 0.2503 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2555 - acc: 0.9415 - precision: 0.9843 - recall: 0.8933 - f1_score: 0.9361 - val_loss: 0.2500 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2552 - acc: 0.9415 - precision: 0.9864 - recall: 0.8978 - f1_score: 0.9390 - val_loss: 0.2496 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2548 - acc: 0.9415 - precision: 0.9861 - recall: 0.8952 - f1_score: 0.9381 - val_loss: 0.2493 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2545 - acc: 0.9415 - precision: 0.9850 - recall: 0.8949 - f1_score: 0.9363 - val_loss: 0.2489 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2542 - acc: 0.9415 - precision: 0.9843 - recall: 0.8934 - f1_score: 0.9355 - val_loss: 0.2486 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2539 - acc: 0.9415 - precision: 0.9884 - recall: 0.8957 - f1_score: 0.9382 - val_loss: 0.2483 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2536 - acc: 0.9415 - precision: 0.9849 - recall: 0.8943 - f1_score: 0.9365 - val_loss: 0.2479 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2533 - acc: 0.9415 - precision: 0.9870 - recall: 0.8953 - f1_score: 0.9376 - val_loss: 0.2476 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2529 - acc: 0.9415 - precision: 0.9870 - recall: 0.8957 - f1_score: 0.9375 - val_loss: 0.2473 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2526 - acc: 0.9415 - precision: 0.9857 - recall: 0.8962 - f1_score: 0.9381 - val_loss: 0.2469 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2523 - acc: 0.9415 - precision: 0.9839 - recall: 0.8955 - f1_score: 0.9371 - val_loss: 0.2466 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2520 - acc: 0.9415 - precision: 0.9868 - recall: 0.8894 - f1_score: 0.9339 - val_loss: 0.2463 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2517 - acc: 0.9415 - precision: 0.9863 - recall: 0.8965 - f1_score: 0.9377 - val_loss: 0.2460 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2514 - acc: 0.9415 - precision: 0.9856 - recall: 0.8951 - f1_score: 0.9379 - val_loss: 0.2456 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2511 - acc: 0.9415 - precision: 0.9852 - recall: 0.8951 - f1_score: 0.9364 - val_loss: 0.2453 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2508 - acc: 0.9415 - precision: 0.9865 - recall: 0.8939 - f1_score: 0.9366 - val_loss: 0.2450 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2505 - acc: 0.9415 - precision: 0.9852 - recall: 0.8961 - f1_score: 0.9365 - val_loss: 0.2447 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2502 - acc: 0.9415 - precision: 0.9859 - recall: 0.9008 - f1_score: 0.9399 - val_loss: 0.2443 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2499 - acc: 0.9415 - precision: 0.9872 - recall: 0.8942 - f1_score: 0.9371 - val_loss: 0.2440 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2496 - acc: 0.9415 - precision: 0.9858 - recall: 0.8970 - f1_score: 0.9383 - val_loss: 0.2437 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2493 - acc: 0.9415 - precision: 0.9870 - recall: 0.8975 - f1_score: 0.9397 - val_loss: 0.2434 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 924/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2490 - acc: 0.9415 - precision: 0.9875 - recall: 0.8987 - f1_score: 0.9404 - val_loss: 0.2431 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2487 - acc: 0.9415 - precision: 0.9872 - recall: 0.8943 - f1_score: 0.9374 - val_loss: 0.2428 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2484 - acc: 0.9415 - precision: 0.9871 - recall: 0.8963 - f1_score: 0.9386 - val_loss: 0.2425 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2481 - acc: 0.9415 - precision: 0.9850 - recall: 0.9025 - f1_score: 0.9403 - val_loss: 0.2421 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2478 - acc: 0.9415 - precision: 0.9856 - recall: 0.8934 - f1_score: 0.9364 - val_loss: 0.2418 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2475 - acc: 0.9415 - precision: 0.9861 - recall: 0.8988 - f1_score: 0.9396 - val_loss: 0.2415 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2473 - acc: 0.9415 - precision: 0.9875 - recall: 0.8946 - f1_score: 0.9371 - val_loss: 0.2412 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2470 - acc: 0.9415 - precision: 0.9863 - recall: 0.8933 - f1_score: 0.9362 - val_loss: 0.2409 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2467 - acc: 0.9415 - precision: 0.9863 - recall: 0.8952 - f1_score: 0.9375 - val_loss: 0.2406 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2464 - acc: 0.9415 - precision: 0.9860 - recall: 0.8969 - f1_score: 0.9388 - val_loss: 0.2403 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2461 - acc: 0.9415 - precision: 0.9871 - recall: 0.8975 - f1_score: 0.9393 - val_loss: 0.2400 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2458 - acc: 0.9415 - precision: 0.9847 - recall: 0.8977 - f1_score: 0.9386 - val_loss: 0.2397 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2455 - acc: 0.9415 - precision: 0.9867 - recall: 0.8889 - f1_score: 0.9325 - val_loss: 0.2394 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2453 - acc: 0.9415 - precision: 0.9869 - recall: 0.8987 - f1_score: 0.9397 - val_loss: 0.2391 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2450 - acc: 0.9415 - precision: 0.9872 - recall: 0.8951 - f1_score: 0.9374 - val_loss: 0.2388 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2447 - acc: 0.9415 - precision: 0.9859 - recall: 0.8979 - f1_score: 0.9385 - val_loss: 0.2385 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2444 - acc: 0.9415 - precision: 0.9872 - recall: 0.8955 - f1_score: 0.9384 - val_loss: 0.2382 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2442 - acc: 0.9415 - precision: 0.9859 - recall: 0.8950 - f1_score: 0.9376 - val_loss: 0.2379 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2439 - acc: 0.9415 - precision: 0.9870 - recall: 0.8955 - f1_score: 0.9367 - val_loss: 0.2376 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2436 - acc: 0.9415 - precision: 0.9839 - recall: 0.8935 - f1_score: 0.9344 - val_loss: 0.2373 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2433 - acc: 0.9415 - precision: 0.9864 - recall: 0.8923 - f1_score: 0.9359 - val_loss: 0.2370 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2431 - acc: 0.9415 - precision: 0.9858 - recall: 0.8972 - f1_score: 0.9376 - val_loss: 0.2367 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2428 - acc: 0.9415 - precision: 0.9853 - recall: 0.8973 - f1_score: 0.9385 - val_loss: 0.2365 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2426 - acc: 0.9415 - precision: 0.9850 - recall: 0.9005 - f1_score: 0.9389 - val_loss: 0.2362 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2423 - acc: 0.9415 - precision: 0.9869 - recall: 0.8962 - f1_score: 0.9379 - val_loss: 0.2359 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2420 - acc: 0.9415 - precision: 0.9870 - recall: 0.8951 - f1_score: 0.9381 - val_loss: 0.2356 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2417 - acc: 0.9415 - precision: 0.9855 - recall: 0.8925 - f1_score: 0.9356 - val_loss: 0.2353 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2415 - acc: 0.9415 - precision: 0.9856 - recall: 0.8960 - f1_score: 0.9380 - val_loss: 0.2350 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2412 - acc: 0.9415 - precision: 0.9856 - recall: 0.8889 - f1_score: 0.9325 - val_loss: 0.2347 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2410 - acc: 0.9415 - precision: 0.9849 - recall: 0.8956 - f1_score: 0.9375 - val_loss: 0.2345 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2407 - acc: 0.9415 - precision: 0.9848 - recall: 0.8932 - f1_score: 0.9360 - val_loss: 0.2342 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2947 - acc: 0.9000 - precision: 1.0000 - recall: 0.8077 - f1_score: 0.893 - 0s - loss: 0.2405 - acc: 0.9415 - precision: 0.9855 - recall: 0.8973 - f1_score: 0.9382 - val_loss: 0.2339 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 956/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2402 - acc: 0.9415 - precision: 0.9873 - recall: 0.8988 - f1_score: 0.9400 - val_loss: 0.2336 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2399 - acc: 0.9415 - precision: 0.9870 - recall: 0.8984 - f1_score: 0.9390 - val_loss: 0.2334 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2397 - acc: 0.9415 - precision: 0.9843 - recall: 0.8970 - f1_score: 0.9379 - val_loss: 0.2331 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2394 - acc: 0.9415 - precision: 0.9864 - recall: 0.8959 - f1_score: 0.9373 - val_loss: 0.2328 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2392 - acc: 0.9415 - precision: 0.9867 - recall: 0.8953 - f1_score: 0.9374 - val_loss: 0.2325 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2389 - acc: 0.9415 - precision: 0.9851 - recall: 0.8951 - f1_score: 0.9373 - val_loss: 0.2323 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2387 - acc: 0.9415 - precision: 0.9865 - recall: 0.8971 - f1_score: 0.9391 - val_loss: 0.2320 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2384 - acc: 0.9415 - precision: 0.9861 - recall: 0.8938 - f1_score: 0.9370 - val_loss: 0.2317 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2382 - acc: 0.9415 - precision: 0.9861 - recall: 0.8958 - f1_score: 0.9375 - val_loss: 0.2315 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2379 - acc: 0.9415 - precision: 0.9849 - recall: 0.8965 - f1_score: 0.9371 - val_loss: 0.2312 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2377 - acc: 0.9415 - precision: 0.9862 - recall: 0.8924 - f1_score: 0.9356 - val_loss: 0.2310 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2374 - acc: 0.9415 - precision: 0.9844 - recall: 0.8951 - f1_score: 0.9363 - val_loss: 0.2307 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2372 - acc: 0.9415 - precision: 0.9839 - recall: 0.8950 - f1_score: 0.9366 - val_loss: 0.2304 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2370 - acc: 0.9415 - precision: 0.9862 - recall: 0.8944 - f1_score: 0.9366 - val_loss: 0.2301 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2367 - acc: 0.9415 - precision: 0.9838 - recall: 0.8944 - f1_score: 0.9360 - val_loss: 0.2299 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2365 - acc: 0.9415 - precision: 0.9868 - recall: 0.9024 - f1_score: 0.9419 - val_loss: 0.2296 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2362 - acc: 0.9415 - precision: 0.9870 - recall: 0.8984 - f1_score: 0.9396 - val_loss: 0.2294 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2360 - acc: 0.9415 - precision: 0.9875 - recall: 0.8982 - f1_score: 0.9394 - val_loss: 0.2291 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2358 - acc: 0.9415 - precision: 0.9861 - recall: 0.8908 - f1_score: 0.9348 - val_loss: 0.2289 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2355 - acc: 0.9415 - precision: 0.9862 - recall: 0.8918 - f1_score: 0.9354 - val_loss: 0.2286 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2353 - acc: 0.9415 - precision: 0.9861 - recall: 0.8951 - f1_score: 0.9378 - val_loss: 0.2283 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2350 - acc: 0.9415 - precision: 0.9848 - recall: 0.8952 - f1_score: 0.9373 - val_loss: 0.2281 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2348 - acc: 0.9415 - precision: 0.9851 - recall: 0.8965 - f1_score: 0.9371 - val_loss: 0.2278 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2346 - acc: 0.9415 - precision: 0.9870 - recall: 0.8907 - f1_score: 0.9348 - val_loss: 0.2276 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2344 - acc: 0.9415 - precision: 0.9851 - recall: 0.8988 - f1_score: 0.9387 - val_loss: 0.2273 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2341 - acc: 0.9415 - precision: 0.9857 - recall: 0.8974 - f1_score: 0.9382 - val_loss: 0.2271 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2339 - acc: 0.9415 - precision: 0.9865 - recall: 0.8959 - f1_score: 0.9379 - val_loss: 0.2268 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2337 - acc: 0.9415 - precision: 0.9869 - recall: 0.8964 - f1_score: 0.9388 - val_loss: 0.2266 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2334 - acc: 0.9415 - precision: 0.9864 - recall: 0.8945 - f1_score: 0.9354 - val_loss: 0.2263 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2332 - acc: 0.9415 - precision: 0.9850 - recall: 0.8976 - f1_score: 0.9380 - val_loss: 0.2261 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2330 - acc: 0.9415 - precision: 0.9868 - recall: 0.8983 - f1_score: 0.9388 - val_loss: 0.2258 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2328 - acc: 0.9415 - precision: 0.9855 - recall: 0.8968 - f1_score: 0.9386 - val_loss: 0.2256 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s - loss: 0.2325 - acc: 0.9415 - precision: 0.9865 - recall: 0.8956 - f1_score: 0.9382 - val_loss: 0.2254 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2323 - acc: 0.9415 - precision: 0.9867 - recall: 0.8973 - f1_score: 0.9385 - val_loss: 0.2251 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2321 - acc: 0.9415 - precision: 0.9870 - recall: 0.8952 - f1_score: 0.9378 - val_loss: 0.2249 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2319 - acc: 0.9415 - precision: 0.9870 - recall: 0.8963 - f1_score: 0.9383 - val_loss: 0.2246 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2317 - acc: 0.9415 - precision: 0.9873 - recall: 0.8966 - f1_score: 0.9394 - val_loss: 0.2244 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2314 - acc: 0.9415 - precision: 0.9870 - recall: 0.8961 - f1_score: 0.9383 - val_loss: 0.2242 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2312 - acc: 0.9415 - precision: 0.9851 - recall: 0.8913 - f1_score: 0.9350 - val_loss: 0.2239 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2310 - acc: 0.9415 - precision: 0.9859 - recall: 0.8946 - f1_score: 0.9373 - val_loss: 0.2237 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2308 - acc: 0.9415 - precision: 0.9862 - recall: 0.8916 - f1_score: 0.9355 - val_loss: 0.2235 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2306 - acc: 0.9415 - precision: 0.9855 - recall: 0.8945 - f1_score: 0.9373 - val_loss: 0.2232 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2303 - acc: 0.9415 - precision: 0.9866 - recall: 0.9000 - f1_score: 0.9406 - val_loss: 0.2230 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2301 - acc: 0.9415 - precision: 0.9853 - recall: 0.8971 - f1_score: 0.9374 - val_loss: 0.2228 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s - loss: 0.2299 - acc: 0.9415 - precision: 0.9866 - recall: 0.8955 - f1_score: 0.9364 - val_loss: 0.2225 - val_acc: 0.9494 - val_precision: 1.0000 - val_recall: 0.8806 - val_f1_score: 0.9340\n",
      " 50/158 [========>.....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# NN model\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FP = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return TP / (TP_plus_FP + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TP_plus_FN = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return TP / (TP_plus_FN + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * prec * rec / (prec + rec + K.epsilon())\n",
    "\n",
    "def nn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(NUMBER_OF_NEURONS,\n",
    "                    input_dim=NUMBER_OF_FEATURES,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(REGULARIZATION_LAMBDA)))\n",
    "#     model.add(layers.Dense(NUMBER_OF_NEURONS, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimazier = optimizers.SGD(lr=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimazier,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', precision, recall, f1_score])\n",
    "    return model\n",
    "\n",
    "train_results = {'models': [], 'history': [], 'score': []}\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS)\n",
    "for train_index, validation_index in kf.split(under_sample_dataset):\n",
    "    k_fold_train, k_fold_validation = under_sample_dataset[train_index], under_sample_dataset[validation_index]\n",
    "\n",
    "    x_train = k_fold_train[:,:-1]\n",
    "    y_train = k_fold_train[:,-1:]\n",
    "        \n",
    "    x_validation = k_fold_validation[:,:-1]\n",
    "    y_validation = k_fold_validation[:,-1:]\n",
    "    \n",
    "    model = nn_model()\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), verbose=1, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    score = model.evaluate(x_validation, y_validation, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    train_results['models'].append(model)\n",
    "    train_results['history'].append(history)\n",
    "    train_results['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.254871</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.930293</td>\n",
       "      <td>0.857281</td>\n",
       "      <td>0.891520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.287081</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.920185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.251360</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.958723</td>\n",
       "      <td>0.880130</td>\n",
       "      <td>0.915612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.199045</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.959870</td>\n",
       "      <td>0.948312</td>\n",
       "      <td>0.953693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.222515</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880635</td>\n",
       "      <td>0.934001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Loss  Accuracy  Precision    Recall  F1_score\n",
       "K-fold 1  0.254871  0.943396   0.930293  0.857281  0.891520\n",
       "K-fold 2  0.287081  0.917722   1.000000  0.854958  0.920185\n",
       "K-fold 3  0.251360  0.917722   0.958723  0.880130  0.915612\n",
       "K-fold 4  0.199045  0.955696   0.959870  0.948312  0.953693\n",
       "K-fold 5  0.222515  0.949367   1.000000  0.880635  0.934001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Loss, Precision, Recall and F1 score in each validation\n",
    "\n",
    "train_results_dict = {'Loss': [i[0] for i in train_results['score']],\n",
    "                      'Accuracy': [i[1] for i in train_results['score']],\n",
    "                      'Precision': [i[2] for i in train_results['score']],\n",
    "                      'Recall': [i[3] for i in train_results['score']],\n",
    "                      'F1_score': [i[4] for i in train_results['score']]}\n",
    "\n",
    "columns = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=train_results_dict, columns=columns, index=indexes)\n",
    "results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCA/0/wFkarylW5kzkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbfe0d4b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxGx0F8sH7DatTB5+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbfe13a320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf475d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbfe0c3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYTwQP8fjM8hOVdM5pIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf44cbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves for validation and training data during learning\n",
    "for history in train_results['history']:\n",
    "    show_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8c378535c047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot learning curves for validation and training data during learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-830689f9cd09>\u001b[0m in \u001b[0;36mshow_loss\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf40a75c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves for validation and training data during learning\n",
    "show_loss(np.average([history.history['val_loss'] for history in train_results['history']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for history in train_results['history']:\n",
    "    print(type(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION ON TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-fold 1</th>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.098166</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.177043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 2</th>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.096234</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.174078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 3</th>\n",
       "      <td>0.981338</td>\n",
       "      <td>0.079545</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.146185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 4</th>\n",
       "      <td>0.980426</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-fold 5</th>\n",
       "      <td>0.983656</td>\n",
       "      <td>0.089921</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.163522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision    Recall  F1_score\n",
       "K-fold 1  0.985148   0.098166  0.900990  0.177043\n",
       "K-fold 2  0.984674   0.096234  0.910891  0.174078\n",
       "K-fold 3  0.981338   0.079545  0.900990  0.146185\n",
       "K-fold 4  0.980426   0.077500  0.920792  0.142967\n",
       "K-fold 5  0.983656   0.089921  0.900990  0.163522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Accuracy, Precision, Recall and F1 score for test dataset for each model from cross validation\n",
    "\n",
    "test_results = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F1_score': []}\n",
    "confusion_matrixes = []\n",
    "for model in train_results['models']:\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    predicted = np.asarray([np.round(j[0]) for j in predicted])\n",
    "    actual = np.asarray([j[0] for j in y_test])\n",
    "        \n",
    "    TP = np.count_nonzero(predicted * actual)\n",
    "    TN = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    FP = np.count_nonzero(predicted * (actual - 1))\n",
    "    FN = np.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "    confusion_matrix_dict = {'actual 1': [TP, FN], 'actual 0': [FP, TN]}\n",
    "    confusion_matrix = pd.DataFrame(data=confusion_matrix_dict, columns =['actual 1', 'actual 0'], index=['predicted 1', 'predicted 0'])\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = metrics.accuracy_score(actual, predicted)\n",
    "    \n",
    "    test_results['Accuracy'].append(accuracy)\n",
    "    test_results['Precision'].append(precision)\n",
    "    test_results['Recall'].append(recall)\n",
    "    test_results['F1_score'].append(f1)\n",
    "    confusion_matrixes.append(confusion_matrix)\n",
    "    \n",
    "columns = ['Accuracy', 'Precision', 'Recall', 'F1_score']\n",
    "indexes = ['K-fold {}'.format(i) for i in range(1, N_SPLITS+1)]\n",
    "results_dataframe = pd.DataFrame(data=test_results, columns=columns, index=indexes)\n",
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejpesko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf44b82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4FOX6//H37G56JdlApFjoXYUoCIgEYqx04eCxIQfE\nQxEEAWnSRIOCSJGDSDsoFr5g4Xh+RzCKAgGkI6CUgNJCSSF9k2yZ3x+RhEASlpDd2d3cr+vyMrsz\n2fnsY5x755nZexRVVVWEEEIIO+i0DiCEEMJ9SNEQQghhNykaQggh7CZFQwghhN2kaAghhLCbFA0h\nhBB2k6IhhBDCblI0hChH//79URQFRVHQ6/XUrl2b559/nnPnzpVY78SJE/Tv359atWrh7e1NzZo1\neeGFFzhx4sR1r5mbm8ubb75Jy5Yt8ff3JywsjDZt2rBgwQJyc3Od9daEqBApGkLcwIMPPsj58+c5\nffo0n376Kfv27aNPnz5Fy/ft20dUVBRnz57l008/JTExkc8//5ykpCSioqLYv39/0bqZmZm0b9+e\nBQsWMHToULZt28aePXt47bXXWLNmDRs3btTiLQphN0W+ES5E2fr378/Zs2eJj48vem7BggW88sor\nZGRkEBQUxD333IOqquzduxeDwVC0nsVi4d5770Wv17Nv3z4URWH48OEsXbqU3377jbvuuqvEtlRV\nJSMjg9DQUKe9PyFulhxpCHETkpKSWLt2LXq9Hr1ez6+//sqvv/7K2LFjSxQMAIPBwNixYzlw4AAH\nDx7EZrOxevVqnnnmmesKBoCiKFIwhMsz3HgVIaq2n376icDAQGw2GyaTCYDRo0cTEBDA0aNHAWjW\nrFmpv3vl+aNHjxIZGcnly5dp2rSpc4IL4QBSNIS4gTZt2vDvf/+bvLw81qxZQ3x8PG+++eZNv47M\nBAtPINNTQtyAn58f9evXp3nz5kyfPp277rqL4cOHA9CwYUMADh06VOrvHj58GIBGjRoRERFBtWrV\n+O2335wTXAgHkBPhQpSjtBPhx48fp0mTJuzYsYPWrVvTsmVLFEUp9UR4q1atUBSF/fv3oygKw4YN\nY9myZWWeCM/MzCQkJMRp70+ImyVHGkLcpAYNGtC1a1cmTpyIoiisXLmSU6dO8dhjj7F582bOnDnD\nli1bePzxxzl9+jQrV65EURQAZs6cSYMGDWjbti1LlizhwIED/PHHH3z11Vc89NBDbNq0SeN3J0T5\n5JyGEBUwZswY2rdvz08//USnTp3YvXs3b775Jv369SM5ORmj0UhsbCx79uyhXr16Rb8XEhLC9u3b\nmTNnDgsWLGDEiBH4+vrSoEEDevXqRWxsrIbvSogbk+kpIYQQdpPpKSGEEHZzyvTUokWL2Lt3LyEh\nIcyZM+e65aqqsmLFCvbt24ePjw9Dhgyhbt26zogmhBDiJjjlSKNTp05MmDChzOX79u3jwoULzJ8/\nn5deeomlS5c6I5YQQoib5JSi0bRpUwIDA8tcvnv3bjp27IiiKDRs2JCcnBwuX77sjGhCCCFugktc\nPZWWlobRaCx6HB4eTlpaGtWqVbtu3fj4+KJr5uPi4pyWUQghhIsUjZsRExNDTExM0eOkpCQN07gO\no9FISkqK1jFcgiuOhapCQQGYTAq5uYX/5OUp5ObqMJvBagWrVcFiAZut8N8lnwOLpeTPpS0vfK74\nZy8vP3Jy8ko8d+Xnwt8pfI1rlxc/V3L59b9TVl5F6yEvQVFUDAbQ61X0ejAYQKe78lzh84XPgcFQ\n8ufSlhc+V3L59c8V/lz4O1dv2/7lV+ctPfuNl/v6QniYFRQFn40b8f35ZwJWrKjwWLpE0QgLCyvx\nP3lqaiphYWEaJhJV0bU7dZNJwWTSlXh87c/X/js3V1fmMqvV8TvS4h1e4b8NBgWdzveGO8mrd2IG\nA/j62spcXvaOs+yd4PXP3czy0neSxe+x/OV6feH7cMUPE46mpKcTPGMG1ttvJ3vECPJjY8mPjSXg\nFl7TJYpGVFQU3333He3bt+f48eP4+/uXOjUlqjaz+fqdeuG/dSUeK4qOlJTAa3b+1+/Uiz/tF/5j\nsdzcTt1gUPH3V/HzK/zH37/4H6PRet2ya9e5sszL69odfek70dJ3kiULwLWq4o5SFPL93/8ImTAB\nXWoq2SNGVNrrOqVovP/++/z2229kZWXx8ssv07dvXywWCwCxsbHce++97N27l1deeQVvb2+GDBni\njFiiklkspe/Ur+zYy15W2qd43XXLzOab2akHo9eX3Flf/e+wMOt1z5W2Uy/+2XbNYxVvb4cNpRAV\npktOJmTSJPy+/RZzs2akrVqFuUWLSnt9t/9GuJzTKGTPJ0qrtbyd+vU7a3unYq48Lii4uU/qOt31\nO2df36t33LZyll27Uy/csfv7q9SpE0Zubgre3qC41tS608mRRrGqMhZeBw4Q3rs32a+8QvY//wle\nXtetU7NmzQq/vktMT7kyVYWEBG+WLAlkzx7X/WipKAqqGlnqMlWFvDyF/Pyb24MqSlk7Z5XISBv+\n/ta/ltlK/bRe2s9Xdux+fio+Po7ZqVerVlgghagq9GfP4vP99+S++CLmu+/m4s6dqA46LyxFowwF\nBfDNN34sWRLIb795ER5u5YknTPj4uOaBma+vH3l5pnKWlz5NU95UjK+vfFIXwqXZbPivWkXwW28B\nkPf449hq1HBYwQApGte5fFnhk08CWLEigIsX9TRsaGb27HR69szF11frdGUzGr1JScnUOoYQwkn0\niYmEjhmDz86d5HXqRMasWdhq1HD4dqVo/OXECT3LlgWyZo0fJpOOjh3zeO+9dB56KF8+bQshXIpi\nMmHs2RPFZuPy3LmY+vRx2rRAlS4aJhNs2uTLmjX+xMf74OUFPXuaGDQomyZNLFrHE0KIEvQnTmCt\nWxfVz4/0+fMxN2uGrXp1p2aockXDbIbNm3345hs/NmzwJTtbh9FoZcSIbF54IYfq1W1aRxRCiJLy\n8gh6/30CFy0ife5cTL17kx8drUmUKlM0jh0zsHRpAP/9rx/p6TpCQmx07WqiWzcT7doVYKgyIyGE\ncCfeu3YRMno0XidOkPu3v5HXpYumeTx+V5mervDee0GsXBmAj4/KI4/k0a2biYceysfHR+t0QghR\ntsC5cwmaMwdrrVqkfvop+Q89pHUkzysaNhv8/LMPJpPCuXN65s8P5PJlHc8+m8vYsVmEhcn0kxDC\nxakqKArmZs3IGTCArHHjUANupWNU5fG4ovHDDz707x9e9LhNm3ymT8+geXM5sS2EcG3K5cuETJ2K\n5c47yX711aIGg67E44rGjz/64u9v46uvUvD1hXr1LHLJrBDC5fl++y0hEyeiS08na+RIreOUyaOK\nhqrCpk0+dOiQL0cWQgi3oLt4sbDB4P/7fxS0bEnqp59iadZM61hlcsrtXp3l5Ek9Z84Y6NQpX+so\nQghhF/3Fi/j89BOZEyeS8p//uHTBAA870vj2Wz8AKRpCCJemP3MG3++/J2fAAMwtW3Jx1y7U0FCt\nY9nFY440kpJ0LFwYyMMP53HHHdLiVAjhgqxWApYtI6JzZ4JmzUJ36RKA2xQM8KCi8fbbwdhsMH16\nhtZRhBDiOobjxzH26kXIG29Q0KYNyT/+6PQWIJXBI6anVLXwuxldu+Zx++1ylCGEcC2KyUR4r16F\nDQbnzcPUu7fb3nfAI4rGhQs6UlP1tGxp1jqKEEIUMSQmYqlXr7DB4MKFmJs2xRYRoXWsW+IR01OH\nDhXezrBFCykaQggXYDIRNHMmEdHR+H35JQD5Dz3k9gUDPOBIw2SCCRNCAGjaVIqGEEJb3jt2EPra\naxj++IOcv/+dvJgYrSNVKrcvGqtXB5CUZKB9+3wCAlzzVqxCiKoh8L33CJ4zB8vtt5Py+ecUPPig\n1pEqndsXjZkzg7n//nzWrEnVOooQoqq60mCwZUuyBw0ia+xYVH9/rVM5hNsXjYIChWHDsrWOIYSo\ngnRpaQRPmYKlbt3CBoMxMeR72HTUtdz+RPiiRWl06SLfABdCOJGq4rt+PRGdOuG3fr3bXj5bEW5/\npBERIffHEEI4j+7CBUImTMBvwwYK7r6b1M8/x9K0qdaxnMbti4aXl5z8FkI4jz45GZ+EBDImTyZn\n4ECq2r2i3f7denlpnUAI4en0p07hu3EjOYMGYW7Rgos7d6KGhGgdSxNuf07DYJAjDSGEg1itBCxZ\nUthgcM6c4gaDVbRggAcUDTnSEEI4guHoUYzduxMybRoF7dtzyU0bDFY2t5+ekiMNIURlU0wmwv9q\nKnj5gw8wde9epa6QKo/bFw050hBCVBbDsWNYGjRA9fPj8qJFWJo1wxYernUsl+L201N6vdYJhBDu\nTjGZCJ4xg4guXfBbtw6Ago4dpWCUwu2PNECmp4QQFee9bRuhY8Zg+PNPcp59lrzYWK0juTS3Lxoy\nzSiEqKig2bMJmjsXy513krJmDQXt22sdyeW5fdHQuf0EmxDC6f5qMFhwzz1kDx5M1pgxqH5+Wqdy\nC04rGvv372fFihXYbDa6dOlCjx49SizPzc1l/vz5pKamYrVa6dq1K9HR0Td8XTnSEELYS5eaSvAb\nb2CpV4/sUaOqRIPByuaUz+k2m41ly5YxYcIE5s6dS0JCAmfPni2xznfffUft2rV59913mTp1KqtW\nrcJisdzwtaVoCCFuSFXRff45EQ89hN9//yuXXd4CpxSNxMREIiMjqVGjBgaDgXbt2rFr164S6yiK\nQl5eHqqqkpeXR2BgIDo75p5kekoIUR5dUhJh/ftjeOEFrHfeSfKGDWQPH651LLfllOmptLQ0wq+6\ndC08PJzjx4+XWOfRRx/lnXfeYfDgwZhMJl599dVSi0Z8fDzx8fEAxMXFER4ehtHo2PzuwGAwYJSB\nAGQsriZjAcrZsxh27sQ2Zw7885+EynX6t8RlToQfOHCAO+64gzfeeIOLFy8yY8YMGjdujP81d7+K\niYkh5qo5yMuX01AUaY9uNBpJSUnROoZLkLEoVlXHQv/HH/h+/z05L70EtWuj7NxJ+F13VcmxKE3N\nmjUr/LtOmdwJCwsjNbX4dqypqamEhYWVWGfTpk20adMGRVGIjIykevXqJCUl3fC1FUW+pyGE+IvF\nQsDixVSPiSFo7lx0yckAqEFBGgfzHE4pGvXq1eP8+fNcunQJi8XCtm3biIqKKrGO0Wjk4MGDAKSn\np5OUlER1O5qDyYlwIQSA4fffCxsMzphBXseOhQ0GIyK0juVxnDI9pdfrGTBgADNnzsRmsxEdHU2d\nOnXYuHEjALGxsfTu3ZtFixYxevRoAJ555hmCg4Nv+NpSNIQQislEeJ8+oNORtmgRed26yc7BQRRV\nVd16fufIkfMEB7v1W6gUVXXuujQyFsU8fSwMR45gadQIFAXvLVsKGwxeM/V9haePxc1w+XMajiSX\n3ApR9Si5uQRPnUpETExxg8EHHyyzYIjK4zJXTwkhhD28t2whdOxYDKdPk/PCC+Q98ojWkaoUKRpC\nCLcR9M47BM2bh+Wuu0hZt46Ctm21jlTlSNEQQrg+mw10OgqiosgaMoSsUaNAGgxqQoqGEMJl6VJS\nCJk8GUu9emS99hr5nTuT37mz1rGqNDmNLIRwPaqK37p1VH/oIXy/+07alruQmz7SyMjIICQkxBFZ\nhBAC3blzhL7+Or4//khB69akz56NpWFDrWOJv9hVNHJzc1m+fDnbt29Hp9Px8ccfs3v3bk6ePEnf\nvn0dnbFc8v0dITyL7vJlvHfvJmP6dHL69wdpMOhS7Jqe+uijj/Dy8mLevHkYDIV1pkGDBiQkJDg0\nnBCiatCfOEHA4sUAWJo35+KuXeT84x9SMFyQXUXj4MGD/OMf/yjRYjkkJIT09HSHBRNCVAEWC4Ef\nfED1hx8maP784gaDgYEaBxNlsato+Pn5kZ2dXeK5lJQUQkNDHRJKCOH5DIcPY3zySYLfeou8zp25\ntGmTNBh0A3ad04iOjua9997j6aefRlVVEhMT+eyzz0rc10IIIeylmEyE/+1vYDCQtmQJeU88oXUk\nYSe7ikbPnj3x8vJi8eLFmM1m5s+fT0xMDE/If2ghxE0w/PYbliZNUP38uPzhh5ibNkWtVk3rWOIm\n2FU0srKy6Nq1K127di3xfGZmpl3tyx1Jrp4SwvUpOTkEzZpFwPLlpM+di6lPHwrat9c6lqgAu85p\nDC/jJuwjRoyo1DBCCM/js3kzEV26ELhsGTn9+5P32GNaRxK3wK4jjdJuuZGXl4dO+pILIcoRFBdH\n0IIFmOvVI+Wrryi4/36tI4lbVG7RGDp0KIqiUFBQwLBhw0osy8rKok2bNg4NJ4RwU1caDN5/P1nD\nhpH16qvg66t1KlEJyi0aL7/8Mqqq8s477zB48OCi5xVFISQkhDp16jg8oBDCfeguXSJk4kQsDRuS\nNWaMNBj0QOUWjRYtWgCwZMkS/P39nRJICOGGVBW/NWsImT4dxWQis3VrrRMJB7HrnIa/vz+nT5/m\nyJEjZGZmllj21FNPOSSYveTqKSG0pT97lpCxY/H9+Wfy77+f9HffxVq/vtaxhIPYVTR+/PFHli9f\nTvPmzTl48CAtWrTg0KFDtJZPE0JUeUpGBt4HDpA+cya5zz8PcoGMR7OraHz99deMHz+eZs2a8eKL\nL/L666+zZ88efvnlF0fnE0K4IH1iIr7ff0/OP/+JpVkzLu7ciRoQoHUs4QR2fSTIyMigWbNmQOFJ\ncJvNRqtWrdi1a5dDwwkhXIzZTOCCBVSPjSVo4UJ0KSkAUjCqELuKRlhYGMl/dZ+87bbb2Lt3L8eP\nHy9qky6E8HyGQ4cKGwzGxZEXE8Oln37CdlXna1E12LXX79q1K2fOnCEiIoJevXrx3nvvYbVaef75\n5x2dTwjhAhSTifB+/cDLi7SPPiLv8ce1jiQ0oqilfd37BgoKCrBYLC5xGe6JE0nI7YPBaDSS8tdU\nQVUnY1HsVsfCcOgQlmbNQFHw3ratsMGgm94SQf4uitWsWbPCv1uhyxy8vb2xWq18+umnFd6wEMJ1\nKdnZhEycSPVHHsFv7VoACtq1c9uCISrPDaenfvrpJ/78809uu+02YmJiyM/PZ926dXz//fc0atTI\nGRmFEE7ks2kTIePGoU9KIvsf/5CpKFFCuUXjk08+YfPmzTRs2JCEhASOHz/OsWPHqFu3LtOnT+fO\nO+90UkwhhDMEvf02QQsXYm7QgJSvv8YcFaV1JOFiyi0aCQkJTJs2jdtuu42zZ88yevRoRowYQbt2\n7ZyVTwjhDFYr6PUUPPAAWXo9WSNGgI+P1qmECyr3nEZubi633XYbALVr18bb21sKhhAeRHfxItUG\nDiRozhwA8jt1ImvsWCkYokzlHmmoqlriagO9Xn/d1QdGuU5bCPdzpcHgtGko+flk3nef1omEmyi3\naOTn5zN06NASz137+Isvvqj8VDdBGhYKcXP0Z84QOmYMPlu2kN+mTWGDwXr1tI4l3ES5ReOzzz5z\nVg4hhJMomZl4HTxI+ltvkfvcc9JgUNyUcotGZd7Odf/+/axYsQKbzUaXLl3o0aPHdescPnyYlStX\nYrVaCQoKYtq0aZW2fSGqMsOxY/hu3Ej2sGGFDQZ37UJ1gS/nCvfjlOZRNpuNZcuWMWnSJMLDwxk/\nfjxRUVHUrl27aJ2cnByWLl3KxIkTMRqNZGRkOCOaEJ6toIDA998naN48bAEB5Pbrh81olIIhKswp\nx6WJiYlERkZSo0YNDAYD7dq1u65D7tatW2nTpk3RifWQkBBnRBPCY3kdOIChXTuC330X02OPkSwN\nBkUlcMqRRlpaGuHh4UWPw8PDOX78eIl1zp8/j8ViYerUqZhMJh5//HEeeuih614rPj6e+Ph4AOLi\n4jAajXK/esBgMMiVbH+RsQBycvB69lnw9cW8di2Grl0J0zqTxuTvonLYXTSsVisnTpwgLS2Ntm3b\nUlBQABT2oaoMVquVP/74g8mTJ1NQUMCkSZNo0KDBdY21YmJiiImJKXqcmpoil5QjzdiuVpXHwuvg\nQczNmoFOh/dHHxHcoQMpFgtU0fG4WlX+u7iWwxsWnjlzhpEjR7JgwQI++OADAA4ePMiiRYvs2khY\nWBipqalFj1NTUwkLK/m5Jzw8nLvvvhtfX1+Cg4Np0qQJp06dsvd9CFGlKVlZhIwfT8Sjj+K3bh0A\nBW3bgjQYFJXMrqKxdOlSevfuzYIFC4puvNSsWTOOHDli10bq1avH+fPnuXTpEhaLhW3bthF1TU+b\nqKgojhw5gtVqJT8/n8TERGrVqnWTb0eIqsfnhx+oHh2N/yefkP3SS+Q98YTWkYQHs2t66vTp09ed\nX/D19SU/P9+ujej1egYMGMDMmTOx2WxER0dTp04dNm7cCEBsbCy1a9fmnnvu4bXXXkOn09G5c2du\nv/32m3w7QlQtQTNnErRoEeaGDUlbsgRzq1ZaRxIezq6iYTQa+eOPP6hbt27RcydOnCAyMtLuDbVq\n1YpW1/xBx8bGlnjcrVs3unXrZvdrClElqSrYbIUNBjt0IMvHh6zhw6VflHAKu4rG3/72N+Li4oiN\njcVisbB+/Xo2bNjAwIEDHZ1PCHEV3fnzhEyYgKVxY7LGjSP/oYfIL+UqQyEcxa6iERUVRWhoKD/8\n8AONGzcmKSmJkSNH0qBBA0fnuyHpPSWqBFXF/9NPCZ4xA8VsJlO6TQuN2FU0srOzqV+/PvXr13d0\nHiHENfSnTxM6ejQ+27aR/8ADhQ0G77pL61iiirKraLz88su0aNGCBx98kKioqEr7boYQ4saUnBwM\nv/9O+qxZ5P7979JgUGhKUVVVvdFK6enpbNu2jYSEBM6ePUtUVBQdOnTg7rvvrtSmhhXx559JSA2T\nLy5dzRPGwnDkSGGDwVdeAUAxmVD9/G76dTxhLCqLjEWxW/lyn11F42oXL15k69atJCQkkJWVxUcf\nfVThjVcGKRqF5H+IYm49FgUFBC5cSND8+diCgkjetOmW+kW59VhUMhmLYg7/RvjVcnNzyc3NxWQy\n4SOX+AlRabz27yfisccInjMH05NPSoNB4ZLsOqeRlJREQkICW7duJTc3lwceeICRI0fSqFEjR+e7\nIbl6SngCJTeX8GeeQfX1JXXFCvKv+Q6TEK7CrqIxfvx47r//fl588UVatmyp+XkMITyF14EDmFu0\nQPX3J23FCsyNG6MGB2sdS4gy2VU0PvroI7liSohKpGRmEvzmmwSsXs3l99/H1KcPBfffr3UsIW6o\nzKKxdetWOnToAMD27dvLfIHS7nkhhCibz8aNhI4fj+7SJbJffpm8J5/UOpIQdiuzaPz8889FReOH\nH34odR1FUaRoCHETgmfMIHDxYsxNmpC2bBnme+7ROpIQN+WmL7l1NadOJeHlpXUK7cnlhMVcbixU\nFaxWMBjw2bwZrz17yB46FGdcK+5yY6EhGYtiDr/kdvz48aU+P3HixApvuLLI1VPClemSkgjr35+g\n2bMByO/YkexXX3VKwRDCEewqGufOnSv1+aSkpEoNI4THsNnw//hjqkdH452QgK16da0TCVEpyr16\n6srtXC0Wy3W3dk1OTqZ27dqOSyaEm9KfOlXYYHD7dvI7dCD9nXew3nGH1rGEqBTlFo2r7+N99c+K\nolC3bl3aSXtmIa6j5OZiOHaM9Nmzye3XT+ZQhUcpt2j069cPgIYNG1531z0hRDHD77/ju2ED2SNH\nYmnShIu//AIVaDAohKsrs2gcOXKExo0bA4X3A//tt99KXa9p06aOSSaEO8jPJ2j+fAIXLsQWEkLu\ns88W9ouSgiE8VJlFY/Hixbz//vsALFiwoMwX+Ne//lX5qYRwA1579hD62mt4HTtGbu/eZEydinrV\nNK4Qnsjtv6dx5kwSer3WKbQn16AXc8ZYKLm51LjvPmz+/mTMmkV+584O3V5Fyd9FMRmLYrfyPQ27\nek9d6/fff0en07lEl1shnMlr717M99yD6u9P6sqVWJo0QQ0M1DqWEE5j1/c0pk6dypEjRwBYv349\ns2fPZs6cOXz99dcODSeEq1AyMgh57TUiunbFb906AMz33ScFQ1Q5dhWN06dP06BBAwDi4+OZOnUq\nb731Fhs3bnRoOCFcge9331E9Ohr/NWvIGjoUkzQYFFWYXdNTqqqiKAoXL17EarVSp04dALKzsx0a\nTgitBU+dSuBHH2Fu2pS0lSsxt2ypdSQhNGVX0WjYsCErV67k8uXL3P9Xz/+LFy8SFBTk0HBCaOKq\nBoN5nTtjq1aN7CFDkM6YQtg5PTV06FC8vb2pWbMmffv2BeDs2bM8+uijDg1nD/myrahM+nPnCHv+\n+aIGgwUdO5I9YoQUDCH+YteRRnBwMM8++2yJ51q3bk3r1q0dEkoIp7PZ8F+1iuC33gKbjbwuXbRO\nJIRLsqtoWK1WvvrqK7Zs2UJaWhphYWE8+OCD9OjRA4OhQlftCuEy9H/8Udhg8JdfyOvYkYx33sH6\n13k7IURJdu3xV69ezdGjR3nhhReIiIggOTmZL7/8ktzcXJ5//nlHZxTCoZT8fAwnT3L5vfcw9e0r\nc55ClMOuorF9+3ZmzZpFcHAwAHXq1KF+/fqMGTNGioZwS4ZDh/DduJHsUaOwNG7MxR07wNdX61hC\nuDy7ToTbbDZ0upKrKoqCm3cgEVVRXh5BcXFEPP44AatWobvSVkIKhhB2setIo02bNsyaNYu+ffti\nNBpJTk5m3bp1tG3b1tH5bkhmEoS9vHbtKmwwmJhIbp8+ZEyZglqtmtaxhHArdhWN5557jv/7v/9j\n8eLFRSfC27dvz1NPPeXofEJUCiU3l/D+/bEFBJC6ejX5nTppHUkIt+T2XW7PnUuSow2kg+fVrh4L\nr927MbdqBTodXrt3Y2ncuEr1i5K/i2IyFsVupcttuec0zp8/z5QpU3jxxReZMWPGLQ34/v37GTFi\nBMOHDy+30WFiYiL9+vVjx44dFd6WEEp6OqGjRhHRvTt+a9cCYI6KqlIFQwhHKLdoLF++nGrVqjF0\n6FCCgoJYuXJlhTZis9lYtmwZEyZMYO7cuSQkJHD27NlS11u9ejV33313hbYjBIDy9ddUj47Gb+1a\nsoYNw9Q2VP4AAAAaVklEQVStm9aRhPAY5Z7TOHnyJP/617/w9vamWbNmjBw5skIbSUxMJDIykho1\nagDQrl07du3aRe3atUus97///Y82bdpw4sSJCm1HiOApU/BauhRzs2akfvwxlubNtY4khEcpt2hY\nLBa8vb0B8PPzo6CgoEIbSUtLIzw8vOhxeHg4x48fv26dnTt3MmXKlHJvIRsfH098fDwAcXFxREQY\nK5TJ0xgMBozGKjoWVzUYVHr3xnbXXagjRhAq/aKq9t/FNWQsKke5RcNsNrP2r/lggIKCghKPgUq7\ngmrlypU888wz130f5FoxMTHExMQUPZYTW4Wq6kk+/ZkzhIwbh7lFC7LGj4eWLTF27lwlx6I0VfXv\nojQyFsUcdrvXBx54gPPnzxc9btu2bYnHip2XLYWFhZGamlr0ODU1lbCwsBLrnDhxgnnz5gGQmZnJ\nvn370Ol0Ra3YhSjBZiNg5UqC3n4bFIU8F+i4LERVUG7RGD58eKVspF69epw/f55Lly4RFhbGtm3b\neOWVV0qs88EHH5T4uXXr1lIwRKn0J08SOmoUPrt2kRcdTUZcHNZrzo8JIRzDKS1q9Xo9AwYMYObM\nmdhsNqKjo6lTp07R7WJjY2OdEUN4CMVsxnDqFJfnzcPUu7e0BRDCidz+y31JSUlaR3AJnj5fazh0\nCL8NG8gaPbrwifx88PEpdV1PH4ubIWNRTMaimMO+3CeE5vLyCHr7bSIefxz/Tz5Bd+XcWBkFQwjh\nWFI0hMvy3rmT6g8/TNDChZieeopLmzZhu+rSbSGE89l9TuPQoUNs27aN9PR0xo4dy8mTJ8nLy6Np\n06aOzCeqKCUnh7AXX8QWFETqZ5+R37Gj1pGEENh5pLFhwwYWL15MeHg4hw8fBgq/KPPZZ585NJyo\nerx37gSbDTUggNRVq0j+4QcpGEK4ELuKxrfffsvkyZPp3bt30Zfvateuzblz5xwaTlQdSloaoa+8\ngrFnz+IGg61bowYEaJxMCHE1u6anTCYTERERJZ6zWq0YDE65Yld4MlXF99tvCZk0CV16OlkjR2Lq\n3l3rVEKIMth1pNG4cWPWr19f4rkNGzbI+Qxxy4KnTCHs5Zex1qxJ8v/7f2SNGSNXRgnhwuw6VBgw\nYABxcXH88MMP5OXlMWrUKAwGA+PHj3d0PuGJVBUsFvDyIi82FltkJNkvvQRy5CqEy7P7y32qqnL0\n6FFSUlIwGo00bNjwhs0FnUG+3FfIXb64pD99mtCxYylo2ZKsCRMcsg13GQtnkLEoJmNRzGENC6+m\nKAqNGzeu8IZEFWe1ErBiBUFxcaDXY3rySa0TCSEqwK6iMXTo0DI72i5cuLBSAwnPoz9xgmqvvor3\nnj3kde5Melwctlq1tI4lhKgAu4rGyy+/XOLx5cuX+e6772jfvr1DQgnPolit6M+d4/KCBZh69pQG\ng0K4MbuKRosWLUp97u233+aJJ56o9FDC/XkdOIDvhg1kjR2LpWFDLm7bJldFCeEBKnwm29vbm4sX\nL1ZmFuEJTCaC33wT45NP4v/FF9JgUAgPY9eRxrW3eM3Pz2fv3r3cfffdDgkl3JP39u2EvvYahj//\nJOeZZ8icOBE1JETrWEKISmRX0bj6Fq8APj4+PPLII3Tq1MkRmYQbUnJyCBs4EFtICClffEFBhw5a\nRxJCOMANi4bNZqNly5Y88MADeHt7OyOTcCPev/xCwX33FTYY/OQTLI0aofr7ax1LCOEgNzynodPp\nWL58uRQMUYIuLY3Q4cMx9upV3GDw3nulYAjh4ew6Ed6qVSv27t3r6CzCHagqvt98Q0SnTvitX0/W\nqFHSYFCIKsSucxqqqjJnzhwaN25M+DV3ThsyZIhDggnXFPzGGwQuX07BPfeQ+sUXWJo00TqSEMKJ\n7CoakZGRdO3a1dFZhKtSVTCbwdubvEcfxVqrFjmDBoFer3UyIYSTlVs0tm7dSocOHejXr5+z8ggX\no//zT0LHjMF8991kTppEQfv2FEgnACGqrHLPaXz00UfOyiFcjdVKwIcfEtGlC14HD2KpV0/rREII\nF1DukYadXdOFhzEkJhI6ciTe+/aR9/DDpL/9NrbbbtM6lhDCBZRbNGw2G4cOHSr3BZo3b16pgYQL\nsNnQX7hA2qJF5HXrJg0GhRBFyi0aZrOZxYsXl3nEoSiKtEb3EF779hU2GHz99eIGg/LdHCHENcot\nGr6+vlIUPJxiMhH07rsEfPQRturVyRk0CFt4uBQMIUSptL9fq9CMd0ICEV26EPjhh+T+/e9c2rSp\nsGAIIUQZ5ER4FaXk5FBt8GDUkBBS/u//KGjXTutIQgg3UG7RWLVqlbNyCCfx3raNgrZtUQMCSLvS\nYNDPT+tYQgg3IdNTVYQuNZXQIUMw9umD37p1AJjvuUcKhhDiptjVRkS4MVXF7+uvCZ48GV1ODplj\nxkiDQSFEhUnR8HAhkyYRsHIlBa1akTpnDpaGDbWOJIRwY1I0PJHNBhYLeHtjeuIJLHfeSc6AAdJg\nUAhxy5xWNPbv38+KFSuw2Wx06dKFHj16lFi+ZcsWvvnmG1RVxc/Pj4EDB3LnnXc6K57H0J88SejY\nsYUNBidPpqBdO7kySghRaZxyItxms7Fs2TImTJjA3LlzSUhI4OzZsyXWqV69OlOnTmXOnDn07t2b\nJUuWOCOa57BYCFi8mOoPP4zX4cOYGzTQOpEQwgM55UgjMTGRyMhIatSoAUC7du3YtWsXtWvXLlqn\nUaNGRT83aNCA1NRUZ0TzCIbjxzGMHk3Inj2YHnmEjLfewhYZqXUsIYQHckrRSEtLK3HHv/DwcI4f\nP17m+j/++CP33ntvqcvi4+OJj48HIC4uDqPRWLlh3VFyMsqlS1hWr0bfuzdhVbzBoMFgkL+Lv8hY\nFJOxqBwudyL80KFDbNq0ienTp5e6PCYmhpiYmKLHKSkpzormUrz27MF340ayxo+HiAiMv/9OSkYG\nyBEaRqOxyv5dXEvGopiMRbGaNWtW+Hedck4jLCysxHRTamoqYWFh16136tQpPvzwQ8aMGUNQUJAz\norkdJTeX4ClTMHbvjt+XX6K7Mq5eXtoGE0JUCU4pGvXq1eP8+fNcunQJi8XCtm3biIqKKrFOSkoK\ns2fPZtiwYbdUBT2Z9+bNRHTuTODSpeS+8ALJ0mBQCOFkTpme0uv1DBgwgJkzZ2Kz2YiOjqZOnTps\n3LgRgNjYWNauXUt2djZLly4t+p24uDhnxHMLSk4O1YYMQQ0NJeXLLylo00brSEKIKkhR3byVbVJS\nktYRHMp761YKHngA9Hq8fv218FLaUvpFyXxtMRmLYjIWxWQsirn8OQ1x83TJyVQbPBjj3/5W3GCw\nZctSC4YQQjiLy109VeWpKn7r1hEyZQpKbi6Z48Zh6tlT61RCCAFI0XA5IRMmELBqFQWtW5M+Zw4W\n+Wa3EMKFSNFwBTYbmM3g44OpWzcsDRqQ88IL0mBQCOFy5JyGxvSJiYT37k3wrFkAFDzwgHSkFUK4\nLCkaWjGbCVy4kOqxsXgdPYq5cWOtEwkhxA3J9JQGDEePEvrKK3gfOoTp8cfJmDkTW/XqWscSQogb\nkqKhBb0eXXo6aUuWkPfEE1qnEUIIu0nRcBKvXbsKGwxOnIilfn0uJSSAQYZfCOFe5JyGgyk5OQRP\nnoyxZ0/81q9Hl5ZWuEAKhhDCDUnRcCCfn38monNnAlasIOfFF0n+8UdspXT3FUIIdyEfdx1Eyckh\ndNgwbNWqkfrVVxTcd5/WkYQQ4pZJ0ahkPps3k9++PWpAAKmffYalfn3w9dU6lhBCVAqZnqokuosX\nqTZoEOFPP43fl18CYGneXAqGEMKjyJHGrVJV/NasIWTaNJS8PDInTJAGg0IIjyVF4xaFvP46AZ98\nQv7995P+7rtY69fXOpIQQjiMFI2KuLrBYM+emJs0Iff550Ens31CCM8me7mbZDh+HGPPngT/dSva\ngrZtye3fXwqGEKJKkD2dvcxmAufPJyI2FkNiIubmzbVOJIQQTifTU3YwHD1KteHD8Tp8GNOTT5Lx\n5pvYIiK0jiWEEE4nRcMOql6PkpVF2tKl5D32mNZxhBBCMzI9VQbvX34hePp0AKz163NpyxYpGEKI\nKk+KxjWU7GxCJkzA2KsXvv/7nzQYFEKIq0jRuIrPjz8SER2N/6pVZA8cSPIPP0iDQSGEuIp8fP6L\nkp1N6IgR2IxGUr75BnPr1lpHEkIIl1O1i4aq4vPTT+R37IgaGEjq558XNhj08dE6mRBCuKQqOz2l\nu3iRagMHEv7ss8UNBps1k4IhhBDlqHpHGqqK3xdfFDYYLCggY9IkaTAohBB2qnJFI2TcOAJWrya/\nbdvCBoN162odSQgh3EbVKBpWa2GDQV9fTL17Y27enNxnn5V+UUIIcZM8fq9pOHoUY/fuxQ0G27SR\njrRCCFFBnrvnLCggcO5cIh55BP2ff2K+5x6tEwkhhNvzyOkpw++/FzYY/P13crt3J3PGDGzh4VrH\nEkIIt+eRRUP18kIxmUhdsYL82Fit4wghhMfwmOkp7+3bCZ42DfirweDmzVIwhBCikjntSGP//v2s\nWLECm81Gly5d6NGjR4nlqqqyYsUK9u3bh4+PD0OGDKGuHZfDKllZBM+cScDHH2O54w6yhw8v7Bel\n1zvqrQghRJXllCMNm83GsmXLmDBhAnPnziUhIYGzZ8+WWGffvn1cuHCB+fPn89JLL7F06VK7Xrt6\ndDT+q1eT/dJL0mBQCCEczClHGomJiURGRlKjRg0A2rVrx65du6hdu3bROrt376Zjx44oikLDhg3J\nycnh8uXLVKtWrdzXtgUHk7ZkCeZWrRz6HoQQQjipaKSlpRF+1dVL4eHhHD9+/Lp1jEZjiXXS0tKu\nKxrx8fHEx8cDEBcXh9eRI8iNVwvVrFlT6wguQ8aimIxFMRmLW+d2J8JjYmKIi4sjLi6O119/Xes4\nLkPGopiMRTEZi2IyFsVuZSycUjTCwsJITU0tepyamkrYNecewsLCSElJKXcdIYQQ2nJK0ahXrx7n\nz5/n0qVLWCwWtm3bRlRUVIl1oqKi2Lx5M6qqcuzYMfz9/W94PkMIIYRz6adOnTrV0RvR6XRERkay\nYMECvvvuOx588EHatm3Lxo0bOXHiBPXq1SMyMpJjx46xcuVK9u/fz+DBg+060rDnstyqQsaimIxF\nMRmLYjIWxSo6FoqqqmolZxFCCOGh3O5EuBBCCO1I0RBCCGE3t2hY6KgWJO7oRmOxZcsWvvnmG1RV\nxc/Pj4EDB3LnnXdqE9bBbjQWVyQmJjJp0iRGjhxJ27ZtnZzSOewZi8OHD7Ny5UqsVitBQUFM+6tX\nm6e50Vjk5uYyf/58UlNTsVqtdO3alejoaI3SOs6iRYvYu3cvISEhzJkz57rlFd5vqi7OarWqw4YN\nUy9cuKCazWb1tddeU8+cOVNinT179qgzZ85UbTabevToUXX8+PEapXUse8biyJEjalZWlqqqqrp3\n794qPRZX1ps6dar61ltvqdu3b9cgqePZMxbZ2dnqyJEj1eTkZFVVVTU9PV2LqA5nz1isW7dO/fjj\nj1VVVdWMjAy1f//+qtls1iKuQx0+fFg9ceKEOmrUqFKXV3S/6fLTU1e3IDEYDEUtSK5WVgsST2PP\nWDRq1IjAwEAAGjRoUOL7MZ7EnrEA+N///kebNm0IDg7WIKVz2DMWW7dupU2bNkVdF0JCQrSI6nD2\njIWiKOTl5aGqKnl5eQQGBqLzwDt5Nm3atGhfUJqK7jddfqRKa0GSlpZ23TqltSDxNPaMxdV+/PFH\n7r33XmdEczp7/y527txJrIe3yLdnLM6fP092djZTp05l3Lhx/Pzzz86O6RT2jMWjjz7KuXPnGDx4\nMKNHj+bFF1/0yKJxIxXdb7rFOQ1x8w4dOsSmTZuYPn261lE0s3LlSp555pkquUO4ltVq5Y8//mDy\n5MkUFBQwadIkGjRoUCV7MR04cIA77riDN954g4sXLzJjxgwaN26Mv7+/1tHcgssXDWlBUsyesQA4\ndeoUH374IePHjycoKMiZEZ3GnrE4ceIE8+bNAyAzM5N9+/ah0+m4//77nZrV0ewZi/DwcIKCgvD1\n9cXX15cmTZpw6tQpjysa9ozFpk2b6NGjB4qiEBkZSfXq1UlKSqJ+/frOjqupiu43Xf4jmLQgKWbP\nWKSkpDB79myGDRvmcTuEq9kzFh988EHRP23btmXgwIEeVzDA/v9Hjhw5gtVqJT8/n8TERGrVqqVR\nYsexZyyMRiMHDx4EID09naSkJKpXr65FXE1VdL/pFt8I37t3L//+97+x2WxER0fTq1cvNm7cCEBs\nbCyqqrJs2TIOHDiAt7c3Q4YMoV69ehqndowbjcXixYv55ZdfiuYq9Xo9cXFxWkZ2mBuNxdU++OAD\nWrdu7bGX3NozFuvXr2fTpk3odDo6d+7ME088oWVkh7nRWKSlpbFo0aKik77du3enY8eOWkZ2iPff\nf5/ffvuNrKwsQkJC6Nu3LxaLBbi1/aZbFA0hhBCuweWnp4QQQrgOKRpCCCHsJkVDCCGE3aRoCCGE\nsJsUDSGEEHaToiHczvz581mzZo3WMW5oxIgR/P7772Uuf/PNN9myZYsTEwlx6+SSW6GZoUOHkp6e\nXqLNx7x58274rdT58+cTGRlJ3759Ky3L/Pnz2b59OwaDAYPBQL169RgwYEClfUHy888/JzU1laFD\nh1bK65XFarXy9NNP4+PjA0BAQADt27e3u53Kr7/+yocffsgHH3zg0JzCfbl8GxHh2caNG0fLli21\njgFAz5496du3L3l5eSxevJh//etfzJgxQ+tYFTJnzpyi9hhTpkyhdu3aHnnPCOF8UjSEy7HZbMyd\nO5cjR45gNpu58847GThwILVr175u3YyMDBYtWsTRo0dRFIXbb7+96OZCqampLF++nCNHjuDr60vX\nrl159NFHb7h9X19f2rdvX/Rpu6CggE8++YQdO3agKArt2rXjmWeewWAwlLv9l19+meHDh5OXl8c3\n33wDwI4dO6hZsyazZs1i8uTJdOnShXbt2jFo0CDeeuutotYe6enpDB06lMWLFxMUFMTu3bv54osv\nSE5Opk6dOgwaNIjbb7/9hu+lZs2aNGrUiD///LPouR9++IFvv/2W1NRUQkJC6NGjB126dCE3N5dZ\ns2ZhsVh47rnnAFi4cCFBQUF8/fXXbNq0idzcXFq0aMHAgQPLbbstPJcUDeGSWrduzZAhQ9Dr9Xz8\n8ccsXLiw1HYo69evp3r16owZMwaAY8eOAYWFJy4ujgceeIBXX32VlJQUZsyYQa1atWjRokW52zaZ\nTGzdupW77roLgLVr13Ly5Elmz56NqqrMmjWLr776ij59+pS5/WvfS/fu3cucnvL29ua+++4jISGh\naMpt27ZttGjRgqCgIBITE/nwww8ZN24cdevW5aeffuLdd99l7ty5GAzl/y989uxZjh49Sq9evYqe\nCwkJ4fXXX6d69eocPnyYt99+m/r163PHHXcwbty466an/vOf/7Bv3z6mTZtGYGAgy5cvZ8WKFQwf\nPrzcbQvPJCfChabeffdd+vfvT//+/XnnnXcA0Ol0dOrUCT8/P7y9venTpw8nT54kLy/vut/X6/Vc\nvnyZlJQUDAYDTZs2BQp33iaTiV69emEwGIiMjCQ6OpqEhIQys3zzzTf079+fESNGYDab+ec//wkU\n3sCoT58+BAcHExISwlNPPcXmzZvL3f7N6tChQ4lsW7dupUOHDgDEx8cTGxtL/fr1i/pGQeENh8oy\nZswYnnvuOUaNGkWLFi14+OGHi5ZFRUVRo0YNFEWhefPmtGjRotwT9t9//z1PP/00YWFheHt789RT\nT7Fjxw5sNluF3qtwb3KkITQ1ZsyY685p2Gw2Pv30U3bs2EFWVhaKogCQlZWFr69viXV79OjBmjVr\nmDFjBjqdjocffphu3bqRkpJCSkoK/fv3L/G65e3Uu3fvXurJ9cuXLxMREVH02Gg0Ft2spqzt36wW\nLVqQk5PDyZMn8ff35+zZs0XdWVNSUti6dSv//e9/i9a3WCzl3jDn3XffxWg0sm3bNr744ouiO9QB\n7Nmzh3Xr1nH+/HlUVSU/P7/cRnUpKSnMmjWr6L/DFZmZmYSGht70exXuTYqGcDk///wz+/bt4403\n3iAiIoKsrCwGDhxIaRf6+fv7Fx2pnD59mmnTplG/fn3Cw8O57bbbmDt37i3nqVatGsnJyUVXUqWk\npBRd4VXW9m/2iEOv19O2bVu2bt2Kv78/UVFRRQUyPDycp556ih49etzUa+p0Ojp06MCuXbv48ssv\nef755ykoKOC9995jxIgRtGrVCoPBQFxcXNHYXlsYrmz/lVdeoUGDBje1feGZZHpKuByTyYTBYCAo\nKIj8/Hw+//zzMtfdvXs3Fy5cQFVV/P390el0Rfc8NhgM/Oc//6GgoACbzcbp06c5efLkTedp3749\na9euJTMzk8zMTNatW8eDDz5Y7vavFRoaSnJycqmF74oOHTqwfft2EhISiqamALp06cKGDRtITEws\nuq/17t27S52uK02PHj34/vvvyczMxGw2Y7FYCA4ORqfTsWfPnqJ7S0Dh+Y7MzExMJlPRcw8//DCf\nffZZ0Q17MjIy2L17t13bFp5HjjSEy4mOjubXX39l8ODBBAUF0adPH+Lj40tdNykpieXLl5OVlUVg\nYCCPPfYYTZo0AWD8+PH8+9//Zv369VgsFmrVqkW/fv1uOk+fPn1YtWoVo0ePLrp6qmfPnjfc/tXa\ntWvH1q1bGTBgAJGRkbz99tvXrdOoUSN0Oh2ZmZklpuwaNmzIoEGDWLp0KRcuXMDHx4fGjRvTvHlz\nu/LfddddNGzYkPXr1/Pss8/ywgsvMHv2bCwWC/fddx+tW7cuWvf222+nTZs2DB06FJvNxrx583jy\nyScBmD59Ounp6YSEhNC+ffvrbm4kqgb5cp8QQgi7yfSUEEIIu0nREEIIYTcpGkIIIewmRUMIIYTd\npGgIIYSwmxQNIYQQdpOiIYQQwm5SNIQQQtjt/wNdDTKJHYSDQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbd7f664e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQthNioYQQgi7SdEQQghht/8HtBBnAoSImygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf44b3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbd7f71860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhhBCCLtJ0RBCCGE3KRpCCCHs9v+dGpYlyWR5SAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbf43fb518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in train_results['models']:\n",
    "    TPR_array = []\n",
    "    FPR_array = []\n",
    "    for i in range(-50,50,5):\n",
    "        predicted = model.predict(x_test)\n",
    "        predicted = np.asarray([np.round(j[0]+i/100) for j in predicted])\n",
    "        actual = np.asarray([j[0] for j in y_test])\n",
    "\n",
    "        TP = np.count_nonzero(np.multiply(predicted, actual))\n",
    "        TN = np.count_nonzero(np.multiply(predicted - 1, actual - 1))\n",
    "        FP = np.count_nonzero(np.multiply(predicted, actual - 1))\n",
    "        FN = np.count_nonzero(np.multiply(predicted - 1, actual))\n",
    "\n",
    "        TPR_array.append(TP / (TP+FN))\n",
    "        FPR_array.append(FP / (FP+TN))\n",
    "\n",
    "    plot_ROC(TPR_array, FPR_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>56025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       836\n",
       "predicted 0        10     56025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>92</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>9</td>\n",
       "      <td>55997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        92       864\n",
       "predicted 0         9     55997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91      1053\n",
       "predicted 0        10     55808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>93</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>8</td>\n",
       "      <td>55754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        93      1107\n",
       "predicted 0         8     55754"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual 1</th>\n",
       "      <th>actual 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted 1</th>\n",
       "      <td>91</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted 0</th>\n",
       "      <td>10</td>\n",
       "      <td>55940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual 1  actual 0\n",
       "predicted 1        91       921\n",
       "predicted 0        10     55940"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrixes for each valdation\n",
    "for matrix in confusion_matrixes:\n",
    "    display(matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
